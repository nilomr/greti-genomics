
# time: 2024-08-27 15:03:13 UTC
# mode: r
+# Import configuration file
+config <- config::get()

# time: 2024-08-27 15:03:45 UTC
# mode: r
+.vsc.attach()

# time: 2024-08-27 15:04:20 UTC
# mode: r
+# Import configuration file
+config <- config::get()

# time: 2024-08-27 15:09:14 UTC
# mode: r
+.vsc.attach()

# time: 2024-08-27 15:10:27 UTC
# mode: r
+# Import configuration file
+config <- config::get()
+
+# parameters
+percent.train = 0.7
+num.threads = 44
+num.eigenvectors = 5
+set.seed(555)
+
+# Input files
+immigrant.vcf <- file.path(config$path$data, "600K_immigrants.vcf")
+resident.vcf <- file.path(config$path$data, "600K_residents.vcf")
+
+immigrant.gds = file.path(config$path$data, "immigrant_recode.gds")
+if (!file.exists(immigrant.gds)) {
+    SNPRelate::snpgdsVCF2GDS(immigrant.vcf, immigrant.gds, method="biallelic.only")
+
+}
+
+genofile.maf = SNPRelate::snpgdsOpen(immigrant.gds)

# time: 2024-08-27 15:10:30 UTC
# mode: r
+genofile.maf

# time: 2024-08-27 15:14:00 UTC
# mode: r
+# Input files
+immigrant.info.file <- file.path(config$path$data, "600K_immigrants.fam")

# time: 2024-08-27 15:14:21 UTC
# mode: r
+immigrant.labels = read.table(immigrant.info.file, header=TRUE, sep="\t")

# time: 2024-08-27 15:14:23 UTC
# mode: r
+immigrant.labels

# time: 2024-08-27 15:15:10 UTC
# mode: r
+immigrant.labels = read.table(immigrant.info.file, header=FALSE, sep="\t")

# time: 2024-08-27 15:15:12 UTC
# mode: r
+immigrant.labels

# time: 2024-08-27 15:16:24 UTC
# mode: r
+genofile.maf

# time: 2024-08-27 15:17:04 UTC
# mode: r
+sample.id = read.gdsn(index.gdsn(genofile.maf, "sample.id"))

# time: 2024-08-27 15:17:12 UTC
# mode: r
+sample.id = gdsfmt::read.gdsn(index.gdsn(genofile.maf, "sample.id"))

# time: 2024-08-27 15:17:19 UTC
# mode: r
+sample.id = gdsfmt::read.gdsn(gdsfmt::index.gdsn(genofile.maf, "sample.id"))

# time: 2024-08-27 15:17:21 UTC
# mode: r
+sample.id

# time: 2024-08-27 15:22:58 UTC
# mode: r
+# Import configuration file
+config <- config::get()
+
+# parameters
+percent.train = 0.7
+num.threads = 44
+num.eigenvectors = 5
+set.seed(555)
+
+# Input files
+immigrant.info <- file.path(config$path$data, "600K_immigrants.fam")
+immigrant.vcf <- file.path(config$path$data, "600K_immigrants.vcf")
+resident.vcf <- file.path(config$path$data, "600K_residents.vcf")
+
+immigrant.gds = file.path(config$path$data, "immigrant_recode.gds")
+resident.gds = file.path(config$path$data, "resident_recode.gds")
+
+SNPRelate::snpgdsVCF2GDS(immigrant.vcf, immigrant.gds, method="biallelic.only")
+SNPRelate::snpgdsVCF2GDS(resident.vcf, resident.gds, method="biallelic.only")

# time: 2024-08-27 15:25:13 UTC
# mode: r
+# remove any existing gds files before creating new ones
+file.remove(list.files(pattern = "\\.gds$"))

# time: 2024-08-27 15:26:51 UTC
# mode: r
+# Import configuration file
+config <- config::get()
+
+# parameters
+percent.train = 0.7
+num.threads = 44
+num.eigenvectors = 5
+set.seed(555)
+
+# Input files
+immigrant.info <- file.path(config$path$data, "600K_immigrants.fam")
+immigrant.vcf <- file.path(config$path$data, "600K_immigrants.vcf")
+resident.vcf <- file.path(config$path$data, "600K_residents.vcf")
+
+immigrant.gds = file.path(config$path$data, "immigrant_recode.gds")
+resident.gds = file.path(config$path$data, "resident_recode.gds")

# time: 2024-08-27 15:27:31 UTC
# mode: r
+# Import configuration file
+config <- config::get()
+
+# parameters
+percent.train = 0.7
+num.threads = 44
+num.eigenvectors = 5
+set.seed(555)
+
+# Input files
+immigrant.info <- file.path(config$path$data, "600K_immigrants.fam")
+immigrant.vcf <- file.path(config$path$data, "600K_immigrants.vcf")
+resident.vcf <- file.path(config$path$data, "600K_residents.vcf")
+
+immigrant.gds = file.path(config$path$data, "immigrant_recode.gds")
+resident.gds = file.path(config$path$data, "resident_recode.gds")
+
+# remove any existing gds files before creating new ones
+file.remove(list.files(config$path$data, pattern = "\\.gds$"))
+
+SNPRelate::snpgdsVCF2GDS(immigrant.vcf, immigrant.gds, method="biallelic.only")
+SNPRelate::snpgdsVCF2GDS(resident.vcf, resident.gds, method="biallelic.only")

# time: 2024-08-27 15:29:27 UTC
# mode: r
+# Append the immigrant and resident data
+SNPRelate::snpgdsCombineGeno(c(immigrant.gds, resident.gds), "allsamples.gds")

# time: 2024-08-27 15:29:58 UTC
# mode: r
+# Append the immigrant and resident data
+SNPRelate::snpgdsCombineGeno(c(immigrant.gds, resident.gds), file.path(config$path$data,"allsamples.gds"))

# time: 2024-08-27 15:30:38 UTC
# mode: r
+all.gds = file.path(config$path$data, "all_recode.gds")

# time: 2024-08-27 15:30:40 UTC
# mode: r
+# Append the immigrant and resident data
+SNPRelate::snpgdsCombineGeno(c(immigrant.gds, resident.gds), all.gds)

# time: 2024-08-27 15:31:14 UTC
# mode: r
+all.maf = SNPRelate::snpgdsOpen(all.gds)

# time: 2024-08-27 15:31:15 UTC
# mode: r
+resident.maf = SNPRelate::snpgdsOpen(resident.gds)

# time: 2024-08-27 15:31:18 UTC
# mode: r
+immigrant.maf = SNPRelate::snpgdsOpen(immigrant.gds)

# time: 2024-08-27 15:31:18 UTC
# mode: r
+resident.maf = SNPRelate::snpgdsOpen(resident.gds)

# time: 2024-08-27 15:31:20 UTC
# mode: r
+all.maf = SNPRelate::snpgdsOpen(all.gds)

# time: 2024-08-27 15:31:21 UTC
# mode: r
+res.sample.id = gdsfmt::read.gdsn(gdsfmt::index.gdsn(genofile.maf, "sample.id"))

# time: 2024-08-27 15:31:23 UTC
# mode: r
+all.maf

# time: 2024-08-27 15:32:00 UTC
# mode: r
+immigrant.id = gdsfmt::read.gdsn(gdsfmt::index.gdsn(immigrant.maf, "sample.id"))

# time: 2024-08-27 15:32:07 UTC
# mode: r
+resident.id = gdsfmt::read.gdsn(gdsfmt::index.gdsn(resident.maf, "sample.id"))

# time: 2024-08-27 15:32:08 UTC
# mode: r
+resident.id

# time: 2024-08-27 15:33:06 UTC
# mode: r
+all.id = gdsfmt::read.gdsn(gdsfmt::index.gdsn(all.maf, "sample.id"))

# time: 2024-08-27 15:33:32 UTC
# mode: r
+all.id$super_pop

# time: 2024-08-27 15:35:06 UTC
# mode: r
+num.samples <- min(length(immigrant.id), length(resident.id))
+immigrant.id <- sample(immigrant.id, num.samples)
+resident.id <- sample(resident.id, num.samples)
+all.id <- c(immigrant.id, resident.id)

# time: 2024-08-27 15:35:12 UTC
# mode: r
+immigrant.id

# time: 2024-08-27 15:35:15 UTC
# mode: r
+resident.id

# time: 2024-08-27 15:35:24 UTC
# mode: r
+num.samples

# time: 2024-08-27 15:35:38 UTC
# mode: r
+immigrant.id

# time: 2024-08-27 15:35:41 UTC
# mode: r
+immigrant.id = gdsfmt::read.gdsn(gdsfmt::index.gdsn(immigrant.maf, "sample.id"))

# time: 2024-08-27 15:35:43 UTC
# mode: r
+immigrant.id

# time: 2024-08-27 15:41:30 UTC
# mode: r
+# Load all the data
+all.maf = SNPRelate::snpgdsOpen(all.gds)
+
+# Load labels
+immigrant.id = gdsfmt::read.gdsn(gdsfmt::index.gdsn(SNPRelate::snpgdsOpen(immigrant.gds), "sample.id"))
+resident.id = gdsfmt::read.gdsn(gdsfmt::index.gdsn(SNPRelate::snpgdsOpen(resident.gds), "sample.id"))
+all.id = gdsfmt::read.gdsn(gdsfmt::index.gdsn(all.maf, "sample.id"))
+
+# randomly subsample the data so that the number of samples in all from immigrant and resident are the same
+num.samples <- min(length(immigrant.id), length(resident.id))
+immigrant.id <- sample(immigrant.id, num.samples)
+resident.id <- sample(resident.id, num.samples)
+all.id <- c(immigrant.id, resident.id)
+
+# Split the data into training and testing sets
+num.train <- round(num.samples * percent.train)
+num.test <- num.samples - num.train
+train.id <- sample(all.id, num.train)
+test.id <- setdiff(all.id, train.id)
+
+# Reduce dimensionality via pca
+num.threads = 3
+pca = snpgdsPCA(all.maf, sample.id=train.id, num.thread=num.threads)

# time: 2024-08-27 15:41:44 UTC
# mode: r
+# Load labels
+immigrant.id = gdsfmt::read.gdsn(gdsfmt::index.gdsn(SNPRelate::snpgdsOpen(immigrant.gds), "sample.id"))

# time: 2024-08-27 15:41:45 UTC
# mode: r
+resident.id = gdsfmt::read.gdsn(gdsfmt::index.gdsn(SNPRelate::snpgdsOpen(resident.gds), "sample.id"))

# time: 2024-08-27 15:41:45 UTC
# mode: r
+all.id = gdsfmt::read.gdsn(gdsfmt::index.gdsn(all.maf, "sample.id"))

# time: 2024-08-27 15:41:50 UTC
# mode: r
+# randomly subsample the data so that the number of samples in all from immigrant and resident are the same
+num.samples <- min(length(immigrant.id), length(resident.id))

# time: 2024-08-27 15:41:51 UTC
# mode: r
+immigrant.id <- sample(immigrant.id, num.samples)

# time: 2024-08-27 15:41:51 UTC
# mode: r
+resident.id <- sample(resident.id, num.samples)

# time: 2024-08-27 15:41:52 UTC
# mode: r
+all.id <- c(immigrant.id, resident.id)

# time: 2024-08-27 15:41:53 UTC
# mode: r
+# Split the data into training and testing sets
+num.train <- round(num.samples * percent.train)

# time: 2024-08-27 15:41:54 UTC
# mode: r
+num.test <- num.samples - num.train

# time: 2024-08-27 15:41:54 UTC
# mode: r
+train.id <- sample(all.id, num.train)

# time: 2024-08-27 15:41:55 UTC
# mode: r
+test.id <- setdiff(all.id, train.id)

# time: 2024-08-27 15:41:56 UTC
# mode: r
+# Reduce dimensionality via pca
+num.threads = 3

# time: 2024-08-27 15:41:56 UTC
# mode: r
+pca = snpgdsPCA(all.maf, sample.id=train.id, num.thread=num.threads)

# time: 2024-08-27 15:42:06 UTC
# mode: r
+pca = SNPRelate::snpgdsPCA(all.maf, sample.id=train.id, num.thread=num.threads)

# time: 2024-08-27 15:42:42 UTC
# mode: r
+pc.percent = pca$varprop*100 
+head(round(pc.percent, num.eigenvectors))

# time: 2024-08-27 15:43:03 UTC
# mode: r
+lbls <- paste("PC", 1:num.eigenvectors, "\n", format(pc.percent[1:num.eigenvectors], digits=2), "%", sep="")
+pairs(pca$eigenvect[,1:num.eigenvectors], col=tab$pop, labels=lbls)

# time: 2024-08-27 15:43:21 UTC
# mode: r
+tab <- data.frame(sample.id=pca$sample.id, pop=factor(pop_code)[match(pca$sample.id, pca$sample.id)], EV1=pca$eigenvect[,1], EV2=pca$eigenvect[,2], stringsAsFactors=FALSE)
+
+lbls <- paste("PC", 1:num.eigenvectors, "\n", format(pc.percent[1:num.eigenvectors], digits=2), "%", sep="")
+pairs(pca$eigenvect[,1:num.eigenvectors], col=tab$pop, labels=lbls)

# time: 2024-08-27 15:43:42 UTC
# mode: r
+test.id

# time: 2024-08-27 15:46:34 UTC
# mode: r
+train.id

# time: 2024-08-27 15:48:55 UTC
# mode: r
+renv::install('rlint')

# time: 2024-08-27 15:53:55 UTC
# mode: r
+.vsc.attach()

# time: 2024-08-27 15:55:58 UTC
# mode: r
+pca$sample.id

# time: 2024-08-27 15:56:03 UTC
# mode: r
+# Import configuration file
+config <- config::get()
+
+# parameters
+percent.train <- 0.7
+num.threads <- 44
+num.eigenvectors <- 5
+set.seed(555)
+
+# Input files
+immigrant.info <- file.path(config$path$data, "600K_immigrants.fam")
+immigrant.vcf <- file.path(config$path$data, "600K_immigrants.vcf")
+resident.vcf <- file.path(config$path$data, "600K_residents.vcf")
+
+immigrant.gds <- file.path(config$path$data, "immigrant_recode.gds")
+resident.gds <- file.path(config$path$data, "resident_recode.gds")
+all.gds <- file.path(config$path$data, "all_recode.gds")
+
+# remove any existing gds files before creating new ones
+file.remove(list.files(config$path$data, pattern = "\\.gds$"))
+
+SNPRelate::snpgdsVCF2GDS(immigrant.vcf, immigrant.gds, method = "biallelic.only")
+SNPRelate::snpgdsVCF2GDS(resident.vcf, resident.gds, method = "biallelic.only")
+
+# Append the immigrant and resident data
+SNPRelate::snpgdsCombineGeno(c(immigrant.gds, resident.gds), all.gds)
+
+# Load all the data
+all.maf <- SNPRelate::snpgdsOpen(all.gds)
+
+# Load labels
+immigrant.id <- gdsfmt::read.gdsn(gdsfmt::index.gdsn(
+    SNPRelate::snpgdsOpen(immigrant.gds),
+    "sample.id"
+))
+resident.id <- gdsfmt::read.gdsn(gdsfmt::index.gdsn(
+    SNPRelate::snpgdsOpen(resident.gds),
+    "sample.id"
+))
+all.id <- gdsfmt::read.gdsn(gdsfmt::index.gdsn(all.maf, "sample.id"))
+
+# randomly subsample the data so that the number of samples in all from immigrant and resident are the same
+num.samples <- min(length(immigrant.id), length(resident.id))
+immigrant.id <- sample(immigrant.id, num.samples)
+resident.id <- sample(resident.id, num.samples)
+all.id <- c(immigrant.id, resident.id)
+
+# Split the data into training and testing sets
+num.train <- round(num.samples * percent.train)
+num.test <- num.samples - num.train
+train.id <- sample(all.id, num.train)
+test.id <- setdiff(all.id, train.id)
+pop_code <- c(rep("immigrant", num.train), rep("resident", num.test))
+
+# Reduce dimensionality via pca
+num.threads <- 3
+pca <- SNPRelate::snpgdsPCA(all.maf, sample.id = train.id, num.thread = num.threads)

# time: 2024-08-27 15:57:06 UTC
# mode: r
+list.files(path = config$path$data, pattern = "*.gds$")

# time: 2024-08-27 15:57:44 UTC
# mode: r
+pca$sample.id

# time: 2024-08-27 15:58:06 UTC
# mode: r
+tab <- data.frame(sample.id = pca$sample.id, pop = factor(pop_code)[match(pca$sample.id, pca$sample.id)], EV1 = pca$eigenvect[, 1], EV2 = pca$eigenvect[, 2], stringsAsFactors = FALSE)

# time: 2024-08-27 15:58:08 UTC
# mode: r
+tab

# time: 2024-08-27 15:58:43 UTC
# mode: r
+pop_code

# time: 2024-08-27 15:59:10 UTC
# mode: r
+train.id

# time: 2024-08-27 15:59:27 UTC
# mode: r
+length(test.id)

# time: 2024-08-27 15:59:29 UTC
# mode: r
+# check the length of the training and testing sets
+length(train.id)

# time: 2024-08-27 15:59:41 UTC
# mode: r
+resident.id

# time: 2024-08-27 16:00:41 UTC
# mode: r
+all.id <- gdsfmt::read.gdsn(gdsfmt::index.gdsn(all.maf, "sample.id"))
+
+# randomly subsample the data so that the number of samples in all from immigrant and resident are the same
+min.samples <- min(length(immigrant.id), length(resident.id))
+immigrant.id <- sample(immigrant.id, min.samples)
+resident.id <- sample(resident.id, min.samples)
+all.id <- c(immigrant.id, resident.id)
+
+# Split the data into training and testing sets
+num.samples <- length(all.id)
+num.train <- round(num.samples * percent.train)
+num.test <- num.samples - num.train
+train.id <- sample(all.id, num.train)
+test.id <- setdiff(all.id, train.id)

# time: 2024-08-27 16:00:44 UTC
# mode: r
+# check the length of the training and testing sets
+length(train.id)

# time: 2024-08-27 16:00:46 UTC
# mode: r
+length(test.id)

# time: 2024-08-27 16:02:58 UTC
# mode: r
+# create a 'train.label' list with wether each sample in train.id is from "immigrant" or "resident"
+
+train.label <- ifelse(train.id %in% immigrant.id, "immigrant", "resident")

# time: 2024-08-27 16:02:58 UTC
# mode: r
+train.label <- ifelse(train.id %in% immigrant.id, "immigrant", "resident")

# time: 2024-08-27 16:03:00 UTC
# mode: r
+train.label

# time: 2024-08-27 16:03:41 UTC
# mode: r
+test.label <- ifelse(test.id %in% immigrant.id, "immigrant", "resident")

# time: 2024-08-27 16:04:20 UTC
# mode: r
+# Identify the population code for each sample
+train.label <- ifelse(train.id %in% immigrant.id, "immigrant", "resident")

# time: 2024-08-27 16:04:20 UTC
# mode: r
+test.label <- ifelse(test.id %in% immigrant.id, "immigrant", "resident")

# time: 2024-08-27 16:04:21 UTC
# mode: r
+# Reduce dimensionality via pca
+num.threads <- 3

# time: 2024-08-27 16:04:22 UTC
# mode: r
+pca <- SNPRelate::snpgdsPCA(all.maf, sample.id = train.id, num.thread = num.threads)

# time: 2024-08-27 16:04:30 UTC
# mode: r
+tab <- data.frame(sample.id = pca$sample.id, pop = factor(train.label), EV1 = pca$eigenvect[, 1], EV2 = pca$eigenvect[, 2], stringsAsFactors = FALSE)

# time: 2024-08-27 16:04:32 UTC
# mode: r
+lbls <- paste("PC", 1:num.eigenvectors, "\n", format(pc.percent[1:num.eigenvectors], digits = 2), "%", sep = "")

# time: 2024-08-27 16:04:47 UTC
# mode: r
+pc.percent <- pca$varprop * 100

# time: 2024-08-27 16:04:48 UTC
# mode: r
+lbls <- paste("PC", 1:num.eigenvectors, "\n", format(pc.percent[1:num.eigenvectors], digits = 2), "%", sep = "")

# time: 2024-08-27 16:04:51 UTC
# mode: r
+pairs(pca$eigenvect[, 1:num.eigenvectors], col = tab$pop, labels = lbls)

# time: 2024-08-27 16:05:37 UTC
# mode: r
+pairs(pca$eigenvect[, 1:num.eigenvectors], col = tab$pop, labels = lbls, aspect = 1)

# time: 2024-08-27 16:08:24 UTC
# mode: r
+# Calculate SNP loadings
+snp_loadings <- SNPRelate::snpgdsPCASNPLoading(pca, all.maf, num.thread = num.threads)

# time: 2024-08-27 16:08:46 UTC
# mode: r
+test.id

# time: 2024-08-27 16:08:52 UTC
# mode: r
+# Extract list of SNPs used in PCA
+snp_list <- SNPRelate::snpgdsSNPList(all.maf)

# time: 2024-08-27 16:08:54 UTC
# mode: r
+snp_rs_id <- snp_list$rs.id[snp_loadings$snp.id]

# time: 2024-08-27 16:08:55 UTC
# mode: r
+snp_chrom <- snp_list$chromosome[snp_loadings$snp.id]

# time: 2024-08-27 16:08:56 UTC
# mode: r
+snp_pos <- snp_list$position[snp_loadings$snp.id]

# time: 2024-08-27 16:08:57 UTC
# mode: r
+# Create dataframe with one SNP per row
+snp_df <- data.frame(snp_rs_id, snp_chrom, snp_pos)

# time: 2024-08-27 16:09:04 UTC
# mode: r
+snp_chrom

# time: 2024-08-27 16:09:09 UTC
# mode: r
+snp_pos

# time: 2024-08-27 16:09:11 UTC
# mode: r
+snp_rs_id

# time: 2024-08-27 16:09:26 UTC
# mode: r
+snp_loadings

# time: 2024-08-27 16:10:55 UTC
# mode: r
+# Extract list of SNPs used in PCA
+snpset.id <- unlist(snpset.maf)

# time: 2024-08-27 16:11:16 UTC
# mode: r
+# Extract list of SNPs used in PCA
+snpset.id <- unlist(all.maf)

# time: 2024-08-27 16:11:21 UTC
# mode: r
+snp_list <- SNPRelate::snpgdsSNPList(all.maf)
+snp_rs_id <- snp_list$rs.id[ssnpset.id]
+snp_chrom <- snp_list$chromosome[ssnpset.id]
+snp_pos <- snp_list$position[ssnpset.id]

# time: 2024-08-27 16:11:30 UTC
# mode: r
+snp_rs_id <- snp_list$rs.id[snpset.id]

# time: 2024-08-27 16:11:34 UTC
# mode: r
+snp_rs_id <- snp_list$rs.id[snpset.id]
+snp_chrom <- snp_list$chromosome[snpset.id]
+snp_pos <- snp_list$position[snpset.id]

# time: 2024-08-27 16:11:42 UTC
# mode: r
+snpset.id

# time: 2024-08-27 16:11:53 UTC
# mode: r
+# Extract list of SNPs used in PCA
+snpset.id <- unlist(all.maf)

# time: 2024-08-27 16:11:56 UTC
# mode: r
+snpset.id

# time: 2024-08-27 16:12:05 UTC
# mode: r
+snp_list

# time: 2024-08-27 16:12:13 UTC
# mode: r
+snp_rs_id <- snp_list$rs.id[snp_list]

# time: 2024-08-27 16:12:14 UTC
# mode: r
+snp_chrom <- snp_list$chromosome[snp_list]

# time: 2024-08-27 16:12:17 UTC
# mode: r
+snp_pos <- snp_list$position[snp_list]

# time: 2024-08-27 16:12:30 UTC
# mode: r
+snp_list <- SNPRelate::snpgdsSNPList(all.maf)

# time: 2024-08-27 16:12:32 UTC
# mode: r
+snp_list

# time: 2024-08-27 16:14:11 UTC
# mode: r
+snp_list$rs.id

# time: 2024-08-27 16:14:32 UTC
# mode: r
+snpset.id <- unlist(all.maf)
+snp_list <- SNPRelate::snpgdsSNPList(all.maf)
+snp_rs_id <- snp_list$snp.id
+snp_chrom <- snp_list$chromosome
+snp_pos <- snp_list$position

# time: 2024-08-27 16:14:36 UTC
# mode: r
+# Create dataframe with one SNP per row
+snp_df <- data.frame(snp_rs_id, snp_chrom, snp_pos)

# time: 2024-08-27 16:14:42 UTC
# mode: r
+# Transpose SNP loading table
+snp_loadings_transposed <- t(snp_loadings$snploading)

# time: 2024-08-27 16:14:46 UTC
# mode: r
+# Match SNPs with loading vectors
+loading_mat <- data.frame(snp_df, snp_loadings_transposed[, 1:num.eigenvectors])

# time: 2024-08-27 16:15:10 UTC
# mode: r
+# Match SNPs with loading vectors
+loading_mat <- data.frame(snp_df, snp_loadings_transposed)

# time: 2024-08-27 16:15:28 UTC
# mode: r
+# Match SNPs with loading vectors
+loading_mat <- data.frame(snp_df, snp_loadings_transposed[, 1:num.eigenvectors])

# time: 2024-08-27 16:15:44 UTC
# mode: r
+snp_df

# time: 2024-08-27 16:15:51 UTC
# mode: r
+head(snp_df)

# time: 2024-08-27 16:16:22 UTC
# mode: r
+# Match SNPs with loading vectors
+loading_mat <- data.frame(snp_df, snp_loadings_transposed[, 1:num.eigenvectors])

# time: 2024-08-27 16:16:29 UTC
# mode: r
+snp_loadings_transposed

# time: 2024-08-27 16:16:40 UTC
# mode: r
+length(snp_loadings_transposed)

# time: 2024-08-27 16:16:44 UTC
# mode: r
+# Match SNPs with loading vectors
+loading_mat <- data.frame(snp_df, snp_loadings_transposed[, 1:num.eigenvectors])

# time: 2024-08-27 16:17:43 UTC
# mode: r
+head(tab)

# time: 2024-08-27 16:18:09 UTC
# mode: r
+snp_list

# time: 2024-08-27 16:18:17 UTC
# mode: r
+head(tab)

# time: 2024-08-27 16:21:40 UTC
# mode: r
+snp_list$snp.id

# time: 2024-08-27 16:21:54 UTC
# mode: r
+tab

# time: 2024-08-27 16:22:32 UTC
# mode: r
+snp_rs_id <- snp_list$snp.id[pca$snp.id]

# time: 2024-08-27 16:22:39 UTC
# mode: r
+snp_pos <- snp_list$position[pca$snp.id]

# time: 2024-08-27 16:22:41 UTC
# mode: r
+snp_chrom <- snp_list$chromosome[pca$snp.id]

# time: 2024-08-27 16:22:44 UTC
# mode: r
+snp_list$chromosome[pca$snp.id]

# time: 2024-08-27 16:22:49 UTC
# mode: r
+# Create dataframe with one SNP per row
+snp_df <- data.frame(snp_rs_id, snp_chrom, snp_pos)

# time: 2024-08-27 16:22:51 UTC
# mode: r
+# Transpose SNP loading table
+snp_loadings_transposed <- t(snp_loadings$snploading)

# time: 2024-08-27 16:22:52 UTC
# mode: r
+# Match SNPs with loading vectors
+loading_mat <- data.frame(snp_df, snp_loadings_transposed[, 1:num.eigenvectors])

# time: 2024-08-27 16:23:04 UTC
# mode: r
+# Create data frames, where sample is paired with eigenvectors
+train_eigenvects <- data.frame(pca$sample.id, pca$eigenvect[, 1:num.eigenvectors])

# time: 2024-08-27 16:23:04 UTC
# mode: r
+test_eigenvects <- data.frame(sample_loadings$sample.id, sample_loadings$eigenvect[, 1:num.eigenvectors])

# time: 2024-08-27 16:23:10 UTC
# mode: r
+# Calculate sample loadings for testing set using SNP loadings
+sample_loadings <- SNPRelate::snpgdsPCASampLoading(snp_loadings, all.maf, sample.id = test.id, num.thread = num.threads)

# time: 2024-08-27 16:23:15 UTC
# mode: r
+# Create data frames, where sample is paired with eigenvectors
+train_eigenvects <- data.frame(pca$sample.id, pca$eigenvect[, 1:num.eigenvectors])

# time: 2024-08-27 16:23:15 UTC
# mode: r
+test_eigenvects <- data.frame(sample_loadings$sample.id, sample_loadings$eigenvect[, 1:num.eigenvectors])

# time: 2024-08-27 16:23:17 UTC
# mode: r
+# Ensure sample.id column is same for all data frames
+colnames(train_eigenvects)[1] <- "sample.id"

# time: 2024-08-27 16:23:17 UTC
# mode: r
+colnames(test_eigenvects)[1] <- "sample.id"

# time: 2024-08-27 16:23:18 UTC
# mode: r
+colnames(sample.info)[1] <- "sample.id"

# time: 2024-08-27 16:23:19 UTC
# mode: r
+# Merge data frames
+train_df <- merge(sample.info, train_eigenvects)

# time: 2024-08-27 16:23:21 UTC
# mode: r
+test_df <- merge(sample.info, test_eigenvects)

# time: 2024-08-27 16:24:46 UTC
# mode: r
+train_eigenvects

# time: 2024-08-27 16:26:00 UTC
# mode: r
+all.label <- ifelse(all.id %in% immigrant.id, "immigrant", "resident")

# time: 2024-08-27 16:26:12 UTC
# mode: r
+# Create a dataframe with 'sample.id' and 'pop' columns
+sample.info <- data.frame(sample.id = all.id, pop = all.label)

# time: 2024-08-27 16:26:17 UTC
# mode: r
+sample.info

# time: 2024-08-27 16:26:34 UTC
# mode: r
+# Merge data frames
+train_df <- merge(sample.info, train_eigenvects)

# time: 2024-08-27 16:26:35 UTC
# mode: r
+test_df <- merge(sample.info, test_eigenvects)

# time: 2024-08-27 16:26:36 UTC
# mode: r
+train_df

# time: 2024-08-27 16:26:50 UTC
# mode: r
+# Check that there is no overlap between training and testing sets
+if (length(intersect(train_df$sample.id, test_df$sample.id)) > 0) {
+    stop("Overlap between training and testing sets")
+}

# time: 2024-08-27 16:27:22 UTC
# mode: r
+train.df

# time: 2024-08-27 16:27:40 UTC
# mode: r
+output.forest <- randomForest(train_df[, 5:9],
+    y = train_df$pop,
+    data = train_df, xtest = test_df[, 5:9], ytest = test_df$pop,
+    ntree = 500, replace = FALSE
+)

# time: 2024-08-27 16:27:57 UTC
# mode: r
+renv::install('randomForest')

# time: 2024-08-27 16:28:02 UTC
# mode: r
+# train random forest using training eigenvectors
+output.forest <- randomForest::randomForest(train_df[, 5:9],
+    y = train_df$pop,
+    data = train_df, xtest = test_df[, 5:9], ytest = test_df$pop,
+    ntree = 500, replace = FALSE
+)

# time: 2024-08-27 16:28:07 UTC
# mode: r
+train_df

# time: 2024-08-27 16:28:40 UTC
# mode: r
+train_df[, 5:9]

# time: 2024-08-27 16:29:22 UTC
# mode: r
+output.forest <- randomForest::randomForest(train_df[, num.eigenvectors-2:2+num.eigenvectors],
+    y = train_df$pop,
+    data = train_df, xtest = test_df[, num.eigenvectors-2:2+num.eigenvectors], ytest = test_df$pop,
+    ntree = 500, replace = FALSE
+)

# time: 2024-08-27 16:29:28 UTC
# mode: r
+train_df[, num.eigenvectors-2:2+num.eigenvectors]

# time: 2024-08-27 16:29:32 UTC
# mode: r
+num.eigenvectors-2

# time: 2024-08-27 16:29:38 UTC
# mode: r
+2+num.eigenvectors

# time: 2024-08-27 16:29:50 UTC
# mode: r
+ncol(train_df)

# time: 2024-08-27 16:30:07 UTC
# mode: r
+train_df[, num.eigenvectors-2:2+num.eigenvectors]

# time: 2024-08-27 16:30:34 UTC
# mode: r
+# train random forest using training eigenvectors
+output.forest <- randomForest::randomForest(train_df[, (num.eigenvectors-2):(2+num.eigenvectors)],
+    y = train_df$pop,
+    data = train_df, xtest = test_df[, (num.eigenvectors-2):(2+num.eigenvectors)], ytest = test_df$pop,
+    ntree = 500, replace = FALSE
+)

# time: 2024-08-27 16:30:58 UTC
# mode: r
+train_df$pop

# time: 2024-08-27 16:31:04 UTC
# mode: r
+rain_df[, (num.eigenvectors - 2):(2 + num.eigenvectors)]

# time: 2024-08-27 16:31:09 UTC
# mode: r
+train_df[, (num.eigenvectors - 2):(2 + num.eigenvectors)]

# time: 2024-08-27 16:31:32 UTC
# mode: r
+test_df

# time: 2024-08-27 16:31:35 UTC
# mode: r
+test_df[, (num.eigenvectors - 2):(2 + num.eigenvectors)]

# time: 2024-08-27 16:31:39 UTC
# mode: r
+output.forest <- randomForest::randomForest(
+    train_df[, (num.eigenvectors - 2):(2 + num.eigenvectors)],
+    y = train_df$pop,
+    data = train_df, 
+    xtest = test_df[, (num.eigenvectors - 2):(2 + num.eigenvectors)], 
+    ytest = test_df$pop,
+    ntree = 500, 
+    replace = FALSE
+)

# time: 2024-08-27 16:31:52 UTC
# mode: r
+test_df$pop

# time: 2024-08-27 16:32:45 UTC
# mode: r
+ncol(train_df[, (num.eigenvectors - 2):(2 + num.eigenvectors)])

# time: 2024-08-27 16:33:09 UTC
# mode: r
+# train random forest using training eigenvectors
+output.forest <- randomForest::randomForest(
+    train_df[, (num.eigenvectors - 2):(2 + num.eigenvectors)],
+    y = as.factor(train_df$pop),
+    data = train_df, 
+    xtest = test_df[, (num.eigenvectors - 2):(2 + num.eigenvectors)], 
+    ytest = as.factor(test_df$pop),
+    ntree = 500, 
+    replace = FALSE
+)

# time: 2024-08-27 16:33:15 UTC
# mode: r
+# Print confusion matrix
+confusionMatrix(output.forest$test$predicted, test_df$pop)

# time: 2024-08-27 16:33:29 UTC
# mode: r
+print(output.forest)

# time: 2024-08-27 16:34:17 UTC
# mode: r
+# train random forest using training eigenvectors
+output.forest <- randomForest::randomForest(
+    train_df[, (num.eigenvectors - 2):(2 + num.eigenvectors)],
+    y = as.factor(train_df$pop),
+    data = train_df, 
+    xtest = test_df[, (num.eigenvectors - 2):(2 + num.eigenvectors)], 
+    ytest = as.factor(test_df$pop),
+    ntree = 1000, 
+    replace = FALSE
+)
+print(output.forest)
+
+# Print confusion matrix

# time: 2024-08-27 16:35:16 UTC
# mode: r
+output.forest <- randomForest::randomForest(
+    train_df[, (num.eigenvectors - 2):(2 + num.eigenvectors)],
+    y = as.factor(train_df$pop),
+    data = train_df, 
+    xtest = test_df[, (num.eigenvectors - 2):(2 + num.eigenvectors)], 
+    ytest = as.factor(test_df$pop),
+    ntree = 1000, 
+    replace = FALSE,
+    proximity = TRUE
+)
+print(output.forest)

# time: 2024-08-27 16:36:52 UTC
# mode: r
+renv::install('rfPermute')

# time: 2024-08-27 16:56:48 UTC
# mode: r
+# Print confusion matrix
+rfPermute::confusionMatrix(output.forest)

# time: 2024-08-27 16:58:17 UTC
# mode: r
+rfPermute::plotPredictedProbs(output.forest, bins = 30, plot = TRUE)

# time: 2024-08-27 16:58:45 UTC
# mode: r
+t

# time: 2024-08-27 16:58:48 UTC
# mode: r
+rfPermute::plotPredictedProbs(output.forest, bins = 30, plot = TRUE)

# time: 2024-08-27 16:59:54 UTC
# mode: r
+rfPermute::plotProximity(output.forest, plot = TRUE)

# time: 2024-08-27 17:00:38 UTC
# mode: r
+# Import configuration file
+config <- config::get()
+
+# parameters
+percent.train <- 0.7
+num.threads <- 44
+num.eigenvectors <- 20
+set.seed(555)
+
+# Input files
+immigrant.info <- file.path(config$path$data, "600K_immigrants.fam")
+immigrant.vcf <- file.path(config$path$data, "600K_immigrants.vcf")
+resident.vcf <- file.path(config$path$data, "600K_residents.vcf")
+
+immigrant.gds <- file.path(config$path$data, "immigrant_recode.gds")
+resident.gds <- file.path(config$path$data, "resident_recode.gds")
+all.gds <- file.path(config$path$data, "all_recode.gds")
+
+# remove any existing gds files before creating new ones
+file.remove(list.files(path = config$path$data, pattern = "*.gds$", full.names = TRUE))
+
+SNPRelate::snpgdsVCF2GDS(immigrant.vcf, immigrant.gds, method = "biallelic.only")
+SNPRelate::snpgdsVCF2GDS(resident.vcf, resident.gds, method = "biallelic.only")
+
+# Append the immigrant and resident data
+SNPRelate::snpgdsCombineGeno(c(immigrant.gds, resident.gds), all.gds)
+
+# Load all the data
+all.maf <- SNPRelate::snpgdsOpen(all.gds)
+
+# Load labels
+immigrant.id <- gdsfmt::read.gdsn(gdsfmt::index.gdsn(
+    SNPRelate::snpgdsOpen(immigrant.gds),
+    "sample.id"
+))
+resident.id <- gdsfmt::read.gdsn(gdsfmt::index.gdsn(
+    SNPRelate::snpgdsOpen(resident.gds),
+    "sample.id"
+))
+all.id <- gdsfmt::read.gdsn(gdsfmt::index.gdsn(all.maf, "sample.id"))
+
+# randomly subsample the data so that the number of samples in all from immigrant and resident are the same
+min.samples <- min(length(immigrant.id), length(resident.id))
+immigrant.id <- sample(immigrant.id, min.samples)
+resident.id <- sample(resident.id, min.samples)
+all.id <- c(immigrant.id, resident.id)
+
+# Split the data into training and testing sets
+num.samples <- length(all.id)
+num.train <- round(num.samples * percent.train)
+num.test <- num.samples - num.train
+train.id <- sample(all.id, num.train)
+test.id <- setdiff(all.id, train.id)
+
+# Identify the population code for each sample
+train.label <- ifelse(train.id %in% immigrant.id, "immigrant", "resident")
+test.label <- ifelse(test.id %in% immigrant.id, "immigrant", "resident")
+all.label <- ifelse(all.id %in% immigrant.id, "immigrant", "resident")
+
+# Reduce dimensionality via pca
+num.threads <- 3
+pca <- SNPRelate::snpgdsPCA(all.maf, sample.id = train.id, num.thread = num.threads)
+
+tab <- data.frame(sample.id = pca$sample.id, pop = factor(train.label), EV1 = pca$eigenvect[, 1], EV2 = pca$eigenvect[, 2], stringsAsFactors = FALSE)
+
+pc.percent <- pca$varprop * 100
+lbls <- paste("PC", 1:num.eigenvectors, "\n", format(pc.percent[1:num.eigenvectors], digits = 2), "%", sep = "")
+pairs(pca$eigenvect[, 1:num.eigenvectors], col = tab$pop, labels = lbls, aspect = 1)
+
+
+
+# Calculate SNP loadings
+snp_loadings <- SNPRelate::snpgdsPCASNPLoading(pca, all.maf, num.thread = num.threads)
+
+# Calculate sample loadings for testing set using SNP loadings
+sample_loadings <- SNPRelate::snpgdsPCASampLoading(snp_loadings, all.maf, sample.id = test.id, num.thread = num.threads)
+
+# Extract list of SNPs used in PCA
+snpset.id <- unlist(all.maf)
+snp_list <- SNPRelate::snpgdsSNPList(all.maf)
+snp_rs_id <- snp_list$snp.id[pca$snp.id]
+snp_chrom <- snp_list$chromosome[pca$snp.id]
+snp_pos <- snp_list$position[pca$snp.id]
+
+# Create dataframe with one SNP per row
+snp_df <- data.frame(snp_rs_id, snp_chrom, snp_pos)
+
+# Transpose SNP loading table
+snp_loadings_transposed <- t(snp_loadings$snploading)
+
+# Match SNPs with loading vectors
+loading_mat <- data.frame(snp_df, snp_loadings_transposed[, 1:num.eigenvectors])
+
+# Write loading data frame to file
+
+# Create data frames, where sample is paired with eigenvectors
+train_eigenvects <- data.frame(pca$sample.id, pca$eigenvect[, 1:num.eigenvectors])
+test_eigenvects <- data.frame(sample_loadings$sample.id, sample_loadings$eigenvect[, 1:num.eigenvectors])
+
+# Ensure sample.id column is same for all data frames
+colnames(train_eigenvects)[1] <- "sample.id"
+colnames(test_eigenvects)[1] <- "sample.id"
+
+# Create a dataframe with 'sample.id' and 'pop' columns
+sample.info <- data.frame(sample.id = all.id, pop = all.label)
+
+# Merge data frames
+train_df <- merge(sample.info, train_eigenvects)
+test_df <- merge(sample.info, test_eigenvects)
+
+# Check that there is no overlap between training and testing sets
+if (length(intersect(train_df$sample.id, test_df$sample.id)) > 0) {
+    stop("There is overlap between training and testing sets")
+}
+
+
+# train random forest using training eigenvectors
+output.forest <- randomForest::randomForest(
+    train_df[, (num.eigenvectors - 2):(2 + num.eigenvectors)],
+    y = as.factor(train_df$pop),
+    data = train_df,
+    xtest = test_df[, (num.eigenvectors - 2):(2 + num.eigenvectors)],
+    ytest = as.factor(test_df$pop),
+    ntree = 1000,
+    replace = FALSE,
+    proximity = TRUE
+)
+print(output.forest)
+
+# Print confusion matrix
+rfPermute::confusionMatrix(output.forest)
+
+rfPermute::plotPredictedProbs(output.forest, bins = 30, plot = TRUE)
+
+rfPermute::plotProximity(output.forest, plot = TRUE)

# time: 2024-08-27 17:02:34 UTC
# mode: r
+# Import configuration file
+config <- config::get()
+
+# parameters
+percent.train <- 0.7
+num.threads <- 44
+num.eigenvectors <- 20
+set.seed(555)
+
+# Input files
+immigrant.info <- file.path(config$path$data, "600K_immigrants.fam")
+immigrant.vcf <- file.path(config$path$data, "600K_immigrants.vcf")
+resident.vcf <- file.path(config$path$data, "600K_residents.vcf")
+
+immigrant.gds <- file.path(config$path$data, "immigrant_recode.gds")
+resident.gds <- file.path(config$path$data, "resident_recode.gds")
+all.gds <- file.path(config$path$data, "all_recode.gds")
+
+# remove any existing gds files before creating new ones
+file.remove(list.files(path = config$path$data, pattern = "*.gds$", full.names = TRUE))
+SNPRelate::snpgdsVCF2GDS(immigrant.vcf, immigrant.gds, method = "biallelic.only")
+SNPRelate::snpgdsVCF2GDS(resident.vcf, resident.gds, method = "biallelic.only")

# time: 2024-08-27 17:03:15 UTC
# mode: r
+# Append the immigrant and resident data
+SNPRelate::snpgdsCombineGeno(c(immigrant.gds, resident.gds), all.gds)

# time: 2024-08-27 17:03:26 UTC
# mode: r
+# Load all the data
+all.maf <- SNPRelate::snpgdsOpen(all.gds)

# time: 2024-08-27 17:03:43 UTC
# mode: r
+# Load labels
+immigrant.id <- gdsfmt::read.gdsn(gdsfmt::index.gdsn(
+    SNPRelate::snpgdsOpen(immigrant.gds),
+    "sample.id"
+))

# time: 2024-08-27 17:03:44 UTC
# mode: r
+resident.id <- gdsfmt::read.gdsn(gdsfmt::index.gdsn(
+    SNPRelate::snpgdsOpen(resident.gds),
+    "sample.id"
+))

# time: 2024-08-27 17:04:18 UTC
# mode: r
+# Append the immigrant and resident data
+SNPRelate::snpgdsCombineGeno(c(immigrant.gds, resident.gds), all.gds, allow.duplicate = TRUE)

# time: 2024-08-27 17:04:29 UTC
# mode: r
+# Append the immigrant and resident data
+SNPRelate::snpgdsCombineGeno(c(immigrant.gds, resident.gds), all.gds)

# time: 2024-08-27 17:06:53 UTC
# mode: r
+gdsfmt::closefn.gds(immigrant.gds)

# time: 2024-08-27 17:07:09 UTC
# mode: r
+gdsfmt::closefn.gds(all.maf)

# time: 2024-08-27 17:07:14 UTC
# mode: r
+# Append the immigrant and resident data
+SNPRelate::snpgdsCombineGeno(c(immigrant.gds, resident.gds), all.gds)

# time: 2024-08-27 17:07:49 UTC
# mode: r
+gdsfmt::showfile.gds(closeall = TRUE)

# time: 2024-08-27 17:07:54 UTC
# mode: r
+# Append the immigrant and resident data
+SNPRelate::snpgdsCombineGeno(c(immigrant.gds, resident.gds), all.gds)

# time: 2024-08-27 17:08:17 UTC
# mode: r
+# Load all the data
+all.maf <- SNPRelate::snpgdsOpen(all.gds)
+
+# Load labels
+immigrant.id <- gdsfmt::read.gdsn(gdsfmt::index.gdsn(
+    SNPRelate::snpgdsOpen(immigrant.gds),
+    "sample.id"
+))
+resident.id <- gdsfmt::read.gdsn(gdsfmt::index.gdsn(
+    SNPRelate::snpgdsOpen(resident.gds),
+    "sample.id"
+))
+
+all.id <- gdsfmt::read.gdsn(gdsfmt::index.gdsn(all.maf, "sample.id"))
+
+# randomly subsample the data so that the number of samples in all from immigrant and resident are the same
+min.samples <- min(length(immigrant.id), length(resident.id))
+immigrant.id <- sample(immigrant.id, min.samples)
+resident.id <- sample(resident.id, min.samples)
+all.id <- c(immigrant.id, resident.id)
+
+# Split the data into training and testing sets
+num.samples <- length(all.id)
+num.train <- round(num.samples * percent.train)
+num.test <- num.samples - num.train
+train.id <- sample(all.id, num.train)
+test.id <- setdiff(all.id, train.id)
+
+# Identify the population code for each sample
+train.label <- ifelse(train.id %in% immigrant.id, "immigrant", "resident")
+test.label <- ifelse(test.id %in% immigrant.id, "immigrant", "resident")
+all.label <- ifelse(all.id %in% immigrant.id, "immigrant", "resident")
+
+# Reduce dimensionality via pca
+num.threads <- 3
+pca <- SNPRelate::snpgdsPCA(all.maf, sample.id = train.id, num.thread = num.threads)
+
+tab <- data.frame(sample.id = pca$sample.id, pop = factor(train.label), EV1 = pca$eigenvect[, 1], EV2 = pca$eigenvect[, 2], stringsAsFactors = FALSE)
+
+pc.percent <- pca$varprop * 100
+lbls <- paste("PC", 1:num.eigenvectors, "\n", format(pc.percent[1:num.eigenvectors], digits = 2), "%", sep = "")
+pairs(pca$eigenvect[, 1:num.eigenvectors], col = tab$pop, labels = lbls, aspect = 1)
+
+
+
+# Calculate SNP loadings
+snp_loadings <- SNPRelate::snpgdsPCASNPLoading(pca, all.maf, num.thread = num.threads)
+
+# Calculate sample loadings for testing set using SNP loadings
+sample_loadings <- SNPRelate::snpgdsPCASampLoading(snp_loadings, all.maf, sample.id = test.id, num.thread = num.threads)
+
+# Extract list of SNPs used in PCA
+snpset.id <- unlist(all.maf)
+snp_list <- SNPRelate::snpgdsSNPList(all.maf)
+snp_rs_id <- snp_list$snp.id[pca$snp.id]
+snp_chrom <- snp_list$chromosome[pca$snp.id]
+snp_pos <- snp_list$position[pca$snp.id]
+
+# Create dataframe with one SNP per row
+snp_df <- data.frame(snp_rs_id, snp_chrom, snp_pos)
+
+# Transpose SNP loading table
+snp_loadings_transposed <- t(snp_loadings$snploading)
+
+# Match SNPs with loading vectors
+loading_mat <- data.frame(snp_df, snp_loadings_transposed[, 1:num.eigenvectors])
+
+# Write loading data frame to file
+
+# Create data frames, where sample is paired with eigenvectors
+train_eigenvects <- data.frame(pca$sample.id, pca$eigenvect[, 1:num.eigenvectors])
+test_eigenvects <- data.frame(sample_loadings$sample.id, sample_loadings$eigenvect[, 1:num.eigenvectors])
+
+# Ensure sample.id column is same for all data frames
+colnames(train_eigenvects)[1] <- "sample.id"
+colnames(test_eigenvects)[1] <- "sample.id"
+
+# Create a dataframe with 'sample.id' and 'pop' columns
+sample.info <- data.frame(sample.id = all.id, pop = all.label)
+
+# Merge data frames
+train_df <- merge(sample.info, train_eigenvects)
+test_df <- merge(sample.info, test_eigenvects)
+
+# Check that there is no overlap between training and testing sets
+if (length(intersect(train_df$sample.id, test_df$sample.id)) > 0) {
+    stop("There is overlap between training and testing sets")
+}
+
+
+# train random forest using training eigenvectors
+output.forest <- randomForest::randomForest(
+    train_df[, (num.eigenvectors - 2):(2 + num.eigenvectors)],
+    y = as.factor(train_df$pop),
+    data = train_df,
+    xtest = test_df[, (num.eigenvectors - 2):(2 + num.eigenvectors)],
+    ytest = as.factor(test_df$pop),
+    ntree = 1000,
+    replace = FALSE,
+    proximity = TRUE
+)
+print(output.forest)
+
+# Print confusion matrix
+rfPermute::confusionMatrix(output.forest)
+
+rfPermute::plotPredictedProbs(output.forest, bins = 30, plot = TRUE)
+
+rfPermute::plotProximity(output.forest, plot = TRUE)

# time: 2024-08-27 17:09:08 UTC
# mode: r
+# train random forest using training eigenvectors
+output.forest <- randomForest::randomForest(
+    train_df[, (num.eigenvectors - 2):(2 + num.eigenvectors)],
+    y = as.factor(train_df$pop),
+    data = train_df,
+    xtest = test_df[, (num.eigenvectors - 2):(2 + num.eigenvectors)],
+    ytest = as.factor(test_df$pop),
+    ntree = 1000,
+    replace = FALSE,
+    proximity = TRUE
+)
+print(output.forest)
+
+# Print confusion matrix
+rfPermute::confusionMatrix(output.forest)

# time: 2024-08-27 17:09:19 UTC
# mode: r
+# Print confusion matrix
+rfPermute::confusionMatrix(output.forest)

# time: 2024-08-27 17:10:05 UTC
# mode: r
+# train random forest using training eigenvectors
+output.forest <- randomForest::randomForest(
+    train_df[, (num.eigenvectors - 2):(2 + num.eigenvectors)],
+    y = as.factor(train_df$pop),
+    data = train_df,
+    xtest = test_df[, (num.eigenvectors - 2):(2 + num.eigenvectors)],
+    ytest = as.factor(test_df$pop),
+    ntree = 1000,
+    replace = FALSE,
+    proximity = TRUE
+)
+print(output.forest)
+
+# Print confusion matrix
+rfPermute::confusionMatrix(output.forest)

# time: 2024-08-27 17:10:28 UTC
# mode: r
+rfPermute::plotPredictedProbs(output.forest, bins = 30, plot = TRUE)

# time: 2024-08-27 17:10:41 UTC
# mode: r
+rfPermute::plotPredictedProbs(output.forest, bins = 20, plot = TRUE)

# time: 2024-08-27 17:11:01 UTC
# mode: r
+rfPermute::plotProximity(output.forest, plot = TRUE)

# time: 2024-08-27 17:11:19 UTC
# mode: r
+num.eigenvectors

# time: 2024-08-27 17:13:53 UTC
# mode: r
+rfPermute::summary(output.forest)

# time: 2024-08-27 17:13:58 UTC
# mode: r
+summary(output.forest)

# time: 2024-08-27 17:14:31 UTC
# mode: r
+# train random forest using training eigenvectors
+output.forest <- randomForest::randomForest(
+    train_df[, (num.eigenvectors - 2):(2 + num.eigenvectors)],
+    y = as.factor(train_df$pop),
+    data = train_df,
+    xtest = test_df[, (num.eigenvectors - 2):(2 + num.eigenvectors)],
+    ytest = as.factor(test_df$pop),
+    ntree = 270,
+    replace = FALSE,
+    proximity = TRUE
+)
+print(output.forest)
+
+# Print confusion matrix
+rfPermute::confusionMatrix(output.forest)

# time: 2024-08-27 17:15:29 UTC
# mode: r
+# train random forest using training eigenvectors
+output.forest <- randomForest::randomForest(
+    train_df[, (num.eigenvectors - 2):(2 + num.eigenvectors)],
+    y = as.factor(train_df$pop),
+    data = train_df,
+    xtest = test_df[, (num.eigenvectors - 2):(2 + num.eigenvectors)],
+    ytest = as.factor(test_df$pop),
+    ntree = 2000,
+    replace = FALSE,
+    proximity = TRUE
+)
+print(output.forest)

# time: 2024-08-27 17:15:35 UTC
# mode: r
+summary(output.forest)

# time: 2024-08-27 17:15:58 UTC
# mode: r
+# train random forest using training eigenvectors
+output.forest <- randomForest::randomForest(
+    train_df[, (num.eigenvectors - 2):(2 + num.eigenvectors)],
+    y = as.factor(train_df$pop),
+    data = train_df,
+    xtest = test_df[, (num.eigenvectors - 2):(2 + num.eigenvectors)],
+    ytest = as.factor(test_df$pop),
+    ntree = 2000,
+    replace = FALSE,
+    proximity = TRUE
+)

# time: 2024-08-27 17:16:02 UTC
# mode: r
+summary(output.forest)

# time: 2024-08-27 17:17:33 UTC
# mode: r
+# Print confusion matrix
+rfPermute::confusionMatrix(output.forest)

# time: 2024-08-27 17:19:10 UTC
# mode: r
+summary(output.forest)

# time: 2024-08-27 17:19:23 UTC
# mode: r
+rfPermute::plotProximity(output.forest)

# time: 2024-08-27 17:19:36 UTC
# mode: r
+xt = summary(output.forest)

# time: 2024-08-27 17:19:39 UTC
# mode: r
+xt

# time: 2024-08-27 17:19:44 UTC
# mode: r
+xt.data

# time: 2024-08-27 17:19:52 UTC
# mode: r
+xt$data

# time: 2024-08-27 17:20:05 UTC
# mode: r
+as.data.frame(xt$data)

# time: 2024-08-27 17:20:28 UTC
# mode: r
+dplyr::as_tibble(xt$data)

# time: 2024-08-27 17:21:03 UTC
# mode: r
+oob_df = dplyr::as_tibble(xt$data)

# time: 2024-08-27 17:21:03 UTC
# mode: r
+# plot using ggplot2
+ggplot2::ggplot(oob_df, ggplot2::aes(x = factor(truth), y = factor(predicted))) +
+    ggplot2::geom_tile(ggplot2::aes(fill = Freq), colour = "white") +
+    ggplot2::scale_fill_gradient(low = "white", high = "steelblue") +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(x = "Truth", y = "Predicted", fill = "Frequency") +
+    ggplot2::theme(axis.text.x = ggplot2::element_text(angle = 45, hjust = 1))

# time: 2024-08-27 17:21:36 UTC
# mode: r
+# plot using ggplot2.
+# data looks like # A tibble: 6,000 × 3
+#    trees class error
+#    <int> <fct> <dbl>
+#  1     1 OOB    54.4
+#  2     2 OOB    55.9
+#  3     3 OOB    56.4
+#  4     4 OOB    58.7
+#  5     5 OOB    57.3
+#  6     6 OOB    59.0
+ggplot2::ggplot(oob_df, ggplot2::aes(x = trees, y = error, color = class)) +
+    ggplot2::geom_line() +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(title = "OOB error rate", x = "Number of trees", y = "Error rate") +
+    ggplot2::scale_color_manual(values = c("OOB" = "red", "Test" = "blue"))

# time: 2024-08-27 17:21:54 UTC
# mode: r
+oob_df

# time: 2024-08-27 17:22:04 UTC
# mode: r
+unique(oob_df$class)

# time: 2024-08-27 17:22:18 UTC
# mode: r
+# plot using ggplot2.
+# data looks like # A tibble: 6,000 × 3
+#    trees class error
+#    <int> <fct> <dbl>
+#  1     1 OOB    54.4
+#  2     2 OOB    55.9
+#  3     3 OOB    56.4
+#  4     4 OOB    58.7
+#  5     5 OOB    57.3
+#  6     6 OOB    59.0
+ggplot2::ggplot(oob_df, ggplot2::aes(x = trees, y = error, color = class)) +
+    ggplot2::geom_line() +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(title = "OOB error rate", x = "Number of trees", y = "Error rate") +
+    ggplot2::scale_color_manual(values = c(
+        "OOB" = "red",
+        "immigrant" = "blue",
+        "resident" = "green"
+    ))

# time: 2024-08-27 17:22:49 UTC
# mode: r
+# plot using ggplot2.
+# data looks like # A tibble: 6,000 × 3
+#    trees class error
+#    <int> <fct> <dbl>
+#  1     1 OOB    54.4
+#  2     2 OOB    55.9
+#  3     3 OOB    56.4
+#  4     4 OOB    58.7
+#  5     5 OOB    57.3
+#  6     6 OOB    59.0
+ggplot2::ggplot(oob_df, ggplot2::aes(x = trees, y = error, color = class)) +
+    ggplot2::geom_line() +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(title = "OOB error rate", x = "Number of trees", y = "Error rate") +
+    ggplot2::scale_color_manual(values = c(
+        "OOB" = "#4e4e4e",
+        "immigrant" = "#5d8566",
+        "resident" = "#c29007"
+    ))

# time: 2024-08-27 17:23:15 UTC
# mode: r
+# plot using ggplot2.
+# data looks like # A tibble: 6,000 × 3
+#    trees class error
+#    <int> <fct> <dbl>
+#  1     1 OOB    54.4
+#  2     2 OOB    55.9
+#  3     3 OOB    56.4
+#  4     4 OOB    58.7
+#  5     5 OOB    57.3
+#  6     6 OOB    59.0
+ggplot2::ggplot(oob_df, ggplot2::aes(x = trees, y = error, color = class)) +
+    ggplot2::geom_line() +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(title = "OOB error rate", x = "Number of trees", y = "Error rate") +
+    ggplot2::scale_color_manual(values = c(
+        "OOB" = "#4e4e4e",
+        "immigrant" = "#5d8566",
+        "resident" = "#c29007"
+    )) +
+    # set y axis limits between 0 and 100
+    ggplot2::coord_cartesian(ylim = c(0, 100))

# time: 2024-08-27 17:24:21 UTC
# mode: r
+ggplot2::ggplot(oob_df, ggplot2::aes(x = trees, y = error, color = class)) +
+    ggplot2::geom_line() +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(title = "OOB error rate", x = "Number of trees", y = "Error rate") +
+    ggplot2::scale_color_manual(values = c(
+        "OOB" = "#4e4e4e",
+        "immigrant" = "#5d8566",
+        "resident" = "#c29007"
+    )) +
+    # set y axis limits between 0 and 100
+    ggplot2::coord_cartesian(ylim = c(0, 100)) +
+    # line at 50% error rate
+    ggplot2::geom_hline(yintercept = 50, linetype = "dashed", color = "red")

# time: 2024-08-27 17:24:40 UTC
# mode: r
+# aspect ratio of 1
+    ggplot2::coord_fixed(ratio = 1)

# time: 2024-08-27 17:24:52 UTC
# mode: r
+ggplot2::ggplot(oob_df, ggplot2::aes(x = trees, y = error, color = class)) +
+    ggplot2::geom_line() +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(title = "OOB error rate", x = "Number of trees", y = "Error rate") +
+    ggplot2::scale_color_manual(values = c(
+        "OOB" = "#4e4e4e",
+        "immigrant" = "#5d8566",
+        "resident" = "#c29007"
+    )) +
+    # set y axis limits between 0 and 100
+    ggplot2::coord_cartesian(ylim = c(0, 100)) +
+    # line at 50% error rate
+    ggplot2::geom_hline(yintercept = 50, linetype = "dashed", color = "red") +
+    # aspect ratio of 1
+    ggplot2::coord_fixed(ratio = 1)

# time: 2024-08-27 17:25:13 UTC
# mode: r
+ggplot2::ggplot(oob_df, ggplot2::aes(x = trees, y = error, color = class)) +
+    ggplot2::geom_line() +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(title = "OOB error rate", x = "Number of trees", y = "Error rate") +
+    ggplot2::scale_color_manual(values = c(
+        "OOB" = "#4e4e4e",
+        "immigrant" = "#5d8566",
+        "resident" = "#c29007"
+    )) +
+    # set y axis limits between 0 and 100
+    ggplot2::coord_cartesian(ylim = c(0, 100)) +
+    # line at 50% error rate
+    ggplot2::geom_hline(yintercept = 50, linetype = "dashed", color = "red") +
+    # aspect ratio of 1
+    ggplot::theme(aspect.ratio = 1)

# time: 2024-08-27 17:25:18 UTC
# mode: r
+ggplot2::ggplot(oob_df, ggplot2::aes(x = trees, y = error, color = class)) +
+    ggplot2::geom_line() +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(title = "OOB error rate", x = "Number of trees", y = "Error rate") +
+    ggplot2::scale_color_manual(values = c(
+        "OOB" = "#4e4e4e",
+        "immigrant" = "#5d8566",
+        "resident" = "#c29007"
+    )) +
+    # set y axis limits between 0 and 100
+    ggplot2::coord_cartesian(ylim = c(0, 100)) +
+    # line at 50% error rate
+    ggplot2::geom_hline(yintercept = 50, linetype = "dashed", color = "red") +
+    # aspect ratio of 1
+    ggplot2::theme(aspect.ratio = 1)

# time: 2024-08-27 17:25:31 UTC
# mode: r
+ggplot2::ggplot(oob_df, ggplot2::aes(x = trees, y = error, color = class)) +
+    ggplot2::geom_line() +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(title = "OOB error rate", x = "Number of trees", y = "Error rate") +
+    ggplot2::scale_color_manual(values = c(
+        "OOB" = "#4e4e4e",
+        "immigrant" = "#5d8566",
+        "resident" = "#c29007"
+    )) +
+    # set y axis limits between 0 and 100
+    ggplot2::coord_cartesian(ylim = c(0, 100)) +
+    # line at 50% error rate
+    ggplot2::geom_hline(yintercept = 50, linetype = "dashed", color = "red") +
+    # aspect ratio of 1
+    ggplot2::theme(aspect.ratio = 1, # text size
+                   text = ggplot2::element_text(size = 12))

# time: 2024-08-27 17:27:39 UTC
# mode: r
+# Train 100 random forests with randomized labels
+random_accuracy <- replicate(100, {
+    # Randomize labels
+    train_df$pop <- sample(train_df$pop)
+    
+    # Train random forest
+    random_forest <- randomForest::randomForest(
+        train_df[, (num.eigenvectors - 2):(2 + num.eigenvectors)],
+        y = as.factor(train_df$pop),
+        data = train_df,
+        ntree = 2000,
+        replace = FALSE,
+        proximity = TRUE
+    )
+    
+    # Return accuracy
+    rfPermute::confusionMatrix(random_forest)$overall["Accuracy"]
+})
+
+# Print average random accuracy
+mean_random_accuracy <- mean(random_accuracy)
+print(paste("Average random accuracy:", mean_random_accuracy))
+# Print confusion matrix

# time: 2024-08-27 17:27:49 UTC
# mode: r
+random_forest

# time: 2024-08-27 17:27:53 UTC
# mode: r
+# Train 100 random forests with randomized labels
+random_accuracy <- replicate(100, {
+    # Randomize labels
+    train_df$pop <- sample(train_df$pop)
+    
+    # Train random forest
+    random_forest <- randomForest::randomForest(
+        train_df[, (num.eigenvectors - 2):(2 + num.eigenvectors)],
+        y = as.factor(train_df$pop),
+        data = train_df,
+        ntree = 2000,
+        replace = FALSE,
+        proximity = TRUE
+    )
+    
+
+})

# time: 2024-08-27 17:29:12 UTC
# mode: r
+random_accuracy

# time: 2024-08-27 17:31:01 UTC
# mode: r
+# for each of the forests in random_accuracy, get the summary and add to a dataframe
+random_accuracy_df <- dplyr::bind_rows(
+    lapply(random_accuracy, function(forest) {
+        xt <- summary(forest)
+        dplyr::as_tibble(xt$data)
+    })
+)

# time: 2024-08-27 17:31:23 UTC
# mode: r
+random_accuracy[1]

# time: 2024-08-27 17:31:47 UTC
# mode: r
+xt

# time: 2024-08-27 17:31:58 UTC
# mode: r
+# for each of the forests in random_accuracy, get the summary and add to a dataframe
+random_accuracy_df <- dplyr::bind_rows(
+    lapply(random_accuracy, function(forest) {
+        d <- summary(forest)
+        dplyr::as_tibble(d$data)
+    })
+)

# time: 2024-08-27 17:32:11 UTC
# mode: r
+d

# time: 2024-08-27 17:32:13 UTC
# mode: r
+# for each of the forests in random_accuracy, get the summary and add to a dataframe
+random_accuracy_df <- dplyr::bind_rows(
+    lapply(random_accuracy, function(forest) {
+        d <- summary(forest)
+        dplyr::as_tibble(d$data)
+    })
+)

# time: 2024-08-27 17:32:17 UTC
# mode: r
+d

# time: 2024-08-27 17:32:25 UTC
# mode: r
+# for each of the forests in random_accuracy, get the summary and add to a dataframe
+random_accuracy_df <- dplyr::bind_rows(
+    lapply(random_accuracy, function(forest) {
+        print(d)
+    })
+)

# time: 2024-08-27 17:32:42 UTC
# mode: r
+# for each of the forests in random_accuracy, get the summary and add to a dataframe
+random_accuracy_df <- dplyr::bind_rows(
+    lapply(random_accuracy, function(forest) {
+        print(summary(d))
+    })
+)

# time: 2024-08-27 17:32:50 UTC
# mode: r
+# for each of the forests in random_accuracy, get the summary and add to a dataframe
+random_accuracy_df <- dplyr::bind_rows(
+    lapply(random_accuracy, function(forest) {
+        print(summary(forest))
+    })
+)

# time: 2024-08-27 17:33:17 UTC
# mode: r
+# for each of the forests in random_accuracy, get the summary and add to a dataframe
+random_accuracy_df <- dplyr::bind_rows(
+    lapply(random_accuracy, function(forest) {
+        d = summary(forest)
+        d$data
+    })
+)

# time: 2024-08-27 17:33:34 UTC
# mode: r
+# for each of the forests in random_accuracy, get the summary and add to a dataframe
+random_accuracy_df <- dplyr::bind_rows(
+    lapply(random_accuracy, function(forest) {
+        d = summary(forest)$data
+    })
+)

# time: 2024-08-27 17:33:51 UTC
# mode: r
+# for each of the forests in random_accuracy, get the summary and add to a dataframe
+random_accuracy_df <- dplyr::bind_rows(
+    lapply(random_accuracy, function(forest) {
+        d = summary(forest)
+        print(d)
+    })
+)

# time: 2024-08-27 17:34:33 UTC
# mode: r
+random_accuracy[1]

# time: 2024-08-27 17:34:48 UTC
# mode: r
+# Train 100 random forests with randomized labels
+random_accuracy <- replicate(100, {
+    # Randomize labels
+    train_df$pop <- sample(train_df$pop)
+    
+    # Train random forest
+    random_forest <- randomForest::randomForest(
+        train_df[, (num.eigenvectors - 2):(2 + num.eigenvectors)],
+        y = as.factor(train_df$pop),
+        data = train_df,
+        ntree = 2000,
+        replace = FALSE,
+        proximity = TRUE
+    )
+
+    random_forest
+    
+
+})

# time: 2024-08-27 17:35:07 UTC
# mode: r
+# Train 100 random forests with randomized labels
+random_accuracy <- replicate(50, {
+    # Randomize labels
+    train_df$pop <- sample(train_df$pop)
+    
+    # Train random forest
+    random_forest <- randomForest::randomForest(
+        train_df[, (num.eigenvectors - 2):(2 + num.eigenvectors)],
+        y = as.factor(train_df$pop),
+        data = train_df,
+        ntree = 1000,
+        replace = FALSE,
+        proximity = TRUE
+    )
+
+    random_forest
+    
+
+})

# time: 2024-08-27 17:35:31 UTC
# mode: r
+random_accuracy[1]

# time: 2024-08-27 17:35:36 UTC
# mode: r
+random_accuracy[[1]]

# time: 2024-08-27 17:35:57 UTC
# mode: r
+summary(random_accuracy[[1]])

# time: 2024-08-27 17:37:14 UTC
# mode: r
+a

# time: 2024-08-27 17:37:16 UTC
# mode: r
+# Train 100 random forests with randomized labels
+random_accuracy <- replicate(50, {
+    # Randomize labels
+    train_df$pop <- sample(train_df$pop)
+    
+    # Train random forest
+    random_forest <- randomForest::randomForest(
+        train_df[, (num.eigenvectors - 2):(2 + num.eigenvectors)],
+        y = as.factor(train_df$pop),
+        data = train_df,
+        ntree = 1000,
+        replace = FALSE,
+        proximity = TRUE
+    )
+
+    return(random_forest)
+    
+
+})

# time: 2024-08-27 17:37:35 UTC
# mode: r
+print(random_accuracy[1])

# time: 2024-08-27 17:37:43 UTC
# mode: r
+print(random_accuracy[[1]])

# time: 2024-08-27 17:37:50 UTC
# mode: r
+print(random_accuracy[[1]]$confusion)

# time: 2024-08-27 17:40:41 UTC
# mode: r
+# Train 100 random forests with randomized labels
+random_accuracy <- replicate(50, {
+    # Randomize labels
+    train_df$pop <- sample(train_df$pop)
+
+    # Train random forest
+    random_forest <- randomForest::randomForest(
+        train_df[, (num.eigenvectors - 2):(2 + num.eigenvectors)],
+        y = as.factor(train_df$pop),
+        data = train_df,
+        xtest = test_df[, (num.eigenvectors - 2):(2 + num.eigenvectors)],
+        ytest = as.factor(test_df$pop),
+        ntree = 1000,
+        replace = FALSE,
+        proximity = TRUE
+    )
+
+    return(random_forest)
+})

# time: 2024-08-27 17:42:00 UTC
# mode: r
+renv::install('progressr')

# time: 2024-08-27 17:42:13 UTC
# mode: r
+handlers(handler_txtprogressbar(char = cli::col_red(cli::symbol$heart)))

# time: 2024-08-27 17:42:28 UTC
# mode: r
+progressr::handlers(progressr::handler_txtprogressbar(char = cli::col_red(cli::symbol$heart)))

# time: 2024-08-27 17:42:45 UTC
# mode: r
+# Train 100 random forests with randomized labels
+random_accuracy <- replicate(50, {
+    # Randomize labels
+    train_df$pop <- sample(train_df$pop)
+
+    # Train random forest
+    random_forest <- randomForest::randomForest(
+        train_df[, (num.eigenvectors - 2):(2 + num.eigenvectors)],
+        y = as.factor(train_df$pop),
+        data = train_df,
+        xtest = test_df[, (num.eigenvectors - 2):(2 + num.eigenvectors)],
+        ytest = as.factor(test_df$pop),
+        ntree = 1000,
+        replace = FALSE,
+        proximity = TRUE
+    )
+
+    progressr::set_progress(progressr::get_progress() + 1)
+    return(random_forest)
+}, .progress = "text")

# time: 2024-08-27 17:42:55 UTC
# mode: r
+# Train 100 random forests with randomized labels
+random_accuracy <- replicate(50, {
+    # Randomize labels
+    train_df$pop <- sample(train_df$pop)
+
+    # Train random forest
+    random_forest <- randomForest::randomForest(
+        train_df[, (num.eigenvectors - 2):(2 + num.eigenvectors)],
+        y = as.factor(train_df$pop),
+        data = train_df,
+        xtest = test_df[, (num.eigenvectors - 2):(2 + num.eigenvectors)],
+        ytest = as.factor(test_df$pop),
+        ntree = 1000,
+        replace = FALSE,
+        proximity = TRUE
+    )
+
+    progressr::set_progress(progressr::get_progress() + 1)
+    return(random_forest)
+})

# time: 2024-08-27 17:44:24 UTC
# mode: r
+# Train 100 random forests with randomized labels
+random_accuracy <- replicate(50, {
+
+    p <- progressr::progressor(along = x)
+
+    # Randomize labels
+    train_df$pop <- sample(train_df$pop)
+
+    # Train random forest
+    random_forest <- randomForest::randomForest(
+        train_df[, (num.eigenvectors - 2):(2 + num.eigenvectors)],
+        y = as.factor(train_df$pop),
+        data = train_df,
+        xtest = test_df[, (num.eigenvectors - 2):(2 + num.eigenvectors)],
+        ytest = as.factor(test_df$pop),
+        ntree = 1000,
+        replace = FALSE,
+        proximity = TRUE
+    )
+    p()
+    return(random_forest)
+})

# time: 2024-08-27 17:44:48 UTC
# mode: r
+# Train 100 random forests with randomized labels
+random_accuracy <- replicate(50, {
+
+    p <- progressr::progressor(steps = length(50))
+
+    # Randomize labels
+    train_df$pop <- sample(train_df$pop)
+
+    # Train random forest
+    random_forest <- randomForest::randomForest(
+        train_df[, (num.eigenvectors - 2):(2 + num.eigenvectors)],
+        y = as.factor(train_df$pop),
+        data = train_df,
+        xtest = test_df[, (num.eigenvectors - 2):(2 + num.eigenvectors)],
+        ytest = as.factor(test_df$pop),
+        ntree = 1000,
+        replace = FALSE,
+        proximity = TRUE
+    )
+    p()
+    return(random_forest)
+})

# time: 2024-08-27 17:45:10 UTC
# mode: r
+# Train 100 random forests with randomized labels
+random_accuracy <- replicate(50, progressr::with_progress({
+    p <- progressr::progressor(steps = length(50))
+
+    # Randomize labels
+    train_df$pop <- sample(train_df$pop)
+
+    # Train random forest
+    random_forest <- randomForest::randomForest(
+        train_df[, (num.eigenvectors - 2):(2 + num.eigenvectors)],
+        y = as.factor(train_df$pop),
+        data = train_df,
+        xtest = test_df[, (num.eigenvectors - 2):(2 + num.eigenvectors)],
+        ytest = as.factor(test_df$pop),
+        ntree = 1000,
+        replace = FALSE,
+        proximity = TRUE
+    )
+    p()
+    return(random_forest)
+}))

# time: 2024-08-27 17:45:24 UTC
# mode: r
+# Train 100 random forests with randomized labels
+random_accuracy <- replicate(50, progressr::with_progress({
+    p <- progressr::progressor(steps = 50)
+
+    # Randomize labels
+    train_df$pop <- sample(train_df$pop)
+
+    # Train random forest
+    random_forest <- randomForest::randomForest(
+        train_df[, (num.eigenvectors - 2):(2 + num.eigenvectors)],
+        y = as.factor(train_df$pop),
+        data = train_df,
+        xtest = test_df[, (num.eigenvectors - 2):(2 + num.eigenvectors)],
+        ytest = as.factor(test_df$pop),
+        ntree = 1000,
+        replace = FALSE,
+        proximity = TRUE
+    )
+    p()
+    return(random_forest)
+}))

# time: 2024-08-27 17:46:32 UTC
# mode: r
+progressr::handlers("cli")

# time: 2024-08-27 17:46:34 UTC
# mode: r
+progressr::handlers(progressr::handler_txtprogressbar(char = cli::col_red(cli::symbol$heart)))

# time: 2024-08-27 17:46:41 UTC
# mode: r
+progressr::handlers("cli")

# time: 2024-08-27 17:46:45 UTC
# mode: r
+# Train 100 random forests with randomized labels
+random_accuracy <- replicate(50, progressr::with_progress({
+    p <- progressr::progressor(steps = length(50))
+
+    # Randomize labels
+    train_df$pop <- sample(train_df$pop)
+
+    # Train random forest
+    random_forest <- randomForest::randomForest(
+        train_df[, (num.eigenvectors - 2):(2 + num.eigenvectors)],
+        y = as.factor(train_df$pop),
+        data = train_df,
+        xtest = test_df[, (num.eigenvectors - 2):(2 + num.eigenvectors)],
+        ytest = as.factor(test_df$pop),
+        ntree = 1000,
+        replace = FALSE,
+        proximity = TRUE
+    )
+    p()
+    return(random_forest)
+}))

# time: 2024-08-27 17:47:34 UTC
# mode: r
+# Train 100 random forests with randomized labels
+random_accuracy <- replicate(50, {
+    # Randomize labels
+    train_df$pop <- sample(train_df$pop)
+
+    # Train random forest
+    random_forest <- randomForest::randomForest(
+        train_df[, (num.eigenvectors - 2):(2 + num.eigenvectors)],
+        y = as.factor(train_df$pop),
+        data = train_df,
+        xtest = test_df[, (num.eigenvectors - 2):(2 + num.eigenvectors)],
+        ytest = as.factor(test_df$pop),
+        ntree = 1000,
+        replace = FALSE,
+        proximity = TRUE
+    )
+
+    return(random_forest)
+})

# time: 2024-08-27 17:48:02 UTC
# mode: r
+# for each of the forests in random_accuracy, get the summary and add to a dataframe
+random_accuracy_df <- dplyr::bind_rows(
+    lapply(random_accuracy, function(forest) {
+        d <- summary(forest)
+        d$data
+    })
+)

# time: 2024-08-27 17:48:11 UTC
# mode: r
+random_accuracy[[1]]

# time: 2024-08-27 17:49:51 UTC
# mode: r
+ggplot2::ggplot(oob_df, ggplot2::aes(x = trees, y = error, color = class)) +
+    ggplot2::geom_line() +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(title = "OOB error rate", x = "Number of trees", y = "Error rate") +
+    ggplot2::scale_color_manual(values = c(
+        "OOB" = "#4e4e4e",
+        "immigrant" = "#5d8566",
+        "resident" = "#c29007"
+    )) +
+    ggplot2::coord_cartesian(ylim = c(0, 100)) +
+    ggplot2::geom_hline(yintercept = 50, linetype = "dashed", color = "red") +
+    ggplot2::theme(
+        aspect.ratio = 1,
+        text = ggplot2::element_text(size = 12)
+    )

# time: 2024-08-27 17:50:31 UTC
# mode: r
+# Print confusion matrix
+rfPermute::confusionMatrix(output.forest)

# time: 2024-08-29 10:34:14 UTC
# mode: r
+# Import configuration file
+config <- config::get()
+
+# parameters
+percent.train <- 0.7
+num.threads <- 44
+num.eigenvectors <- 20
+set.seed(555)
+
+# Input files
+immigrant.info <- file.path(config$path$data, "600K_immigrants.fam")
+immigrant.vcf <- file.path(config$path$data, "600K_immigrants.vcf")
+resident.vcf <- file.path(config$path$data, "600K_residents.vcf")
+
+immigrant.gds <- file.path(config$path$data, "immigrant_recode.gds")
+resident.gds <- file.path(config$path$data, "resident_recode.gds")
+all.gds <- file.path(config$path$data, "all_recode.gds")
+
+# remove any existing gds files before creating new ones
+file.remove(list.files(path = config$path$data, pattern = "*.gds$", full.names = TRUE))
+SNPRelate::snpgdsVCF2GDS(immigrant.vcf, immigrant.gds, method = "biallelic.only")
+SNPRelate::snpgdsVCF2GDS(resident.vcf, resident.gds, method = "biallelic.only")
+gdsfmt::showfile.gds(closeall = TRUE)
+# Append the immigrant and resident data
+SNPRelate::snpgdsCombineGeno(c(immigrant.gds, resident.gds), all.gds)
+
+# Load all the data
+all.maf <- SNPRelate::snpgdsOpen(all.gds)
+
+# Load labels
+immigrant.id <- gdsfmt::read.gdsn(gdsfmt::index.gdsn(
+    SNPRelate::snpgdsOpen(immigrant.gds),
+    "sample.id"
+))
+resident.id <- gdsfmt::read.gdsn(gdsfmt::index.gdsn(
+    SNPRelate::snpgdsOpen(resident.gds),
+    "sample.id"
+))
+
+all.id <- gdsfmt::read.gdsn(gdsfmt::index.gdsn(all.maf, "sample.id"))
+
+# randomly subsample the data so that the number of samples in all from immigrant and resident are the same
+min.samples <- min(length(immigrant.id), length(resident.id))
+immigrant.id <- sample(immigrant.id, min.samples)
+resident.id <- sample(resident.id, min.samples)
+all.id <- c(immigrant.id, resident.id)
+
+# Split the data into training and testing sets
+num.samples <- length(all.id)
+num.train <- round(num.samples * percent.train)
+num.test <- num.samples - num.train
+train.id <- sample(all.id, num.train)
+test.id <- setdiff(all.id, train.id)
+
+# Identify the population code for each sample
+train.label <- ifelse(train.id %in% immigrant.id, "immigrant", "resident")
+test.label <- ifelse(test.id %in% immigrant.id, "immigrant", "resident")
+all.label <- ifelse(all.id %in% immigrant.id, "immigrant", "resident")
+
+# Reduce dimensionality via pca
+num.threads <- 3
+pca <- SNPRelate::snpgdsPCA(all.maf, sample.id = train.id, num.thread = num.threads)
+
+tab <- data.frame(sample.id = pca$sample.id, pop = factor(train.label), EV1 = pca$eigenvect[, 1], EV2 = pca$eigenvect[, 2], stringsAsFactors = FALSE)
+
+pc.percent <- pca$varprop * 100
+lbls <- paste("PC", 1:num.eigenvectors, "\n", format(pc.percent[1:num.eigenvectors], digits = 2), "%", sep = "")
+pairs(pca$eigenvect[, 1:num.eigenvectors], col = tab$pop, labels = lbls, aspect = 1)
+
+
+
+# Calculate SNP loadings
+snp_loadings <- SNPRelate::snpgdsPCASNPLoading(pca, all.maf, num.thread = num.threads)
+
+# Calculate sample loadings for testing set using SNP loadings
+sample_loadings <- SNPRelate::snpgdsPCASampLoading(snp_loadings, all.maf, sample.id = test.id, num.thread = num.threads)
+
+# Extract list of SNPs used in PCA
+snpset.id <- unlist(all.maf)
+snp_list <- SNPRelate::snpgdsSNPList(all.maf)
+snp_rs_id <- snp_list$snp.id[pca$snp.id]
+snp_chrom <- snp_list$chromosome[pca$snp.id]
+snp_pos <- snp_list$position[pca$snp.id]
+
+# Create dataframe with one SNP per row
+snp_df <- data.frame(snp_rs_id, snp_chrom, snp_pos)
+
+# Transpose SNP loading table
+snp_loadings_transposed <- t(snp_loadings$snploading)
+
+# Match SNPs with loading vectors
+loading_mat <- data.frame(snp_df, snp_loadings_transposed[, 1:num.eigenvectors])
+
+# Write loading data frame to file
+
+# Create data frames, where sample is paired with eigenvectors
+train_eigenvects <- data.frame(pca$sample.id, pca$eigenvect[, 1:num.eigenvectors])
+test_eigenvects <- data.frame(sample_loadings$sample.id, sample_loadings$eigenvect[, 1:num.eigenvectors])
+
+# Ensure sample.id column is same for all data frames
+colnames(train_eigenvects)[1] <- "sample.id"
+colnames(test_eigenvects)[1] <- "sample.id"
+
+# Create a dataframe with 'sample.id' and 'pop' columns
+sample.info <- data.frame(sample.id = all.id, pop = all.label)
+
+# Merge data frames
+train_df <- merge(sample.info, train_eigenvects)
+test_df <- merge(sample.info, test_eigenvects)
+
+# Check that there is no overlap between training and testing sets
+if (length(intersect(train_df$sample.id, test_df$sample.id)) > 0) {
+    stop("There is overlap between training and testing sets")
+}
+
+
+# train random forest using training eigenvectors
+output.forest <- randomForest::randomForest(
+    train_df[, (num.eigenvectors - 2):(2 + num.eigenvectors)],
+    y = as.factor(train_df$pop),
+    data = train_df,
+    xtest = test_df[, (num.eigenvectors - 2):(2 + num.eigenvectors)],
+    ytest = as.factor(test_df$pop),
+    ntree = 2000,
+    replace = FALSE,
+    proximity = TRUE
+)
+print(output.forest)

# time: 2024-08-29 12:46:26 UTC
# mode: r
+loading_mat

# time: 2024-08-29 12:46:33 UTC
# mode: r
+snp_loadings

# time: 2024-08-29 12:52:03 UTC
# mode: r
+# Calculate the number of samples from each group
+num_immigrant <- sum(all.label == "immigrant")
+num_resident <- sum(all.label == "resident")
+
+# Calculate the number of samples from each group in the train set
+num_train_immigrant <- round(num_immigrant * percent.train)
+num_train_resident <- round(num_resident * percent.train)
+
+# Calculate the number of samples from each group in the test set
+num_test_immigrant <- num_immigrant - num_train_immigrant
+num_test_resident <- num_resident - num_train_resident
+
+# Create train and test sets with balanced samples from each group
+train_immigrant <- sample(immigrant.id, num_train_immigrant)
+train_resident <- sample(resident.id, num_train_resident)
+test_immigrant <- sample(setdiff(immigrant.id, train_immigrant), num_test_immigrant)
+test_resident <- sample(setdiff(resident.id, train_resident), num_test_resident)
+
+# Combine the train and test sets
+train.id <- c(train_immigrant, train_resident)
+test.id <- c(test_immigrant, test_resident)

# time: 2024-08-29 12:52:05 UTC
# mode: r
+test.id

# time: 2024-08-29 12:52:10 UTC
# mode: r
+# Identify the population code for each sample
+train.label <- ifelse(train.id %in% immigrant.id, "immigrant", "resident")

# time: 2024-08-29 12:52:11 UTC
# mode: r
+test.label <- ifelse(test.id %in% immigrant.id, "immigrant", "resident")

# time: 2024-08-29 12:52:11 UTC
# mode: r
+all.label <- ifelse(all.id %in% immigrant.id, "immigrant", "resident")

# time: 2024-08-29 12:53:17 UTC
# mode: r
+# check the proportion of immigrant and residents in each label variable
+prop_immigrant <- sum(train.label == "immigrant") / length(train.label)
+prop_resident <- sum(train.label == "resident") / length(train.label)
+
+prop_immigrant
+prop_resident

# time: 2024-08-29 14:40:22 UTC
# mode: r
+# Import configuration file
+config <- config::get()
+
+# parameters
+percent.train <- 0.7
+num.threads <- 44
+num.eigenvectors <- 20
+set.seed(555)
+
+# Input files
+immigrant.info <- file.path(config$path$data, "600K_immigrants.fam")
+immigrant.vcf <- file.path(config$path$data, "600K_immigrants.vcf")
+resident.vcf <- file.path(config$path$data, "600K_residents.vcf")
+
+immigrant.gds <- file.path(config$path$data, "immigrant_recode.gds")
+resident.gds <- file.path(config$path$data, "resident_recode.gds")
+all.gds <- file.path(config$path$data, "all_recode.gds")
+
+# remove any existing gds files before creating new ones
+file.remove(list.files(path = config$path$data, pattern = "*.gds$", full.names = TRUE))
+SNPRelate::snpgdsVCF2GDS(immigrant.vcf, immigrant.gds, method = "biallelic.only")
+SNPRelate::snpgdsVCF2GDS(resident.vcf, resident.gds, method = "biallelic.only")
+gdsfmt::showfile.gds(closeall = TRUE)
+# Append the immigrant and resident data
+SNPRelate::snpgdsCombineGeno(c(immigrant.gds, resident.gds), all.gds)
+
+# Load all the data
+all.maf <- SNPRelate::snpgdsOpen(all.gds)
+
+# Load labels
+immigrant.id <- gdsfmt::read.gdsn(gdsfmt::index.gdsn(
+    SNPRelate::snpgdsOpen(immigrant.gds),
+    "sample.id"
+))
+resident.id <- gdsfmt::read.gdsn(gdsfmt::index.gdsn(
+    SNPRelate::snpgdsOpen(resident.gds),
+    "sample.id"
+))
+
+all.id <- gdsfmt::read.gdsn(gdsfmt::index.gdsn(all.maf, "sample.id"))
+
+# randomly subsample the data so that the number of samples in all from immigrant and resident are the same
+min.samples <- min(length(immigrant.id), length(resident.id))
+immigrant.id <- sample(immigrant.id, min.samples)
+resident.id <- sample(resident.id, min.samples)
+all.id <- c(immigrant.id, resident.id)
+
+# Split the data into training and testing sets
+# Calculate the number of samples from each group
+num_immigrant <- sum(all.label == "immigrant")
+num_resident <- sum(all.label == "resident")
+
+# Calculate the number of samples from each group in the train set
+num_train_immigrant <- round(num_immigrant * percent.train)
+num_train_resident <- round(num_resident * percent.train)
+
+# Calculate the number of samples from each group in the test set
+num_test_immigrant <- num_immigrant - num_train_immigrant
+num_test_resident <- num_resident - num_train_resident
+
+# Create train and test sets with balanced samples from each group
+train_immigrant <- sample(immigrant.id, num_train_immigrant)
+train_resident <- sample(resident.id, num_train_resident)
+test_immigrant <- sample(setdiff(immigrant.id, train_immigrant), num_test_immigrant)
+test_resident <- sample(setdiff(resident.id, train_resident), num_test_resident)
+
+# Combine the train and test sets
+train.id <- c(train_immigrant, train_resident)
+test.id <- c(test_immigrant, test_resident)
+
+# Identify the population code for each sample
+train.label <- ifelse(train.id %in% immigrant.id, "immigrant", "resident")
+test.label <- ifelse(test.id %in% immigrant.id, "immigrant", "resident")
+all.label <- ifelse(all.id %in% immigrant.id, "immigrant", "resident")
+
+# check the proportion of immigrant and residents in each label variable
+prop_immigrant <- sum(train.label == "immigrant") / length(train.label)
+prop_resident <- sum(train.label == "resident") / length(train.label)

# time: 2024-08-29 14:42:13 UTC
# mode: r
+all.id <- gdsfmt::read.gdsn(gdsfmt::index.gdsn(all.maf, "sample.id"))
+
+# randomly subsample the data so that the number of samples in all from immigrant and resident are the same
+min.samples <- min(length(immigrant.id), length(resident.id))
+immigrant.id <- sample(immigrant.id, min.samples)
+resident.id <- sample(resident.id, min.samples)
+all.id <- c(immigrant.id, resident.id)
+
+# Split the data into training and testing sets
+# Calculate the number of samples from each group
+num_immigrant <- sum(all.label == "immigrant")
+num_resident <- sum(all.label == "resident")
+all.label <- ifelse(all.id %in% immigrant.id, "immigrant", "resident")
+
+# Calculate the number of samples from each group in the train set
+num_train_immigrant <- round(num_immigrant * percent.train)
+num_train_resident <- round(num_resident * percent.train)
+
+# Calculate the number of samples from each group in the test set
+num_test_immigrant <- num_immigrant - num_train_immigrant
+num_test_resident <- num_resident - num_train_resident
+
+# Create train and test sets with balanced samples from each group
+train_immigrant <- sample(immigrant.id, num_train_immigrant)
+train_resident <- sample(resident.id, num_train_resident)
+test_immigrant <- sample(setdiff(immigrant.id, train_immigrant), num_test_immigrant)
+test_resident <- sample(setdiff(resident.id, train_resident), num_test_resident)
+
+# Combine the train and test sets
+train.id <- c(train_immigrant, train_resident)
+test.id <- c(test_immigrant, test_resident)
+
+# Identify the population code for each sample
+train.label <- ifelse(train.id %in% immigrant.id, "immigrant", "resident")
+test.label <- ifelse(test.id %in% immigrant.id, "immigrant", "resident")
+
+# check the proportion of immigrant and residents in each label variable
+prop_immigrant <- sum(train.label == "immigrant") / length(train.label)
+prop_resident <- sum(train.label == "resident") / length(train.label)

# time: 2024-08-29 14:42:24 UTC
# mode: r
+all.id <- gdsfmt::read.gdsn(gdsfmt::index.gdsn(all.maf, "sample.id"))
+
+# randomly subsample the data so that the number of samples in all from immigrant and resident are the same
+min.samples <- min(length(immigrant.id), length(resident.id))
+immigrant.id <- sample(immigrant.id, min.samples)
+resident.id <- sample(resident.id, min.samples)
+all.id <- c(immigrant.id, resident.id)
+
+# Split the data into training and testing sets
+# Calculate the number of samples from each group
+all.label <- ifelse(all.id %in% immigrant.id, "immigrant", "resident")
+num_immigrant <- sum(all.label == "immigrant")
+num_resident <- sum(all.label == "resident")
+
+# Calculate the number of samples from each group in the train set
+num_train_immigrant <- round(num_immigrant * percent.train)
+num_train_resident <- round(num_resident * percent.train)
+
+# Calculate the number of samples from each group in the test set
+num_test_immigrant <- num_immigrant - num_train_immigrant
+num_test_resident <- num_resident - num_train_resident
+
+# Create train and test sets with balanced samples from each group
+train_immigrant <- sample(immigrant.id, num_train_immigrant)
+train_resident <- sample(resident.id, num_train_resident)
+test_immigrant <- sample(setdiff(immigrant.id, train_immigrant), num_test_immigrant)
+test_resident <- sample(setdiff(resident.id, train_resident), num_test_resident)
+
+# Combine the train and test sets
+train.id <- c(train_immigrant, train_resident)
+test.id <- c(test_immigrant, test_resident)
+
+# Identify the population code for each sample
+train.label <- ifelse(train.id %in% immigrant.id, "immigrant", "resident")
+test.label <- ifelse(test.id %in% immigrant.id, "immigrant", "resident")
+
+# check the proportion of immigrant and residents in each label variable
+prop_immigrant <- sum(train.label == "immigrant") / length(train.label)
+prop_resident <- sum(train.label == "resident") / length(train.label)

# time: 2024-08-29 14:42:25 UTC
# mode: r
+prop_resident

# time: 2024-08-29 14:43:03 UTC
# mode: r
+# now for the test set
+prop_immigrant_test <- sum(test.label == "immigrant") / length(test.label)

# time: 2024-08-29 14:43:04 UTC
# mode: r
+prop_resident_test <- sum(test.label == "resident") / length(test.label)

# time: 2024-08-29 14:43:05 UTC
# mode: r
+prop_immigrant_test

# time: 2024-08-29 14:43:07 UTC
# mode: r
+prop_resident_test

# time: 2024-08-29 14:43:33 UTC
# mode: r
+if (length(intersect(train.id, test.id)) > 0) {
+    stop("There is overlap between training and testing sets")
+}

# time: 2024-08-29 14:43:50 UTC
# mode: r
+test.label

# time: 2024-08-29 14:44:05 UTC
# mode: r
+immigrant.id

# time: 2024-08-29 14:44:09 UTC
# mode: r
+train.id

# time: 2024-08-29 14:46:05 UTC
# mode: r
+# Subsample data to balance immigrant and resident samples
+min_samples <- min(length(immigrant.id), length(resident.id))
+all.id <- c(sample(immigrant.id, min_samples), sample(resident.id, min_samples))
+all.label <- ifelse(all.id %in% immigrant.id, "immigrant", "resident")
+
+# Split data into training and testing sets
+num_train <- round(length(all.id) * percent.train)
+train.id <- sample(all.id, num_train)
+test.id <- setdiff(all.id, train.id)
+
+train.label <- all.label[all.id %in% train.id]
+test.label <- all.label[all.id %in% test.id]
+
+# Check proportions
+prop_train <- table(train.label) / length(train.label)
+prop_test <- table(test.label) / length(test.label)
+
+# Verify no overlap between train and test sets
+if (length(intersect(train.id, test.id)) > 0) stop("Overlap between train and test sets")

# time: 2024-08-29 14:46:07 UTC
# mode: r
+prop_train

# time: 2024-08-29 14:46:11 UTC
# mode: r
+prop_test

# time: 2024-08-29 14:47:37 UTC
# mode: r
+# Verify no overlap between train and test sets
+if (length(intersect(train.id, test.id)) > 0) stop("Overlap between train and test sets")

# time: 2024-08-29 14:47:51 UTC
# mode: r
+num.threads <- 4
+pca <- SNPRelate::snpgdsPCA(all.maf, sample.id = train.id, num.thread = num.threads)
+
+tab <- data.frame(sample.id = pca$sample.id, pop = factor(train.label), EV1 = pca$eigenvect[, 1], EV2 = pca$eigenvect[, 2], stringsAsFactors = FALSE)
+
+pc.percent <- pca$varprop * 100
+lbls <- paste("PC", 1:num.eigenvectors, "\n", format(pc.percent[1:num.eigenvectors], digits = 2), "%", sep = "")
+pairs(pca$eigenvect[, 1:num.eigenvectors], col = tab$pop, labels = lbls, aspect = 1)

# time: 2024-08-29 14:48:45 UTC
# mode: r
+# Calculate SNP loadings
+snp_loadings <- SNPRelate::snpgdsPCASNPLoading(pca, all.maf, num.thread = num.threads)
+
+# Calculate sample loadings for testing set using SNP loadings
+sample_loadings <- SNPRelate::snpgdsPCASampLoading(snp_loadings, all.maf, sample.id = test.id, num.thread = num.threads)
+
+# Extract list of SNPs used in PCA
+snpset.id <- unlist(all.maf)
+snp_list <- SNPRelate::snpgdsSNPList(all.maf)
+snp_rs_id <- snp_list$snp.id[pca$snp.id]
+snp_chrom <- snp_list$chromosome[pca$snp.id]
+snp_pos <- snp_list$position[pca$snp.id]
+
+# Create dataframe with one SNP per row
+snp_df <- data.frame(snp_rs_id, snp_chrom, snp_pos)
+
+# Transpose SNP loading table
+snp_loadings_transposed <- t(snp_loadings$snploading)
+
+# Match SNPs with loading vectors
+loading_mat <- data.frame(snp_df, snp_loadings_transposed[, 1:num.eigenvectors])
+
+# Write loading data frame to file
+
+# Create data frames, where sample is paired with eigenvectors
+train_eigenvects <- data.frame(pca$sample.id, pca$eigenvect[, 1:num.eigenvectors])
+test_eigenvects <- data.frame(sample_loadings$sample.id, sample_loadings$eigenvect[, 1:num.eigenvectors])
+
+# Ensure sample.id column is same for all data frames
+colnames(train_eigenvects)[1] <- "sample.id"
+colnames(test_eigenvects)[1] <- "sample.id"
+
+# Create a dataframe with 'sample.id' and 'pop' columns
+sample.info <- data.frame(sample.id = all.id, pop = all.label)
+
+# Merge data frames
+train_df <- merge(sample.info, train_eigenvects)
+test_df <- merge(sample.info, test_eigenvects)

# time: 2024-08-29 14:48:58 UTC
# mode: r
+output.forest <- randomForest::randomForest(
+    train_df[, (num.eigenvectors - 2):(2 + num.eigenvectors)],
+    y = as.factor(train_df$pop),
+    data = train_df,
+    xtest = test_df[, (num.eigenvectors - 2):(2 + num.eigenvectors)],
+    ytest = as.factor(test_df$pop),
+    ntree = 2000,
+    replace = FALSE,
+    proximity = TRUE
+)
+print(output.forest)

# time: 2024-08-29 14:49:40 UTC
# mode: r
+# Print confusion matrix
+rfPermute::confusionMatrix(output.forest)

# time: 2024-08-29 14:50:28 UTC
# mode: r
+rfPermute::plotPredictedProbs(output.forest, bins = 20, plot = TRUE)

# time: 2024-08-29 14:50:36 UTC
# mode: r
+rfPermute::plotProximity(output.forest)

# time: 2024-08-29 14:51:03 UTC
# mode: r
+xt <- summary(output.forest)

# time: 2024-08-29 14:54:11 UTC
# mode: r
+xt <- function(...) {
+    png(tempfile(fileext = ".png"))
+    xt = summary(output.forest)
+    dev.off()
+    return(xt)
+}

# time: 2024-08-29 14:54:13 UTC
# mode: r
+oob_df <- dplyr::as_tibble(xt$data)

# time: 2024-08-29 14:55:20 UTC
# mode: r
+oob_sum <- function(...) {
+    png(tempfile(fileext = ".png"))
+    xt = summary(...)
+    dev.off()
+    return(xt$data)
+}

# time: 2024-08-29 14:55:22 UTC
# mode: r
+oob_df <- dplyr::as_tibble(oob_sum(output.forest))

# time: 2024-08-29 14:55:28 UTC
# mode: r
+oob_df

# time: 2024-08-29 14:56:39 UTC
# mode: r
+invisible(capture.output(xt = summary(output.forest)))

# time: 2024-08-29 14:56:57 UTC
# mode: r
+oob_sum <- function(...) {
+    png(tempfile(fileext = ".png"))
+    invisible(capture.output(xt = summary(...)))
+    dev.off()
+    return(xt$data)
+}

# time: 2024-08-29 14:56:58 UTC
# mode: r
+oob_df <- dplyr::as_tibble(oob_sum(output.forest))

# time: 2024-08-29 14:57:28 UTC
# mode: r
+oob_sum <- function(...) {
+    png(tempfile(fileext = ".png"))
+    sink("file")
+    xt = summary(...)
+    dev.off()
+    sink()
+    return(xt$data)
+}

# time: 2024-08-29 14:57:30 UTC
# mode: r
+xt = summary(output.forest)

# time: 2024-08-29 14:57:34 UTC
# mode: r
+oob_sum <- function(...) {
+    png(tempfile(fileext = ".png"))
+    sink("file")
+    xt = summary(...)
+    dev.off()
+    sink()
+    return(xt$data)
+}

# time: 2024-08-29 14:57:36 UTC
# mode: r
+oob_df <- dplyr::as_tibble(oob_sum(output.forest))

# time: 2024-08-29 14:57:38 UTC
# mode: r
+oob_df

# time: 2024-08-29 14:58:00 UTC
# mode: r
+oob_sum <- function(...) { # This is so stupid omg
+    png(tempfile(fileext = ".png"))
+    sink("file")
+    xt = summary(...)
+    dev.off()
+    sink()
+    return(xt$data)
+}

# time: 2024-08-29 14:58:00 UTC
# mode: r
+oob_df <- dplyr::as_tibble(oob_sum(output.forest))

# time: 2024-08-29 14:58:04 UTC
# mode: r
+# for each of the forests in random_accuracy, get the summary and add to a dataframe
+random_accuracy_df <- dplyr::bind_rows(
+    lapply(random_accuracy, function(forest) {
+        d <- summary(forest)
+        d$data
+    })
+)

# time: 2024-08-29 14:58:29 UTC
# mode: r
+# train random forest using training eigenvectors
+output.forest <- randomForest::randomForest(
+    train_df[, (num.eigenvectors - 2):(2 + num.eigenvectors)],
+    y = as.factor(train_df$pop),
+    data = train_df,
+    xtest = test_df[, (num.eigenvectors - 2):(2 + num.eigenvectors)],
+    ytest = as.factor(test_df$pop),
+    ntree = 2000,
+    replace = FALSE,
+    proximity = TRUE
+)

# time: 2024-08-29 14:58:31 UTC
# mode: r
+print(output.forest)

# time: 2024-08-29 14:58:36 UTC
# mode: r
+# train random forest using training eigenvectors
+output.forest <- randomForest::randomForest(
+    train_df[, (num.eigenvectors - 2):(2 + num.eigenvectors)],
+    y = as.factor(train_df$pop),
+    data = train_df,
+    xtest = test_df[, (num.eigenvectors - 2):(2 + num.eigenvectors)],
+    ytest = as.factor(test_df$pop),
+    ntree = 2000,
+    replace = FALSE,
+    proximity = TRUE
+)

# time: 2024-08-29 14:58:40 UTC
# mode: r
+output.forest

# time: 2024-08-29 14:58:43 UTC
# mode: r
+# Print confusion matrix
+rfPermute::confusionMatrix(output.forest)

# time: 2024-08-29 14:58:50 UTC
# mode: r
+oob_df <- dplyr::as_tibble(oob_sum(output.forest))

# time: 2024-08-29 14:58:51 UTC
# mode: r
+ggplot2::ggplot(oob_df, ggplot2::aes(x = trees, y = error, color = class)) +
+    ggplot2::geom_line() +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(title = "OOB error rate", x = "Number of trees", y = "Error rate") +
+    ggplot2::scale_color_manual(values = c(
+        "OOB" = "#4e4e4e",
+        "immigrant" = "#5d8566",
+        "resident" = "#c29007"
+    )) +
+    ggplot2::coord_cartesian(ylim = c(0, 100)) +
+    ggplot2::geom_hline(yintercept = 50, linetype = "dashed", color = "red") +
+    ggplot2::theme(
+        aspect.ratio = 1,
+        text = ggplot2::element_text(size = 12)
+    )

# time: 2024-08-29 14:59:12 UTC
# mode: r
+# train random forest using training eigenvectors
+output.forest <- randomForest::randomForest(
+    train_df[, (num.eigenvectors - 2):(2 + num.eigenvectors)],
+    y = as.factor(train_df$pop),
+    data = train_df,
+    xtest = test_df[, (num.eigenvectors - 2):(2 + num.eigenvectors)],
+    ytest = as.factor(test_df$pop),
+    ntree = 2000,
+    replace = FALSE,
+    proximity = TRUE
+)
+
+
+# Print confusion matrix
+# rfPermute::confusionMatrix(output.forest)
+# rfPermute::plotPredictedProbs(output.forest, bins = 20, plot = TRUE)
+# rfPermute::plotProximity(output.forest)
+
+
+
+oob_sum <- function(...) { # This is so stupid omg
+    png(tempfile(fileext = ".png"))
+    sink("file")
+    xt = summary(...)
+    dev.off()
+    sink()
+    return(xt$data)
+}
+oob_df <- dplyr::as_tibble(oob_sum(output.forest))
+
+
+
+ggplot2::ggplot(oob_df, ggplot2::aes(x = trees, y = error, color = class)) +
+    ggplot2::geom_line() +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(title = "OOB error rate", x = "Number of trees", y = "Error rate") +
+    ggplot2::scale_color_manual(values = c(
+        "OOB" = "#4e4e4e",
+        "immigrant" = "#5d8566",
+        "resident" = "#c29007"
+    )) +
+    ggplot2::coord_cartesian(ylim = c(0, 100)) +
+    ggplot2::geom_hline(yintercept = 50, linetype = "dashed", color = "red") +
+    ggplot2::theme(
+        aspect.ratio = 1,
+        text = ggplot2::element_text(size = 12)
+    )
+
+#

# time: 2024-08-29 14:59:33 UTC
# mode: r
+# Subsample data to balance immigrant and resident samples
+min_samples <- min(length(immigrant.id), length(resident.id))
+all.id <- c(sample(immigrant.id, min_samples), sample(resident.id, min_samples))
+all.label <- ifelse(all.id %in% immigrant.id, "immigrant", "resident")
+
+# Split data into training and testing sets
+num_train <- round(length(all.id) * percent.train)
+train.id <- sample(all.id, num_train)
+test.id <- setdiff(all.id, train.id)
+
+train.label <- all.label[all.id %in% train.id]
+test.label <- all.label[all.id %in% test.id]
+
+# Check proportions
+prop_train <- table(train.label) / length(train.label)
+prop_test <- table(test.label) / length(test.label)
+
+# Verify no overlap between train and test sets
+if (length(intersect(train.id, test.id)) > 0) stop("Overlap between train and test sets")
+
+# Reduce dimensionality via pca
+num.threads <- 4
+pca <- SNPRelate::snpgdsPCA(all.maf, sample.id = train.id, num.thread = num.threads)
+
+tab <- data.frame(sample.id = pca$sample.id, pop = factor(train.label), EV1 = pca$eigenvect[, 1], EV2 = pca$eigenvect[, 2], stringsAsFactors = FALSE)
+
+pc.percent <- pca$varprop * 100
+lbls <- paste("PC", 1:num.eigenvectors, "\n", format(pc.percent[1:num.eigenvectors], digits = 2), "%", sep = "")
+pairs(pca$eigenvect[, 1:num.eigenvectors], col = tab$pop, labels = lbls, aspect = 1)
+
+
+# Calculate SNP loadings
+snp_loadings <- SNPRelate::snpgdsPCASNPLoading(pca, all.maf, num.thread = num.threads)
+
+# Calculate sample loadings for testing set using SNP loadings
+sample_loadings <- SNPRelate::snpgdsPCASampLoading(snp_loadings, all.maf, sample.id = test.id, num.thread = num.threads)
+
+# Extract list of SNPs used in PCA
+snpset.id <- unlist(all.maf)
+snp_list <- SNPRelate::snpgdsSNPList(all.maf)
+snp_rs_id <- snp_list$snp.id[pca$snp.id]
+snp_chrom <- snp_list$chromosome[pca$snp.id]
+snp_pos <- snp_list$position[pca$snp.id]
+
+# Create dataframe with one SNP per row
+snp_df <- data.frame(snp_rs_id, snp_chrom, snp_pos)
+
+# Transpose SNP loading table
+snp_loadings_transposed <- t(snp_loadings$snploading)
+
+# Match SNPs with loading vectors
+loading_mat <- data.frame(snp_df, snp_loadings_transposed[, 1:num.eigenvectors])
+
+# Write loading data frame to file
+
+# Create data frames, where sample is paired with eigenvectors
+train_eigenvects <- data.frame(pca$sample.id, pca$eigenvect[, 1:num.eigenvectors])
+test_eigenvects <- data.frame(sample_loadings$sample.id, sample_loadings$eigenvect[, 1:num.eigenvectors])
+
+# Ensure sample.id column is same for all data frames
+colnames(train_eigenvects)[1] <- "sample.id"
+colnames(test_eigenvects)[1] <- "sample.id"
+
+# Create a dataframe with 'sample.id' and 'pop' columns
+sample.info <- data.frame(sample.id = all.id, pop = all.label)
+
+# Merge data frames
+train_df <- merge(sample.info, train_eigenvects)
+test_df <- merge(sample.info, test_eigenvects)
+
+
+# train random forest using training eigenvectors
+output.forest <- randomForest::randomForest(
+    train_df[, (num.eigenvectors - 2):(2 + num.eigenvectors)],
+    y = as.factor(train_df$pop),
+    data = train_df,
+    xtest = test_df[, (num.eigenvectors - 2):(2 + num.eigenvectors)],
+    ytest = as.factor(test_df$pop),
+    ntree = 2000,
+    replace = FALSE,
+    proximity = TRUE
+)
+
+
+# Print confusion matrix
+# rfPermute::confusionMatrix(output.forest)
+# rfPermute::plotPredictedProbs(output.forest, bins = 20, plot = TRUE)
+# rfPermute::plotProximity(output.forest)
+
+
+
+oob_sum <- function(...) { # This is so stupid omg
+    png(tempfile(fileext = ".png"))
+    sink("file")
+    xt = summary(...)
+    dev.off()
+    sink()
+    return(xt$data)
+}
+oob_df <- dplyr::as_tibble(oob_sum(output.forest))
+
+
+
+ggplot2::ggplot(oob_df, ggplot2::aes(x = trees, y = error, color = class)) +
+    ggplot2::geom_line() +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(title = "OOB error rate", x = "Number of trees", y = "Error rate") +
+    ggplot2::scale_color_manual(values = c(
+        "OOB" = "#4e4e4e",
+        "immigrant" = "#5d8566",
+        "resident" = "#c29007"
+    )) +
+    ggplot2::coord_cartesian(ylim = c(0, 100)) +
+    ggplot2::geom_hline(yintercept = 50, linetype = "dashed", color = "red") +
+    ggplot2::theme(
+        aspect.ratio = 1,
+        text = ggplot2::element_text(size = 12)
+    )
+
+#

# time: 2024-08-29 15:00:24 UTC
# mode: r
+# Print confusion matrix
+rfPermute::confusionMatrix(output.forest)

# time: 2024-08-29 15:03:34 UTC
# mode: r
+# Function to train a random forest with randomized labels
+train_random_forest <- function(train_df, test_df, num.eigenvectors) {
+    # Randomize training labels
+    train_df$random_pop <- sample(train_df$pop)
+
+    # Train random forest
+    rf <- randomForest::randomForest(
+        train_df[, (num.eigenvectors - 2):(2 + num.eigenvectors)],
+        y = as.factor(train_df$random_pop),
+        data = train_df,
+        xtest = test_df[, (num.eigenvectors - 2):(2 + num.eigenvectors)],
+        ytest = as.factor(test_df$pop),
+        ntree = 1000,
+        replace = FALSE,
+        proximity = TRUE
+    )
+
+    return(rf)
+}
+
+# Train 100 random forests with randomized labels
+set.seed(123) # For reproducibility
+random_forests <- replicate(5, train_random_forest(train_df, test_df, num.eigenvectors), simplify = FALSE)
+
+# Extract OOB error rates
+random_oob_data <- lapply(random_forests, function(rf) {
+    oob_sum(rf)$data
+})
+
+# Combine OOB error rates
+random_oob_df <- do.call(rbind, random_oob_data)
+random_oob_df$iteration <- rep(1:100, each = nrow(random_oob_data[[1]]))
+
+# Calculate mean OOB error rates across iterations
+mean_random_oob <- random_oob_df %>%
+    group_by(trees, class) %>%
+    summarise(mean_error = mean(error), .groups = "drop")
+
+# Add random forest results to the plot
+ggplot2::ggplot() +
+    # Original data
+    ggplot2::geom_line(data = oob_df, ggplot2::aes(x = trees, y = error, color = class)) +
+    # Random forest results
+    ggplot2::geom_line(data = mean_random_oob, ggplot2::aes(x = trees, y = mean_error, color = class), linetype = "dashed") +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(
+        title = "OOB error rate (Solid: Original, Dashed: Randomized)",
+        x = "Number of trees", y = "Error rate"
+    ) +
+    ggplot2::scale_color_manual(values = c(
+        "OOB" = "#4e4e4e",
+        "immigrant" = "#5d8566",
+        "resident" = "#c29007"
+    )) +
+    ggplot2::coord_cartesian(ylim = c(0, 100)) +
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "red") +
+    ggplot2::theme(
+        aspect.ratio = 1,
+        text = ggplot2::element_text(size = 12)
+    )

# time: 2024-08-29 15:07:06 UTC
# mode: r
+# Function to train a random forest with randomized labels
+train_random_forest <- function(train_df, test_df, num.eigenvectors) {
+    # Randomize training labels
+    train_df$random_pop <- sample(train_df$pop)
+
+    # Train random forest
+    rf <- randomForest::randomForest(
+        train_df[, (num.eigenvectors - 2):(2 + num.eigenvectors)],
+        y = as.factor(train_df$random_pop),
+        data = train_df,
+        xtest = test_df[, (num.eigenvectors - 2):(2 + num.eigenvectors)],
+        ytest = as.factor(test_df$pop),
+        ntree = 1000,
+        replace = FALSE,
+        proximity = TRUE
+    )
+
+    return(rf)
+}
+
+# Train 100 random forests with randomized labels
+set.seed(123) # For reproducibility
+random_forests <- replicate(5, train_random_forest(train_df, test_df, num.eigenvectors), simplify = FALSE)
+
+# Extract OOB error rates
+random_oob_data <- lapply(random_forests, function(rf) {
+    oob_sum(rf)$data
+})
+
+# Combine OOB error rates
+random_oob_df <- do.call(rbind, random_oob_data)
+random_oob_df$iteration <- rep(1:100, each = nrow(random_oob_data[[1]]))
+
+# Calculate mean OOB error rates across iterations
+mean_random_oob <- random_oob_df |>
+    group_by(trees, class) |>
+    summarise(mean_error = mean(error), .groups = "drop")
+
+# Add random forest results to the plot
+ggplot2::ggplot() +
+    # Original data
+    ggplot2::geom_line(data = oob_df, ggplot2::aes(x = trees, y = error, color = class)) +
+    # Random forest results
+    ggplot2::geom_line(data = mean_random_oob, ggplot2::aes(x = trees, y = mean_error, color = class), linetype = "dashed") +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(
+        title = "OOB error rate (Solid: Original, Dashed: Randomized)",
+        x = "Number of trees", y = "Error rate"
+    ) +
+    ggplot2::scale_color_manual(values = c(
+        "OOB" = "#4e4e4e",
+        "immigrant" = "#5d8566",
+        "resident" = "#c29007"
+    )) +
+    ggplot2::coord_cartesian(ylim = c(0, 100)) +
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "red") +
+    ggplot2::theme(
+        aspect.ratio = 1,
+        text = ggplot2::element_text(size = 12)
+    )

# time: 2024-08-29 15:07:29 UTC
# mode: r
+# Function to train a random forest with randomized labels
+train_random_forest <- function(train_df, test_df, num.eigenvectors) {
+    # Randomize training labels
+    train_df$random_pop <- sample(train_df$pop)
+
+    # Train random forest
+    rf <- randomForest::randomForest(
+        train_df[, (num.eigenvectors - 2):(2 + num.eigenvectors)],
+        y = as.factor(train_df$random_pop),
+        data = train_df,
+        xtest = test_df[, (num.eigenvectors - 2):(2 + num.eigenvectors)],
+        ytest = as.factor(test_df$pop),
+        ntree = 1000,
+        replace = FALSE,
+        proximity = TRUE
+    )
+
+    return(rf)
+}
+
+# Train 100 random forests with randomized labels
+set.seed(123) # For reproducibility
+random_forests <- replicate(5, train_random_forest(train_df, test_df, num.eigenvectors), simplify = FALSE)
+
+# Extract OOB error rates
+random_oob_data <- lapply(random_forests, function(rf) {
+    oob_sum(rf)$data
+})
+
+# Combine OOB error rates
+random_oob_df <- do.call(rbind, random_oob_data)
+random_oob_df$iteration <- rep(1:100, each = nrow(random_oob_data[[1]]))
+
+# Calculate mean OOB error rates across iterations
+mean_random_oob <- random_oob_df |>
+    dplyr::group_by(trees, class) |>
+    dplyr::summarise(mean_error = mean(error), .groups = "drop")
+
+# Add random forest results to the plot
+ggplot2::ggplot() +
+    # Original data
+    ggplot2::geom_line(data = oob_df, ggplot2::aes(x = trees, y = error, color = class)) +
+    # Random forest results
+    ggplot2::geom_line(data = mean_random_oob, ggplot2::aes(x = trees, y = mean_error, color = class), linetype = "dashed") +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(
+        title = "OOB error rate (Solid: Original, Dashed: Randomized)",
+        x = "Number of trees", y = "Error rate"
+    ) +
+    ggplot2::scale_color_manual(values = c(
+        "OOB" = "#4e4e4e",
+        "immigrant" = "#5d8566",
+        "resident" = "#c29007"
+    )) +
+    ggplot2::coord_cartesian(ylim = c(0, 100)) +
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "red") +
+    ggplot2::theme(
+        aspect.ratio = 1,
+        text = ggplot2::element_text(size = 12)
+    )

# time: 2024-08-29 15:07:39 UTC
# mode: r
+mean_random_oob

# time: 2024-08-29 15:07:41 UTC
# mode: r
+random_oob_data

# time: 2024-08-29 15:07:43 UTC
# mode: r
+random_forests

# time: 2024-08-29 15:08:48 UTC
# mode: r
+# Extract OOB error rates
+random_oob_data <- lapply(random_forests, function(rf) {
+    oob_sum(rf)
+})

# time: 2024-08-29 15:08:50 UTC
# mode: r
+random_oob_data

# time: 2024-08-29 15:09:02 UTC
# mode: r
+# Extract OOB error rates
+random_oob_data <- lapply(random_forests, function(rf) {
+    oob_sum(rf)
+})

# time: 2024-08-29 15:09:03 UTC
# mode: r
+# Combine OOB error rates
+random_oob_df <- do.call(rbind, random_oob_data)

# time: 2024-08-29 15:09:04 UTC
# mode: r
+random_oob_df$iteration <- rep(1:100, each = nrow(random_oob_data[[1]]))

# time: 2024-08-29 15:09:46 UTC
# mode: r
+# Combine OOB error rates
+random_oob_df <- do.call(rbind, random_oob_data)

# time: 2024-08-29 15:09:47 UTC
# mode: r
+# Calculate mean OOB error rates across iterations
+mean_random_oob <- random_oob_df |>
+    dplyr::group_by(trees, class) |>
+    dplyr::summarise(mean_error = mean(error), .groups = "drop")

# time: 2024-08-29 15:09:49 UTC
# mode: r
+mean_random_oob

# time: 2024-08-29 15:10:04 UTC
# mode: r
+oob_df

# time: 2024-08-29 15:10:35 UTC
# mode: r
+# Combine OOB error rates
+random_oob_df <- do.call(rbind, random_oob_data)

# time: 2024-08-29 15:10:37 UTC
# mode: r
+# Calculate mean OOB error rates across iterations
+random_oob <- random_oob_df |>
+    dplyr::group_by(trees, class) |>
+    dplyr::summarise(mean_error = mean(error), .groups = "drop")

# time: 2024-08-29 15:10:45 UTC
# mode: r
+# Add random forest results to the plot
+ggplot2::ggplot() +
+    # Original data
+    ggplot2::geom_line(data = oob_df, ggplot2::aes(x = trees, y = error, color = class)) +
+    # Random forest results
+    ggplot2::geom_line(data = random_oob, ggplot2::aes(x = trees, y = error, color = class), linetype = "dashed") +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(
+        title = "OOB error rate (Solid: Original, Dashed: Randomized)",
+        x = "Number of trees", y = "Error rate"
+    ) +
+    ggplot2::scale_color_manual(values = c(
+        "OOB" = "#4e4e4e",
+        "immigrant" = "#5d8566",
+        "resident" = "#c29007"
+    )) +
+    ggplot2::coord_cartesian(ylim = c(0, 100)) +
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "red") +
+    ggplot2::theme(
+        aspect.ratio = 1,
+        text = ggplot2::element_text(size = 12)
+    )

# time: 2024-08-29 15:10:54 UTC
# mode: r
+random_oob_df

# time: 2024-08-29 15:11:08 UTC
# mode: r
+# Combine OOB error rates
+random_oob_df <- do.call(rbind, random_oob_data)

# time: 2024-08-29 15:11:09 UTC
# mode: r
+# Add random forest results to the plot
+ggplot2::ggplot() +
+    # Original data
+    ggplot2::geom_line(data = oob_df, ggplot2::aes(x = trees, y = error, color = class)) +
+    # Random forest results
+    ggplot2::geom_line(data = random_oob, ggplot2::aes(x = trees, y = error, color = class), linetype = "dashed") +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(
+        title = "OOB error rate (Solid: Original, Dashed: Randomized)",
+        x = "Number of trees", y = "Error rate"
+    ) +
+    ggplot2::scale_color_manual(values = c(
+        "OOB" = "#4e4e4e",
+        "immigrant" = "#5d8566",
+        "resident" = "#c29007"
+    )) +
+    ggplot2::coord_cartesian(ylim = c(0, 100)) +
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "red") +
+    ggplot2::theme(
+        aspect.ratio = 1,
+        text = ggplot2::element_text(size = 12)
+    )

# time: 2024-08-29 15:11:14 UTC
# mode: r
+random_oob_df

# time: 2024-08-29 15:11:25 UTC
# mode: r
+# Combine OOB error rates
+random_oob_df <- dplyr::as_tibble(do.call(rbind, random_oob_data))

# time: 2024-08-29 15:11:27 UTC
# mode: r
+random_oob_df

# time: 2024-08-29 15:11:37 UTC
# mode: r
+oob_df

# time: 2024-08-29 15:11:48 UTC
# mode: r
+# Add random forest results to the plot
+ggplot2::ggplot() +
+    # Original data
+    ggplot2::geom_line(data = oob_df, ggplot2::aes(x = trees, y = error, color = class)) +
+    # Random forest results
+    ggplot2::geom_line(data = random_oob_df, ggplot2::aes(x = trees, y = error, color = class), linetype = "dashed") +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(
+        title = "OOB error rate (Solid: Original, Dashed: Randomized)",
+        x = "Number of trees", y = "Error rate"
+    ) +
+    ggplot2::scale_color_manual(values = c(
+        "OOB" = "#4e4e4e",
+        "immigrant" = "#5d8566",
+        "resident" = "#c29007"
+    )) +
+    ggplot2::coord_cartesian(ylim = c(0, 100)) +
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "red") +
+    ggplot2::theme(
+        aspect.ratio = 1,
+        text = ggplot2::element_text(size = 12)
+    )

# time: 2024-08-29 15:15:04 UTC
# mode: r
+# Function to train a random forest with optional randomized labels
+train_random_forest <- function(
+    train_df,
+    test_df,
+    num.eigenvectors,
+    randomize_labels = FALSE) {
+    if (randomize_labels) {
+        # Randomize training labels
+        train_df$random_pop <- sample(train_df$pop)
+        y_train <- as.factor(train_df$random_pop)
+    } else {
+        y_train <- as.factor(train_df$pop)
+    }
+
+    # Train random forest
+    rf <- randomForest::randomForest(
+        train_df[, (num.eigenvectors - 2):(2 + num.eigenvectors)],
+        y = y_train,
+        data = train_df,
+        xtest = test_df[, (num.eigenvectors - 2):(2 + num.eigenvectors)],
+        ytest = as.factor(test_df$pop),
+        ntree = 1000,
+        replace = FALSE,
+        proximity = TRUE
+    )
+
+    return(rf)
+}

# time: 2024-08-29 15:15:05 UTC
# mode: r
+# Train random forest
+output.forest <- train_random_forest(train_df, test_df, num.eigenvectors)

# time: 2024-08-29 15:15:09 UTC
# mode: r
+# Print confusion matrix
+rfPermute::confusionMatrix(output.forest)

# time: 2024-08-29 15:15:25 UTC
# mode: r
+oob_df <- dplyr::as_tibble(oob_sum(output.forest))

# time: 2024-08-29 15:15:31 UTC
# mode: r
+# Train 100 random forests with randomized labels
+set.seed(123) # For reproducibility
+random_forests <- replicate(5, train_random_forest(
+    train_df, test_df, num.eigenvectors,
+    randomize_labels = TRUE
+),
+simplify = FALSE
+)
+
+# Extract OOB error rates
+random_oob_data <- lapply(random_forests, function(rf) {
+    oob_sum(rf)
+})
+
+# Combine OOB error rates
+random_oob_df <- dplyr::as_tibble(do.call(rbind, random_oob_data))
+
+
+# Add random forest results to the plot
+ggplot2::ggplot() +
+    # Original data
+    ggplot2::geom_line(data = oob_df, ggplot2::aes(x = trees, y = error, color = class)) +
+    # Random forest results
+    ggplot2::geom_line(data = random_oob_df, ggplot2::aes(x = trees, y = error, color = class), linetype = "dashed") +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(
+        title = "OOB error rate (Solid: Original, Dashed: Randomized)",
+        x = "Number of trees", y = "Error rate"
+    ) +
+    ggplot2::scale_color_manual(values = c(
+        "OOB" = "#4e4e4e",
+        "immigrant" = "#5d8566",
+        "resident" = "#c29007"
+    )) +
+    ggplot2::coord_cartesian(ylim = c(0, 100)) +
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "red") +
+    ggplot2::theme(
+        aspect.ratio = 1,
+        text = ggplot2::element_text(size = 12)
+    )

# time: 2024-08-29 15:18:31 UTC
# mode: r
+# Calculate mean error for original data
+mean_oob_df <- oob_df %>%
+    dplyr::group_by(trees, class) %>%
+    dplyr::summarise(mean_error = mean(error), .groups = "drop")

# time: 2024-08-29 15:18:39 UTC
# mode: r
+# Calculate mean error for original data
+mean_oob_df <- oob_df |>
+    dplyr::group_by(trees, class) |>
+    dplyr::summarise(mean_error = mean(error), .groups = "drop")

# time: 2024-08-29 15:18:42 UTC
# mode: r
+# Calculate mean error for randomized data
+mean_random_oob_df <- random_oob_df |>
+    dplyr::group_by(trees, class) |>
+    dplyr::summarise(mean_error = mean(error), .groups = "drop")

# time: 2024-08-29 15:18:44 UTC
# mode: r
+# Add random forest results to the plot
+ggplot2::ggplot() +
+    # Original data (individual lines with low opacity)
+    ggplot2::geom_line(data = oob_df, ggplot2::aes(x = trees, y = error, color = class, group = interaction(class, iteration)), alpha = 0.1) +
+    # Random forest results (individual lines with low opacity)
+    ggplot2::geom_line(data = random_oob_df, ggplot2::aes(x = trees, y = error, color = class, group = interaction(class, iteration)), alpha = 0.1, linetype = "dashed") +
+    # Smooth mean lines for original data
+    ggplot2::geom_smooth(data = mean_oob_df, ggplot2::aes(x = trees, y = mean_error, color = class), se = FALSE, size = 1.5) +
+    # Smooth mean lines for randomized data
+    ggplot2::geom_smooth(data = mean_random_oob_df, ggplot2::aes(x = trees, y = mean_error, color = class), se = FALSE, size = 1.5, linetype = "dashed") +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(
+        title = "OOB error rate (Solid: Original, Dashed: Randomized)",
+        x = "Number of trees", y = "Error rate"
+    ) +
+    ggplot2::scale_color_manual(values = c(
+        "OOB" = "#4e4e4e",
+        "immigrant" = "#5d8566",
+        "resident" = "#c29007"
+    )) +
+    ggplot2::coord_cartesian(ylim = c(0, 100)) +
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "red") +
+    ggplot2::theme(
+        aspect.ratio = 1,
+        text = ggplot2::element_text(size = 12)
+    )

# time: 2024-08-29 15:19:06 UTC
# mode: r
+mean_random_oob_df

# time: 2024-08-29 15:19:52 UTC
# mode: r
+# Add random forest results to the plot
+ggplot2::ggplot() +
+    # Original data (individual lines with low opacity)
+    ggplot2::geom_line(data = oob_df, ggplot2::aes(x = trees, y = error, color = class), alpha = 0.1) +
+    # Random forest results (individual lines with low opacity)
+    ggplot2::geom_line(data = random_oob_df, ggplot2::aes(x = trees, y = error, color = class), alpha = 0.1, linetype = "dashed") +
+    # Smooth mean lines for original data
+    ggplot2::geom_smooth(data = mean_oob_df, ggplot2::aes(x = trees, y = mean_error, color = class), se = FALSE, size = 1.5) +
+    # Smooth mean lines for randomized data
+    ggplot2::geom_smooth(data = mean_random_oob_df, ggplot2::aes(x = trees, y = mean_error, color = class), se = FALSE, size = 1.5, linetype = "dashed") +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(
+        title = "OOB error rate (Solid: Original, Dashed: Randomized)",
+        x = "Number of trees", y = "Error rate"
+    ) +
+    ggplot2::scale_color_manual(values = c(
+        "OOB" = "#4e4e4e",
+        "immigrant" = "#5d8566",
+        "resident" = "#c29007"
+    )) +
+    ggplot2::coord_cartesian(ylim = c(0, 100)) +
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "red") +
+    ggplot2::theme(
+        aspect.ratio = 1,
+        text = ggplot2::element_text(size = 12)
+    )

# time: 2024-08-29 15:21:34 UTC
# mode: r
+# Add random forest results to the plot
+ggplot2::ggplot() +
+    # Original data (individual lines with low opacity)
+    ggplot2::geom_line(
+        data = oob_df,
+        ggplot2::aes(x = trees, y = error, color = class), alpha = 0.1
+    ) +
+    # Random forest results (individual lines with low opacity)
+    ggplot2::geom_line(
+        data = random_oob_df,
+        ggplot2::aes(x = trees, y = error, color = class), alpha = 0.1, linetype = "dashed"
+    ) +
+    # Smooth mean lines for original data
+    ggplot2::geom_line(
+        data = mean_oob_df,
+        ggplot2::aes(x = trees, y = mean_error, color = class), size = 1.5
+    ) +
+    # Smooth mean lines for randomized data
+    ggplot2::geom_line(
+        data = mean_random_oob_df,
+        ggplot2::aes(x = trees, y = mean_error, color = class), size = 1.5,
+        linetype = "dashed"
+    ) +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(
+        title = "OOB error rate (Solid: Original, Dashed: Randomized)",
+        x = "Number of trees", y = "Error rate"
+    ) +
+    ggplot2::scale_color_manual(values = c(
+        "OOB" = "#4e4e4e",
+        "immigrant" = "#5d8566",
+        "resident" = "#c29007"
+    )) +
+    ggplot2::coord_cartesian(ylim = c(0, 100)) +
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "red") +
+    ggplot2::theme(
+        aspect.ratio = 1,
+        text = ggplot2::element_text(size = 12)
+    )

# time: 2024-08-29 15:23:46 UTC
# mode: r
+# Train 100 random forests with original labels
+set.seed(123) # For reproducibility
+randf <- replicate(5, train_random_forest(
+    train_df, test_df, num.eigenvectors,
+    randomize_labels = FALSE
+),
+simplify = FALSE
+)
+
+# Extract OOB error rates
+oob_data <- lapply(randf, function(rf) {
+    oob_sum(rf)
+})
+
+oob_df <- dplyr::as_tibble(do.call(rbind, oob_data))

# time: 2024-08-29 15:23:52 UTC
# mode: r
+# Calculate mean error for original data
+mean_oob_df <- oob_df |>
+    dplyr::group_by(trees, class) |>
+    dplyr::summarise(mean_error = mean(error), .groups = "drop")
+
+# Calculate mean error for randomized data
+mean_random_oob_df <- random_oob_df |>
+    dplyr::group_by(trees, class) |>
+    dplyr::summarise(mean_error = mean(error), .groups = "drop")
+
+# Add random forest results to the plot
+ggplot2::ggplot() +
+    # Original data (individual lines with low opacity)
+    ggplot2::geom_line(
+        data = oob_df,
+        ggplot2::aes(x = trees, y = error, color = class), alpha = 0.1
+    ) +
+    # Random forest results (individual lines with low opacity)
+    ggplot2::geom_line(
+        data = random_oob_df,
+        ggplot2::aes(x = trees, y = error, color = class), alpha = 0.1, linetype = "dashed"
+    ) +
+    # Smooth mean lines for original data
+    ggplot2::geom_line(
+        data = mean_oob_df,
+        ggplot2::aes(x = trees, y = mean_error, color = class), size = 1.5
+    ) +
+    # Smooth mean lines for randomized data
+    ggplot2::geom_line(
+        data = mean_random_oob_df,
+        ggplot2::aes(x = trees, y = mean_error, color = class), size = 1.5,
+        linetype = "dashed"
+    ) +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(
+        title = "OOB error rate (Solid: Original, Dashed: Randomized)",
+        x = "Number of trees", y = "Error rate"
+    ) +
+    ggplot2::scale_color_manual(values = c(
+        "OOB" = "#4e4e4e",
+        "immigrant" = "#5d8566",
+        "resident" = "#c29007"
+    )) +
+    ggplot2::coord_cartesian(ylim = c(0, 100)) +
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "red") +
+    ggplot2::theme(
+        aspect.ratio = 1,
+        text = ggplot2::element_text(size = 12)
+    )

# time: 2024-08-29 15:24:53 UTC
# mode: r
+# Function to train a random forest with optional randomized labels
+train_random_forest <- function(
+    train_df,
+    test_df,
+    num.eigenvectors,
+    randomize_labels = FALSE) {
+    if (randomize_labels) {
+        # Randomize training labels
+        train_df$random_pop <- sample(train_df$pop)
+        y_train <- as.factor(train_df$random_pop)
+    } else {
+        y_train <- as.factor(train_df$pop)
+    }
+
+    # Train random forest
+    rf <- randomForest::randomForest(
+        train_df[, (num.eigenvectors - 2):(2 + num.eigenvectors)],
+        y = y_train,
+        data = train_df,
+        xtest = test_df[, (num.eigenvectors - 2):(2 + num.eigenvectors)],
+        ytest = as.factor(test_df$pop),
+        ntree = 500,
+        replace = FALSE,
+        proximity = TRUE
+    )
+
+    return(rf)
+}

# time: 2024-08-29 15:25:08 UTC
# mode: r
+# Train 100 random forests with randomized labels
+set.seed(123) # For reproducibility
+randrandf <- replicate(20, train_random_forest(
+    train_df, test_df, num.eigenvectors,
+    randomize_labels = TRUE
+),
+simplify = FALSE
+)
+# Extract OOB error rates
+random_oob_data <- lapply(randrandf, function(rf) {
+    oob_sum(rf)
+})
+
+random_oob_df <- dplyr::as_tibble(do.call(rbind, random_oob_data))
+
+
+# Train 100 random forests with original labels
+set.seed(123) # For reproducibility
+randf <- replicate(20, train_random_forest(
+    train_df, test_df, num.eigenvectors,
+    randomize_labels = FALSE
+),
+simplify = FALSE
+)
+
+# Extract OOB error rates
+oob_data <- lapply(randf, function(rf) {
+    oob_sum(rf)
+})
+
+oob_df <- dplyr::as_tibble(do.call(rbind, oob_data))
+
+
+# Calculate mean error for original data
+mean_oob_df <- oob_df |>
+    dplyr::group_by(trees, class) |>
+    dplyr::summarise(mean_error = mean(error), .groups = "drop")
+
+# Calculate mean error for randomized data
+mean_random_oob_df <- random_oob_df |>
+    dplyr::group_by(trees, class) |>
+    dplyr::summarise(mean_error = mean(error), .groups = "drop")
+
+# Add random forest results to the plot
+ggplot2::ggplot() +
+    # Original data (individual lines with low opacity)
+    ggplot2::geom_line(
+        data = oob_df,
+        ggplot2::aes(x = trees, y = error, color = class), alpha = 0.1
+    ) +
+    # Random forest results (individual lines with low opacity)
+    ggplot2::geom_line(
+        data = random_oob_df,
+        ggplot2::aes(x = trees, y = error, color = class), alpha = 0.1, linetype = "dashed"
+    ) +
+    # Smooth mean lines for original data
+    ggplot2::geom_line(
+        data = mean_oob_df,
+        ggplot2::aes(x = trees, y = mean_error, color = class), size = 1.5
+    ) +
+    # Smooth mean lines for randomized data
+    ggplot2::geom_line(
+        data = mean_random_oob_df,
+        ggplot2::aes(x = trees, y = mean_error, color = class), size = 1.5,
+        linetype = "dashed"
+    ) +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(
+        title = "OOB error rate (Solid: Original, Dashed: Randomized)",
+        x = "Number of trees", y = "Error rate"
+    ) +
+    ggplot2::scale_color_manual(values = c(
+        "OOB" = "#4e4e4e",
+        "immigrant" = "#5d8566",
+        "resident" = "#c29007"
+    )) +
+    ggplot2::coord_cartesian(ylim = c(0, 100)) +
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "red") +
+    ggplot2::theme(
+        aspect.ratio = 1,
+        text = ggplot2::element_text(size = 12)
+    )

# time: 2024-08-29 15:26:29 UTC
# mode: r
+# Subsample data to balance immigrant and resident samples
+min_samples <- min(length(immigrant.id), length(resident.id))
+all.id <- c(sample(immigrant.id, min_samples), sample(resident.id, min_samples))
+all.label <- ifelse(all.id %in% immigrant.id, "immigrant", "resident")
+
+# Split data into training and testing sets
+num_train <- round(length(all.id) * percent.train)
+train.id <- sample(all.id, num_train)
+test.id <- setdiff(all.id, train.id)
+
+train.label <- all.label[all.id %in% train.id]
+test.label <- all.label[all.id %in% test.id]
+
+# Check proportions
+prop_train <- table(train.label) / length(train.label)
+prop_test <- table(test.label) / length(test.label)
+
+# Verify no overlap between train and test sets
+if (length(intersect(train.id, test.id)) > 0) stop("Overlap between train and test sets")
+
+# Reduce dimensionality via pca
+num.threads <- 4
+pca <- SNPRelate::snpgdsPCA(all.maf, sample.id = train.id, num.thread = num.threads)
+
+tab <- data.frame(sample.id = pca$sample.id, pop = factor(train.label), EV1 = pca$eigenvect[, 1], EV2 = pca$eigenvect[, 2], stringsAsFactors = FALSE)
+
+
+# Calculate SNP loadings
+snp_loadings <- SNPRelate::snpgdsPCASNPLoading(pca, all.maf, num.thread = num.threads)
+
+# Calculate sample loadings for testing set using SNP loadings
+sample_loadings <- SNPRelate::snpgdsPCASampLoading(snp_loadings, all.maf, sample.id = test.id, num.thread = num.threads)
+
+# Extract list of SNPs used in PCA
+snpset.id <- unlist(all.maf)
+snp_list <- SNPRelate::snpgdsSNPList(all.maf)
+snp_rs_id <- snp_list$snp.id[pca$snp.id]
+snp_chrom <- snp_list$chromosome[pca$snp.id]
+snp_pos <- snp_list$position[pca$snp.id]
+
+# Create dataframe with one SNP per row
+snp_df <- data.frame(snp_rs_id, snp_chrom, snp_pos)
+
+# Transpose SNP loading table
+snp_loadings_transposed <- t(snp_loadings$snploading)
+
+# Match SNPs with loading vectors
+loading_mat <- data.frame(snp_df, snp_loadings_transposed[, 1:num.eigenvectors])
+
+# Write loading data frame to file
+
+# Create data frames, where sample is paired with eigenvectors
+train_eigenvects <- data.frame(pca$sample.id, pca$eigenvect[, 1:num.eigenvectors])
+test_eigenvects <- data.frame(sample_loadings$sample.id, sample_loadings$eigenvect[, 1:num.eigenvectors])
+
+# Ensure sample.id column is same for all data frames
+colnames(train_eigenvects)[1] <- "sample.id"
+colnames(test_eigenvects)[1] <- "sample.id"
+
+# Create a dataframe with 'sample.id' and 'pop' columns
+sample.info <- data.frame(sample.id = all.id, pop = all.label)
+
+# Merge data frames
+train_df <- merge(sample.info, train_eigenvects)
+test_df <- merge(sample.info, test_eigenvects)
+
+
+# Function to train a random forest with optional randomized labels
+train_random_forest <- function(
+    train_df,
+    test_df,
+    num.eigenvectors,
+    randomize_labels = FALSE) {
+    if (randomize_labels) {
+        # Randomize training labels
+        train_df$random_pop <- sample(train_df$pop)
+        y_train <- as.factor(train_df$random_pop)
+    } else {
+        y_train <- as.factor(train_df$pop)
+    }
+
+    # Train random forest
+    rf <- randomForest::randomForest(
+        train_df[, (num.eigenvectors - 2):(2 + num.eigenvectors)],
+        y = y_train,
+        data = train_df,
+        xtest = test_df[, (num.eigenvectors - 2):(2 + num.eigenvectors)],
+        ytest = as.factor(test_df$pop),
+        ntree = 500,
+        replace = FALSE,
+        proximity = TRUE
+    )
+
+    return(rf)
+}
+
+oob_sum <- function(...) { # This is so stupid omg
+    png(tempfile(fileext = ".png"))
+    sink("file")
+    xt <- summary(...)
+    dev.off()
+    sink()
+    return(xt$data)
+}
+
+
+# Print confusion matrix
+rfPermute::confusionMatrix(output.forest)
+rfPermute::plotPredictedProbs(output.forest, bins = 20, plot = TRUE)
+rfPermute::plotProximity(output.forest)
+
+
+# Train 100 random forests with randomized labels
+set.seed(123) # For reproducibility
+randrandf <- replicate(20, train_random_forest(
+    train_df, test_df, num.eigenvectors,
+    randomize_labels = TRUE
+),
+simplify = FALSE
+)
+# Extract OOB error rates
+random_oob_data <- lapply(randrandf, function(rf) {
+    oob_sum(rf)
+})
+
+random_oob_df <- dplyr::as_tibble(do.call(rbind, random_oob_data))
+
+
+# Train 100 random forests with original labels
+set.seed(123) # For reproducibility
+randf <- replicate(20, train_random_forest(
+    train_df, test_df, num.eigenvectors,
+    randomize_labels = FALSE
+),
+simplify = FALSE
+)
+
+# Extract OOB error rates
+oob_data <- lapply(randf, function(rf) {
+    oob_sum(rf)
+})
+
+oob_df <- dplyr::as_tibble(do.call(rbind, oob_data))
+
+
+# Calculate mean error for original data
+mean_oob_df <- oob_df |>
+    dplyr::group_by(trees, class) |>
+    dplyr::summarise(mean_error = mean(error), .groups = "drop")
+
+# Calculate mean error for randomized data
+mean_random_oob_df <- random_oob_df |>
+    dplyr::group_by(trees, class) |>
+    dplyr::summarise(mean_error = mean(error), .groups = "drop")
+
+# Add random forest results to the plot
+ggplot2::ggplot() +
+    # Original data (individual lines with low opacity)
+    ggplot2::geom_line(
+        data = oob_df,
+        ggplot2::aes(x = trees, y = error, color = class), alpha = 0.1
+    ) +
+    # Random forest results (individual lines with low opacity)
+    ggplot2::geom_line(
+        data = random_oob_df,
+        ggplot2::aes(x = trees, y = error, color = class), alpha = 0.1, linetype = "dashed"
+    ) +
+    # Smooth mean lines for original data
+    ggplot2::geom_line(
+        data = mean_oob_df,
+        ggplot2::aes(x = trees, y = mean_error, color = class), size = 1.5
+    ) +
+    # Smooth mean lines for randomized data
+    ggplot2::geom_line(
+        data = mean_random_oob_df,
+        ggplot2::aes(x = trees, y = mean_error, color = class), size = 1.5,
+        linetype = "dashed"
+    ) +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(
+        title = "OOB error rate (Solid: Original, Dashed: Randomized)",
+        x = "Number of trees", y = "Error rate"
+    ) +
+    ggplot2::scale_color_manual(values = c(
+        "OOB" = "#4e4e4e",
+        "immigrant" = "#5d8566",
+        "resident" = "#c29007"
+    )) +
+    ggplot2::coord_cartesian(ylim = c(0, 100)) +
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "red") +
+    ggplot2::theme(
+        aspect.ratio = 1,
+        text = ggplot2::element_text(size = 12)
+    )

# time: 2024-08-29 15:43:43 UTC
# mode: r
+all.id <- gdsfmt::read.gdsn(gdsfmt::index.gdsn(all.maf, "sample.id"))
+
+# Subsample data to balance immigrant and resident samples
+min_samples <- min(length(immigrant.id), length(resident.id))
+all.id <- c(sample(immigrant.id, min_samples), sample(resident.id, min_samples))
+all.label <- ifelse(all.id %in% immigrant.id, "immigrant", "resident")
+
+# Split data into training and testing sets
+num_train <- round(length(all.id) * percent.train)
+train.id <- sample(all.id, num_train)
+test.id <- setdiff(all.id, train.id)
+
+train.label <- all.label[all.id %in% train.id]
+test.label <- all.label[all.id %in% test.id]
+
+# Check proportions
+prop_train <- table(train.label) / length(train.label)
+prop_test <- table(test.label) / length(test.label)
+
+# Verify no overlap between train and test sets
+if (length(intersect(train.id, test.id)) > 0) stop("Overlap between train and test sets")
+
+# Reduce dimensionality via pca
+num.threads <- 4
+pca <- SNPRelate::snpgdsPCA(all.maf, sample.id = train.id, num.thread = num.threads)
+
+tab <- data.frame(sample.id = pca$sample.id, pop = factor(train.label), EV1 = pca$eigenvect[, 1], EV2 = pca$eigenvect[, 2], stringsAsFactors = FALSE)
+
+
+# Calculate SNP loadings
+snp_loadings <- SNPRelate::snpgdsPCASNPLoading(pca, all.maf, num.thread = num.threads)
+
+# Calculate sample loadings for testing set using SNP loadings
+sample_loadings <- SNPRelate::snpgdsPCASampLoading(snp_loadings, all.maf, sample.id = test.id, num.thread = num.threads)
+
+# Extract list of SNPs used in PCA
+snpset.id <- unlist(all.maf)
+snp_list <- SNPRelate::snpgdsSNPList(all.maf)
+snp_rs_id <- snp_list$snp.id[pca$snp.id]
+snp_chrom <- snp_list$chromosome[pca$snp.id]
+snp_pos <- snp_list$position[pca$snp.id]
+
+# Create dataframe with one SNP per row
+snp_df <- data.frame(snp_rs_id, snp_chrom, snp_pos)
+
+# Transpose SNP loading table
+snp_loadings_transposed <- t(snp_loadings$snploading)
+
+# Match SNPs with loading vectors
+loading_mat <- data.frame(snp_df, snp_loadings_transposed[, 1:num.eigenvectors])
+
+# Write loading data frame to file
+
+# Create data frames, where sample is paired with eigenvectors
+train_eigenvects <- data.frame(pca$sample.id, pca$eigenvect[, 1:num.eigenvectors])
+test_eigenvects <- data.frame(sample_loadings$sample.id, sample_loadings$eigenvect[, 1:num.eigenvectors])
+
+# Ensure sample.id column is same for all data frames
+colnames(train_eigenvects)[1] <- "sample.id"
+colnames(test_eigenvects)[1] <- "sample.id"
+
+# Create a dataframe with 'sample.id' and 'pop' columns
+sample.info <- data.frame(sample.id = all.id, pop = all.label)
+
+# Merge data frames
+train_df <- merge(sample.info, train_eigenvects)
+test_df <- merge(sample.info, test_eigenvects)
+
+
+# Function to train a random forest with optional randomized labels
+train_random_forest <- function(
+    train_df,
+    test_df,
+    num.eigenvectors,
+    randomize_labels = FALSE) {
+    if (randomize_labels) {
+        # Randomize training labels
+        train_df$random_pop <- sample(train_df$pop)
+        y_train <- as.factor(train_df$random_pop)
+    } else {
+        y_train <- as.factor(train_df$pop)
+    }
+
+    # Train random forest
+    rf <- randomForest::randomForest(
+        train_df[, (num.eigenvectors - 2):(2 + num.eigenvectors)],
+        y = y_train,
+        data = train_df,
+        xtest = test_df[, (num.eigenvectors - 2):(2 + num.eigenvectors)],
+        ytest = as.factor(test_df$pop),
+        ntree = 500,
+        replace = FALSE,
+        proximity = TRUE
+    )
+
+    return(rf)
+}
+
+oob_sum <- function(...) { # This is so stupid omg
+    png(tempfile(fileext = ".png"))
+    sink("file")
+    xt <- summary(...)
+    dev.off()
+    sink()
+    return(xt$data)
+}
+
+
+# Print confusion matrix
+# rfPermute::confusionMatrix(output.forest)
+# rfPermute::plotPredictedProbs(output.forest, bins = 20, plot = TRUE)
+# rfPermute::plotProximity(output.forest)
+
+
+# Train 100 random forests with randomized labels
+set.seed(123) # For reproducibility
+randrandf <- replicate(20, train_random_forest(
+    train_df, test_df, num.eigenvectors,
+    randomize_labels = TRUE
+),
+simplify = FALSE
+)
+# Extract OOB error rates
+random_oob_data <- lapply(randrandf, function(rf) {
+    oob_sum(rf)
+})
+
+random_oob_df <- dplyr::as_tibble(do.call(rbind, random_oob_data))
+
+
+# Train 100 random forests with original labels
+set.seed(123) # For reproducibility
+randf <- replicate(20, train_random_forest(
+    train_df, test_df, num.eigenvectors,
+    randomize_labels = FALSE
+),
+simplify = FALSE
+)
+
+# Extract OOB error rates
+oob_data <- lapply(randf, function(rf) {
+    oob_sum(rf)
+})
+
+oob_df <- dplyr::as_tibble(do.call(rbind, oob_data))
+
+
+# Calculate mean error for original data
+mean_oob_df <- oob_df |>
+    dplyr::group_by(trees, class) |>
+    dplyr::summarise(mean_error = mean(error), .groups = "drop")
+
+# Calculate mean error for randomized data
+mean_random_oob_df <- random_oob_df |>
+    dplyr::group_by(trees, class) |>
+    dplyr::summarise(mean_error = mean(error), .groups = "drop")
+
+# Add random forest results to the plot
+ggplot2::ggplot() +
+    # Original data (individual lines with low opacity)
+    ggplot2::geom_line(
+        data = oob_df,
+        ggplot2::aes(x = trees, y = error, color = class), alpha = 0.1
+    ) +
+    # Random forest results (individual lines with low opacity)
+    ggplot2::geom_line(
+        data = random_oob_df,
+        ggplot2::aes(x = trees, y = error, color = class), alpha = 0.1, linetype = "dashed"
+    ) +
+    # Smooth mean lines for original data
+    ggplot2::geom_line(
+        data = mean_oob_df,
+        ggplot2::aes(x = trees, y = mean_error, color = class), size = 1.5
+    ) +
+    # Smooth mean lines for randomized data
+    ggplot2::geom_line(
+        data = mean_random_oob_df,
+        ggplot2::aes(x = trees, y = mean_error, color = class), size = 1.5,
+        linetype = "dashed"
+    ) +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(
+        title = "OOB error rate (Solid: Original, Dashed: Randomized)",
+        x = "Number of trees", y = "Error rate"
+    ) +
+    ggplot2::scale_color_manual(values = c(
+        "OOB" = "#4e4e4e",
+        "immigrant" = "#5d8566",
+        "resident" = "#c29007"
+    )) +
+    ggplot2::coord_cartesian(ylim = c(0, 100)) +
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "red") +
+    ggplot2::theme(
+        aspect.ratio = 1,
+        text = ggplot2::element_text(size = 12)
+    )

# time: 2024-08-29 15:52:27 UTC
# mode: r
+# Function to split data into training and testing sets
+split_data <- function(all.id, all.label, percent.train) {
+    num_train <- round(length(all.id) * percent.train)
+    train.id <- sample(all.id, num_train)
+    test.id <- setdiff(all.id, train.id)
+    train.label <- all.label[all.id %in% train.id]
+    test.label <- all.label[all.id %in% test.id]
+
+    list(
+        train.id = train.id, test.id = test.id,
+        train.label = train.label, test.label = test.label
+    )
+}
+
+# Function to perform PCA and prepare data frames
+prepare_data <- function(all.maf, train.id, test.id, train.label, test.label, num.eigenvectors, num.threads) {
+    pca <- SNPRelate::snpgdsPCA(all.maf, sample.id = train.id, num.thread = num.threads)
+    snp_loadings <- SNPRelate::snpgdsPCASNPLoading(pca, all.maf, num.thread = num.threads)
+    sample_loadings <- SNPRelate::snpgdsPCASampLoading(snp_loadings, all.maf, sample.id = test.id, num.thread = num.threads)
+
+    train_eigenvects <- data.frame(sample.id = pca$sample.id, pca$eigenvect[, 1:num.eigenvectors])
+    test_eigenvects <- data.frame(sample.id = sample_loadings$sample.id, sample_loadings$eigenvect[, 1:num.eigenvectors])
+
+    train_df <- data.frame(sample.id = train.id, pop = train.label, train_eigenvects[, -1])
+    test_df <- data.frame(sample.id = test.id, pop = test.label, test_eigenvects[, -1])
+
+    list(train_df = train_df, test_df = test_df)
+}
+
+# Function to train a random forest with optional randomized labels
+train_random_forest <- function(train_df, test_df, num.eigenvectors, randomize_labels = FALSE) {
+    if (randomize_labels) {
+        train_df$pop <- sample(train_df$pop)
+    }
+
+    rf <- randomForest::randomForest(
+        train_df[, 3:(2 + num.eigenvectors)],
+        y = as.factor(train_df$pop),
+        data = train_df,
+        xtest = test_df[, 3:(2 + num.eigenvectors)],
+        ytest = as.factor(test_df$pop),
+        ntree = 500,
+        replace = FALSE,
+        proximity = TRUE
+    )
+
+    return(rf)
+}
+
+# Function to extract OOB error rates
+oob_sum <- function(...) {
+    png(tempfile(fileext = ".png"))
+    sink("file")
+    xt <- summary(...)
+    dev.off()
+    sink()
+    return(xt$data)
+}
+
+# Function to run a single iteration
+run_iteration <- function(all.id, all.label, all.maf, percent.train, num.eigenvectors, num.threads, randomize_labels) {
+    # Split data
+    split <- split_data(all.id, all.label, percent.train)
+
+    # Prepare data
+    data <- prepare_data(all.maf, split$train.id, split$test.id, split$train.label, split$test.label, num.eigenvectors, num.threads)
+
+    # Train random forest
+    rf <- train_random_forest(data$train_df, data$test_df, num.eigenvectors, randomize_labels)
+
+    # Extract OOB error rates
+    oob_data <- oob_sum(rf)
+
+    return(oob_data)
+}
+
+# Main function to run multiple iterations
+run_analysis <- function(all.id, all.label, all.maf, percent.train, num.eigenvectors, num.threads, n_iterations = 20) {
+    set.seed(123) # For reproducibility
+
+    # Run iterations with original labels
+    original_results <- replicate(n_iterations,
+        run_iteration(all.id, all.label, all.maf, percent.train, num.eigenvectors, num.threads, FALSE),
+        simplify = FALSE
+    )
+
+    # Run iterations with randomized labels
+    random_results <- replicate(n_iterations,
+        run_iteration(all.id, all.label, all.maf, percent.train, num.eigenvectors, num.threads, TRUE),
+        simplify = FALSE
+    )
+
+    # Combine results
+    oob_df <- dplyr::as_tibble(do.call(rbind, original_results))
+    random_oob_df <- dplyr::as_tibble(do.call(rbind, random_results))
+
+    list(oob_df = oob_df, random_oob_df = random_oob_df)
+}
+
+# Run the analysis
+results <- run_analysis(all.id, all.label, all.maf, percent.train, num.eigenvectors, num.threads)
+
+# Calculate mean error for original data
+mean_oob_df <- results$oob_df |>
+    dplyr::group_by(trees, class) |>
+    dplyr::summarise(mean_error = mean(error), .groups = "drop")
+
+# Calculate mean error for randomized data
+mean_random_oob_df <- results$random_oob_df |>
+    dplyr::group_by(trees, class) |>
+    dplyr::summarise(mean_error = mean(error), .groups = "drop")
+
+# Create the plot
+ggplot2::ggplot() +
+    ggplot2::geom_line(data = results$oob_df, ggplot2::aes(x = trees, y = error, color = class), alpha = 0.1) +
+    ggplot2::geom_line(data = results$random_oob_df, ggplot2::aes(x = trees, y = error, color = class), alpha = 0.1, linetype = "dashed") +
+    ggplot2::geom_line(data = mean_oob_df, ggplot2::aes(x = trees, y = mean_error, color = class), size = 1.5) +
+    ggplot2::geom_line(data = mean_random_oob_df, ggplot2::aes(x = trees, y = mean_error, color = class), size = 1.5, linetype = "dashed") +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(title = "OOB error rate (Solid: Original, Dashed: Randomized)", x = "Number of trees", y = "Error rate") +
+    ggplot2::scale_color_manual(values = c("OOB" = "#4e4e4e", "immigrant" = "#5d8566", "resident" = "#c29007")) +
+    ggplot2::coord_cartesian(ylim = c(0, 100)) +
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "red") +
+    ggplot2::theme(aspect.ratio = 1, text = ggplot2::element_text(size = 12))

# time: 2024-08-29 16:06:13 UTC
# mode: r
+rfPermute::plotProximity(output.forest)

# time: 2024-08-29 16:06:18 UTC
# mode: r
+rfPermute::plotPredictedProbs(output.forest, bins = 20, plot = TRUE)

# time: 2024-08-29 16:06:23 UTC
# mode: r
+rfPermute::confusionMatrix(output.forest)

# time: 2024-08-29 16:06:25 UTC
# mode: r
+rfPermute::plotPredictedProbs(output.forest, bins = 20, plot = TRUE)

# time: 2024-08-29 16:06:33 UTC
# mode: r
+summary(output.forest)

# time: 2024-08-29 16:07:49 UTC
# mode: r
+ggplot2::ggplot() +
+    ggplot2::geom_line(data = results$oob_df, ggplot2::aes(x = trees, y = error, color = class), alpha = 0.1) +
+    ggplot2::geom_line(data = results$random_oob_df, ggplot2::aes(x = trees, y = error, color = class), alpha = 0.1, linetype = "dashed") +
+    ggplot2::geom_line(data = mean_oob_df, ggplot2::aes(x = trees, y = mean_error, color = class), size = 1.5) +
+    ggplot2::geom_line(data = mean_random_oob_df, ggplot2::aes(x = trees, y = mean_error, color = class), size = 1.5, linetype = "dashed") +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(title = "OOB error rate (Solid: Original, Dashed: Randomized)", x = "Number of trees", y = "Percent correct") +
+    ggplot2::scale_color_manual(values = c("OOB" = "#4e4e4e", "immigrant" = "#5d8566", "resident" = "#c29007")) +
+    ggplot2::coord_cartesian(ylim = c(0, 100)) +
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "red") +
+    ggplot2::theme(aspect.ratio = 1, text = ggplot2::element_text(size = 12)) +
+    ggplot2::scale_y_continuous(labels = scales::percent_format())

# time: 2024-08-29 16:10:03 UTC
# mode: r
+ggplot2::ggplot() +
+    ggplot2::geom_line(data = results$oob_df, ggplot2::aes(
+        x = trees, y = error, color = class
+    ), alpha = 0.1) +
+    ggplot2::geom_line(data = results$random_oob_df, ggplot2::aes(
+        x = trees, y = error, color = class
+    ), alpha = 0.1, linetype = "dashed") +
+    ggplot2::geom_line(data = mean_oob_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class
+    ), size = 1.5) +
+    ggplot2::geom_line(data = mean_random_oob_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class
+    ), size = 1.5, linetype = "dashed") +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(
+        title = "OOB error rate (Solid: Original, Dashed: Randomized)",
+        x = "Number of trees", y = "Percent correct"
+    ) +
+    ggplot2::scale_color_manual(values = c(
+        "OOB" = "#4e4e4e",
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    ggplot2::coord_cartesian(ylim = c(0, 100)) +
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "red") +
+    ggplot2::theme(aspect.ratio = 1, text = ggplot2::element_text(size = 12))

# time: 2024-08-29 16:10:23 UTC
# mode: r
+# Create the plot
+ggplot2::ggplot() +
+    ggplot2::geom_line(data = results$oob_df, ggplot2::aes(
+        x = trees, y = error, color = class
+    ), alpha = 0.1) +
+    ggplot2::geom_line(data = results$random_oob_df, ggplot2::aes(
+        x = trees, y = error, color = class
+    ), alpha = 0.1, linetype = "dashed") +
+    ggplot2::geom_line(data = mean_oob_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class
+    ), size = 1.5) +
+    ggplot2::geom_line(data = mean_random_oob_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class
+    ), size = 1.5, linetype = "dashed") +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(
+        title = "OOB error rate (Solid: Original, Dashed: Randomized)",
+        x = "Number of trees", y = "Percent correct"
+    ) +
+    ggplot2::scale_color_manual(values = c(
+        "OOB" = "#4e4e4e",
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    ggplot2::coord_cartesian(ylim = c(0, 100)) +
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "red") +
+    ggplot2::theme(aspect.ratio = 1, text = ggplot2::element_text(size = 12)) +
+    ggplot2::scale_y_continuous(labels = scales::percent_format(scale=1))

# time: 2024-08-29 16:13:26 UTC
# mode: r
+rfPermute::varImpPlot(output.forest)

# time: 2024-08-29 16:14:19 UTC
# mode: r
+rfPermute::plotTrace(output.forest)

# time: 2024-08-29 16:15:06 UTC
# mode: r
+# Create the plot
+ggplot2::ggplot() +
+    ggplot2::geom_line(data = results$oob_df, ggplot2::aes(
+        x = trees, y = error, color = class
+    ), alpha = 0.1) +
+    ggplot2::geom_line(data = results$random_oob_df, ggplot2::aes(
+        x = trees, y = error, color = class
+    ), alpha = 0.1, linetype = "dashed") +
+    ggplot2::geom_line(data = mean_oob_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class
+    ), size = 1.5) +
+    ggplot2::geom_line(data = mean_random_oob_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class
+    ), size = 1.5, linetype = "dashed") +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(
+        title = "OOB error rate (Solid: Original, Dashed: Randomized)",
+        x = "Number of trees", y = "Percent correct"
+    ) +
+    ggplot2::scale_color_manual(values = c(
+        "OOB" = "#4e4e4e",
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    ggplot2::coord_cartesian(ylim = c(0, 100)) +
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "red") +
+    ggplot2::theme(aspect.ratio = 1, text = ggplot2::element_text(size = 12)) +
+    ggplot2::scale_y_continuous(labels = scales::percent_format(scale=1))

# time: 2024-08-29 16:15:18 UTC
# mode: r
+# Create the plot
+
+oobplot = 
+ggplot2::ggplot() +
+    ggplot2::geom_line(data = results$oob_df, ggplot2::aes(
+        x = trees, y = error, color = class
+    ), alpha = 0.1) +
+    ggplot2::geom_line(data = results$random_oob_df, ggplot2::aes(
+        x = trees, y = error, color = class
+    ), alpha = 0.1, linetype = "dashed") +
+    ggplot2::geom_line(data = mean_oob_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class
+    ), size = 1.5) +
+    ggplot2::geom_line(data = mean_random_oob_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class
+    ), size = 1.5, linetype = "dashed") +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(
+        title = "OOB error rate (Solid: Original, Dashed: Randomized)",
+        x = "Number of trees", y = "Percent correct"
+    ) +
+    ggplot2::scale_color_manual(values = c(
+        "OOB" = "#4e4e4e",
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    ggplot2::coord_cartesian(ylim = c(0, 100)) +
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "red") +
+    ggplot2::theme(aspect.ratio = 1, text = ggplot2::element_text(size = 12)) +
+    ggplot2::scale_y_continuous(labels = scales::percent_format(scale=1))

# time: 2024-08-29 16:15:26 UTC
# mode: r
+# Save the plot
+ggplot2::ggsave(file.path(config$path$output, "oob_plot.png"), oobplot, width = 8, height = 6)

# time: 2024-08-29 16:15:42 UTC
# mode: r
+config$path$output

# time: 2024-08-29 16:16:16 UTC
# mode: r
+# Save the plot
+ggplot2::ggsave(file.path(config$path$figures, "oob_plot.png"), oobplot, width = 8, height = 6)

# time: 2024-08-29 16:16:38 UTC
# mode: r
+# Save the plot
+ggplot2::ggsave(file.path(config$path$figures, "oob_plot.jpg"), plot =
+    oobplot,
+    width = 8, 
+    height = 6
+)

# time: 2024-08-30 10:05:08 UTC
# mode: r
+# Import configuration file
+config <- config::get()
+
+# parameters
+percent.train <- 0.7
+num.threads <- 44
+num.eigenvectors <- 20
+set.seed(555)
+
+# Input files
+immigrant.info <- file.path(config$path$data, "600K_immigrants.fam")
+immigrant.vcf <- file.path(config$path$data, "600K_immigrants.vcf")
+resident.vcf <- file.path(config$path$data, "600K_residents.vcf")
+
+immigrant.gds <- file.path(config$path$data, "immigrant_recode.gds")
+resident.gds <- file.path(config$path$data, "resident_recode.gds")
+all.gds <- file.path(config$path$data, "all_recode.gds")
+
+# remove any existing gds files before creating new ones
+file.remove(list.files(path = config$path$data, pattern = "*.gds$", full.names = TRUE))
+SNPRelate::snpgdsVCF2GDS(immigrant.vcf, immigrant.gds, method = "biallelic.only")
+SNPRelate::snpgdsVCF2GDS(resident.vcf, resident.gds, method = "biallelic.only")
+gdsfmt::showfile.gds(closeall = TRUE)
+# Append the immigrant and resident data
+SNPRelate::snpgdsCombineGeno(c(immigrant.gds, resident.gds), all.gds)
+
+# Load all the data
+all.maf <- SNPRelate::snpgdsOpen(all.gds)
+
+# Load labels
+immigrant.id <- gdsfmt::read.gdsn(gdsfmt::index.gdsn(
+    SNPRelate::snpgdsOpen(immigrant.gds),
+    "sample.id"
+))
+resident.id <- gdsfmt::read.gdsn(gdsfmt::index.gdsn(
+    SNPRelate::snpgdsOpen(resident.gds),
+    "sample.id"
+))
+
+all.id <- gdsfmt::read.gdsn(gdsfmt::index.gdsn(all.maf, "sample.id"))
+
+
+# Function to split data into training and testing sets
+split_data <- function(all.id, all.label, percent.train) {
+    num_train <- round(length(all.id) * percent.train)
+    train.id <- sample(all.id, num_train)
+    test.id <- setdiff(all.id, train.id)
+    train.label <- all.label[all.id %in% train.id]
+    test.label <- all.label[all.id %in% test.id]
+
+    list(
+        train.id = train.id, test.id = test.id,
+        train.label = train.label, test.label = test.label
+    )
+}
+
+# Function to perform PCA and prepare data frames
+prepare_data <- function(
+    all.maf, train.id, test.id,
+    train.label, test.label, num.eigenvectors, num.threads) {
+    pca <- SNPRelate::snpgdsPCA(
+        all.maf,
+        sample.id = train.id, num.thread = num.threads
+    )
+    snp_loadings <- SNPRelate::snpgdsPCASNPLoading(
+        pca, all.maf,
+        num.thread = num.threads
+    )
+    sample_loadings <- SNPRelate::snpgdsPCASampLoading(
+        snp_loadings, all.maf,
+        sample.id = test.id, num.thread = num.threads
+    )
+
+    train_eigenvects <- data.frame(
+        sample.id = pca$sample.id, pca$eigenvect[, 1:num.eigenvectors]
+    )
+    test_eigenvects <- data.frame(
+        sample.id = sample_loadings$sample.id, sample_loadings$eigenvect[, 1:num.eigenvectors]
+    )
+
+    train_df <- data.frame(sample.id = train.id, pop = train.label, train_eigenvects[, -1])
+    test_df <- data.frame(sample.id = test.id, pop = test.label, test_eigenvects[, -1])
+
+    list(train_df = train_df, test_df = test_df)
+}
+
+# Function to train a random forest with optional randomized labels
+train_random_forest <- function(
+    train_df, test_df, num.eigenvectors, randomize_labels = FALSE
+    ) {
+    if (randomize_labels) {
+        train_df$pop <- sample(train_df$pop)
+    }
+
+    rf <- randomForest::randomForest(
+        train_df[, 3:(2 + num.eigenvectors)],
+        y = as.factor(train_df$pop),
+        data = train_df,
+        xtest = test_df[, 3:(2 + num.eigenvectors)],
+        ytest = as.factor(test_df$pop),
+        ntree = 500,
+        replace = FALSE,
+        proximity = TRUE
+    )
+
+    return(rf)
+}
+
+# Function to extract OOB error rates
+oob_sum <- function(...) {
+    png(tempfile(fileext = ".png"))
+    sink("file")
+    xt <- summary(...)
+    dev.off()
+    sink()
+    return(xt$data)
+}
+
+# Function to run a single iteration
+run_iteration <- function(
+    all.id, all.label, all.maf, percent.train, num.eigenvectors, num.threads, randomize_labels) {
+    # Split data
+    split <- split_data(all.id, all.label, percent.train)
+
+    # Prepare data
+    data <- prepare_data(
+        all.maf, split$train.id, split$test.id, split$train.label, split$test.label, 
+        num.eigenvectors, num.threads
+    )
+
+    # Train random forest
+    rf <- train_random_forest(data$train_df, data$test_df, num.eigenvectors, randomize_labels)
+
+    # Extract OOB error rates
+    oob_data <- oob_sum(rf)
+
+    return(oob_data)
+}
+
+# Main function to run multiple iterations
+run_analysis <- function(
+    all.id, all.label, all.maf, percent.train, 
+    num.eigenvectors, num.threads, 
+    n_iterations = 5) {
+    set.seed(123) # For reproducibility
+
+    # Run iterations with original labels
+    original_results <- replicate(n_iterations,
+        run_iteration(all.id, all.label, all.maf, percent.train, num.eigenvectors, num.threads, FALSE),
+        simplify = FALSE
+    )
+
+    # Run iterations with randomized labels
+    random_results <- replicate(n_iterations,
+        run_iteration(all.id, all.label, all.maf, percent.train, num.eigenvectors, num.threads, TRUE),
+        simplify = FALSE
+    )
+
+    # Combine results
+    oob_df <- dplyr::as_tibble(do.call(rbind, original_results))
+    random_oob_df <- dplyr::as_tibble(do.call(rbind, random_results))
+
+    list(oob_df = oob_df, random_oob_df = random_oob_df)
+}
+
+# Run the analysis
+results <- run_analysis(all.id, all.label, all.maf, percent.train, num.eigenvectors, num.threads)
+
+# Calculate mean error for original data
+mean_oob_df <- results$oob_df |>
+    dplyr::group_by(trees, class) |>
+    dplyr::summarise(mean_error = mean(error), .groups = "drop")
+
+# Calculate mean error for randomized data
+mean_random_oob_df <- results$random_oob_df |>
+    dplyr::group_by(trees, class) |>
+    dplyr::summarise(mean_error = mean(error), .groups = "drop")
+
+# Create the plot
+
+oobplot =
+    ggplot2::ggplot() +
+    ggplot2::geom_line(data = results$oob_df, ggplot2::aes(
+        x = trees, y = error, color = class
+    ), alpha = 0.1) +
+    ggplot2::geom_line(data = results$random_oob_df, ggplot2::aes(
+        x = trees, y = error, color = class
+    ), alpha = 0.1, linetype = "dashed") +
+    ggplot2::geom_line(data = mean_oob_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class
+    ), size = 1.5) +
+    ggplot2::geom_line(data = mean_random_oob_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class
+    ), size = 1.5, linetype = "dashed") +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(
+        title = "OOB error rate (Solid: Original, Dashed: Randomized)",
+        x = "Number of trees", y = "Percent correct"
+    ) +
+    ggplot2::scale_color_manual(values = c(
+        "OOB" = "#4e4e4e",
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    ggplot2::coord_cartesian(ylim = c(0, 100)) +
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "red") +
+    ggplot2::theme(aspect.ratio = 1, text = ggplot2::element_text(size = 12)) +
+    ggplot2::scale_y_continuous(labels = scales::percent_format(scale = 1))
+
+# Save the plot
+ggplot2::ggsave(file.path(config$path$figures, "oob_plot.jpg"),
+    plot =
+        oobplot,
+    width = 8,
+    height = 6
+)
+
+
+# rfPermute::confusionMatrix(output.forest)
+# rfPermute::plotPredictedProbs(output.forest, bins = 20, plot = TRUE)
+# rfPermute::plotProximity(output.forest)
+# summary(output.forest)
+# rfPermute::plotTrace(output.forest)

# time: 2024-08-30 10:09:16 UTC
# mode: r
+# Import configuration file
+config <- config::get()
+
+# parameters
+percent.train <- 0.7
+num.threads <- 44
+num.eigenvectors <- 20
+set.seed(555)
+
+# Input files
+immigrant.info <- file.path(config$path$data, "600K_immigrants.fam")
+immigrant.vcf <- file.path(config$path$data, "600K_immigrants.vcf")
+resident.vcf <- file.path(config$path$data, "600K_residents.vcf")
+
+immigrant.gds <- file.path(config$path$data, "immigrant_recode.gds")
+resident.gds <- file.path(config$path$data, "resident_recode.gds")
+all.gds <- file.path(config$path$data, "all_recode.gds")
+
+# remove any existing gds files before creating new ones
+file.remove(list.files(path = config$path$data, pattern = "*.gds$", full.names = TRUE))
+SNPRelate::snpgdsVCF2GDS(immigrant.vcf, immigrant.gds, method = "biallelic.only")
+SNPRelate::snpgdsVCF2GDS(resident.vcf, resident.gds, method = "biallelic.only")
+gdsfmt::showfile.gds(closeall = TRUE)
+# Append the immigrant and resident data
+SNPRelate::snpgdsCombineGeno(c(immigrant.gds, resident.gds), all.gds)
+
+# Load all the data
+all.maf <- SNPRelate::snpgdsOpen(all.gds)
+
+# Load labels
+immigrant.id <- gdsfmt::read.gdsn(gdsfmt::index.gdsn(
+    SNPRelate::snpgdsOpen(immigrant.gds),
+    "sample.id"
+))
+resident.id <- gdsfmt::read.gdsn(gdsfmt::index.gdsn(
+    SNPRelate::snpgdsOpen(resident.gds),
+    "sample.id"
+))
+
+all.id <- gdsfmt::read.gdsn(gdsfmt::index.gdsn(all.maf, "sample.id"))
+all.label <- ifelse(all.id %in% immigrant.id, "immigrant", "resident")
+
+
+# Function to split data into training and testing sets
+split_data <- function(all.id, all.label, percent.train) {
+    num_train <- round(length(all.id) * percent.train)
+    train.id <- sample(all.id, num_train)
+    test.id <- setdiff(all.id, train.id)
+    train.label <- all.label[all.id %in% train.id]
+    test.label <- all.label[all.id %in% test.id]
+
+    list(
+        train.id = train.id, test.id = test.id,
+        train.label = train.label, test.label = test.label
+    )
+}
+
+# Function to perform PCA and prepare data frames
+prepare_data <- function(
+    all.maf, train.id, test.id,
+    train.label, test.label, num.eigenvectors, num.threads) {
+    pca <- SNPRelate::snpgdsPCA(
+        all.maf,
+        sample.id = train.id, num.thread = num.threads
+    )
+    snp_loadings <- SNPRelate::snpgdsPCASNPLoading(
+        pca, all.maf,
+        num.thread = num.threads
+    )
+    sample_loadings <- SNPRelate::snpgdsPCASampLoading(
+        snp_loadings, all.maf,
+        sample.id = test.id, num.thread = num.threads
+    )
+
+    train_eigenvects <- data.frame(
+        sample.id = pca$sample.id, pca$eigenvect[, 1:num.eigenvectors]
+    )
+    test_eigenvects <- data.frame(
+        sample.id = sample_loadings$sample.id, sample_loadings$eigenvect[, 1:num.eigenvectors]
+    )
+
+    train_df <- data.frame(sample.id = train.id, pop = train.label, train_eigenvects[, -1])
+    test_df <- data.frame(sample.id = test.id, pop = test.label, test_eigenvects[, -1])
+
+    list(train_df = train_df, test_df = test_df)
+}
+
+# Function to train a random forest with optional randomized labels
+train_random_forest <- function(
+    train_df, test_df, num.eigenvectors, randomize_labels = FALSE
+    ) {
+    if (randomize_labels) {
+        train_df$pop <- sample(train_df$pop)
+    }
+
+    rf <- randomForest::randomForest(
+        train_df[, 3:(2 + num.eigenvectors)],
+        y = as.factor(train_df$pop),
+        data = train_df,
+        xtest = test_df[, 3:(2 + num.eigenvectors)],
+        ytest = as.factor(test_df$pop),
+        ntree = 500,
+        replace = FALSE,
+        proximity = TRUE
+    )
+
+    return(rf)
+}
+
+# Function to extract OOB error rates
+oob_sum <- function(...) {
+    png(tempfile(fileext = ".png"))
+    sink("file")
+    xt <- summary(...)
+    dev.off()
+    sink()
+    return(xt$data)
+}
+
+# Function to run a single iteration
+run_iteration <- function(
+    all.id, all.label, all.maf, percent.train, num.eigenvectors, num.threads, randomize_labels) {
+    # Split data
+    split <- split_data(all.id, all.label, percent.train)
+
+    # Prepare data
+    data <- prepare_data(
+        all.maf, split$train.id, split$test.id, split$train.label, split$test.label, 
+        num.eigenvectors, num.threads
+    )
+
+    # Train random forest
+    rf <- train_random_forest(data$train_df, data$test_df, num.eigenvectors, randomize_labels)
+
+    # Extract OOB error rates
+    oob_data <- oob_sum(rf)
+
+    return(oob_data)
+}
+
+# Main function to run multiple iterations
+run_analysis <- function(
+    all.id, all.label, all.maf, percent.train, 
+    num.eigenvectors, num.threads, 
+    n_iterations = 5) {
+    set.seed(123) # For reproducibility
+
+    # Run iterations with original labels
+    original_results <- replicate(n_iterations,
+        run_iteration(all.id, all.label, all.maf, percent.train, num.eigenvectors, num.threads, FALSE),
+        simplify = FALSE
+    )
+
+    # Run iterations with randomized labels
+    random_results <- replicate(n_iterations,
+        run_iteration(all.id, all.label, all.maf, percent.train, num.eigenvectors, num.threads, TRUE),
+        simplify = FALSE
+    )
+
+    # Combine results
+    oob_df <- dplyr::as_tibble(do.call(rbind, original_results))
+    random_oob_df <- dplyr::as_tibble(do.call(rbind, random_results))
+
+    list(oob_df = oob_df, random_oob_df = random_oob_df)
+}
+
+# Run the analysis
+results <- run_analysis(all.id, all.label, all.maf, percent.train, num.eigenvectors, num.threads)
+
+# Calculate mean error for original data
+mean_oob_df <- results$oob_df |>
+    dplyr::group_by(trees, class) |>
+    dplyr::summarise(mean_error = mean(error), .groups = "drop")
+
+# Calculate mean error for randomized data
+mean_random_oob_df <- results$random_oob_df |>
+    dplyr::group_by(trees, class) |>
+    dplyr::summarise(mean_error = mean(error), .groups = "drop")
+
+# Create the plot
+
+oobplot =
+    ggplot2::ggplot() +
+    ggplot2::geom_line(data = results$oob_df, ggplot2::aes(
+        x = trees, y = error, color = class
+    ), alpha = 0.1) +
+    ggplot2::geom_line(data = results$random_oob_df, ggplot2::aes(
+        x = trees, y = error, color = class
+    ), alpha = 0.1, linetype = "dashed") +
+    ggplot2::geom_line(data = mean_oob_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class
+    ), size = 1.5) +
+    ggplot2::geom_line(data = mean_random_oob_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class
+    ), size = 1.5, linetype = "dashed") +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(
+        title = "OOB error rate (Solid: Original, Dashed: Randomized)",
+        x = "Number of trees", y = "Percent correct"
+    ) +
+    ggplot2::scale_color_manual(values = c(
+        "OOB" = "#4e4e4e",
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    ggplot2::coord_cartesian(ylim = c(0, 100)) +
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "red") +
+    ggplot2::theme(aspect.ratio = 1, text = ggplot2::element_text(size = 12)) +
+    ggplot2::scale_y_continuous(labels = scales::percent_format(scale = 1))
+
+# Save the plot
+ggplot2::ggsave(file.path(config$path$figures, "oob_plot.jpg"),
+    plot =
+        oobplot,
+    width = 8,
+    height = 6
+)
+
+
+# rfPermute::confusionMatrix(output.forest)
+# rfPermute::plotPredictedProbs(output.forest, bins = 20, plot = TRUE)
+# rfPermute::plotProximity(output.forest)
+# summary(output.forest)
+# rfPermute::plotTrace(output.forest)

# time: 2024-08-30 10:11:22 UTC
# mode: r
+results

# time: 2024-08-30 10:11:33 UTC
# mode: r
+original_results <- replicate(n_iterations,
+        run_iteration(all.id, all.label, all.maf, percent.train, num.eigenvectors, num.threads, FALSE),
+        simplify = FALSE
+    )

# time: 2024-08-30 10:12:17 UTC
# mode: r
+all.id

# time: 2024-08-30 10:12:22 UTC
# mode: r
+all.label

# time: 2024-08-30 10:12:42 UTC
# mode: r
+split_data(all.id, all.label, percent.train)

# time: 2024-08-30 10:14:57 UTC
# mode: r
+source("/home/nilomr/projects/greti-genomics/main.R", encoding = "UTF-8")

# time: 2024-08-30 10:19:23 UTC
# mode: r
+renv::install('vscdebugger')

# time: 2024-08-30 10:19:53 UTC
# mode: r
+renv::install('vscDebugger')

# time: 2024-08-30 10:22:37 UTC
# mode: r
+renv::paths$library()

# time: 2024-08-30 10:35:38 UTC
# mode: r
+source("/home/nilomr/projects/greti-genomics/0-read-data.R", encoding = "UTF-8")

# time: 2024-08-30 10:36:46 UTC
# mode: r
+# Import configuration file
+config <- config::get()
+
+# parameters
+percent.train <- 0.7
+num.threads <- 44
+num.eigenvectors <- 20
+set.seed(555)
+
+# Input files
+immigrant.info <- file.path(config$path$data, "600K_immigrants.fam")
+immigrant.vcf <- file.path(config$path$data, "600K_immigrants.vcf")
+resident.vcf <- file.path(config$path$data, "600K_residents.vcf")
+
+immigrant.gds <- file.path(config$path$data, "immigrant_recode.gds")
+resident.gds <- file.path(config$path$data, "resident_recode.gds")
+all.gds <- file.path(config$path$data, "all_recode.gds")
+
+
+# Load all the data
+all.maf <- SNPRelate::snpgdsOpen(all.gds)
+
+# Load labels
+immigrant.id <- gdsfmt::read.gdsn(gdsfmt::index.gdsn(
+    SNPRelate::snpgdsOpen(immigrant.gds),
+    "sample.id"
+))
+resident.id <- gdsfmt::read.gdsn(gdsfmt::index.gdsn(
+    SNPRelate::snpgdsOpen(resident.gds),
+    "sample.id"
+))
+
+all.id <- gdsfmt::read.gdsn(gdsfmt::index.gdsn(all.maf, "sample.id"))
+all.label <- ifelse(all.id %in% immigrant.id, "immigrant", "resident")
+
+
+# Function to split data into training and testing sets
+# TODO balence so that .5 per class
+split_data <- function(all.id, all.label, percent.train) {
+    num_train <- round(length(all.id) * percent.train)
+    train.id <- sample(all.id, num_train)
+    test.id <- setdiff(all.id, train.id)
+    train.label <- all.label[all.id %in% train.id]
+    test.label <- all.label[all.id %in% test.id]
+
+    list(
+        train.id = train.id, test.id = test.id,
+        train.label = train.label, test.label = test.label
+    )
+}
+
+# Function to perform PCA and prepare data frames
+prepare_data <- function(
+    all.maf, train.id, test.id,
+    train.label, test.label, num.eigenvectors, num.threads) {
+    pca <- SNPRelate::snpgdsPCA(
+        all.maf,
+        sample.id = train.id, num.thread = num.threads
+    )
+    snp_loadings <- SNPRelate::snpgdsPCASNPLoading(
+        pca, all.maf,
+        num.thread = num.threads
+    )
+    sample_loadings <- SNPRelate::snpgdsPCASampLoading(
+        snp_loadings, all.maf,
+        sample.id = test.id, num.thread = num.threads
+    )
+
+    train_eigenvects <- data.frame(
+        sample.id = pca$sample.id, pca$eigenvect[, 1:num.eigenvectors]
+    )
+    test_eigenvects <- data.frame(
+        sample.id = sample_loadings$sample.id, sample_loadings$eigenvect[, 1:num.eigenvectors]
+    )
+
+    train_df <- data.frame(sample.id = train.id, pop = train.label, train_eigenvects[, -1])
+    test_df <- data.frame(sample.id = test.id, pop = test.label, test_eigenvects[, -1])
+
+    list(train_df = train_df, test_df = test_df)
+}
+
+# Function to train a random forest with optional randomized labels
+train_random_forest <- function(
+    train_df, test_df, num.eigenvectors, randomize_labels = FALSE) {
+    if (randomize_labels) {
+        train_df$pop <- sample(train_df$pop)
+    }
+
+    rf <- randomForest::randomForest(
+        train_df[, 3:(2 + num.eigenvectors)],
+        y = as.factor(train_df$pop),
+        data = train_df,
+        xtest = test_df[, 3:(2 + num.eigenvectors)],
+        ytest = as.factor(test_df$pop),
+        ntree = 500,
+        replace = FALSE,
+        proximity = TRUE
+    )
+
+    return(rf)
+}
+
+
+
+# Function to run a single iteration
+run_iteration <- function(
+    all.id, all.label, all.maf, percent.train, num.eigenvectors, num.threads, randomize_labels) {
+    # Split data
+    split <- split_data(all.id, all.label, percent.train)
+
+    # Prepare data
+    data <- prepare_data(
+        all.maf, split$train.id, split$test.id, split$train.label, split$test.label,
+        num.eigenvectors, num.threads
+    )
+
+    # Train random forest
+    rf <- train_random_forest(data$train_df, data$test_df, num.eigenvectors, randomize_labels)
+
+    # Extract OOB error rates
+    oob_data <- rfPermute::plotTrace(rf, plot = FALSE)$data
+
+    return(oob_data)
+}
+
+# Main function to run multiple iterations
+run_analysis <- function(
+    all.id, all.label, all.maf, percent.train,
+    num.eigenvectors, num.threads,
+    n_iterations = 5) {
+    set.seed(123) # For reproducibility
+
+    # Run iterations with original labels
+    original_results <- replicate(n_iterations,
+        run_iteration(all.id, all.label, all.maf, percent.train, num.eigenvectors, num.threads, FALSE),
+        simplify = FALSE
+    )
+
+    # Run iterations with randomized labels
+    random_results <- replicate(n_iterations,
+        run_iteration(all.id, all.label, all.maf, percent.train, num.eigenvectors, num.threads, TRUE),
+        simplify = FALSE
+    )
+
+    # Combine results
+    oob_df <- dplyr::as_tibble(do.call(rbind, original_results))
+    random_oob_df <- dplyr::as_tibble(do.call(rbind, random_results))
+
+    list(oob_df = oob_df, random_oob_df = random_oob_df)
+}
+
+# Run the analysis
+results <- run_analysis(all.id, all.label, all.maf, percent.train, num.eigenvectors, num.threads)
+
+# Calculate mean error for original data
+mean_oob_df <- results$oob_df |>
+    dplyr::group_by(trees, class) |>
+    dplyr::summarise(mean_error = mean(error), .groups = "drop")
+
+# Calculate mean error for randomized data
+mean_random_oob_df <- results$random_oob_df |>
+    dplyr::group_by(trees, class) |>
+    dplyr::summarise(mean_error = mean(error), .groups = "drop")
+
+# Create the plot
+
+oobplot =
+    ggplot2::ggplot() +
+    ggplot2::geom_line(data = results$oob_df, ggplot2::aes(
+        x = trees, y = error, color = class
+    ), alpha = 0.1) +
+    ggplot2::geom_line(data = results$random_oob_df, ggplot2::aes(
+        x = trees, y = error, color = class
+    ), alpha = 0.1, linetype = "dashed") +
+    ggplot2::geom_line(data = mean_oob_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class
+    ), size = 1.5) +
+    ggplot2::geom_line(data = mean_random_oob_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class
+    ), size = 1.5, linetype = "dashed") +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(
+        title = "OOB error rate (Solid: Original, Dashed: Randomized)",
+        x = "Number of trees", y = "Percent correct"
+    ) +
+    ggplot2::scale_color_manual(values = c(
+        "OOB" = "#4e4e4e",
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    ggplot2::coord_cartesian(ylim = c(0, 100)) +
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "red") +
+    ggplot2::theme(aspect.ratio = 1, text = ggplot2::element_text(size = 12)) +
+    ggplot2::scale_y_continuous(labels = scales::percent_format(scale = 1))
+
+# Save the plot
+ggplot2::ggsave(file.path(config$path$figures, "oob_plot.jpg"),
+    plot =
+        oobplot,
+    width = 8,
+    height = 6
+)
+
+
+# rfPermute::confusionMatrix(output.forest)
+# rfPermute::plotPredictedProbs(output.forest, bins = 20, plot = TRUE)
+# rfPermute::plotProximity(output.forest)
+# summary(output.forest)
+# rfPermute::plotTrace(output.forest)

# time: 2024-08-30 10:41:05 UTC
# mode: r
+# Create the plot
+
+oobplot =
+    ggplot2::ggplot() +
+    ggplot2::geom_line(data = results$oob_df, ggplot2::aes(
+        x = trees, y = error, color = class
+    ), alpha = 0.1) +
+    ggplot2::geom_line(data = results$random_oob_df, ggplot2::aes(
+        x = trees, y = error, color = class
+    ), alpha = 0.1, linetype = "dashed") +
+    ggplot2::geom_line(data = mean_oob_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class
+    ), linewidth = 1.5) +
+    ggplot2::geom_line(data = mean_random_oob_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class
+    ), linewidth = 1.5, linetype = "dashed") +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(
+        title = "OOB error rate (Solid: Original, Dashed: Randomized)",
+        x = "Number of trees", y = "Percent correct"
+    ) +
+    ggplot2::scale_color_manual(values = c(
+        "OOB" = "#4e4e4e",
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    ggplot2::coord_cartesian(ylim = c(0, 100)) +
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "red") +
+    ggplot2::theme(aspect.ratio = 1, text = ggplot2::element_text(linewidth = 12)) +
+    ggplot2::scale_y_continuous(labels = scales::percent_format(scale = 1))

# time: 2024-08-30 10:41:18 UTC
# mode: r
+# Create the plot
+
+oobplot <-
+    ggplot2::ggplot() +
+    ggplot2::geom_line(data = results$oob_df, ggplot2::aes(
+        x = trees, y = error, color = class
+    ), alpha = 0.1) +
+    ggplot2::geom_line(data = results$random_oob_df, ggplot2::aes(
+        x = trees, y = error, color = class
+    ), alpha = 0.1, linetype = "dashed") +
+    ggplot2::geom_line(data = mean_oob_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class
+    ), linewidth = 1.5) +
+    ggplot2::geom_line(data = mean_random_oob_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class
+    ), linewidth = 1.5, linetype = "dashed") +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(
+        title = "OOB error rate (Solid: Original, Dashed: Randomized)",
+        x = "Number of trees", y = "Percent correct"
+    ) +
+    ggplot2::scale_color_manual(values = c(
+        "OOB" = "#4e4e4e",
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    ggplot2::coord_cartesian(ylim = c(0, 100)) +
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "red") +
+    ggplot2::theme(aspect.ratio = 1, text = ggplot2::element_text(size = 12)) +
+    ggplot2::scale_y_continuous(labels = scales::percent_format(scale = 1))

# time: 2024-08-30 10:41:20 UTC
# mode: r
+# Save the plot
+ggplot2::ggsave(file.path(config$path$figures, "oob_plot.jpg"),
+    plot =
+        oobplot,
+    width = 8,
+    height = 6
+)

# time: 2024-08-30 10:42:01 UTC
# mode: r
+results

# time: 2024-08-30 10:42:37 UTC
# mode: r
+# Create the plot
+
+oobplot <-
+    ggplot2::ggplot() +
+    ggplot2::geom_line(data = results$oob_df, ggplot2::aes(
+        x = trees, y = error, color = class
+    ), alpha = 0.1) +
+    ggplot2::geom_line(data = results$random_oob_df, ggplot2::aes(
+        x = trees, y = error, color = class
+    ), alpha = 0.1, linetype = "dashed") +
+    ggplot2::geom_line(data = mean_oob_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class
+    ), linewidth = 1.5) +
+    ggplot2::geom_line(data = mean_random_oob_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class
+    ), linewidth = 1.5, linetype = "dashed") +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(
+        title = "OOB error rate (Solid: Original, Dashed: Randomized)",
+        x = "Number of trees", y = "Percent correct"
+    ) +
+    ggplot2::scale_color_manual(values = c(
+        "OOB" = "#4e4e4e",
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    ggplot2::coord_cartesian(ylim = c(0, 100)) +
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "red") +
+    ggplot2::theme(aspect.ratio = 1, text = ggplot2::element_text(size = 12))

# time: 2024-08-30 10:42:38 UTC
# mode: r
+#ggplot2::scale_y_continuous(labels = scales::percent_format(scale = 1))
+
+# Save the plot
+ggplot2::ggsave(file.path(config$path$figures, "oob_plot.jpg"),
+    plot =
+        oobplot,
+    width = 8,
+    height = 6
+)

# time: 2024-08-30 10:42:49 UTC
# mode: r
+mean_oob_df

# time: 2024-08-30 10:42:55 UTC
# mode: r
+mean_random_oob_df

# time: 2024-08-30 10:43:46 UTC
# mode: r
+all.label

# time: 2024-08-30 10:43:53 UTC
# mode: r
+all.id

# time: 2024-08-30 10:46:18 UTC
# mode: r
+# Import configuration file
+config <- config::get()
+
+# parameters
+percent.train <- 0.7
+num.threads <- 44
+num.eigenvectors <- 20
+set.seed(555)
+
+# Input files
+immigrant.info <- file.path(config$path$data, "600K_immigrants.fam")
+immigrant.vcf <- file.path(config$path$data, "600K_immigrants.vcf")
+resident.vcf <- file.path(config$path$data, "600K_residents.vcf")
+
+immigrant.gds <- file.path(config$path$data, "immigrant_recode.gds")
+resident.gds <- file.path(config$path$data, "resident_recode.gds")
+all.gds <- file.path(config$path$data, "all_recode.gds")
+
+
+# Load all the data
+all.maf <- SNPRelate::snpgdsOpen(all.gds)
+
+# Load labels
+immigrant.id <- gdsfmt::read.gdsn(gdsfmt::index.gdsn(
+    SNPRelate::snpgdsOpen(immigrant.gds),
+    "sample.id"
+))
+resident.id <- gdsfmt::read.gdsn(gdsfmt::index.gdsn(
+    SNPRelate::snpgdsOpen(resident.gds),
+    "sample.id"
+))
+
+all.id <- gdsfmt::read.gdsn(gdsfmt::index.gdsn(all.maf, "sample.id"))
+all.label <- ifelse(all.id %in% immigrant.id, "immigrant", "resident")
+
+
+# Function to split data into training and testing sets
+# TODO balence so that there are .5 per class in both train and test sets
+subset_by_class <- function(ids, labels, num_samples_per_class) {
+    subset_ids <- c()
+    for (class_label in unique(labels)) {
+        class_ids <- ids[labels == class_label]
+        class_ids <- sample(class_ids, num_samples_per_class)
+        subset_ids <- c(subset_ids, class_ids)
+    }
+    subset_ids
+}
+split_data <- function(all.id, all.label, percent.train) {
+    num_train <- round(length(all.id) * percent.train)
+    train.id <- sample(all.id, num_train)
+    test.id <- setdiff(all.id, train.id)
+    
+    # Balance the train and test sets
+    train.label <- all.label[all.id %in% train.id]
+    test.label <- all.label[all.id %in% test.id]
+    
+    # Calculate the number of samples per class
+    num_samples_per_class <- min(table(train.label), table(test.label))
+    
+    # Subset the train and test sets to have equal number of samples per class
+    train.id <- subset_by_class(train.id, train.label, num_samples_per_class)
+    test.id <- subset_by_class(test.id, test.label, num_samples_per_class)
+    
+    list(
+        train.id = train.id, test.id = test.id,
+        train.label = train.label, test.label = test.label
+    )
+}
+
+
+# Function to perform PCA and prepare data frames
+prepare_data <- function(
+    all.maf, train.id, test.id,
+    train.label, test.label, num.eigenvectors, num.threads) {
+    pca <- SNPRelate::snpgdsPCA(
+        all.maf,
+        sample.id = train.id, num.thread = num.threads
+    )
+    snp_loadings <- SNPRelate::snpgdsPCASNPLoading(
+        pca, all.maf,
+        num.thread = num.threads
+    )
+    sample_loadings <- SNPRelate::snpgdsPCASampLoading(
+        snp_loadings, all.maf,
+        sample.id = test.id, num.thread = num.threads
+    )
+
+    train_eigenvects <- data.frame(
+        sample.id = pca$sample.id, pca$eigenvect[, 1:num.eigenvectors]
+    )
+    test_eigenvects <- data.frame(
+        sample.id = sample_loadings$sample.id, sample_loadings$eigenvect[, 1:num.eigenvectors]
+    )
+
+    train_df <- data.frame(sample.id = train.id, pop = train.label, train_eigenvects[, -1])
+    test_df <- data.frame(sample.id = test.id, pop = test.label, test_eigenvects[, -1])
+
+    list(train_df = train_df, test_df = test_df)
+}
+
+# Function to train a random forest with optional randomized labels
+train_random_forest <- function(
+    train_df, test_df, num.eigenvectors, randomize_labels = FALSE) {
+    if (randomize_labels) {
+        train_df$pop <- sample(train_df$pop)
+    }
+
+    rf <- randomForest::randomForest(
+        train_df[, 3:(2 + num.eigenvectors)],
+        y = as.factor(train_df$pop),
+        data = train_df,
+        xtest = test_df[, 3:(2 + num.eigenvectors)],
+        ytest = as.factor(test_df$pop),
+        ntree = 500,
+        replace = FALSE,
+        proximity = TRUE
+    )
+
+    return(rf)
+}
+
+
+
+# Function to run a single iteration
+run_iteration <- function(
+    all.id, all.label, all.maf, percent.train, num.eigenvectors, num.threads, randomize_labels) {
+    # Split data
+    split <- split_data(all.id, all.label, percent.train)
+
+    # Prepare data
+    data <- prepare_data(
+        all.maf, split$train.id, split$test.id, split$train.label, split$test.label,
+        num.eigenvectors, num.threads
+    )
+
+    # Train random forest
+    rf <- train_random_forest(data$train_df, data$test_df, num.eigenvectors, randomize_labels)
+
+    # Extract OOB error rates
+    oob_data <- rfPermute::plotTrace(rf, plot = FALSE)$data
+
+    return(oob_data)
+}
+
+# Main function to run multiple iterations
+run_analysis <- function(
+    all.id, all.label, all.maf, percent.train,
+    num.eigenvectors, num.threads,
+    n_iterations = 5) {
+    set.seed(123) # For reproducibility
+
+    # Run iterations with original labels
+    original_results <- replicate(n_iterations,
+        run_iteration(all.id, all.label, all.maf, percent.train, num.eigenvectors, num.threads, FALSE),
+        simplify = FALSE
+    )
+
+    # Run iterations with randomized labels
+    random_results <- replicate(n_iterations,
+        run_iteration(all.id, all.label, all.maf, percent.train, num.eigenvectors, num.threads, TRUE),
+        simplify = FALSE
+    )
+
+    # Combine results
+    oob_df <- dplyr::as_tibble(do.call(rbind, original_results))
+    random_oob_df <- dplyr::as_tibble(do.call(rbind, random_results))
+
+    list(oob_df = oob_df, random_oob_df = random_oob_df)
+}
+
+# Run the analysis
+results <- run_analysis(all.id, all.label, all.maf, percent.train, num.eigenvectors, num.threads)
+
+# Calculate mean error for original data
+mean_oob_df <- results$oob_df |>
+    dplyr::group_by(trees, class) |>
+    dplyr::summarise(mean_error = mean(error), .groups = "drop")
+
+# Calculate mean error for randomized data
+mean_random_oob_df <- results$random_oob_df |>
+    dplyr::group_by(trees, class) |>
+    dplyr::summarise(mean_error = mean(error), .groups = "drop")
+
+# Create the plot
+
+oobplot <-
+    ggplot2::ggplot() +
+    ggplot2::geom_line(data = results$oob_df, ggplot2::aes(
+        x = trees, y = error, color = class
+    ), alpha = 0.1) +
+    ggplot2::geom_line(data = results$random_oob_df, ggplot2::aes(
+        x = trees, y = error, color = class
+    ), alpha = 0.1, linetype = "dashed") +
+    ggplot2::geom_line(data = mean_oob_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class
+    ), linewidth = 1.5) +
+    ggplot2::geom_line(data = mean_random_oob_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class
+    ), linewidth = 1.5, linetype = "dashed") +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(
+        title = "OOB error rate (Solid: Original, Dashed: Randomized)",
+        x = "Number of trees", y = "Percent correct"
+    ) +
+    ggplot2::scale_color_manual(values = c(
+        "OOB" = "#4e4e4e",
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    ggplot2::coord_cartesian(ylim = c(0, 100)) +
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "red") +
+    ggplot2::theme(aspect.ratio = 1, text = ggplot2::element_text(size = 12)) +
+    ggplot2::scale_y_continuous(labels = scales::percent_format(scale = 1))
+
+# Save the plot
+ggplot2::ggsave(file.path(config$path$figures, "oob_plot.jpg"),
+    plot =
+        oobplot,
+    width = 8,
+    height = 6
+)
+
+
+# rfPermute::confusionMatrix(output.forest)
+# rfPermute::plotPredictedProbs(output.forest, bins = 20, plot = TRUE)
+# rfPermute::plotProximity(output.forest)
+# summary(output.forest)
+# rfPermute::plotTrace(output.forest)

# time: 2024-08-30 10:56:37 UTC
# mode: r
+# Import configuration file
+config <- config::get()
+
+# parameters
+percent.train <- 0.7
+num.threads <- 44
+num.eigenvectors <- 20
+set.seed(555)
+
+# Input files
+immigrant.info <- file.path(config$path$data, "600K_immigrants.fam")
+immigrant.vcf <- file.path(config$path$data, "600K_immigrants.vcf")
+resident.vcf <- file.path(config$path$data, "600K_residents.vcf")
+
+immigrant.gds <- file.path(config$path$data, "immigrant_recode.gds")
+resident.gds <- file.path(config$path$data, "resident_recode.gds")
+all.gds <- file.path(config$path$data, "all_recode.gds")
+
+
+# Load all the data
+all.maf <- SNPRelate::snpgdsOpen(all.gds)
+
+# Load labels
+immigrant.id <- gdsfmt::read.gdsn(gdsfmt::index.gdsn(
+    SNPRelate::snpgdsOpen(immigrant.gds),
+    "sample.id"
+))
+resident.id <- gdsfmt::read.gdsn(gdsfmt::index.gdsn(
+    SNPRelate::snpgdsOpen(resident.gds),
+    "sample.id"
+))
+
+all.id <- gdsfmt::read.gdsn(gdsfmt::index.gdsn(all.maf, "sample.id"))
+all.label <- ifelse(all.id %in% immigrant.id, "immigrant", "resident")
+
+
+# Function to split data into training and testing sets
+# TODO balence so that there are .5 per class in both train and test sets
+split_data <- function(all.id, all.label, percent.train) {
+    num_train <- round(length(all.id) * percent.train)
+    train.id <- sample(all.id, num_train)
+    test.id <- setdiff(all.id, train.id)
+    train.label <- all.label[all.id %in% train.id]
+    test.label <- all.label[all.id %in% test.id]
+
+    list(
+        train.id = train.id, test.id = test.id,
+        train.label = train.label, test.label = test.label
+    )
+}
+
+# Function to perform PCA and prepare data frames
+prepare_data <- function(all.maf, train.id, test.id, train.label, test.label, num.eigenvectors, num.threads) {
+    print(paste("Number of train.id:", length(train.id)))
+    print(paste("Number of train.label:", length(train.label)))
+
+    pca <- SNPRelate::snpgdsPCA(all.maf, sample.id = train.id, num.thread = num.threads)
+
+    print(paste("Number of pca$sample.id:", length(pca$sample.id)))
+
+    snp_loadings <- SNPRelate::snpgdsPCASNPLoading(pca, all.maf, num.thread = num.threads)
+    sample_loadings <- SNPRelate::snpgdsPCASampLoading(snp_loadings, all.maf, sample.id = test.id, num.thread = num.threads)
+
+    train_eigenvects <- data.frame(sample.id = pca$sample.id, pca$eigenvect[, 1:num.eigenvectors])
+    test_eigenvects <- data.frame(sample.id = sample_loadings$sample.id, sample_loadings$eigenvect[, 1:num.eigenvectors])
+
+    print(paste("Number of rows in train_eigenvects:", nrow(train_eigenvects)))
+
+    train_df <- data.frame(sample.id = train.id, pop = train.label, train_eigenvects[, -1])
+    test_df <- data.frame(sample.id = test.id, pop = test.label, test_eigenvects[, -1])
+
+    list(train_df = train_df, test_df = test_df)
+}
+
+# Function to train a random forest with optional randomized labels
+train_random_forest <- function(
+    train_df, test_df, num.eigenvectors, randomize_labels = FALSE) {
+    if (randomize_labels) {
+        train_df$pop <- sample(train_df$pop)
+    }
+
+    rf <- randomForest::randomForest(
+        train_df[, 3:(2 + num.eigenvectors)],
+        y = as.factor(train_df$pop),
+        data = train_df,
+        xtest = test_df[, 3:(2 + num.eigenvectors)],
+        ytest = as.factor(test_df$pop),
+        ntree = 500,
+        replace = FALSE,
+        proximity = TRUE
+    )
+
+    return(rf)
+}
+
+
+
+# Function to run a single iteration
+run_iteration <- function(
+    all.id, all.label, all.maf, percent.train, num.eigenvectors, num.threads, randomize_labels) {
+    # Split data
+    split <- split_data(all.id, all.label, percent.train)
+
+    # Prepare data
+    data <- prepare_data(
+        all.maf, split$train.id, split$test.id, split$train.label, split$test.label,
+        num.eigenvectors, num.threads
+    )
+
+    # Train random forest
+    rf <- train_random_forest(data$train_df, data$test_df, num.eigenvectors, randomize_labels)
+
+    # Extract OOB error rates
+    oob_data <- rfPermute::plotTrace(rf, plot = FALSE)$data
+
+    return(oob_data)
+}
+
+# Main function to run multiple iterations
+run_analysis <- function(
+    all.id, all.label, all.maf, percent.train,
+    num.eigenvectors, num.threads,
+    n_iterations = 5) {
+    set.seed(123) # For reproducibility
+
+    # Run iterations with original labels
+    original_results <- replicate(n_iterations,
+        run_iteration(all.id, all.label, all.maf, percent.train, num.eigenvectors, num.threads, FALSE),
+        simplify = FALSE
+    )
+
+    # Run iterations with randomized labels
+    random_results <- replicate(n_iterations,
+        run_iteration(all.id, all.label, all.maf, percent.train, num.eigenvectors, num.threads, TRUE),
+        simplify = FALSE
+    )
+
+    # Combine results
+    oob_df <- dplyr::as_tibble(do.call(rbind, original_results))
+    random_oob_df <- dplyr::as_tibble(do.call(rbind, random_results))
+
+    list(oob_df = oob_df, random_oob_df = random_oob_df)
+}
+
+# Run the analysis
+results <- run_analysis(all.id, all.label, all.maf, percent.train, num.eigenvectors, num.threads)
+
+# Calculate mean error for original data
+mean_oob_df <- results$oob_df |>
+    dplyr::group_by(trees, class) |>
+    dplyr::summarise(mean_error = mean(error), .groups = "drop")
+
+# Calculate mean error for randomized data
+mean_random_oob_df <- results$random_oob_df |>
+    dplyr::group_by(trees, class) |>
+    dplyr::summarise(mean_error = mean(error), .groups = "drop")
+
+# Create the plot
+
+oobplot <-
+    ggplot2::ggplot() +
+    ggplot2::geom_line(data = results$oob_df, ggplot2::aes(
+        x = trees, y = error, color = class
+    ), alpha = 0.1) +
+    ggplot2::geom_line(data = results$random_oob_df, ggplot2::aes(
+        x = trees, y = error, color = class
+    ), alpha = 0.1, linetype = "dashed") +
+    ggplot2::geom_line(data = mean_oob_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class
+    ), linewidth = 1.5) +
+    ggplot2::geom_line(data = mean_random_oob_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class
+    ), linewidth = 1.5, linetype = "dashed") +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(
+        title = "OOB error rate (Solid: Original, Dashed: Randomized)",
+        x = "Number of trees", y = "Percent correct"
+    ) +
+    ggplot2::scale_color_manual(values = c(
+        "OOB" = "#4e4e4e",
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    ggplot2::coord_cartesian(ylim = c(0, 100)) +
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "red") +
+    ggplot2::theme(aspect.ratio = 1, text = ggplot2::element_text(size = 12)) +
+    ggplot2::scale_y_continuous(labels = scales::percent_format(scale = 1))
+
+# Save the plot
+ggplot2::ggsave(file.path(config$path$figures, "oob_plot.jpg"),
+    plot =
+        oobplot,
+    width = 8,
+    height = 6
+)
+
+
+# rfPermute::confusionMatrix(output.forest)
+# rfPermute::plotPredictedProbs(output.forest, bins = 20, plot = TRUE)
+# rfPermute::plotProximity(output.forest)
+# summary(output.forest)
+# rfPermute::plotTrace(output.forest)

# time: 2024-08-30 10:57:54 UTC
# mode: r
+# Import configuration file
+config <- config::get()
+
+# parameters
+percent.train <- 0.7
+num.threads <- 44
+num.eigenvectors <- 20
+set.seed(555)
+
+# Input files
+immigrant.info <- file.path(config$path$data, "600K_immigrants.fam")
+immigrant.vcf <- file.path(config$path$data, "600K_immigrants.vcf")
+resident.vcf <- file.path(config$path$data, "600K_residents.vcf")
+
+immigrant.gds <- file.path(config$path$data, "immigrant_recode.gds")
+resident.gds <- file.path(config$path$data, "resident_recode.gds")
+all.gds <- file.path(config$path$data, "all_recode.gds")
+
+
+# Load all the data
+all.maf <- SNPRelate::snpgdsOpen(all.gds, allow.duplicate = TRUE)
+
+# Load labels
+immigrant.id <- gdsfmt::read.gdsn(gdsfmt::index.gdsn(
+    SNPRelate::snpgdsOpen(immigrant.gds),
+    "sample.id"
+))
+resident.id <- gdsfmt::read.gdsn(gdsfmt::index.gdsn(
+    SNPRelate::snpgdsOpen(resident.gds),
+    "sample.id"
+))
+
+all.id <- gdsfmt::read.gdsn(gdsfmt::index.gdsn(all.maf, "sample.id"))
+all.label <- ifelse(all.id %in% immigrant.id, "immigrant", "resident")
+
+
+# Function to split data into training and testing sets
+# TODO balence so that there are .5 per class in both train and test sets
+split_data <- function(all.id, all.label, percent.train) {
+    num_train <- round(length(all.id) * percent.train)
+    train.id <- sample(all.id, num_train)
+    test.id <- setdiff(all.id, train.id)
+    train.label <- all.label[all.id %in% train.id]
+    test.label <- all.label[all.id %in% test.id]
+
+    list(
+        train.id = train.id, test.id = test.id,
+        train.label = train.label, test.label = test.label
+    )
+}
+
+# Function to perform PCA and prepare data frames
+prepare_data <- function(all.maf, train.id, test.id, train.label, test.label, num.eigenvectors, num.threads) {
+    print(paste("Number of train.id:", length(train.id)))
+    print(paste("Number of train.label:", length(train.label)))
+
+    pca <- SNPRelate::snpgdsPCA(all.maf, sample.id = train.id, num.thread = num.threads)
+
+    print(paste("Number of pca$sample.id:", length(pca$sample.id)))
+
+    snp_loadings <- SNPRelate::snpgdsPCASNPLoading(pca, all.maf, num.thread = num.threads)
+    sample_loadings <- SNPRelate::snpgdsPCASampLoading(snp_loadings, all.maf, sample.id = test.id, num.thread = num.threads)
+
+    train_eigenvects <- data.frame(sample.id = pca$sample.id, pca$eigenvect[, 1:num.eigenvectors])
+    test_eigenvects <- data.frame(sample.id = sample_loadings$sample.id, sample_loadings$eigenvect[, 1:num.eigenvectors])
+
+    print(paste("Number of rows in train_eigenvects:", nrow(train_eigenvects)))
+
+    train_df <- data.frame(sample.id = train.id, pop = train.label, train_eigenvects[, -1])
+    test_df <- data.frame(sample.id = test.id, pop = test.label, test_eigenvects[, -1])
+
+    list(train_df = train_df, test_df = test_df)
+}
+
+# Function to train a random forest with optional randomized labels
+train_random_forest <- function(
+    train_df, test_df, num.eigenvectors, randomize_labels = FALSE) {
+    if (randomize_labels) {
+        train_df$pop <- sample(train_df$pop)
+    }
+
+    rf <- randomForest::randomForest(
+        train_df[, 3:(2 + num.eigenvectors)],
+        y = as.factor(train_df$pop),
+        data = train_df,
+        xtest = test_df[, 3:(2 + num.eigenvectors)],
+        ytest = as.factor(test_df$pop),
+        ntree = 500,
+        replace = FALSE,
+        proximity = TRUE
+    )
+
+    return(rf)
+}
+
+
+
+# Function to run a single iteration
+run_iteration <- function(
+    all.id, all.label, all.maf, percent.train, num.eigenvectors, num.threads, randomize_labels) {
+    # Split data
+    split <- split_data(all.id, all.label, percent.train)
+
+    # Prepare data
+    data <- prepare_data(
+        all.maf, split$train.id, split$test.id, split$train.label, split$test.label,
+        num.eigenvectors, num.threads
+    )
+
+    # Train random forest
+    rf <- train_random_forest(data$train_df, data$test_df, num.eigenvectors, randomize_labels)
+
+    # Extract OOB error rates
+    oob_data <- rfPermute::plotTrace(rf, plot = FALSE)$data
+
+    return(oob_data)
+}
+
+# Main function to run multiple iterations
+run_analysis <- function(
+    all.id, all.label, all.maf, percent.train,
+    num.eigenvectors, num.threads,
+    n_iterations = 5) {
+    set.seed(123) # For reproducibility
+
+    # Run iterations with original labels
+    original_results <- replicate(n_iterations,
+        run_iteration(all.id, all.label, all.maf, percent.train, num.eigenvectors, num.threads, FALSE),
+        simplify = FALSE
+    )
+
+    # Run iterations with randomized labels
+    random_results <- replicate(n_iterations,
+        run_iteration(all.id, all.label, all.maf, percent.train, num.eigenvectors, num.threads, TRUE),
+        simplify = FALSE
+    )
+
+    # Combine results
+    oob_df <- dplyr::as_tibble(do.call(rbind, original_results))
+    random_oob_df <- dplyr::as_tibble(do.call(rbind, random_results))
+
+    list(oob_df = oob_df, random_oob_df = random_oob_df)
+}
+
+# Run the analysis
+results <- run_analysis(all.id, all.label, all.maf, percent.train, num.eigenvectors, num.threads)
+
+# Calculate mean error for original data
+mean_oob_df <- results$oob_df |>
+    dplyr::group_by(trees, class) |>
+    dplyr::summarise(mean_error = mean(error), .groups = "drop")
+
+# Calculate mean error for randomized data
+mean_random_oob_df <- results$random_oob_df |>
+    dplyr::group_by(trees, class) |>
+    dplyr::summarise(mean_error = mean(error), .groups = "drop")
+
+# Create the plot
+
+oobplot <-
+    ggplot2::ggplot() +
+    ggplot2::geom_line(data = results$oob_df, ggplot2::aes(
+        x = trees, y = error, color = class
+    ), alpha = 0.1) +
+    ggplot2::geom_line(data = results$random_oob_df, ggplot2::aes(
+        x = trees, y = error, color = class
+    ), alpha = 0.1, linetype = "dashed") +
+    ggplot2::geom_line(data = mean_oob_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class
+    ), linewidth = 1.5) +
+    ggplot2::geom_line(data = mean_random_oob_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class
+    ), linewidth = 1.5, linetype = "dashed") +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(
+        title = "OOB error rate (Solid: Original, Dashed: Randomized)",
+        x = "Number of trees", y = "Percent correct"
+    ) +
+    ggplot2::scale_color_manual(values = c(
+        "OOB" = "#4e4e4e",
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    ggplot2::coord_cartesian(ylim = c(0, 100)) +
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "red") +
+    ggplot2::theme(aspect.ratio = 1, text = ggplot2::element_text(size = 12)) +
+    ggplot2::scale_y_continuous(labels = scales::percent_format(scale = 1))
+
+# Save the plot
+ggplot2::ggsave(file.path(config$path$figures, "oob_plot.jpg"),
+    plot =
+        oobplot,
+    width = 8,
+    height = 6
+)
+
+
+# rfPermute::confusionMatrix(output.forest)
+# rfPermute::plotPredictedProbs(output.forest, bins = 20, plot = TRUE)
+# rfPermute::plotProximity(output.forest)
+# summary(output.forest)
+# rfPermute::plotTrace(output.forest)

# time: 2024-08-30 11:01:13 UTC
# mode: r
+# Calculate mean error for original data
+mean_oob_df <- results$oob_df |>
+    dplyr::group_by(trees, class) |>
+    dplyr::summarise(mean_error = mean(error), .groups = "drop")
+
+# Calculate mean error for randomized data
+mean_random_oob_df <- results$random_oob_df |>
+    dplyr::group_by(trees, class) |>
+    dplyr::summarise(mean_error = mean(error), .groups = "drop")
+
+# Create the plot
+
+oobplot <-
+    ggplot2::ggplot() +
+    ggplot2::geom_line(data = results$oob_df, ggplot2::aes(
+        x = trees, y = error, color = class
+    ), alpha = 0.1) +
+    ggplot2::geom_line(data = results$random_oob_df, ggplot2::aes(
+        x = trees, y = error, color = class
+    ), alpha = 0.1, linetype = "dashed") +
+    ggplot2::geom_line(data = mean_oob_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class
+    ), linewidth = 1.5) +
+    ggplot2::geom_line(data = mean_random_oob_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class
+    ), linewidth = 1.5, linetype = "dashed") +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(
+        title = "OOB error rate (Solid: Original, Dashed: Randomized)",
+        x = "Number of trees", y = "Percent correct"
+    ) +
+    ggplot2::scale_color_manual(values = c(
+        "OOB" = "#4e4e4e",
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    ggplot2::coord_cartesian(ylim = c(0, 100)) +
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "red") +
+    ggplot2::theme(aspect.ratio = 1, text = ggplot2::element_text(size = 12)) +
+    ggplot2::scale_y_continuous(labels = scales::percent_format(scale = 1))
+
+# Save the plot
+ggplot2::ggsave(file.path(config$path$figures, "oob_plot.jpg"),
+    plot =
+        oobplot,
+    width = 8,
+    height = 6
+)

# time: 2024-08-30 11:05:33 UTC
# mode: r
+# Import configuration file
+config <- config::get()
+
+# parameters
+percent.train <- 0.7
+num.threads <- 44
+num.eigenvectors <- 20
+set.seed(555)
+
+# Input files
+immigrant.info <- file.path(config$path$data, "600K_immigrants.fam")
+immigrant.vcf <- file.path(config$path$data, "600K_immigrants.vcf")
+resident.vcf <- file.path(config$path$data, "600K_residents.vcf")
+
+immigrant.gds <- file.path(config$path$data, "immigrant_recode.gds")
+resident.gds <- file.path(config$path$data, "resident_recode.gds")
+all.gds <- file.path(config$path$data, "all_recode.gds")
+
+
+# Load all the data
+all.maf <- SNPRelate::snpgdsOpen(all.gds, allow.duplicate = TRUE)
+
+# Load labels
+immigrant.id <- gdsfmt::read.gdsn(gdsfmt::index.gdsn(
+    SNPRelate::snpgdsOpen(immigrant.gds),
+    "sample.id"
+))
+resident.id <- gdsfmt::read.gdsn(gdsfmt::index.gdsn(
+    SNPRelate::snpgdsOpen(resident.gds),
+    "sample.id"
+))
+
+all.id <- gdsfmt::read.gdsn(gdsfmt::index.gdsn(all.maf, "sample.id"))
+all.label <- ifelse(all.id %in% immigrant.id, "immigrant", "resident")
+
+
+# Function to split data into training and testing sets
+# TODO balence so that there are .5 per class in both train and test sets
+split_data <- function(all.id, all.label, percent.train) {
+    # Split data by class
+    class_0 <- all.id[all.label == 0]
+    class_1 <- all.id[all.label == 1]
+
+    # Determine the size of the smaller class
+    min_class_size <- min(length(class_0), length(class_1))
+
+    # Undersample the majority class
+    if (length(class_0) > min_class_size) {
+        class_0 <- sample(class_0, min_class_size)
+    } else {
+        class_1 <- sample(class_1, min_class_size)
+    }
+
+    # Combine the balanced classes
+    balanced_ids <- c(class_0, class_1)
+    balanced_labels <- c(rep(0, length(class_0)), rep(1, length(class_1)))
+
+    # Calculate the number of samples for training
+    num_train <- round(length(balanced_ids) * percent.train)
+
+    # Ensure equal representation of both classes in train and test sets
+    num_train_per_class <- num_train %/% 2
+
+    # Randomly select samples for training from each class
+    train_indices <- c(
+        sample(1:min_class_size, num_train_per_class),
+        sample((min_class_size + 1):(2 * min_class_size), num_train_per_class)
+    )
+
+    train.id <- balanced_ids[train_indices]
+    test.id <- balanced_ids[-train_indices]
+    train.label <- balanced_labels[train_indices]
+    test.label <- balanced_labels[-train_indices]
+
+    list(
+        train.id = train.id, test.id = test.id,
+        train.label = train.label, test.label = test.label
+    )
+}
+# Function to perform PCA and prepare data frames
+prepare_data <- function(all.maf, train.id, test.id, train.label, test.label, num.eigenvectors, num.threads) {
+    print(paste("Number of train.id:", length(train.id)))
+    print(paste("Number of train.label:", length(train.label)))
+
+    pca <- SNPRelate::snpgdsPCA(all.maf, sample.id = train.id, num.thread = num.threads)
+
+    print(paste("Number of pca$sample.id:", length(pca$sample.id)))
+
+    snp_loadings <- SNPRelate::snpgdsPCASNPLoading(pca, all.maf, num.thread = num.threads)
+    sample_loadings <- SNPRelate::snpgdsPCASampLoading(snp_loadings, all.maf, sample.id = test.id, num.thread = num.threads)
+
+    train_eigenvects <- data.frame(sample.id = pca$sample.id, pca$eigenvect[, 1:num.eigenvectors])
+    test_eigenvects <- data.frame(sample.id = sample_loadings$sample.id, sample_loadings$eigenvect[, 1:num.eigenvectors])
+
+    print(paste("Number of rows in train_eigenvects:", nrow(train_eigenvects)))
+
+    train_df <- data.frame(sample.id = train.id, pop = train.label, train_eigenvects[, -1])
+    test_df <- data.frame(sample.id = test.id, pop = test.label, test_eigenvects[, -1])
+
+    list(train_df = train_df, test_df = test_df)
+}
+
+# Function to train a random forest with optional randomized labels
+train_random_forest <- function(
+    train_df, test_df, num.eigenvectors, randomize_labels = FALSE) {
+    if (randomize_labels) {
+        train_df$pop <- sample(train_df$pop)
+    }
+
+    rf <- randomForest::randomForest(
+        train_df[, 3:(2 + num.eigenvectors)],
+        y = as.factor(train_df$pop),
+        data = train_df,
+        xtest = test_df[, 3:(2 + num.eigenvectors)],
+        ytest = as.factor(test_df$pop),
+        ntree = 500,
+        replace = FALSE,
+        proximity = TRUE
+    )
+
+    return(rf)
+}
+
+
+
+# Function to run a single iteration
+run_iteration <- function(
+    all.id, all.label, all.maf, percent.train, num.eigenvectors, num.threads, randomize_labels) {
+    # Split data
+    split <- split_data(all.id, all.label, percent.train)
+
+    # Prepare data
+    data <- prepare_data(
+        all.maf, split$train.id, split$test.id, split$train.label, split$test.label,
+        num.eigenvectors, num.threads
+    )
+
+    # Train random forest
+    rf <- train_random_forest(data$train_df, data$test_df, num.eigenvectors, randomize_labels)
+
+    # Extract OOB error rates
+    oob_data <- rfPermute::plotTrace(rf, plot = FALSE)$data
+
+    return(oob_data)
+}
+
+# Main function to run multiple iterations
+run_analysis <- function(
+    all.id, all.label, all.maf, percent.train,
+    num.eigenvectors, num.threads,
+    n_iterations = 1) {
+    set.seed(123) # For reproducibility
+
+    # Run iterations with original labels
+    original_results <- replicate(n_iterations,
+        run_iteration(all.id, all.label, all.maf, percent.train, num.eigenvectors, num.threads, FALSE),
+        simplify = FALSE
+    )
+
+    # Run iterations with randomized labels
+    random_results <- replicate(n_iterations,
+        run_iteration(all.id, all.label, all.maf, percent.train, num.eigenvectors, num.threads, TRUE),
+        simplify = FALSE
+    )
+
+    # Combine results
+    oob_df <- dplyr::as_tibble(do.call(rbind, original_results))
+    random_oob_df <- dplyr::as_tibble(do.call(rbind, random_results))
+
+    list(oob_df = oob_df, random_oob_df = random_oob_df)
+}
+
+# Run the analysis
+results <- run_analysis(all.id, all.label, all.maf, percent.train, num.eigenvectors, num.threads)
+
+# Calculate mean error for original data
+mean_oob_df <- results$oob_df |>
+    dplyr::group_by(trees, class) |>
+    dplyr::summarise(mean_error = mean(error), .groups = "drop")
+
+# Calculate mean error for randomized data
+mean_random_oob_df <- results$random_oob_df |>
+    dplyr::group_by(trees, class) |>
+    dplyr::summarise(mean_error = mean(error), .groups = "drop")
+
+# Create the plot
+
+oobplot <-
+    ggplot2::ggplot() +
+    ggplot2::geom_line(data = results$oob_df, ggplot2::aes(
+        x = trees, y = error, color = class
+    ), alpha = 0.1) +
+    ggplot2::geom_line(data = results$random_oob_df, ggplot2::aes(
+        x = trees, y = error, color = class
+    ), alpha = 0.1, linetype = "dashed") +
+    ggplot2::geom_line(data = mean_oob_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class
+    ), linewidth = 1.5) +
+    ggplot2::geom_line(data = mean_random_oob_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class
+    ), linewidth = 1.5, linetype = "dashed") +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(
+        title = "OOB error rate (Solid: Original, Dashed: Randomized)",
+        x = "Number of trees", y = "Percent correct"
+    ) +
+    ggplot2::scale_color_manual(values = c(
+        "OOB" = "#4e4e4e",
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    ggplot2::coord_cartesian(ylim = c(0, 100)) +
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "red") +
+    ggplot2::theme(aspect.ratio = 1, text = ggplot2::element_text(size = 12)) +
+    ggplot2::scale_y_continuous(labels = scales::percent_format(scale = 1))
+
+# Save the plot
+ggplot2::ggsave(file.path(config$path$figures, "oob_plot.jpg"),
+    plot =
+        oobplot,
+    width = 8,
+    height = 6
+)
+
+
+# rfPermute::confusionMatrix(output.forest)
+# rfPermute::plotPredictedProbs(output.forest, bins = 20, plot = TRUE)
+# rfPermute::plotProximity(output.forest)
+# summary(output.forest)
+# rfPermute::plotTrace(output.forest)

# time: 2024-08-30 11:05:54 UTC
# mode: r
+factor(all.label)

# time: 2024-08-30 11:06:03 UTC
# mode: r
+labels <- unique(all.label)

# time: 2024-08-30 11:06:06 UTC
# mode: r
+labels

# time: 2024-08-30 11:06:17 UTC
# mode: r
+# Import configuration file
+config <- config::get()
+
+# parameters
+percent.train <- 0.7
+num.threads <- 44
+num.eigenvectors <- 20
+set.seed(555)
+
+# Input files
+immigrant.info <- file.path(config$path$data, "600K_immigrants.fam")
+immigrant.vcf <- file.path(config$path$data, "600K_immigrants.vcf")
+resident.vcf <- file.path(config$path$data, "600K_residents.vcf")
+
+immigrant.gds <- file.path(config$path$data, "immigrant_recode.gds")
+resident.gds <- file.path(config$path$data, "resident_recode.gds")
+all.gds <- file.path(config$path$data, "all_recode.gds")
+
+
+# Load all the data
+all.maf <- SNPRelate::snpgdsOpen(all.gds, allow.duplicate = TRUE)
+
+# Load labels
+immigrant.id <- gdsfmt::read.gdsn(gdsfmt::index.gdsn(
+    SNPRelate::snpgdsOpen(immigrant.gds),
+    "sample.id"
+))
+resident.id <- gdsfmt::read.gdsn(gdsfmt::index.gdsn(
+    SNPRelate::snpgdsOpen(resident.gds),
+    "sample.id"
+))
+
+all.id <- gdsfmt::read.gdsn(gdsfmt::index.gdsn(all.maf, "sample.id"))
+all.label <- ifelse(all.id %in% immigrant.id, "immigrant", "resident")
+
+
+# Function to split data into training and testing sets
+# TODO balence so that there are .5 per class in both train and test sets
+split_data <- function(all.id, all.label, percent.train) {
+    # Split data by class
+    labels <- unique(all.label)
+    class_0 <- all.id[all.label == labels[1]]
+    class_1 <- all.id[all.label == labels[2]]
+
+    # Determine the size of the smaller class
+    min_class_size <- min(length(class_0), length(class_1))
+
+    # Undersample the majority class
+    if (length(class_0) > min_class_size) {
+        class_0 <- sample(class_0, min_class_size)
+    } else {
+        class_1 <- sample(class_1, min_class_size)
+    }
+
+    # Combine the balanced classes
+    balanced_ids <- c(class_0, class_1)
+    balanced_labels <- c(rep(0, length(class_0)), rep(1, length(class_1)))
+
+    # Calculate the number of samples for training
+    num_train <- round(length(balanced_ids) * percent.train)
+
+    # Ensure equal representation of both classes in train and test sets
+    num_train_per_class <- num_train %/% 2
+
+    # Randomly select samples for training from each class
+    train_indices <- c(
+        sample(1:min_class_size, num_train_per_class),
+        sample((min_class_size + 1):(2 * min_class_size), num_train_per_class)
+    )
+
+    train.id <- balanced_ids[train_indices]
+    test.id <- balanced_ids[-train_indices]
+    train.label <- balanced_labels[train_indices]
+    test.label <- balanced_labels[-train_indices]
+
+    list(
+        train.id = train.id, test.id = test.id,
+        train.label = train.label, test.label = test.label
+    )
+}
+# Function to perform PCA and prepare data frames
+prepare_data <- function(all.maf, train.id, test.id, train.label, test.label, num.eigenvectors, num.threads) {
+    print(paste("Number of train.id:", length(train.id)))
+    print(paste("Number of train.label:", length(train.label)))
+
+    pca <- SNPRelate::snpgdsPCA(all.maf, sample.id = train.id, num.thread = num.threads)
+
+    print(paste("Number of pca$sample.id:", length(pca$sample.id)))
+
+    snp_loadings <- SNPRelate::snpgdsPCASNPLoading(pca, all.maf, num.thread = num.threads)
+    sample_loadings <- SNPRelate::snpgdsPCASampLoading(snp_loadings, all.maf, sample.id = test.id, num.thread = num.threads)
+
+    train_eigenvects <- data.frame(sample.id = pca$sample.id, pca$eigenvect[, 1:num.eigenvectors])
+    test_eigenvects <- data.frame(sample.id = sample_loadings$sample.id, sample_loadings$eigenvect[, 1:num.eigenvectors])
+
+    print(paste("Number of rows in train_eigenvects:", nrow(train_eigenvects)))
+
+    train_df <- data.frame(sample.id = train.id, pop = train.label, train_eigenvects[, -1])
+    test_df <- data.frame(sample.id = test.id, pop = test.label, test_eigenvects[, -1])
+
+    list(train_df = train_df, test_df = test_df)
+}
+
+# Function to train a random forest with optional randomized labels
+train_random_forest <- function(
+    train_df, test_df, num.eigenvectors, randomize_labels = FALSE) {
+    if (randomize_labels) {
+        train_df$pop <- sample(train_df$pop)
+    }
+
+    rf <- randomForest::randomForest(
+        train_df[, 3:(2 + num.eigenvectors)],
+        y = as.factor(train_df$pop),
+        data = train_df,
+        xtest = test_df[, 3:(2 + num.eigenvectors)],
+        ytest = as.factor(test_df$pop),
+        ntree = 500,
+        replace = FALSE,
+        proximity = TRUE
+    )
+
+    return(rf)
+}
+
+
+
+# Function to run a single iteration
+run_iteration <- function(
+    all.id, all.label, all.maf, percent.train, num.eigenvectors, num.threads, randomize_labels) {
+    # Split data
+    split <- split_data(all.id, all.label, percent.train)
+
+    # Prepare data
+    data <- prepare_data(
+        all.maf, split$train.id, split$test.id, split$train.label, split$test.label,
+        num.eigenvectors, num.threads
+    )
+
+    # Train random forest
+    rf <- train_random_forest(data$train_df, data$test_df, num.eigenvectors, randomize_labels)
+
+    # Extract OOB error rates
+    oob_data <- rfPermute::plotTrace(rf, plot = FALSE)$data
+
+    return(oob_data)
+}
+
+# Main function to run multiple iterations
+run_analysis <- function(
+    all.id, all.label, all.maf, percent.train,
+    num.eigenvectors, num.threads,
+    n_iterations = 1) {
+    set.seed(123) # For reproducibility
+
+    # Run iterations with original labels
+    original_results <- replicate(n_iterations,
+        run_iteration(all.id, all.label, all.maf, percent.train, num.eigenvectors, num.threads, FALSE),
+        simplify = FALSE
+    )
+
+    # Run iterations with randomized labels
+    random_results <- replicate(n_iterations,
+        run_iteration(all.id, all.label, all.maf, percent.train, num.eigenvectors, num.threads, TRUE),
+        simplify = FALSE
+    )
+
+    # Combine results
+    oob_df <- dplyr::as_tibble(do.call(rbind, original_results))
+    random_oob_df <- dplyr::as_tibble(do.call(rbind, random_results))
+
+    list(oob_df = oob_df, random_oob_df = random_oob_df)
+}
+
+# Run the analysis
+results <- run_analysis(all.id, all.label, all.maf, percent.train, num.eigenvectors, num.threads)
+
+# Calculate mean error for original data
+mean_oob_df <- results$oob_df |>
+    dplyr::group_by(trees, class) |>
+    dplyr::summarise(mean_error = mean(error), .groups = "drop")
+
+# Calculate mean error for randomized data
+mean_random_oob_df <- results$random_oob_df |>
+    dplyr::group_by(trees, class) |>
+    dplyr::summarise(mean_error = mean(error), .groups = "drop")
+
+# Create the plot
+
+oobplot <-
+    ggplot2::ggplot() +
+    ggplot2::geom_line(data = results$oob_df, ggplot2::aes(
+        x = trees, y = error, color = class
+    ), alpha = 0.1) +
+    ggplot2::geom_line(data = results$random_oob_df, ggplot2::aes(
+        x = trees, y = error, color = class
+    ), alpha = 0.1, linetype = "dashed") +
+    ggplot2::geom_line(data = mean_oob_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class
+    ), linewidth = 1.5) +
+    ggplot2::geom_line(data = mean_random_oob_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class
+    ), linewidth = 1.5, linetype = "dashed") +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(
+        title = "OOB error rate (Solid: Original, Dashed: Randomized)",
+        x = "Number of trees", y = "Percent correct"
+    ) +
+    ggplot2::scale_color_manual(values = c(
+        "OOB" = "#4e4e4e",
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    ggplot2::coord_cartesian(ylim = c(0, 100)) +
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "red") +
+    ggplot2::theme(aspect.ratio = 1, text = ggplot2::element_text(size = 12)) +
+    ggplot2::scale_y_continuous(labels = scales::percent_format(scale = 1))
+
+# Save the plot
+ggplot2::ggsave(file.path(config$path$figures, "oob_plot.jpg"),
+    plot =
+        oobplot,
+    width = 8,
+    height = 6
+)
+
+
+# rfPermute::confusionMatrix(output.forest)
+# rfPermute::plotPredictedProbs(output.forest, bins = 20, plot = TRUE)
+# rfPermute::plotProximity(output.forest)
+# summary(output.forest)
+# rfPermute::plotTrace(output.forest)

# time: 2024-08-30 11:08:38 UTC
# mode: r
+mean_random_oob_df

# time: 2024-08-30 11:14:21 UTC
# mode: r
+# Import configuration file
+config <- config::get()
+
+# parameters
+percent.train <- 0.7
+num.threads <- 44
+num.eigenvectors <- 20
+set.seed(555)
+
+# Input files
+immigrant.info <- file.path(config$path$data, "600K_immigrants.fam")
+immigrant.vcf <- file.path(config$path$data, "600K_immigrants.vcf")
+resident.vcf <- file.path(config$path$data, "600K_residents.vcf")
+
+immigrant.gds <- file.path(config$path$data, "immigrant_recode.gds")
+resident.gds <- file.path(config$path$data, "resident_recode.gds")
+all.gds <- file.path(config$path$data, "all_recode.gds")
+
+
+# Load all the data
+all.maf <- SNPRelate::snpgdsOpen(all.gds, allow.duplicate = TRUE)
+
+# Load labels
+immigrant.id <- gdsfmt::read.gdsn(gdsfmt::index.gdsn(
+    SNPRelate::snpgdsOpen(immigrant.gds),
+    "sample.id"
+))
+resident.id <- gdsfmt::read.gdsn(gdsfmt::index.gdsn(
+    SNPRelate::snpgdsOpen(resident.gds),
+    "sample.id"
+))
+
+all.id <- gdsfmt::read.gdsn(gdsfmt::index.gdsn(all.maf, "sample.id"))
+all.label <- ifelse(all.id %in% immigrant.id, "immigrant", "resident")
+
+
+# Function to split data into training and testing sets
+# TODO balence so that there are .5 per class in both train and test sets
+split_data <- function(all.id, all.label, percent.train) {
+    # Split data by class
+    labels <- unique(all.label)
+    class_0 <- all.id[all.label == labels[1]]
+    class_1 <- all.id[all.label == labels[2]]
+
+    # Determine the size of the smaller class
+    min_class_size <- min(length(class_0), length(class_1))
+
+    # Undersample the majority class
+    if (length(class_0) > min_class_size) {
+        class_0 <- sample(class_0, min_class_size)
+    } else {
+        class_1 <- sample(class_1, min_class_size)
+    }
+
+    # Combine the balanced classes
+    balanced_ids <- c(class_0, class_1)
+    balanced_labels <- c(rep(labels[1], length(class_0)), rep(labels[2], length(class_1)))
+
+    # Calculate the number of samples for training
+    num_train <- round(length(balanced_ids) * percent.train)
+
+    # Ensure equal representation of both classes in train and test sets
+    num_train_per_class <- num_train %/% 2
+
+    # Randomly select samples for training from each class
+    train_indices <- c(
+        sample(1:min_class_size, num_train_per_class),
+        sample((min_class_size + 1):(2 * min_class_size), num_train_per_class)
+    )
+
+    train.id <- balanced_ids[train_indices]
+    test.id <- balanced_ids[-train_indices]
+    train.label <- balanced_labels[train_indices]
+    test.label <- balanced_labels[-train_indices]
+
+    list(
+        train.id = train.id, test.id = test.id,
+        train.label = train.label, test.label = test.label
+    )
+}
+# Function to perform PCA and prepare data frames
+prepare_data <- function(all.maf, train.id, test.id, train.label, test.label, num.eigenvectors, num.threads) {
+    pca <- SNPRelate::snpgdsPCA(all.maf, sample.id = train.id, num.thread = num.threads)
+    snp_loadings <- SNPRelate::snpgdsPCASNPLoading(pca, all.maf, num.thread = num.threads)
+    sample_loadings <- SNPRelate::snpgdsPCASampLoading(snp_loadings, all.maf, sample.id = test.id, num.thread = num.threads)
+    train_eigenvects <- data.frame(sample.id = pca$sample.id, pca$eigenvect[, 1:num.eigenvectors])
+    test_eigenvects <- data.frame(sample.id = sample_loadings$sample.id, sample_loadings$eigenvect[, 1:num.eigenvectors])
+    train_df <- data.frame(sample.id = train.id, pop = train.label, train_eigenvects[, -1])
+    test_df <- data.frame(sample.id = test.id, pop = test.label, test_eigenvects[, -1])
+    list(train_df = train_df, test_df = test_df)
+}
+
+# Function to train a random forest with optional randomized labels
+train_random_forest <- function(
+    train_df, test_df, num.eigenvectors, randomize_labels = FALSE) {
+    if (randomize_labels) {
+        train_df$pop <- sample(train_df$pop)
+    }
+
+    rf <- randomForest::randomForest(
+        train_df[, 3:(2 + num.eigenvectors)],
+        y = as.factor(train_df$pop),
+        data = train_df,
+        xtest = test_df[, 3:(2 + num.eigenvectors)],
+        ytest = as.factor(test_df$pop),
+        ntree = 500,
+        replace = FALSE,
+        proximity = TRUE
+    )
+
+    return(rf)
+}
+
+
+
+# Function to run a single iteration
+# Function to run a single iteration
+run_iteration <- function(
+    all.id, all.label, all.maf, percent.train, num.eigenvectors, num.threads, randomize_labels) {
+    # Split data
+    split <- split_data(all.id, all.label, percent.train)
+
+    # Prepare data
+    data <- prepare_data(
+        all.maf, split$train.id, split$test.id, split$train.label, split$test.label,
+        num.eigenvectors, num.threads
+    )
+
+    # Train random forest
+    rf <- train_random_forest(data$train_df, data$test_df, num.eigenvectors, randomize_labels)
+
+    # Extract OOB error rates
+    oob_data <- rfPermute::plotTrace(rf, plot = FALSE)$data
+
+    # Return both OOB data and the random forest model
+    return(list(oob_data = oob_data, rf_model = rf))
+}
+
+# Main function to run multiple iterations
+run_analysis <- function(
+    all.id, all.label, all.maf, percent.train,
+    num.eigenvectors, num.threads,
+    n_iterations = 1) {
+    set.seed(123) # For reproducibility
+
+    # Run iterations with original labels
+    original_results <- replicate(n_iterations,
+        run_iteration(all.id, all.label, all.maf, percent.train, num.eigenvectors, num.threads, FALSE),
+        simplify = FALSE
+    )
+
+    # Run iterations with randomized labels
+    random_results <- replicate(n_iterations,
+        run_iteration(all.id, all.label, all.maf, percent.train, num.eigenvectors, num.threads, TRUE),
+        simplify = FALSE
+    )
+
+    # Separate OOB data and RF models
+    original_oob <- lapply(original_results, function(x) x$oob_data)
+    original_rf_models <- lapply(original_results, function(x) x$rf_model)
+
+    random_oob <- lapply(random_results, function(x) x$oob_data)
+    random_rf_models <- lapply(random_results, function(x) x$rf_model)
+
+    # Combine OOB results
+    oob_df <- dplyr::as_tibble(do.call(rbind, original_oob))
+    random_oob_df <- dplyr::as_tibble(do.call(rbind, random_oob))
+
+    list(
+        oob_df = oob_df,
+        random_oob_df = random_oob_df,
+        original_rf_models = original_rf_models,
+        random_rf_models = random_rf_models
+    )
+}
+
+# Run the analysis
+results <- run_analysis(all.id, all.label, all.maf, percent.train, num.eigenvectors, num.threads)
+
+# Calculate mean error for original data
+mean_oob_df <- results$oob_df |>
+    dplyr::group_by(trees, class) |>
+    dplyr::summarise(mean_error = mean(error), .groups = "drop")
+
+# Calculate mean error for randomized data
+mean_random_oob_df <- results$random_oob_df |>
+    dplyr::group_by(trees, class) |>
+    dplyr::summarise(mean_error = mean(error), .groups = "drop")
+
+# Create the plot
+
+oobplot <-
+    ggplot2::ggplot() +
+    ggplot2::geom_line(data = results$oob_df, ggplot2::aes(
+        x = trees, y = error, color = class
+    ), alpha = 0.1) +
+    ggplot2::geom_line(data = results$random_oob_df, ggplot2::aes(
+        x = trees, y = error, color = class
+    ), alpha = 0.1, linetype = "dashed") +
+    ggplot2::geom_line(data = mean_oob_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class
+    ), linewidth = 1.5) +
+    ggplot2::geom_line(data = mean_random_oob_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class
+    ), linewidth = 1.5, linetype = "dashed") +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(
+        title = "OOB error rate (Solid: Original, Dashed: Randomized)",
+        x = "Number of trees", y = "Percent correct"
+    ) +
+    ggplot2::scale_color_manual(values = c(
+        "OOB" = "#4e4e4e",
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    ggplot2::coord_cartesian(ylim = c(0, 100)) +
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "red") +
+    ggplot2::theme(aspect.ratio = 1, text = ggplot2::element_text(size = 12)) +
+    ggplot2::scale_y_continuous(labels = scales::percent_format(scale = 1))
+
+# Save the plot
+ggplot2::ggsave(file.path(config$path$figures, "oob_plot.jpg"),
+    plot =
+        oobplot,
+    width = 8,
+    height = 6
+)
+
+
+# rfPermute::confusionMatrix(output.forest)
+# rfPermute::plotPredictedProbs(output.forest, bins = 20, plot = TRUE)
+# rfPermute::plotProximity(output.forest)
+# summary(output.forest)
+# rfPermute::plotTrace(output.forest)

# time: 2024-08-30 11:16:23 UTC
# mode: r
+# Example of how you might calculate summary statistics across replicates
+calculate_summary_stats <- function(rf_models) {
+    # Extract variable importance from each model
+    var_imp_list <- lapply(rf_models, function(model) model$importance)
+    
+    # Combine variable importance across all models
+    var_imp_df <- do.call(rbind, var_imp_list)
+    
+    # Calculate mean and standard deviation of variable importance
+    var_imp_summary <- data.frame(
+        mean_importance = apply(var_imp_df, 2, mean),
+        sd_importance = apply(var_imp_df, 2, sd)
+    )
+    
+    # Extract and summarize other relevant statistics as needed
+    # For example, you might want to look at average OOB error rate
+    oob_error_rates <- sapply(rf_models, function(model) model$err.rate[nrow(model$err.rate), "OOB"])
+    mean_oob_error <- mean(oob_error_rates)
+    sd_oob_error <- sd(oob_error_rates)
+    
+    # Return the summary statistics
+    list(
+        var_imp_summary = var_imp_summary,
+        mean_oob_error = mean_oob_error,
+        sd_oob_error = sd_oob_error
+    )
+}
+
+# Calculate summary statistics for original and randomized models
+original_summary <- calculate_summary_stats(results$original_rf_models)
+random_summary <- calculate_summary_stats(results$random_rf_models)

# time: 2024-08-30 11:16:25 UTC
# mode: r
+random_summary

# time: 2024-08-30 11:16:35 UTC
# mode: r
+original_summary

# time: 2024-08-30 11:18:24 UTC
# mode: r
+# Calculate summary statistics for the random and original models
+
+
+
+randomForest::MDSplot(results$original_rf_models[[1]], all.label)

# time: 2024-08-30 11:18:34 UTC
# mode: r
+results$original_rf_models[[1]]

# time: 2024-08-30 11:18:58 UTC
# mode: r
+# rfPermute::confusionMatrix(output.forest)
+# rfPermute::plotPredictedProbs(output.forest, bins = 20, plot = TRUE)
+# rfPermute::plotProximity(output.forest)
+# summary(output.forest)
+# rfPermute::plotTrace(output.forest)
+
+results$original_rf_models[[1]]$labels

# time: 2024-08-30 11:19:07 UTC
# mode: r
+results

# time: 2024-08-30 11:22:11 UTC
# mode: r
+# Calculate summary statistics for the random and original models
+
+
+
+randomForest::MDSplot(results$original_rf_models[[1]])

# time: 2024-08-30 11:23:28 UTC
# mode: r
+# Import configuration file
+config <- config::get()
+
+# parameters
+percent.train <- 0.7
+num.threads <- 44
+num.eigenvectors <- 20
+set.seed(555)
+
+# Input files
+immigrant.info <- file.path(config$path$data, "600K_immigrants.fam")
+immigrant.vcf <- file.path(config$path$data, "600K_immigrants.vcf")
+resident.vcf <- file.path(config$path$data, "600K_residents.vcf")
+
+immigrant.gds <- file.path(config$path$data, "immigrant_recode.gds")
+resident.gds <- file.path(config$path$data, "resident_recode.gds")
+all.gds <- file.path(config$path$data, "all_recode.gds")
+
+
+# Load all the data
+all.maf <- SNPRelate::snpgdsOpen(all.gds, allow.duplicate = TRUE)
+
+# Load labels
+immigrant.id <- gdsfmt::read.gdsn(gdsfmt::index.gdsn(
+    SNPRelate::snpgdsOpen(immigrant.gds),
+    "sample.id"
+))
+resident.id <- gdsfmt::read.gdsn(gdsfmt::index.gdsn(
+    SNPRelate::snpgdsOpen(resident.gds),
+    "sample.id"
+))
+
+all.id <- gdsfmt::read.gdsn(gdsfmt::index.gdsn(all.maf, "sample.id"))
+all.label <- ifelse(all.id %in% immigrant.id, "immigrant", "resident")
+
+
+# Function to split data into training and testing sets
+# TODO balence so that there are .5 per class in both train and test sets
+split_data <- function(all.id, all.label, percent.train) {
+    # Split data by class
+    labels <- unique(all.label)
+    class_0 <- all.id[all.label == labels[1]]
+    class_1 <- all.id[all.label == labels[2]]
+
+    # Determine the size of the smaller class
+    min_class_size <- min(length(class_0), length(class_1))
+
+    # Undersample the majority class
+    if (length(class_0) > min_class_size) {
+        class_0 <- sample(class_0, min_class_size)
+    } else {
+        class_1 <- sample(class_1, min_class_size)
+    }
+
+    # Combine the balanced classes
+    balanced_ids <- c(class_0, class_1)
+    balanced_labels <- c(rep(labels[1], length(class_0)), rep(labels[2], length(class_1)))
+
+    # Calculate the number of samples for training
+    num_train <- round(length(balanced_ids) * percent.train)
+
+    # Ensure equal representation of both classes in train and test sets
+    num_train_per_class <- num_train %/% 2
+
+    # Randomly select samples for training from each class
+    train_indices <- c(
+        sample(1:min_class_size, num_train_per_class),
+        sample((min_class_size + 1):(2 * min_class_size), num_train_per_class)
+    )
+
+    train.id <- balanced_ids[train_indices]
+    test.id <- balanced_ids[-train_indices]
+    train.label <- balanced_labels[train_indices]
+    test.label <- balanced_labels[-train_indices]
+
+    list(
+        train.id = train.id, test.id = test.id,
+        train.label = train.label, test.label = test.label
+    )
+}
+# Function to perform PCA and prepare data frames
+prepare_data <- function(all.maf, train.id, test.id, train.label, test.label, num.eigenvectors, num.threads) {
+    pca <- SNPRelate::snpgdsPCA(all.maf, sample.id = train.id, num.thread = num.threads)
+    snp_loadings <- SNPRelate::snpgdsPCASNPLoading(pca, all.maf, num.thread = num.threads)
+    sample_loadings <- SNPRelate::snpgdsPCASampLoading(snp_loadings, all.maf, sample.id = test.id, num.thread = num.threads)
+    train_eigenvects <- data.frame(sample.id = pca$sample.id, pca$eigenvect[, 1:num.eigenvectors])
+    test_eigenvects <- data.frame(sample.id = sample_loadings$sample.id, sample_loadings$eigenvect[, 1:num.eigenvectors])
+    train_df <- data.frame(sample.id = train.id, pop = train.label, train_eigenvects[, -1])
+    test_df <- data.frame(sample.id = test.id, pop = test.label, test_eigenvects[, -1])
+    list(train_df = train_df, test_df = test_df)
+}
+
+# Function to train a random forest with optional randomized labels
+train_random_forest <- function(
+    train_df, test_df, num.eigenvectors, randomize_labels = FALSE) {
+    if (randomize_labels) {
+        train_df$pop <- sample(train_df$pop)
+    }
+
+    rf <- randomForest::randomForest(
+        train_df[, 3:(2 + num.eigenvectors)],
+        y = as.factor(train_df$pop),
+        data = train_df,
+        xtest = test_df[, 3:(2 + num.eigenvectors)],
+        ytest = as.factor(test_df$pop),
+        ntree = 500,
+        replace = FALSE,
+        proximity = TRUE
+    )
+
+    return(rf)
+}
+
+# Function to run a single iteration
+run_iteration <- function(
+    all.id, all.label, all.maf, percent.train, num.eigenvectors, num.threads, randomize_labels) {
+    # Split data
+    split <- split_data(all.id, all.label, percent.train)
+
+    # Prepare data
+    data <- prepare_data(
+        all.maf, split$train.id, split$test.id, split$train.label, split$test.label,
+        num.eigenvectors, num.threads
+    )
+
+    # Train random forest
+    rf <- train_random_forest(data$train_df, data$test_df, num.eigenvectors, randomize_labels)
+
+    # Extract OOB error rates
+    oob_data <- rfPermute::plotTrace(rf, plot = FALSE)$data
+
+    # Return both OOB data, the random forest model, and the train/test labels
+    return(list(oob_data = oob_data, rf_model = rf, train_labels = split$train.label, test_labels = split$test.label))
+}
+
+# Main function to run multiple iterations
+run_analysis <- function(
+    all.id, all.label, all.maf, percent.train,
+    num.eigenvectors, num.threads,
+    n_iterations = 1) {
+    set.seed(123) # For reproducibility
+
+    # Run iterations with original labels
+    original_results <- replicate(n_iterations,
+        run_iteration(all.id, all.label, all.maf, percent.train, 
+        num.eigenvectors, num.threads, FALSE),
+        simplify = FALSE
+    )
+
+    # Run iterations with randomized labels
+    random_results <- replicate(n_iterations,
+        run_iteration(all.id, all.label, all.maf, percent.train, 
+        num.eigenvectors, num.threads, TRUE),
+        simplify = FALSE
+    )
+
+    # Separate OOB data, RF models, and train/test labels
+    original_oob <- lapply(original_results, function(x) x$oob_data)
+    original_rf_models <- lapply(original_results, function(x) x$rf_model)
+    original_train_labels <- lapply(original_results, function(x) x$train_labels)
+    original_test_labels <- lapply(original_results, function(x) x$test_labels)
+
+    random_oob <- lapply(random_results, function(x) x$oob_data)
+    random_rf_models <- lapply(random_results, function(x) x$rf_model)
+    random_train_labels <- lapply(random_results, function(x) x$train_labels)
+    random_test_labels <- lapply(random_results, function(x) x$test_labels)
+
+    # Combine OOB results
+    oob_df <- dplyr::as_tibble(do.call(rbind, original_oob))
+    random_oob_df <- dplyr::as_tibble(do.call(rbind, random_oob))
+
+    list(
+        oob_df = oob_df,
+        random_oob_df = random_oob_df,
+        original_rf_models = original_rf_models,
+        random_rf_models = random_rf_models,
+        original_train_labels = original_train_labels,
+        original_test_labels = original_test_labels,
+        random_train_labels = random_train_labels,
+        random_test_labels = random_test_labels
+    )
+}
+
+# Run the analysis
+results <- run_analysis(all.id, all.label, all.maf, percent.train, num.eigenvectors, num.threads)

# time: 2024-08-30 11:23:54 UTC
# mode: r
+# Calculate summary statistics for the random and original models
+
+
+
+randomForest::MDSplot(results$original_rf_models[[1]], results$original_train_labels[[1]])

# time: 2024-08-30 11:24:02 UTC
# mode: r
+results$original_train_labels[[1]]

# time: 2024-08-30 11:24:08 UTC
# mode: r
+# Calculate summary statistics for the random and original models
+
+
+
+randomForest::MDSplot(results$original_rf_models[[1]], results$original_test_labels[[1]])

# time: 2024-08-30 11:25:28 UTC
# mode: r
+results$original_train_labels[[1]]

# time: 2024-08-30 11:25:37 UTC
# mode: r
+results$original_rf_models[[1]]

# time: 2024-08-30 11:27:10 UTC
# mode: r
+results

# time: 2024-08-30 11:30:05 UTC
# mode: r
+# Import configuration file
+config <- config::get()
+
+# parameters
+percent.train <- 0.7
+num.threads <- 44
+num.eigenvectors <- 20
+set.seed(555)
+
+# Input files
+immigrant.info <- file.path(config$path$data, "600K_immigrants.fam")
+immigrant.vcf <- file.path(config$path$data, "600K_immigrants.vcf")
+resident.vcf <- file.path(config$path$data, "600K_residents.vcf")
+
+immigrant.gds <- file.path(config$path$data, "immigrant_recode.gds")
+resident.gds <- file.path(config$path$data, "resident_recode.gds")
+all.gds <- file.path(config$path$data, "all_recode.gds")
+
+
+# Load all the data
+all.maf <- SNPRelate::snpgdsOpen(all.gds, allow.duplicate = TRUE)
+
+# Load labels
+immigrant.id <- gdsfmt::read.gdsn(gdsfmt::index.gdsn(
+    SNPRelate::snpgdsOpen(immigrant.gds),
+    "sample.id"
+))
+resident.id <- gdsfmt::read.gdsn(gdsfmt::index.gdsn(
+    SNPRelate::snpgdsOpen(resident.gds),
+    "sample.id"
+))
+
+all.id <- gdsfmt::read.gdsn(gdsfmt::index.gdsn(all.maf, "sample.id"))
+all.label <- ifelse(all.id %in% immigrant.id, "immigrant", "resident")
+
+
+# Function to split data into training and testing sets
+# TODO balence so that there are .5 per class in both train and test sets
+split_data <- function(all.id, all.label, percent.train) {
+    # Split data by class
+    labels <- unique(all.label)
+    class_0 <- all.id[all.label == labels[1]]
+    class_1 <- all.id[all.label == labels[2]]
+
+    # Determine the size of the smaller class
+    min_class_size <- min(length(class_0), length(class_1))
+
+    # Undersample the majority class
+    if (length(class_0) > min_class_size) {
+        class_0 <- sample(class_0, min_class_size)
+    } else {
+        class_1 <- sample(class_1, min_class_size)
+    }
+
+    # Combine the balanced classes
+    balanced_ids <- c(class_0, class_1)
+    balanced_labels <- c(rep(labels[1], length(class_0)), rep(labels[2], length(class_1)))
+
+    # Calculate the number of samples for training
+    num_train <- round(length(balanced_ids) * percent.train)
+
+    # Ensure equal representation of both classes in train and test sets
+    num_train_per_class <- num_train %/% 2
+
+    # Randomly select samples for training from each class
+    train_indices <- c(
+        sample(1:min_class_size, num_train_per_class),
+        sample((min_class_size + 1):(2 * min_class_size), num_train_per_class)
+    )
+
+    train.id <- balanced_ids[train_indices]
+    test.id <- balanced_ids[-train_indices]
+    train.label <- balanced_labels[train_indices]
+    test.label <- balanced_labels[-train_indices]
+
+    list(
+        train.id = train.id, test.id = test.id,
+        train.label = train.label, test.label = test.label
+    )
+}
+# Function to perform PCA and prepare data frames
+prepare_data <- function(all.maf, train.id, test.id, train.label, test.label, num.eigenvectors, num.threads) {
+    pca <- SNPRelate::snpgdsPCA(all.maf, sample.id = train.id, num.thread = num.threads)
+    snp_loadings <- SNPRelate::snpgdsPCASNPLoading(pca, all.maf, num.thread = num.threads)
+    sample_loadings <- SNPRelate::snpgdsPCASampLoading(snp_loadings, all.maf, sample.id = test.id, num.thread = num.threads)
+    train_eigenvects <- data.frame(sample.id = pca$sample.id, pca$eigenvect[, 1:num.eigenvectors])
+    test_eigenvects <- data.frame(sample.id = sample_loadings$sample.id, sample_loadings$eigenvect[, 1:num.eigenvectors])
+    train_df <- data.frame(sample.id = train.id, pop = train.label, train_eigenvects[, -1])
+    test_df <- data.frame(sample.id = test.id, pop = test.label, test_eigenvects[, -1])
+    list(train_df = train_df, test_df = test_df)
+}
+
+# Function to train a random forest with optional randomized labels
+train_random_forest <- function(
+    train_df, test_df, num.eigenvectors, randomize_labels = FALSE) {
+    if (randomize_labels) {
+        train_df$pop <- sample(train_df$pop)
+    }
+
+    return(randomForest::randomForest(
+        train_df[, 3:(2 + num.eigenvectors)],
+        y = as.factor(train_df$pop),
+        data = train_df,
+        xtest = test_df[, 3:(2 + num.eigenvectors)],
+        ytest = as.factor(test_df$pop),
+        ntree = 500,
+        replace = FALSE,
+        proximity = TRUE
+    ))
+}
+
+# Function to run a single iteration
+run_iteration <- function(
+    all.id, all.label, all.maf, percent.train, num.eigenvectors, num.threads, randomize_labels) {
+    # Split data
+    split <- split_data(all.id, all.label, percent.train)
+
+    # Prepare data
+    data <- prepare_data(
+        all.maf, split$train.id, split$test.id, split$train.label, split$test.label,
+        num.eigenvectors, num.threads
+    )
+
+    # Train random forest
+    rf <- train_random_forest(data$train_df, data$test_df, num.eigenvectors, randomize_labels)
+
+    # Extract OOB error rates
+    oob_data <- rfPermute::plotTrace(rf, plot = FALSE)$data
+
+    # Return both OOB data, the random forest model, and the train/test labels
+    return(list(oob_data = oob_data, rf_model = rf, train_labels = split$train.label, test_labels = split$test.label))
+}
+
+# Main function to run multiple iterations
+run_analysis <- function(
+    all.id, all.label, all.maf, percent.train,
+    num.eigenvectors, num.threads,
+    n_iterations = 1) {
+    set.seed(123) # For reproducibility
+
+    # Run iterations with original labels
+    original_results <- replicate(n_iterations,
+        run_iteration(all.id, all.label, all.maf, percent.train, 
+        num.eigenvectors, num.threads, FALSE),
+        simplify = FALSE
+    )
+
+    # Run iterations with randomized labels
+    random_results <- replicate(n_iterations,
+        run_iteration(all.id, all.label, all.maf, percent.train, 
+        num.eigenvectors, num.threads, TRUE),
+        simplify = FALSE
+    )
+
+    # Separate OOB data, RF models, and train/test labels
+    original_oob <- lapply(original_results, function(x) x$oob_data)
+    original_rf_models <- lapply(original_results, function(x) x$rf_model)
+    original_train_labels <- lapply(original_results, function(x) x$train_labels)
+    original_test_labels <- lapply(original_results, function(x) x$test_labels)
+
+    random_oob <- lapply(random_results, function(x) x$oob_data)
+    random_rf_models <- lapply(random_results, function(x) x$rf_model)
+    random_train_labels <- lapply(random_results, function(x) x$train_labels)
+    random_test_labels <- lapply(random_results, function(x) x$test_labels)
+
+    # Combine OOB results
+    oob_df <- dplyr::as_tibble(do.call(rbind, original_oob))
+    random_oob_df <- dplyr::as_tibble(do.call(rbind, random_oob))
+
+    list(
+        oob_df = oob_df,
+        random_oob_df = random_oob_df,
+        original_rf_models = original_rf_models,
+        random_rf_models = random_rf_models,
+        original_train_labels = original_train_labels,
+        original_test_labels = original_test_labels,
+        random_train_labels = random_train_labels,
+        random_test_labels = random_test_labels
+    )
+}
+
+# Run the analysis
+results <- run_analysis(all.id, all.label, all.maf, percent.train, num.eigenvectors, num.threads)

# time: 2024-08-30 11:30:34 UTC
# mode: r
+rfPermute::confusionMatrix(results$original_rf_models[[1]])

# time: 2024-08-30 11:30:37 UTC
# mode: r
+# Calculate summary statistics for the random and original models
+
+
+
+randomForest::MDSplot(results$original_rf_models[[1]], results$original_train_labels[[1]])

# time: 2024-08-30 11:30:53 UTC
# mode: r
+# rfPermute::plotPredictedProbs(output.forest, bins = 20, plot = TRUE)
+# rfPermute::plotProximity(output.forest)
+# summary(output.forest)
+# rfPermute::plotTrace(output.forest)
+
+results$original_rf_models[[1]]$importance

# time: 2024-08-30 11:31:22 UTC
# mode: r
+results$original_rf_models[[1]]$confusion

# time: 2024-08-30 11:34:31 UTC
# mode: r
+all.maf

# time: 2024-08-30 11:34:45 UTC
# mode: r
+# Import configuration file
+config <- config::get()
+
+# parameters
+percent.train <- 0.7
+num.threads <- 44
+num.eigenvectors <- 20
+set.seed(555)
+
+# Input files
+immigrant.info <- file.path(config$path$data, "600K_immigrants.fam")
+immigrant.vcf <- file.path(config$path$data, "600K_immigrants.vcf")
+resident.vcf <- file.path(config$path$data, "600K_residents.vcf")
+
+immigrant.gds <- file.path(config$path$data, "immigrant_recode.gds")
+resident.gds <- file.path(config$path$data, "resident_recode.gds")
+all.gds <- file.path(config$path$data, "all_recode.gds")
+
+
+# Load all the data
+all.maf <- SNPRelate::snpgdsOpen(all.gds, allow.duplicate = TRUE)
+
+# Load labels
+immigrant.id <- gdsfmt::read.gdsn(gdsfmt::index.gdsn(
+    SNPRelate::snpgdsOpen(immigrant.gds),
+    "sample.id"
+))
+resident.id <- gdsfmt::read.gdsn(gdsfmt::index.gdsn(
+    SNPRelate::snpgdsOpen(resident.gds),
+    "sample.id"
+))
+
+all.id <- gdsfmt::read.gdsn(gdsfmt::index.gdsn(all.maf, "sample.id"))
+all.label <- ifelse(all.id %in% immigrant.id, "immigrant", "resident")
+
+
+# Function to split data into training and testing sets
+# TODO balence so that there are .5 per class in both train and test sets
+split_data <- function(all.id, all.label, percent.train) {
+    # Split data by class
+    labels <- unique(all.label)
+    class_0 <- all.id[all.label == labels[1]]
+    class_1 <- all.id[all.label == labels[2]]
+
+    # Determine the size of the smaller class
+    min_class_size <- min(length(class_0), length(class_1))
+
+    # Undersample the majority class
+    if (length(class_0) > min_class_size) {
+        class_0 <- sample(class_0, min_class_size)
+    } else {
+        class_1 <- sample(class_1, min_class_size)
+    }
+
+    # Combine the balanced classes
+    balanced_ids <- c(class_0, class_1)
+    balanced_labels <- c(rep(labels[1], length(class_0)), rep(labels[2], length(class_1)))
+
+    # Calculate the number of samples for training
+    num_train <- round(length(balanced_ids) * percent.train)
+
+    # Ensure equal representation of both classes in train and test sets
+    num_train_per_class <- num_train %/% 2
+
+    # Randomly select samples for training from each class
+    train_indices <- c(
+        sample(1:min_class_size, num_train_per_class),
+        sample((min_class_size + 1):(2 * min_class_size), num_train_per_class)
+    )
+
+    train.id <- balanced_ids[train_indices]
+    test.id <- balanced_ids[-train_indices]
+    train.label <- balanced_labels[train_indices]
+    test.label <- balanced_labels[-train_indices]
+
+    list(
+        train.id = train.id, test.id = test.id,
+        train.label = train.label, test.label = test.label
+    )
+}
+# Function to perform PCA and prepare data frames
+prepare_data <- function(all.maf, train.id, test.id, train.label, test.label, num.eigenvectors, num.threads) {
+    pca <- SNPRelate::snpgdsPCA(all.maf, sample.id = train.id, num.thread = num.threads)
+    snp_loadings <- SNPRelate::snpgdsPCASNPLoading(pca, all.maf, num.thread = num.threads)
+    sample_loadings <- SNPRelate::snpgdsPCASampLoading(snp_loadings, all.maf, sample.id = test.id, num.thread = num.threads)
+    train_eigenvects <- data.frame(sample.id = pca$sample.id, pca$eigenvect[, 1:num.eigenvectors])
+    test_eigenvects <- data.frame(sample.id = sample_loadings$sample.id, sample_loadings$eigenvect[, 1:num.eigenvectors])
+    train_df <- data.frame(sample.id = train.id, pop = train.label, train_eigenvects[, -1])
+    test_df <- data.frame(sample.id = test.id, pop = test.label, test_eigenvects[, -1])
+    list(train_df = train_df, test_df = test_df)
+}
+
+# Function to train a random forest with optional randomized labels
+train_random_forest <- function(
+    train_df, test_df, num.eigenvectors, randomize_labels = FALSE) {
+    if (randomize_labels) {
+        train_df$pop <- sample(train_df$pop)
+    }
+
+    return(randomForest::randomForest(
+        train_df[, 3:(2 + num.eigenvectors)],
+        y = as.factor(train_df$pop),
+        data = train_df,
+        xtest = test_df[, 3:(2 + num.eigenvectors)],
+        ytest = as.factor(test_df$pop),
+        ntree = 500,
+        replace = FALSE,
+        proximity = TRUE
+    ))
+}
+
+# Function to run a single iteration
+run_iteration <- function(
+    all.id, all.label, all.maf, percent.train, num.eigenvectors, num.threads, randomize_labels) {
+    # Split data
+    split <- split_data(all.id, all.label, percent.train)
+
+    # Prepare data
+    data <- prepare_data(
+        all.maf, split$train.id, split$test.id, split$train.label, split$test.label,
+        num.eigenvectors, num.threads
+    )
+
+    # Train random forest
+    rf <- train_random_forest(data$train_df, data$test_df, num.eigenvectors, randomize_labels)
+
+    # Extract OOB error rates
+    oob_data <- rfPermute::plotTrace(rf, plot = FALSE)$data
+
+    # Return both OOB data, the random forest model, and the train/test labels
+    return(list(oob_data = oob_data, rf_model = rf, train_labels = split$train.label, test_labels = split$test.label))
+}
+
+# Main function to run multiple iterations
+run_analysis <- function(
+    all.id, all.label, all.maf, percent.train,
+    num.eigenvectors, num.threads,
+    n_iterations = 1) {
+    set.seed(123) # For reproducibility
+
+    # Run iterations with original labels
+    original_results <- replicate(n_iterations,
+        run_iteration(all.id, all.label, all.maf, percent.train, 
+        num.eigenvectors, num.threads, FALSE),
+        simplify = FALSE
+    )
+
+    # Run iterations with randomized labels
+    random_results <- replicate(n_iterations,
+        run_iteration(all.id, all.label, all.maf, percent.train, 
+        num.eigenvectors, num.threads, TRUE),
+        simplify = FALSE
+    )
+
+    # Separate OOB data, RF models, and train/test labels
+    original_oob <- lapply(original_results, function(x) x$oob_data)
+    original_rf_models <- lapply(original_results, function(x) x$rf_model)
+    original_train_labels <- lapply(original_results, function(x) x$train_labels)
+    original_test_labels <- lapply(original_results, function(x) x$test_labels)
+
+    random_oob <- lapply(random_results, function(x) x$oob_data)
+    random_rf_models <- lapply(random_results, function(x) x$rf_model)
+    random_train_labels <- lapply(random_results, function(x) x$train_labels)
+    random_test_labels <- lapply(random_results, function(x) x$test_labels)
+
+    # Combine OOB results
+    oob_df <- dplyr::as_tibble(do.call(rbind, original_oob))
+    random_oob_df <- dplyr::as_tibble(do.call(rbind, random_oob))
+
+    list(
+        oob_df = oob_df,
+        random_oob_df = random_oob_df,
+        original_rf_models = original_rf_models,
+        random_rf_models = random_rf_models,
+        original_train_labels = original_train_labels,
+        original_test_labels = original_test_labels,
+        random_train_labels = random_train_labels,
+        random_test_labels = random_test_labels
+    )
+}
+
+# Run the analysis
+results <- run_analysis(all.id, all.label, all.maf, percent.train, num.eigenvectors, num.threads)
+
+# Calculate mean error for original data
+mean_oob_df <- results$oob_df |>
+    dplyr::group_by(trees, class) |>
+    dplyr::summarise(mean_error = mean(error), .groups = "drop")
+
+# Calculate mean error for randomized data
+mean_random_oob_df <- results$random_oob_df |>
+    dplyr::group_by(trees, class) |>
+    dplyr::summarise(mean_error = mean(error), .groups = "drop")
+
+# Create the plot
+
+oobplot <-
+    ggplot2::ggplot() +
+    ggplot2::geom_line(data = results$oob_df, ggplot2::aes(
+        x = trees, y = error, color = class
+    ), alpha = 0.1) +
+    ggplot2::geom_line(data = results$random_oob_df, ggplot2::aes(
+        x = trees, y = error, color = class
+    ), alpha = 0.1, linetype = "dashed") +
+    ggplot2::geom_line(data = mean_oob_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class
+    ), linewidth = 1.5) +
+    ggplot2::geom_line(data = mean_random_oob_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class
+    ), linewidth = 1.5, linetype = "dashed") +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(
+        title = "OOB error rate (Solid: Original, Dashed: Randomized)",
+        x = "Number of trees", y = "Percent correct"
+    ) +
+    ggplot2::scale_color_manual(values = c(
+        "OOB" = "#4e4e4e",
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    ggplot2::coord_cartesian(ylim = c(0, 100)) +
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "red") +
+    ggplot2::theme(aspect.ratio = 1, text = ggplot2::element_text(size = 12)) +
+    ggplot2::scale_y_continuous(labels = scales::percent_format(scale = 1))
+
+# Save the plot
+ggplot2::ggsave(file.path(config$path$figures, "oob_plot.jpg"),
+    plot =
+        oobplot,
+    width = 8,
+    height = 6
+)
+
+
+# Calculate summary statistics for the random and original models
+
+
+
+randomForest::MDSplot(results$original_rf_models[[1]], results$original_train_labels[[1]])
+
+rfPermute::confusionMatrix(results$original_rf_models[[1]])
+# rfPermute::plotPredictedProbs(output.forest, bins = 20, plot = TRUE)
+# rfPermute::plotProximity(output.forest)
+# summary(output.forest)
+# rfPermute::plotTrace(output.forest)
+
+results$original_rf_models[[1]]$importance
+results$original_rf_models[[1]]$confusion

# time: 2024-08-30 11:37:00 UTC
# mode: r
+head(all.maf)

# time: 2024-08-30 13:14:58 UTC
# mode: r
+# Import configuration file
+config <- config::get()
+
+# parameters
+percent.train <- 0.7
+num.threads <- 44
+num.eigenvectors <- 5
+set.seed(555)
+
+# Input files
+immigrant.info <- file.path(config$path$data, "600K_immigrants.fam")
+immigrant.vcf <- file.path(config$path$data, "600K_immigrants.vcf")
+resident.vcf <- file.path(config$path$data, "600K_residents.vcf")
+
+immigrant.gds <- file.path(config$path$data, "immigrant_recode.gds")
+resident.gds <- file.path(config$path$data, "resident_recode.gds")
+all.gds <- file.path(config$path$data, "all_recode.gds")
+
+
+# Load all the data
+all.maf <- SNPRelate::snpgdsOpen(all.gds, allow.duplicate = TRUE)
+
+# Load labels
+immigrant.id <- gdsfmt::read.gdsn(gdsfmt::index.gdsn(
+    SNPRelate::snpgdsOpen(immigrant.gds),
+    "sample.id"
+))
+resident.id <- gdsfmt::read.gdsn(gdsfmt::index.gdsn(
+    SNPRelate::snpgdsOpen(resident.gds),
+    "sample.id"
+))
+
+all.id <- gdsfmt::read.gdsn(gdsfmt::index.gdsn(all.maf, "sample.id"))
+all.label <- ifelse(all.id %in% immigrant.id, "immigrant", "resident")
+
+
+# Function to split data into training and testing sets
+# TODO balence so that there are .5 per class in both train and test sets
+split_data <- function(all.id, all.label, percent.train) {
+    # Split data by class
+    labels <- unique(all.label)
+    class_0 <- all.id[all.label == labels[1]]
+    class_1 <- all.id[all.label == labels[2]]
+
+    # Determine the size of the smaller class
+    min_class_size <- min(length(class_0), length(class_1))
+
+    # Undersample the majority class
+    if (length(class_0) > min_class_size) {
+        class_0 <- sample(class_0, min_class_size)
+    } else {
+        class_1 <- sample(class_1, min_class_size)
+    }
+
+    # Combine the balanced classes
+    balanced_ids <- c(class_0, class_1)
+    balanced_labels <- c(rep(labels[1], length(class_0)), rep(labels[2], length(class_1)))
+
+    # Calculate the number of samples for training
+    num_train <- round(length(balanced_ids) * percent.train)
+
+    # Ensure equal representation of both classes in train and test sets
+    num_train_per_class <- num_train %/% 2
+
+    # Randomly select samples for training from each class
+    train_indices <- c(
+        sample(1:min_class_size, num_train_per_class),
+        sample((min_class_size + 1):(2 * min_class_size), num_train_per_class)
+    )
+
+    train.id <- balanced_ids[train_indices]
+    test.id <- balanced_ids[-train_indices]
+    train.label <- balanced_labels[train_indices]
+    test.label <- balanced_labels[-train_indices]
+
+    list(
+        train.id = train.id, test.id = test.id,
+        train.label = train.label, test.label = test.label
+    )
+}
+# Function to perform PCA and prepare data frames
+prepare_data <- function(all.maf, train.id, test.id, train.label, test.label, num.eigenvectors, num.threads) {
+    pca <- SNPRelate::snpgdsPCA(all.maf, sample.id = train.id, num.thread = num.threads)
+    snp_loadings <- SNPRelate::snpgdsPCASNPLoading(pca, all.maf, num.thread = num.threads)
+    sample_loadings <- SNPRelate::snpgdsPCASampLoading(snp_loadings, all.maf, sample.id = test.id, num.thread = num.threads)
+    train_eigenvects <- data.frame(sample.id = pca$sample.id, pca$eigenvect[, 1:num.eigenvectors])
+    test_eigenvects <- data.frame(sample.id = sample_loadings$sample.id, sample_loadings$eigenvect[, 1:num.eigenvectors])
+    train_df <- data.frame(sample.id = train.id, pop = train.label, train_eigenvects[, -1])
+    test_df <- data.frame(sample.id = test.id, pop = test.label, test_eigenvects[, -1])
+    list(train_df = train_df, test_df = test_df)
+}
+
+# Function to train a random forest with optional randomized labels
+train_random_forest <- function(
+    train_df, test_df, num.eigenvectors, randomize_labels = FALSE) {
+    if (randomize_labels) {
+        train_df$pop <- sample(train_df$pop)
+    }
+
+    return(randomForest::randomForest(
+        train_df[, 3:(2 + num.eigenvectors)],
+        y = as.factor(train_df$pop),
+        data = train_df,
+        xtest = test_df[, 3:(2 + num.eigenvectors)],
+        ytest = as.factor(test_df$pop),
+        ntree = 500,
+        replace = FALSE,
+        proximity = TRUE
+    ))
+}
+
+# Function to run a single iteration
+run_iteration <- function(
+    all.id, all.label, all.maf, percent.train, num.eigenvectors, num.threads, randomize_labels) {
+    # Split data
+    split <- split_data(all.id, all.label, percent.train)
+
+    # Prepare data
+    data <- prepare_data(
+        all.maf, split$train.id, split$test.id, split$train.label, split$test.label,
+        num.eigenvectors, num.threads
+    )
+
+    # Train random forest
+    rf <- train_random_forest(data$train_df, data$test_df, num.eigenvectors, randomize_labels)
+
+    # Extract OOB error rates
+    oob_data <- rfPermute::plotTrace(rf, plot = FALSE)$data
+
+    # Return both OOB data, the random forest model, and the train/test labels
+    return(list(oob_data = oob_data, rf_model = rf, train_labels = split$train.label, test_labels = split$test.label))
+}
+
+# Main function to run multiple iterations
+run_analysis <- function(
+    all.id, all.label, all.maf, percent.train,
+    num.eigenvectors, num.threads,
+    n_iterations = 1) {
+    set.seed(123) # For reproducibility
+
+    # Run iterations with original labels
+    original_results <- replicate(n_iterations,
+        run_iteration(
+            all.id, all.label, all.maf, percent.train,
+            num.eigenvectors, num.threads, FALSE
+        ),
+        simplify = FALSE
+    )
+
+    # Run iterations with randomized labels
+    random_results <- replicate(n_iterations,
+        run_iteration(
+            all.id, all.label, all.maf, percent.train,
+            num.eigenvectors, num.threads, TRUE
+        ),
+        simplify = FALSE
+    )
+
+    # Separate OOB data, RF models, and train/test labels
+    original_oob <- lapply(original_results, function(x) x$oob_data)
+    original_rf_models <- lapply(original_results, function(x) x$rf_model)
+    original_train_labels <- lapply(original_results, function(x) x$train_labels)
+    original_test_labels <- lapply(original_results, function(x) x$test_labels)
+
+    random_oob <- lapply(random_results, function(x) x$oob_data)
+    random_rf_models <- lapply(random_results, function(x) x$rf_model)
+    random_train_labels <- lapply(random_results, function(x) x$train_labels)
+    random_test_labels <- lapply(random_results, function(x) x$test_labels)
+
+    # Combine OOB results
+    oob_df <- dplyr::as_tibble(do.call(rbind, original_oob))
+    random_oob_df <- dplyr::as_tibble(do.call(rbind, random_oob))
+
+    list(
+        oob_df = oob_df,
+        random_oob_df = random_oob_df,
+        original_rf_models = original_rf_models,
+        random_rf_models = random_rf_models,
+        original_train_labels = original_train_labels,
+        original_test_labels = original_test_labels,
+        random_train_labels = random_train_labels,
+        random_test_labels = random_test_labels
+    )
+}
+
+# Run the analysis
+results <- run_analysis(all.id, all.label, all.maf, percent.train, num.eigenvectors, num.threads)
+
+# Calculate mean error for original data
+mean_oob_df <- results$oob_df |>
+    dplyr::group_by(trees, class) |>
+    dplyr::summarise(mean_error = mean(error), .groups = "drop")
+
+# Calculate mean error for randomized data
+mean_random_oob_df <- results$random_oob_df |>
+    dplyr::group_by(trees, class) |>
+    dplyr::summarise(mean_error = mean(error), .groups = "drop")
+
+# Create the plot
+
+oobplot <-
+    ggplot2::ggplot() +
+    ggplot2::geom_line(data = results$oob_df, ggplot2::aes(
+        x = trees, y = error, color = class
+    ), alpha = 0.1) +
+    ggplot2::geom_line(data = results$random_oob_df, ggplot2::aes(
+        x = trees, y = error, color = class
+    ), alpha = 0.1, linetype = "dashed") +
+    ggplot2::geom_line(data = mean_oob_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class
+    ), linewidth = 1.5) +
+    ggplot2::geom_line(data = mean_random_oob_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class
+    ), linewidth = 1.5, linetype = "dashed") +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(
+        title = "OOB error rate (Solid: Original, Dashed: Randomized)",
+        x = "Number of trees", y = "Percent correct"
+    ) +
+    ggplot2::scale_color_manual(values = c(
+        "OOB" = "#4e4e4e",
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    ggplot2::coord_cartesian(ylim = c(0, 100)) +
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "red") +
+    ggplot2::theme(aspect.ratio = 1, text = ggplot2::element_text(size = 12)) +
+    ggplot2::scale_y_continuous(labels = scales::percent_format(scale = 1))
+
+# Save the plot
+ggplot2::ggsave(file.path(config$path$figures, "oob_plot.jpg"),
+    plot =
+        oobplot,
+    width = 8,
+    height = 6
+)
+
+
+# Calculate summary statistics for the random and original models
+
+
+
+# randomForest::MDSplot(results$original_rf_models[[1]], results$original_train_labels[[1]])
+
+# rfPermute::confusionMatrix(results$original_rf_models[[1]])
+# # rfPermute::plotPredictedProbs(output.forest, bins = 20, plot = TRUE)
+# # rfPermute::plotProximity(output.forest)
+# # summary(output.forest)
+# # rfPermute::plotTrace(output.forest)
+
+# results$original_rf_models[[1]]$importance
+# results$original_rf_models[[1]]$confusion

# time: 2024-08-30 13:16:36 UTC
# mode: r
+# Calculate mean error for original data
+mean_oob_df <- results$oob_df |>
+    dplyr::group_by(trees, class) |>
+    dplyr::summarise(mean_error = mean(error), .groups = "drop") |>
+    dplyr::filter(class != "OOB")
+
+# Calculate mean error for randomized data
+mean_random_oob_df <- results$random_oob_df |>
+    dplyr::group_by(trees, class) |>
+    dplyr::summarise(mean_error = mean(error), .groups = "drop") |>
+    dplyr::filter(class != "OOB")
+
+# Create the plot
+
+oobplot <-
+    ggplot2::ggplot() +
+    ggplot2::geom_line(data = results$oob_df, ggplot2::aes(
+        x = trees, y = error, color = class
+    ), alpha = 0.1) +
+    ggplot2::geom_line(data = results$random_oob_df, ggplot2::aes(
+        x = trees, y = error, color = class
+    ), alpha = 0.1, linetype = "dashed") +
+    ggplot2::geom_line(data = mean_oob_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class
+    ), linewidth = 1.5) +
+    ggplot2::geom_line(data = mean_random_oob_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class
+    ), linewidth = 1.5, linetype = "dashed") +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(
+        title = "OOB error rate (Solid: Original, Dashed: Randomized)",
+        x = "Number of trees", y = "Percent correct"
+    ) +
+    ggplot2::scale_color_manual(values = c(
+        "OOB" = "#4e4e4e",
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    ggplot2::coord_cartesian(ylim = c(0, 100)) +
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "red") +
+    ggplot2::theme(aspect.ratio = 1, text = ggplot2::element_text(size = 12)) +
+    ggplot2::scale_y_continuous(labels = scales::percent_format(scale = 1))
+
+# Save the plot
+ggplot2::ggsave(file.path(config$path$figures, "oob_plot.jpg"),
+    plot =
+        oobplot,
+    width = 8,
+    height = 6
+)
+
+
+# Calculate summary statistics for the random and original models
+
+
+
+# randomForest::MDSplot(results$original_rf_models[[1]], results$original_train_labels[[1]])
+
+# rfPermute::confusionMatrix(results$original_rf_models[[1]])
+# # rfPermute::plotPredictedProbs(output.forest, bins = 20, plot = TRUE)
+# # rfPermute::plotProximity(output.forest)
+# # summary(output.forest)
+# # rfPermute::plotTrace(output.forest)
+
+# results$original_rf_models[[1]]$importance
+# results$original_rf_models[[1]]$confusion

# time: 2024-08-30 13:17:19 UTC
# mode: r
+# Create the plot
+
+oobplot <-
+    ggplot2::ggplot() +
+    ggplot2::geom_line(data = results$oob_df |> dplyr::filter(class != "OOB"), ggplot2::aes(
+        x = trees, y = error, color = class
+    ), alpha = 0.1) +
+    ggplot2::geom_line(data = results$random_oob_df|> dplyr::filter(class != "OOB"), ggplot2::aes(
+        x = trees, y = error, color = class
+    ), alpha = 0.1, linetype = "dashed") +
+    ggplot2::geom_line(data = mean_oob_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class
+    ), linewidth = 1.5) +
+    ggplot2::geom_line(data = mean_random_oob_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class
+    ), linewidth = 1.5, linetype = "dashed") +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(
+        title = "OOB error rate (Solid: Original, Dashed: Randomized)",
+        x = "Number of trees", y = "Percent correct"
+    ) +
+    ggplot2::scale_color_manual(values = c(
+        "OOB" = "#4e4e4e",
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    ggplot2::coord_cartesian(ylim = c(0, 100)) +
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "red") +
+    ggplot2::theme(aspect.ratio = 1, text = ggplot2::element_text(size = 12)) +
+    ggplot2::scale_y_continuous(labels = scales::percent_format(scale = 1))

# time: 2024-08-30 13:17:19 UTC
# mode: r
+# Save the plot
+ggplot2::ggsave(file.path(config$path$figures, "oob_plot.jpg"),
+    plot =
+        oobplot,
+    width = 8,
+    height = 6
+)

# time: 2024-08-30 13:18:33 UTC
# mode: r
+# Calculate mean error for original data
+mean_oob_df <- results$oob_df %>%
+    dplyr::group_by(trees, class) %>%
+    dplyr::summarise(mean_error = mean(error), .groups = "drop") %>%
+    dplyr::filter(class != "OOB")

# time: 2024-08-30 13:18:34 UTC
# mode: r
+# Calculate mean error for randomized data
+mean_random_oob_df <- results$random_oob_df %>%
+    dplyr::group_by(trees, class) %>%
+    dplyr::summarise(mean_error = mean(error), .groups = "drop") %>%
+    dplyr::filter(class != "OOB")

# time: 2024-08-30 13:18:49 UTC
# mode: r
+# Calculate mean error for original data
+mean_oob_df <- results$oob_df |>
+    dplyr::group_by(trees, class) |>
+    dplyr::summarise(mean_error = mean(error), .groups = "drop") |>
+    dplyr::filter(class != "OOB")

# time: 2024-08-30 13:18:49 UTC
# mode: r
+# Calculate mean error for randomized data
+mean_random_oob_df <- results$random_oob_df |>
+    dplyr::group_by(trees, class) |>
+    dplyr::summarise(mean_error = mean(error), .groups = "drop") |>
+    dplyr::filter(class != "OOB")

# time: 2024-08-30 13:18:50 UTC
# mode: r
+# Create the plot data
+plot_data <- list(
+    oob_df = results$oob_df |>
+        dplyr::filter(class != "OOB"),
+    random_oob_df = results$random_oob_df |>
+        dplyr::filter(class != "OOB"),
+    mean_oob_df = mean_oob_df,
+    mean_random_oob_df = mean_random_oob_df
+)

# time: 2024-08-30 13:18:51 UTC
# mode: r
+# Create the plot
+oobplot <- ggplot2::ggplot() +
+    ggplot2::geom_line(data = plot_data$oob_df, ggplot2::aes(
+        x = trees, y = error, color = class
+    ), alpha = 0.1) +
+    ggplot2::geom_line(data = plot_data$random_oob_df, ggplot2::aes(
+        x = trees, y = error, color = class
+    ), alpha = 0.1, linetype = "dashed") +
+    ggplot2::geom_line(data = plot_data$mean_oob_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class
+    ), linewidth = 1.5) +
+    ggplot2::geom_line(data = plot_data$mean_random_oob_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class
+    ), linewidth = 1.5, linetype = "dashed") +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(
+        title = "OOB error rate (Solid: Original, Dashed: Randomized)",
+        x = "Number of trees", y = "Percent correct"
+    ) +
+    ggplot2::scale_color_manual(values = c(
+        "OOB" = "#4e4e4e",
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    ggplot2::coord_cartesian(ylim = c(0, 100)) +
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "red") +
+    ggplot2::theme(aspect.ratio = 1, text = ggplot2::element_text(size = 12)) +
+    ggplot2::scale_y_continuous(labels = scales::percent_format(scale = 1))

# time: 2024-08-30 13:18:51 UTC
# mode: r
+# Save the plot
+ggplot2::ggsave(file.path(config$path$figures, "oob_plot.jpg"),
+    plot =
+        oobplot,
+    width = 8,
+    height = 6
+)

# time: 2024-08-30 13:19:30 UTC
# mode: r
+# Calculate mean error for original data
+# Define a function to calculate mean error
+calculate_mean_error <- function(data) {
+    data |>
+        dplyr::group_by(trees, class) |>
+        dplyr::summarise(mean_error = mean(error), .groups = "drop") |>
+        dplyr::filter(class != "OOB")
+}

# time: 2024-08-30 13:19:31 UTC
# mode: r
+# Calculate mean error for original data
+mean_oob_df <- calculate_mean_error(results$oob_df)

# time: 2024-08-30 13:19:31 UTC
# mode: r
+# Calculate mean error for randomized data
+mean_random_oob_df <- calculate_mean_error(results$random_oob_df)

# time: 2024-08-30 13:19:32 UTC
# mode: r
+# Create the plot data
+plot_data <- list(
+    oob_df = results$oob_df |>
+        dplyr::filter(class != "OOB"),
+    random_oob_df = results$random_oob_df |>
+        dplyr::filter(class != "OOB"),
+    mean_oob_df = mean_oob_df,
+    mean_random_oob_df = mean_random_oob_df
+)

# time: 2024-08-30 13:19:34 UTC
# mode: r
+plot_data

# time: 2024-08-30 13:20:05 UTC
# mode: r
+calculate_mean_error <- function(data) {
+    data |>
+        dplyr::group_by(trees, class) |>
+        dplyr::summarise(mean_error = mean(error), .groups = "drop") |>
+        dplyr::filter(class != "OOB")
+}

# time: 2024-08-30 13:24:14 UTC
# mode: r
+renv::status()

# time: 2024-08-30 13:24:31 UTC
# mode: r
+renv::snapshot()

# time: 2024-08-30 13:25:05 UTC
# mode: r
+renv::dependencies('httpgd')

# time: 2024-08-30 13:25:12 UTC
# mode: r
+renv::dependencies()

# time: 2024-08-30 13:26:01 UTC
# mode: r
+renv::snapshot()

# time: 2024-08-30 13:34:18 UTC
# mode: r
+# Function to prepare data but using the SNPs directly
+prepare_data_snps <- function(all.maf, train.id, test.id, train.label, test.label, num.threads) {
+    train_df <- SNPRelate::snpgdsLDPruning(all.maf, sample.id = train.id, num.thread = num.threads)
+    test_df <- SNPRelate::snpgdsLDPruning(all.maf, sample.id = test.id, num.thread = num.threads)
+    list(train_df = train_df, test_df = test_df)
+}

# time: 2024-08-30 13:34:45 UTC
# mode: r
+# Function to run a single iteration
+run_iteration <- function(
+    all.id, all.label, all.maf, percent.train, num.eigenvectors, num.threads, randomize_labels) {
+    # Split data
+    split <- split_data(all.id, all.label, percent.train)
+
+    # Prepare data
+    data <- prepare_data_snps()(
+        all.maf, split$train.id, split$test.id, split$train.label, split$test.label,
+        num.eigenvectors, num.threads
+    )
+
+    # Train random forest
+    rf <- train_random_forest(data$train_df, data$test_df, num.eigenvectors, randomize_labels)
+
+    # Extract OOB error rates
+    oob_data <- rfPermute::plotTrace(rf, plot = FALSE)$data
+
+    # Return both OOB data, the random forest model, and the train/test labels
+    return(list(oob_data = oob_data, rf_model = rf, train_labels = split$train.label, test_labels = split$test.label))
+}

# time: 2024-08-30 13:34:46 UTC
# mode: r
+# Main function to run multiple iterations
+run_analysis <- function(
+    all.id, all.label, all.maf, percent.train,
+    num.eigenvectors, num.threads,
+    n_iterations = 1) {
+    set.seed(123) # For reproducibility
+
+    # Run iterations with original labels
+    original_results <- replicate(n_iterations,
+        run_iteration(
+            all.id, all.label, all.maf, percent.train,
+            num.eigenvectors, num.threads, FALSE
+        ),
+        simplify = FALSE
+    )
+
+    # Run iterations with randomized labels
+    random_results <- replicate(n_iterations,
+        run_iteration(
+            all.id, all.label, all.maf, percent.train,
+            num.eigenvectors, num.threads, TRUE
+        ),
+        simplify = FALSE
+    )
+
+    # Separate OOB data, RF models, and train/test labels
+    original_oob <- lapply(original_results, function(x) x$oob_data)
+    original_rf_models <- lapply(original_results, function(x) x$rf_model)
+    original_train_labels <- lapply(original_results, function(x) x$train_labels)
+    original_test_labels <- lapply(original_results, function(x) x$test_labels)
+
+    random_oob <- lapply(random_results, function(x) x$oob_data)
+    random_rf_models <- lapply(random_results, function(x) x$rf_model)
+    random_train_labels <- lapply(random_results, function(x) x$train_labels)
+    random_test_labels <- lapply(random_results, function(x) x$test_labels)
+
+    # Combine OOB results
+    oob_df <- dplyr::as_tibble(do.call(rbind, original_oob))
+    random_oob_df <- dplyr::as_tibble(do.call(rbind, random_oob))
+
+    list(
+        oob_df = oob_df,
+        random_oob_df = random_oob_df,
+        original_rf_models = original_rf_models,
+        random_rf_models = random_rf_models,
+        original_train_labels = original_train_labels,
+        original_test_labels = original_test_labels,
+        random_train_labels = random_train_labels,
+        random_test_labels = random_test_labels
+    )
+}

# time: 2024-08-30 13:34:53 UTC
# mode: r
+# Function to prepare data but using the SNPs directly
+prepare_data_snps <- function(all.maf, train.id, test.id, train.label, test.label, num.threads) {
+    train_df <- SNPRelate::snpgdsLDPruning(all.maf, sample.id = train.id, num.thread = num.threads)
+    test_df <- SNPRelate::snpgdsLDPruning(all.maf, sample.id = test.id, num.thread = num.threads)
+    list(train_df = train_df, test_df = test_df)
+}

# time: 2024-08-30 13:34:58 UTC
# mode: r
+# Main function to run multiple iterations
+run_analysis <- function(
+    all.id, all.label, all.maf, percent.train,
+    num.eigenvectors, num.threads,
+    n_iterations = 1) {
+    set.seed(123) # For reproducibility
+
+    # Run iterations with original labels
+    original_results <- replicate(n_iterations,
+        run_iteration(
+            all.id, all.label, all.maf, percent.train,
+            num.eigenvectors, num.threads, FALSE
+        ),
+        simplify = FALSE
+    )
+
+    # Run iterations with randomized labels
+    random_results <- replicate(n_iterations,
+        run_iteration(
+            all.id, all.label, all.maf, percent.train,
+            num.eigenvectors, num.threads, TRUE
+        ),
+        simplify = FALSE
+    )
+
+    # Separate OOB data, RF models, and train/test labels
+    original_oob <- lapply(original_results, function(x) x$oob_data)
+    original_rf_models <- lapply(original_results, function(x) x$rf_model)
+    original_train_labels <- lapply(original_results, function(x) x$train_labels)
+    original_test_labels <- lapply(original_results, function(x) x$test_labels)
+
+    random_oob <- lapply(random_results, function(x) x$oob_data)
+    random_rf_models <- lapply(random_results, function(x) x$rf_model)
+    random_train_labels <- lapply(random_results, function(x) x$train_labels)
+    random_test_labels <- lapply(random_results, function(x) x$test_labels)
+
+    # Combine OOB results
+    oob_df <- dplyr::as_tibble(do.call(rbind, original_oob))
+    random_oob_df <- dplyr::as_tibble(do.call(rbind, random_oob))
+
+    list(
+        oob_df = oob_df,
+        random_oob_df = random_oob_df,
+        original_rf_models = original_rf_models,
+        random_rf_models = random_rf_models,
+        original_train_labels = original_train_labels,
+        original_test_labels = original_test_labels,
+        random_train_labels = random_train_labels,
+        random_test_labels = random_test_labels
+    )
+}

# time: 2024-08-30 13:34:59 UTC
# mode: r
+calculate_mean_error <- function(data) {
+    data |>
+        dplyr::group_by(trees, class) |>
+        dplyr::summarise(mean_error = mean(error), .groups = "drop") |> # nolint: object_usage_linter.
+        dplyr::filter(class != "OOB")
+}

# time: 2024-08-30 13:35:01 UTC
# mode: r
+# ----------------------------------- main ----------------------------------- #
+
+
+# Run the analysis
+results <- run_analysis(all.id, all.label, all.maf, percent.train, num.eigenvectors, num.threads)

# time: 2024-08-30 13:35:34 UTC
# mode: r
+all.maf

# time: 2024-08-30 13:35:44 UTC
# mode: r
+# Function to prepare data but using the SNPs directly
+
+all.maf$genotype

# time: 2024-08-30 13:36:27 UTC
# mode: r
+# Calculate summary statistics for the random and original models
+
+
+
+# randomForest::MDSplot(results$original_rf_models[[1]], results$original_train_labels[[1]])
+
+# rfPermute::confusionMatrix(results$original_rf_models[[1]])
+# # rfPermute::plotPredictedProbs(output.forest, bins = 20, plot = TRUE)
+# # rfPermute::plotProximity(output.forest)
+# # summary(output.forest)
+# # rfPermute::plotTrace(output.forest)
+
+results$original_rf_models[[1]]$importance

# time: 2024-08-30 13:36:33 UTC
# mode: r
+results$original_rf_models[[1]]$confusion

# time: 2024-08-30 13:41:32 UTC
# mode: r
+# Calculate summary statistics for the random and original models
+
+
+
+# randomForest::MDSplot(results$original_rf_models[[1]], results$original_train_labels[[1]])
+
+# rfPermute::confusionMatrix(results$original_rf_models[[1]])
+# # rfPermute::plotPredictedProbs(output.forest, bins = 20, plot = TRUE)
+# # rfPermute::plotProximity(output.forest)
+# # summary(output.forest)
+# # rfPermute::plotTrace(output.forest)
+
+# run a single random forest model
+singlerf <- randomForest::randomForest(
+    results$original_train_labels[[1]][, 3:(2 + num.eigenvectors)],
+    y = as.factor(results$original_train_labels[[1]]$pop),
+    data = results$original_train_labels[[1]],
+    xtest = results$original_test_labels[[1]][, 3:(2 + num.eigenvectors)],
+    ytest = as.factor(results$original_test_labels[[1]]$pop),
+    ntree = 500,
+    replace = FALSE,
+    proximity = TRUE
+)

# time: 2024-08-30 13:42:16 UTC
# mode: r
+train.set <- prepare_data(all.maf, all.id, all.id, all.label, all.label, num.eigenvectors, num.threads)
+test.set <- prepare_data(all.maf, all.id, all.id, all.label, all.label, num.eigenvectors, num.threads)
+
+# 2 train model
+rf <- train_random_forest(train.set$train_df, test.set$test_df, num.eigenvectors, FALSE)

# time: 2024-08-30 13:43:31 UTC
# mode: r
+randomForest::MDSplot(rf, train.set$train_df$pop)

# time: 2024-08-30 13:43:42 UTC
# mode: r
+train.set$train_df

# time: 2024-08-30 13:44:12 UTC
# mode: r
+# Calculate summary statistics for the random and original models
+
+
+
+# randomForest::MDSplot(results$original_rf_models[[1]], results$original_train_labels[[1]])
+
+# rfPermute::confusionMatrix(results$original_rf_models[[1]])
+# # rfPermute::plotPredictedProbs(output.forest, bins = 20, plot = TRUE)
+# # rfPermute::plotProximity(output.forest)
+# # summary(output.forest)
+# # rfPermute::plotTrace(output.forest)
+
+# run a single random forest model:
+
+# 1 prepare data
+split <- split_data(all.id, all.label, percent.train)

# time: 2024-08-30 13:44:15 UTC
# mode: r
+data <- prepare_data(
+    all.maf, split$train.id, split$test.id, split$train.label, split$test.label,
+    num.eigenvectors, num.threads
+)

# time: 2024-08-30 13:44:32 UTC
# mode: r
+# 2 train model
+rf <- train_random_forest(data$train_df, data$test_df, num.eigenvectors, FALSE)

# time: 2024-08-30 13:44:34 UTC
# mode: r
+randomForest::MDSplot(rf, train.set$train_df$pop)

# time: 2024-08-30 13:44:45 UTC
# mode: r
+rfPermute::plotProximity(RF)

# time: 2024-08-30 13:44:51 UTC
# mode: r
+rfPermute::plotProximity(rf)

# time: 2024-08-30 13:45:23 UTC
# mode: r
+# extract the proximity matrix
+prox <- rf$proximity

# time: 2024-08-30 13:45:40 UTC
# mode: r
+# 3 plot the proximity matrix
+prox_df <- as.data.frame(prox)

# time: 2024-08-30 13:45:40 UTC
# mode: r
+rownames(prox_df) <- data$train_df$sample.id

# time: 2024-08-30 13:45:41 UTC
# mode: r
+colnames(prox_df) <- data$train_df$sample.id

# time: 2024-08-30 13:45:43 UTC
# mode: r
+# Create the plot
+proxplot <- ggplot2::ggplot() +
+    ggplot2::geom_tile(data = prox_df, ggplot2::aes(
+        x = Var1, y = Var2, fill = value
+    )) +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(
+        title = "Proximity matrix",
+        x = "Sample ID", y = "Sample ID"
+    ) +
+    ggplot2::scale_fill_viridis_c() +
+    ggplot2::theme(aspect.ratio = 1, text = ggplot2::element_text(size = 12))

# time: 2024-08-30 13:45:50 UTC
# mode: r
+proxplot

# time: 2024-08-30 13:45:55 UTC
# mode: r
+prox_df

# time: 2024-08-30 13:46:11 UTC
# mode: r
+# 3 plot the proximity matrix
+prox_df <- as.data.frame(prox) |> dplyr::as_tibble()

# time: 2024-08-30 13:46:12 UTC
# mode: r
+rownames(prox_df) <- data$train_df$sample.id

# time: 2024-08-30 13:46:13 UTC
# mode: r
+colnames(prox_df) <- data$train_df$sample.id

# time: 2024-08-30 13:46:23 UTC
# mode: r
+prox_df

# time: 2024-08-30 13:46:51 UTC
# mode: r
+# MDS and plot the proximity matrix
+mds <- stats::cmdscale(prox, k = 2)

# time: 2024-08-30 13:46:56 UTC
# mode: r
+# plot the MDS
+plot(mds, type = "n", xlab = "", ylab = "", main = "MDS of RF Proximity Matrix")

# time: 2024-08-30 13:46:59 UTC
# mode: r
+text(mds, labels = data$test_df$pop, col = c("red", "blue")[as.numeric(data$test_df$pop)], cex = 0.5)

# time: 2024-08-30 13:47:12 UTC
# mode: r
+mds

# time: 2024-08-30 13:47:34 UTC
# mode: r
+# plot the MDS
+plot(mds, type = "p", xlab = "", ylab = "", main = "MDS of RF Proximity Matrix")

# time: 2024-08-30 13:48:45 UTC
# mode: r
+# rfPermute::plotProximity(rf)
+
+
+# cmd the proximity matrix from the model and plot
+prox = 1 - rf$proximity

# time: 2024-08-30 13:48:49 UTC
# mode: r
+mds = stats::cmdscale(prox, k = 2)

# time: 2024-08-30 13:48:59 UTC
# mode: r
+# plot the MDS
+mds_df <- data.frame(mds, class = rf$y, predicted = rf$predicted)

# time: 2024-08-30 13:49:00 UTC
# mode: r
+colnames(mds_df)[1:2] <- c("x", "y")

# time: 2024-08-30 13:49:03 UTC
# mode: r
+g <- ggplot2::ggplot(mds_df, ggplot2::aes_(~x, ~y, color = ~class))

# time: 2024-08-30 13:49:06 UTC
# mode: r
+g

# time: 2024-08-30 13:50:09 UTC
# mode: r
+rfPermute::plotProximity(rf, plot = FALSE)

# time: 2024-08-30 13:50:16 UTC
# mode: r
+prox = rfPermute::plotProximity(rf, plot = FALSE)

# time: 2024-08-30 13:50:20 UTC
# mode: r
+prox

# time: 2024-08-30 13:50:39 UTC
# mode: r
+prox$g

# time: 2024-08-30 13:52:14 UTC
# mode: r
+# read in kinship CSV
+kinship <- read.csv(file.path(config$path$data, "kinship.csv"))

# time: 2024-08-30 13:52:26 UTC
# mode: r
+# read in kinship CSV
+kinship <- readr::read_csv(file.path(config$path$data, "kinship.csv"))

# time: 2024-08-30 13:52:32 UTC
# mode: r
+# read in kinship CSV
+kinship <- dplyr::read_csv(file.path(config$path$data, "kinship.csv"))

# time: 2024-08-30 13:52:57 UTC
# mode: r
+# read in kinship CSV
+kinship <- readr::read_csv(file.path(config$path$data, "kinship.csv"))

# time: 2024-08-30 13:53:10 UTC
# mode: r
+renv::install('readr')

# time: 2024-08-30 13:53:15 UTC
# mode: r
+# read in kinship CSV
+kinship <- readr::read_csv(file.path(config$path$data, "kinship.csv"))

# time: 2024-08-30 13:53:19 UTC
# mode: r
+kinship

# time: 2024-08-30 14:00:25 UTC
# mode: r
+# recode the kinship_degree column so unrelated is 0, first_degree is 1, second_degree is 2, and third_degree is 3
+kinship$kinship_degree <- factor(kinship$kinship_degree, levels = c("unrelated", "first_degree", "second_degree", "third_degree"), labels = c(0, 1, 2, 3))

# time: 2024-08-30 14:00:27 UTC
# mode: r
+kinship

# time: 2024-08-30 14:01:26 UTC
# mode: r
+# read in kinship CSV
+kinship <- readr::read_csv(file.path(config$path$data, "kinship.csv"))

# time: 2024-08-30 14:01:28 UTC
# mode: r
+# recode the kinship_degree column so unrelated is 0, first_degree is 1, second_degree is 2, and third_degree is 3
+kinship$kinship_degree <- factor(kinship$kinship_degree, levels = c("unrelated", "first_degree", "second_degree", "third_degree"), labels = c(0, 3, 2, 1))

# time: 2024-08-30 14:09:33 UTC
# mode: r
+# Function to split data into training and testing sets
+split_data <- function(all.id, all.label, percent.train, kinship, kinship_threshold = NA) {
+    # Split data by class
+    labels <- unique(all.label)
+    class_0 <- all.id[all.label == labels[1]]
+    class_1 <- all.id[all.label == labels[2]]
+
+    if (is.na(kinship_threshold)) {
+        # Determine the size of the smaller class
+        min_class_size <- min(length(class_0), length(class_1))
+
+        # Undersample the majority class
+        if (length(class_0) > min_class_size) {
+            class_0 <- sample(class_0, min_class_size)
+        } else {
+            class_1 <- sample(class_1, min_class_size)
+        }
+
+        # Combine the balanced classes
+        balanced_ids <- c(class_0, class_1)
+        balanced_labels <- c(rep(labels[1], length(class_0)), rep(labels[2], length(class_1)))
+
+        # Calculate the number of samples for training
+        num_train <- round(length(balanced_ids) * percent.train)
+
+        # Ensure equal representation of both classes in train and test sets
+        num_train_per_class <- num_train %/% 2
+
+        # Randomly select samples for training from each class
+        train_indices <- c(
+            sample(1:min_class_size, num_train_per_class),
+            sample((min_class_size + 1):(2 * min_class_size), num_train_per_class)
+        )
+
+        train.id <- balanced_ids[train_indices]
+        test.id <- balanced_ids[-train_indices]
+        train.label <- balanced_labels[train_indices]
+        test.label <- balanced_labels[-train_indices]
+    } else {
+        # Randomly select training samples
+        num_train <- round(length(all.id) * percent.train)
+        train_indices <- sample(1:length(all.id), num_train)
+        train.id <- all.id[train_indices]
+        train.label <- all.label[train_indices]
+
+        # Identify kinship relationships
+        kinship_filtered <- kinship[kinship$kinship_degree <= kinship_threshold, ]
+        kinship_train <- kinship_filtered[kinship_filtered$IID1 %in% train.id | kinship_filtered$IID2 %in% train.id, ]
+
+        # Build the test set
+        test.id <- setdiff(all.id, train.id)
+        test.id <- test.id[test.id %in% unique(c(kinship_train$IID1, kinship_train$IID2))]
+        test.label <- all.label[all.id %in% test.id]
+    }
+
+    list(
+        train.id = train.id, test.id = test.id,
+        train.label = train.label, test.label = test.label
+    )
+}

# time: 2024-08-30 14:10:56 UTC
# mode: r
+list(
+        train.id = train.id, test.id = test.id,
+        train.label = train.label, test.label = test.label
+    )

# time: 2024-08-30 14:10:57 UTC
# mode: r
+# Function to split data into training and testing sets
+split_data <- function(all.id, all.label, percent.train, kinship, kinship_threshold = NA) {
+    # Split data by class
+    labels <- unique(all.label)
+    class_0 <- all.id[all.label == labels[1]]
+    class_1 <- all.id[all.label == labels[2]]
+
+    if (is.na(kinship_threshold)) {
+        # Determine the size of the smaller class
+        min_class_size <- min(length(class_0), length(class_1))
+
+        # Undersample the majority class
+        if (length(class_0) > min_class_size) {
+            class_0 <- sample(class_0, min_class_size)
+        } else {
+            class_1 <- sample(class_1, min_class_size)
+        }
+
+        # Combine the balanced classes
+        balanced_ids <- c(class_0, class_1)
+        balanced_labels <- c(rep(labels[1], length(class_0)), rep(labels[2], length(class_1)))
+
+        # Calculate the number of samples for training
+        num_train <- round(length(balanced_ids) * percent.train)
+
+        # Ensure equal representation of both classes in train and test sets
+        num_train_per_class <- num_train %/% 2
+
+        # Randomly select samples for training from each class
+        train_indices <- c(
+            sample(1:min_class_size, num_train_per_class),
+            sample((min_class_size + 1):(2 * min_class_size), num_train_per_class)
+        )
+
+        train.id <- balanced_ids[train_indices]
+        test.id <- balanced_ids[-train_indices]
+        train.label <- balanced_labels[train_indices]
+        test.label <- balanced_labels[-train_indices]
+    } else {
+        # Randomly select training samples
+        num_train <- round(length(all.id) * percent.train)
+        train_indices <- sample(1:length(all.id), num_train)
+        train.id <- all.id[train_indices]
+        train.label <- all.label[train_indices]
+
+        # Identify kinship relationships
+        kinship_filtered <- kinship[kinship$kinship_degree <= kinship_threshold, ]
+        kinship_train <- kinship_filtered[kinship_filtered$IID1 %in% train.id | kinship_filtered$IID2 %in% train.id, ]
+
+        # Build the test set
+        test.id <- setdiff(all.id, train.id)
+        test.id <- test.id[test.id %in% unique(c(kinship_train$IID1, kinship_train$IID2))]
+        test.label <- all.label[all.id %in% test.id]
+
+        # print information about the split (proportion of each class in train and test), sample size
+        print(paste("Train size:", length(train.id), "Test size:", length(test.id)))
+        print(paste("Train class 0:", sum(train.label == labels[1]), "Train class 1:", sum(train.label == labels[2])))
+        print(paste("Test class 0:", sum(test.label == labels[1]), "Test class 1:", sum(test.label == labels[2])))
+        
+    }
+
+    list(
+        train.id = train.id, test.id = test.id,
+        train.label = train.label, test.label = test.label
+    )
+}

# time: 2024-08-30 14:11:00 UTC
# mode: r
+# Function to perform PCA and prepare data frames
+prepare_data <- function(all.maf, train.id, test.id, train.label, test.label, num.eigenvectors, num.threads) {
+    pca <- SNPRelate::snpgdsPCA(all.maf, sample.id = train.id, num.thread = num.threads)
+    snp_loadings <- SNPRelate::snpgdsPCASNPLoading(pca, all.maf, num.thread = num.threads)
+    sample_loadings <- SNPRelate::snpgdsPCASampLoading(snp_loadings, all.maf, sample.id = test.id, num.thread = num.threads)
+    train_eigenvects <- data.frame(sample.id = pca$sample.id, pca$eigenvect[, 1:num.eigenvectors])
+    test_eigenvects <- data.frame(sample.id = sample_loadings$sample.id, sample_loadings$eigenvect[, 1:num.eigenvectors])
+    train_df <- data.frame(sample.id = train.id, pop = train.label, train_eigenvects[, -1])
+    test_df <- data.frame(sample.id = test.id, pop = test.label, test_eigenvects[, -1])
+    list(train_df = train_df, test_df = test_df)
+}

# time: 2024-08-30 14:11:01 UTC
# mode: r
+# Function to train a random forest with optional randomized labels
+train_random_forest <- function(
+    train_df, test_df, num.eigenvectors, randomize_labels = FALSE) {
+    if (randomize_labels) {
+        train_df$pop <- sample(train_df$pop)
+    }
+
+    return(randomForest::randomForest(
+        train_df[, 3:(2 + num.eigenvectors)],
+        y = as.factor(train_df$pop),
+        data = train_df,
+        xtest = test_df[, 3:(2 + num.eigenvectors)],
+        ytest = as.factor(test_df$pop),
+        ntree = 500,
+        replace = FALSE,
+        proximity = TRUE
+    ))
+}

# time: 2024-08-30 14:11:52 UTC
# mode: r
+# 1 prepare data
+split <- split_data(all.id, all.label, percent.train, kinship, kinship_threshold = 0)
+
+data <- prepare_data(
+    all.maf, split$train.id, split$test.id, split$train.label, split$test.label,
+    num.eigenvectors, num.threads
+)
+
+# 2 train model
+rf <- train_random_forest(data$train_df, data$test_df, num.eigenvectors, FALSE)
+
+prox <- rfPermute::plotProximity(rf, plot = FALSE)
+
+
+# cmd the proximity matrix from the model and plot
+prox = 1 - rf$proximity
+mds <- stats::cmdscale(prox, k = 2)
+
+# plot the MDS
+mds_df <- data.frame(mds, class = rf$y, predicted = rf$predicted)

# time: 2024-08-30 14:12:16 UTC
# mode: r
+rfPermute::plotProximity(rf)

# time: 2024-08-30 14:13:31 UTC
# mode: r
+# read in kinship CSV
+kinship <- readr::read_csv(file.path(config$path$data, "kinship.csv"))

# time: 2024-08-30 14:13:33 UTC
# mode: r
+# recode the kinship_degree column so unrelated is 0, first_degree is 1, second_degree is 2, and third_degree is 3
+kinship$kinship_degree <- as.numeric(factor(kinship$kinship_degree, levels = c("unrelated", "first_degree", "second_degree", "third_degree"), labels = c(0, 3, 2, 1)))

# time: 2024-08-30 14:13:40 UTC
# mode: r
+# Load all the data
+all.maf <- SNPRelate::snpgdsOpen(all.gds, allow.duplicate = TRUE)
+
+# Load labels
+immigrant.id <- gdsfmt::read.gdsn(gdsfmt::index.gdsn(
+    SNPRelate::snpgdsOpen(immigrant.gds),
+    "sample.id"
+))
+resident.id <- gdsfmt::read.gdsn(gdsfmt::index.gdsn(
+    SNPRelate::snpgdsOpen(resident.gds),
+    "sample.id"
+))
+
+all.id <- gdsfmt::read.gdsn(gdsfmt::index.gdsn(all.maf, "sample.id"))
+all.label <- ifelse(all.id %in% immigrant.id, "immigrant", "resident")

# time: 2024-08-30 14:13:43 UTC
# mode: r
+# Calculate summary statistics for the random and original models
+
+
+
+# randomForest::MDSplot(results$original_rf_models[[1]], results$original_train_labels[[1]])
+
+# rfPermute::confusionMatrix(results$original_rf_models[[1]])
+# # rfPermute::plotPredictedProbs(output.forest, bins = 20, plot = TRUE)
+# # rfPermute::plotProximity(output.forest)
+# # summary(output.forest)
+# # rfPermute::plotTrace(output.forest)
+
+# run a single random forest model:
+
+# 1 prepare data
+split <- split_data(all.id, all.label, percent.train, kinship, kinship_threshold = 0)

# time: 2024-08-30 14:13:58 UTC
# mode: r
+# Calculate summary statistics for the random and original models
+
+
+
+# randomForest::MDSplot(results$original_rf_models[[1]], results$original_train_labels[[1]])
+
+# rfPermute::confusionMatrix(results$original_rf_models[[1]])
+# # rfPermute::plotPredictedProbs(output.forest, bins = 20, plot = TRUE)
+# # rfPermute::plotProximity(output.forest)
+# # summary(output.forest)
+# # rfPermute::plotTrace(output.forest)
+
+# run a single random forest model:
+
+# 1 prepare data
+split <- split_data(all.id, all.label, percent.train, kinship, kinship_threshold = 1)

# time: 2024-08-30 14:14:10 UTC
# mode: r
+kinship

# time: 2024-08-30 14:14:39 UTC
# mode: r
+kinship$kinship_degree

# time: 2024-08-30 14:14:58 UTC
# mode: r
+# read in kinship CSV
+kinship <- readr::read_csv(file.path(config$path$data, "kinship.csv"))

# time: 2024-08-30 14:15:01 UTC
# mode: r
+kinship

# time: 2024-08-30 14:15:34 UTC
# mode: r
+# recode the kinship_degree column so unrelated is 0, first_degree is 1, second_degree is 2, and third_degree is 3
+kinship$kinship_degree <- as.numeric(factor(kinship$kinship_degree, levels = c("unrelated", "first_degree", "second_degree", "third_degree"), labels = c(0, 3, 2, 1)))

# time: 2024-08-30 14:15:37 UTC
# mode: r
+kinship

# time: 2024-08-30 14:16:24 UTC
# mode: r
+# read in kinship CSV
+kinship <- readr::read_csv(file.path(config$path$data, "kinship.csv"))
+# recode the kinship_degree column so unrelated is 0, first_degree is 3, second_degree is 2, and third_degree is 1
+kinship$kinship_degree <- factor(kinship$kinship_degree, levels = c("unrelated", "third_degree", "second_degree", "first_degree"))
+kinship$kinship_degree <- as.integer(kinship$kinship_degree)

# time: 2024-08-30 14:16:26 UTC
# mode: r
+kinship

# time: 2024-08-30 14:16:49 UTC
# mode: r
+# read in kinship CSV
+kinship <- readr::read_csv(file.path(config$path$data, "kinship.csv"))

# time: 2024-08-30 14:16:51 UTC
# mode: r
+# recode the kinship_degree column so unrelated is 0, first_degree is 3, second_degree is 2, and third_degree is 1. use dplyr
+kinship <- dplyr::mutate(kinship, kinship_degree = case_when(
+    kinship_degree == "unrelated" ~ 0,
+    kinship_degree == "third_degree" ~ 1,
+    kinship_degree == "second_degree" ~ 2,
+    kinship_degree == "first_degree" ~ 3
+))

# time: 2024-08-30 14:16:59 UTC
# mode: r
+# recode the kinship_degree column so unrelated is 0, first_degree is 3, second_degree is 2, and third_degree is 1. use dplyr
+kinship <- dplyr::mutate(kinship, kinship_degree = dplyr::case_when(
+    kinship_degree == "unrelated" ~ 0,
+    kinship_degree == "third_degree" ~ 1,
+    kinship_degree == "second_degree" ~ 2,
+    kinship_degree == "first_degree" ~ 3
+))

# time: 2024-08-30 14:17:01 UTC
# mode: r
+kinship

# time: 2024-08-30 14:17:21 UTC
# mode: r
+# Calculate summary statistics for the random and original models
+
+
+
+# randomForest::MDSplot(results$original_rf_models[[1]], results$original_train_labels[[1]])
+
+# rfPermute::confusionMatrix(results$original_rf_models[[1]])
+# # rfPermute::plotPredictedProbs(output.forest, bins = 20, plot = TRUE)
+# # rfPermute::plotProximity(output.forest)
+# # summary(output.forest)
+# # rfPermute::plotTrace(output.forest)
+
+# run a single random forest model:
+
+# 1 prepare data
+split <- split_data(all.id, all.label, percent.train, kinship, kinship_threshold = 1)

# time: 2024-08-30 14:17:42 UTC
# mode: r
+percent.train

# time: 2024-08-30 14:17:44 UTC
# mode: r
+kinship

# time: 2024-08-30 14:17:51 UTC
# mode: r
+# Calculate summary statistics for the random and original models
+
+
+
+# randomForest::MDSplot(results$original_rf_models[[1]], results$original_train_labels[[1]])
+
+# rfPermute::confusionMatrix(results$original_rf_models[[1]])
+# # rfPermute::plotPredictedProbs(output.forest, bins = 20, plot = TRUE)
+# # rfPermute::plotProximity(output.forest)
+# # summary(output.forest)
+# # rfPermute::plotTrace(output.forest)
+
+# run a single random forest model:
+
+# 1 prepare data
+split <- split_data(all.id, all.label, percent.train, kinship, kinship_threshold = 0)

# time: 2024-08-30 14:17:56 UTC
# mode: r
+all.label

# time: 2024-08-30 14:18:08 UTC
# mode: r
+# Calculate summary statistics for the random and original models
+
+
+
+# randomForest::MDSplot(results$original_rf_models[[1]], results$original_train_labels[[1]])
+
+# rfPermute::confusionMatrix(results$original_rf_models[[1]])
+# # rfPermute::plotPredictedProbs(output.forest, bins = 20, plot = TRUE)
+# # rfPermute::plotProximity(output.forest)
+# # summary(output.forest)
+# # rfPermute::plotTrace(output.forest)
+
+# run a single random forest model:
+
+# 1 prepare data
+split <- split_data(all.id, all.label, percent.train, kinship, kinship_threshold = 0)

# time: 2024-08-30 14:18:19 UTC
# mode: r
+num_train <- round(length(all.id) * percent.train)

# time: 2024-08-30 14:18:21 UTC
# mode: r
+num_train

# time: 2024-08-30 14:18:25 UTC
# mode: r
+train_indices <- sample(1:length(all.id), num_train)

# time: 2024-08-30 14:18:36 UTC
# mode: r
+length(train_indices)

# time: 2024-08-30 14:18:52 UTC
# mode: r
+length(all.id)

# time: 2024-08-30 14:20:56 UTC
# mode: r
+num_train <- round(length(all.id) * percent.train)
+        train_indices <- sample(1:length(all.id), num_train)
+        train.id <- all.id[train_indices]
+        train.label <- all.label[train_indices]

# time: 2024-08-30 14:21:01 UTC
# mode: r
+kinship[kinship$kinship_degree <= kinship_threshold, ]

# time: 2024-08-30 14:21:14 UTC
# mode: r
+train.id

# time: 2024-08-30 14:22:21 UTC
# mode: r
+# read in kinship CSV
+kinship <- readr::read_csv(file.path(config$path$data, "kinship.csv")) |>
+    dplyr::mutate(kinship, kinship_degree = dplyr::case_when(
+        kinship_degree == "unrelated" ~ 0,
+        kinship_degree == "third_degree" ~ 1,
+        kinship_degree == "second_degree" ~ 2,
+        kinship_degree == "first_degree" ~ 3
+    )) |>
+    # add 'Wytham_UK_' to the beginning of each IID column
+    dplyr::mutate(across(starts_with("IID"), ~ paste("Wytham_UK_", ., sep = "")))

# time: 2024-08-30 14:22:29 UTC
# mode: r
+kinship

# time: 2024-08-30 14:23:33 UTC
# mode: r
+# read in kinship CSV
+kinship <- readr::read_csv(file.path(config$path$data, "kinship.csv")) |>
+    dplyr::mutate(kinship, kinship_degree = dplyr::case_when(
+        kinship_degree == "unrelated" ~ 0,
+        kinship_degree == "third_degree" ~ 1,
+        kinship_degree == "second_degree" ~ 2,
+        kinship_degree == "first_degree" ~ 3
+    )) |>
+    # add 'Wytham_UK_' to the beginning of each IID column
+    dplyr::mutate(dplyr::across(dplyr::starts_with("IID"), ~ paste("Wytham_UK_", ., sep = "")))

# time: 2024-08-30 14:23:37 UTC
# mode: r
+kinship

# time: 2024-08-30 14:23:56 UTC
# mode: r
+# read in kinship CSV
+kinship <- readr::read_csv(file.path(config$path$data, "kinship.csv")) |>
+    dplyr::mutate(kinship_degree = dplyr::case_when(
+        kinship_degree == "unrelated" ~ 0,
+        kinship_degree == "third_degree" ~ 1,
+        kinship_degree == "second_degree" ~ 2,
+        kinship_degree == "first_degree" ~ 3
+    )) |>
+    # add 'Wytham_UK_' to the beginning of each IID column
+    dplyr::mutate(dplyr::across(dplyr::starts_with("IID"), ~ paste("Wytham_UK_", ., sep = "")))

# time: 2024-08-30 14:23:59 UTC
# mode: r
+kinship

# time: 2024-08-30 14:24:05 UTC
# mode: r
+# Load all the data
+all.maf <- SNPRelate::snpgdsOpen(all.gds, allow.duplicate = TRUE)

# time: 2024-08-30 14:24:05 UTC
# mode: r
+# Load labels
+immigrant.id <- gdsfmt::read.gdsn(gdsfmt::index.gdsn(
+    SNPRelate::snpgdsOpen(immigrant.gds),
+    "sample.id"
+))

# time: 2024-08-30 14:24:06 UTC
# mode: r
+resident.id <- gdsfmt::read.gdsn(gdsfmt::index.gdsn(
+    SNPRelate::snpgdsOpen(resident.gds),
+    "sample.id"
+))

# time: 2024-08-30 14:24:07 UTC
# mode: r
+all.id <- gdsfmt::read.gdsn(gdsfmt::index.gdsn(all.maf, "sample.id"))

# time: 2024-08-30 14:24:07 UTC
# mode: r
+all.label <- ifelse(all.id %in% immigrant.id, "immigrant", "resident")

# time: 2024-08-30 14:24:10 UTC
# mode: r
+# Calculate summary statistics for the random and original models
+
+
+
+# randomForest::MDSplot(results$original_rf_models[[1]], results$original_train_labels[[1]])
+
+# rfPermute::confusionMatrix(results$original_rf_models[[1]])
+# # rfPermute::plotPredictedProbs(output.forest, bins = 20, plot = TRUE)
+# # rfPermute::plotProximity(output.forest)
+# # summary(output.forest)
+# # rfPermute::plotTrace(output.forest)
+
+# run a single random forest model:
+
+# 1 prepare data
+split <- split_data(all.id, all.label, percent.train, kinship, kinship_threshold = 0)

# time: 2024-08-30 14:25:11 UTC
# mode: r
+data <- prepare_data(
+    all.maf, split$train.id, split$test.id, split$train.label, split$test.label,
+    num.eigenvectors, num.threads
+)

# time: 2024-08-30 14:25:27 UTC
# mode: r
+# 2 train model
+rf <- train_random_forest(data$train_df, data$test_df, num.eigenvectors, FALSE)

# time: 2024-08-30 14:25:28 UTC
# mode: r
+rfPermute::plotProximity(rf)

# time: 2024-08-30 14:25:36 UTC
# mode: r
+rf

# time: 2024-08-30 14:26:08 UTC
# mode: r
+summary(rf)

# time: 2024-08-30 14:26:23 UTC
# mode: r
+split <- split_data(all.id, all.label, percent.train, kinship, kinship_threshold = 0)
+
+data <- prepare_data(
+    all.maf, split$train.id, split$test.id, split$train.label, split$test.label,
+    num.eigenvectors, num.threads
+)
+
+# 2 train model
+rf <- train_random_forest(data$train_df, data$test_df, num.eigenvectors, FALSE)
+
+rfPermute::plotProximity(rf)
+summary(rf)

# time: 2024-08-30 14:26:46 UTC
# mode: r
+rfPermute::plotProximity(rf)

# time: 2024-08-30 14:26:58 UTC
# mode: r
+summary(rf)

# time: 2024-08-30 14:27:11 UTC
# mode: r
+split

# time: 2024-08-30 14:33:55 UTC
# mode: r
+# Function to split data into training and testing sets
+split_data <- function(all.id, all.label, percent.train, kinship, kinship_threshold = NA) {
+    # Split data by class
+    labels <- unique(all.label)
+    class_0 <- all.id[all.label == labels[1]]
+    class_1 <- all.id[all.label == labels[2]]
+
+    if (is.na(kinship_threshold)) {
+        # Determine the size of the smaller class
+        min_class_size <- min(length(class_0), length(class_1))
+
+        # Undersample the majority class
+        if (length(class_0) > min_class_size) {
+            class_0 <- sample(class_0, min_class_size)
+        } else {
+            class_1 <- sample(class_1, min_class_size)
+        }
+
+        # Combine the balanced classes
+        balanced_ids <- c(class_0, class_1)
+        balanced_labels <- c(rep(labels[1], length(class_0)), rep(labels[2], length(class_1)))
+
+        # Calculate the number of samples for training
+        num_train <- round(length(balanced_ids) * percent.train)
+
+        # Ensure equal representation of both classes in train and test sets
+        num_train_per_class <- num_train %/% 2
+
+        # Randomly select samples for training from each class
+        train_indices <- c(
+            sample(1:min_class_size, num_train_per_class),
+            sample((min_class_size + 1):(2 * min_class_size), num_train_per_class)
+        )
+
+        train.id <- balanced_ids[train_indices]
+        test.id <- balanced_ids[-train_indices]
+        train.label <- balanced_labels[train_indices]
+        test.label <- balanced_labels[-train_indices]
+    } else {
+        # Randomly select training samples
+        num_train <- round(length(all.id) * percent.train)
+        train_indices <- sample(1:length(all.id), num_train)
+        train.id <- all.id[train_indices]
+        train.label <- all.label[train_indices]
+
+        # Identify kinship relationships
+        kinship_filtered <- kinship[kinship$kinship_degree <= kinship_threshold, ]
+        kinship_train <- kinship_filtered[kinship_filtered$IID1 %in% train.id | kinship_filtered$IID2 %in% train.id, ]
+
+        # Build the test set
+        test.id <- setdiff(all.id, train.id)
+        test.id <- test.id[test.id %in% unique(c(kinship_train$IID1, kinship_train$IID2))]
+        test.label <- all.label[all.id %in% test.id]
+
+    }
+
+    # Determine the size of the smaller class
+    min_class_size <- min(length(class_0), length(class_1))
+
+    # Set the desired number of samples for training and testing
+    num_train_per_class <- 200
+    num_test_per_class <- 80
+
+    # Randomly select samples for training from each class
+    train_indices <- c(
+        sample(class_0, num_train_per_class),
+        sample(class_1, num_train_per_class)
+    )
+
+    # Randomly select samples for testing from each class
+    test_indices <- c(
+        sample(setdiff(class_0, train_indices), num_test_per_class),
+        sample(setdiff(class_1, train_indices), num_test_per_class)
+    )
+
+    train.id <- balanced_ids[train_indices]
+    test.id <- balanced_ids[test_indices]
+    train.label <- balanced_labels[train_indices]
+    test.label <- balanced_labels[test_indices]
+
+
+}

# time: 2024-08-30 14:33:57 UTC
# mode: r
+# Calculate summary statistics for the random and original models
+
+
+
+# randomForest::MDSplot(results$original_rf_models[[1]], results$original_train_labels[[1]])
+
+# rfPermute::confusionMatrix(results$original_rf_models[[1]])
+# # rfPermute::plotPredictedProbs(output.forest, bins = 20, plot = TRUE)
+# # rfPermute::plotProximity(output.forest)
+# # summary(output.forest)
+# # rfPermute::plotTrace(output.forest)
+
+# run a single random forest model:
+
+# 1 prepare data
+split <- split_data(all.id, all.label, percent.train, kinship, kinship_threshold = 0)

# time: 2024-08-30 14:37:19 UTC
# mode: r
+if (is.na(kinship_threshold)) {
+        # Determine the size of the smaller class
+        min_class_size <- min(length(class_0), length(class_1))
+
+        # Undersample the majority class
+        if (length(class_0) > min_class_size) {
+            class_0 <- sample(class_0, min_class_size)
+        } else {
+            class_1 <- sample(class_1, min_class_size)
+        }
+
+        # Combine the balanced classes
+        balanced_ids <- c(class_0, class_1)
+        balanced_labels <- c(rep(labels[1], length(class_0)), rep(labels[2], length(class_1)))
+
+        # Calculate the number of samples for training
+        num_train <- round(length(balanced_ids) * percent.train)
+
+        # Ensure equal representation of both classes in train and test sets
+        num_train_per_class <- num_train %/% 2
+
+        # Randomly select samples for training from each class
+        train_indices <- c(
+            sample(1:min_class_size, num_train_per_class),
+            sample((min_class_size + 1):(2 * min_class_size), num_train_per_class)
+        )
+
+        train.id <- balanced_ids[train_indices]
+        test.id <- balanced_ids[-train_indices]
+        train.label <- balanced_labels[train_indices]
+        test.label <- balanced_labels[-train_indices]
+    } else {
+        # Randomly select training samples
+        num_train <- round(length(all.id) * percent.train)
+        train_indices <- sample(1:length(all.id), num_train)
+        train.id <- all.id[train_indices]
+        train.label <- all.label[train_indices]
+
+        # Identify kinship relationships
+        kinship_filtered <- kinship[kinship$kinship_degree <= kinship_threshold, ]
+        kinship_train <- kinship_filtered[kinship_filtered$IID1 %in% train.id | kinship_filtered$IID2 %in% train.id, ]
+
+        # Build the test set
+        test.id <- setdiff(all.id, train.id)
+        test.id <- test.id[test.id %in% unique(c(kinship_train$IID1, kinship_train$IID2))]
+        test.label <- all.label[all.id %in% test.id]
+
+        # Subsample the resulting selection so that there are 200 samples in each class in the training set
+        # and 80 samples in each class in the test set
+        train.id <- c(
+            sample(train.id[train.label == labels[1], ], 200),
+            sample(train.id[train.label == labels[2], ], 200)
+        )
+        test.id <- c(
+            sample(test.id[test.label == labels[1], ], 80),
+            sample(test.id[test.label == labels[2], ], 80)
+        )
+        train.label <- all.label[all.id %in% train.id]
+        test.label <- all.label[all.id %in% test.id]
+        
+
+    }

# time: 2024-08-30 14:37:24 UTC
# mode: r
+# Function to split data into training and testing sets
+split_data <- function(all.id, all.label, percent.train, kinship, kinship_threshold = NA) {
+    # Split data by class
+    labels <- unique(all.label)
+    class_0 <- all.id[all.label == labels[1]]
+    class_1 <- all.id[all.label == labels[2]]
+
+    if (is.na(kinship_threshold)) {
+        # Determine the size of the smaller class
+        min_class_size <- min(length(class_0), length(class_1))
+
+        # Undersample the majority class
+        if (length(class_0) > min_class_size) {
+            class_0 <- sample(class_0, min_class_size)
+        } else {
+            class_1 <- sample(class_1, min_class_size)
+        }
+
+        # Combine the balanced classes
+        balanced_ids <- c(class_0, class_1)
+        balanced_labels <- c(rep(labels[1], length(class_0)), rep(labels[2], length(class_1)))
+
+        # Calculate the number of samples for training
+        num_train <- round(length(balanced_ids) * percent.train)
+
+        # Ensure equal representation of both classes in train and test sets
+        num_train_per_class <- num_train %/% 2
+
+        # Randomly select samples for training from each class
+        train_indices <- c(
+            sample(1:min_class_size, num_train_per_class),
+            sample((min_class_size + 1):(2 * min_class_size), num_train_per_class)
+        )
+
+        train.id <- balanced_ids[train_indices]
+        test.id <- balanced_ids[-train_indices]
+        train.label <- balanced_labels[train_indices]
+        test.label <- balanced_labels[-train_indices]
+    } else {
+        # Randomly select training samples
+        num_train <- round(length(all.id) * percent.train)
+        train_indices <- sample(1:length(all.id), num_train)
+        train.id <- all.id[train_indices]
+        train.label <- all.label[train_indices]
+
+        # Identify kinship relationships
+        kinship_filtered <- kinship[kinship$kinship_degree <= kinship_threshold, ]
+        kinship_train <- kinship_filtered[kinship_filtered$IID1 %in% train.id | kinship_filtered$IID2 %in% train.id, ]
+
+        # Build the test set
+        test.id <- setdiff(all.id, train.id)
+        test.id <- test.id[test.id %in% unique(c(kinship_train$IID1, kinship_train$IID2))]
+        test.label <- all.label[all.id %in% test.id]
+
+        # Subsample the resulting selection so that there are 200 samples in each class in the training set
+        # and 80 samples in each class in the test set
+        train.id <- c(
+            sample(train.id[train.label == labels[1], ], 200),
+            sample(train.id[train.label == labels[2], ], 200)
+        )
+        test.id <- c(
+            sample(test.id[test.label == labels[1], ], 80),
+            sample(test.id[test.label == labels[2], ], 80)
+        )
+        train.label <- all.label[all.id %in% train.id]
+        test.label <- all.label[all.id %in% test.id]
+        
+
+    }
+
+    list(
+        train.id = train.id, test.id = test.id,
+        train.label = train.label, test.label = test.label
+    )
+    
+}

# time: 2024-08-30 14:37:27 UTC
# mode: r
+# Calculate summary statistics for the random and original models
+
+
+
+# randomForest::MDSplot(results$original_rf_models[[1]], results$original_train_labels[[1]])
+
+# rfPermute::confusionMatrix(results$original_rf_models[[1]])
+# # rfPermute::plotPredictedProbs(output.forest, bins = 20, plot = TRUE)
+# # rfPermute::plotProximity(output.forest)
+# # summary(output.forest)
+# # rfPermute::plotTrace(output.forest)
+
+# run a single random forest model:
+
+# 1 prepare data
+split <- split_data(all.id, all.label, percent.train, kinship, kinship_threshold = 0)

# time: 2024-08-30 14:37:42 UTC
# mode: r
+labels[1]

# time: 2024-08-30 14:37:56 UTC
# mode: r
+labels <- unique(all.label)

# time: 2024-08-30 14:37:58 UTC
# mode: r
+labels

# time: 2024-08-30 14:38:00 UTC
# mode: r
+class_0 <- all.id[all.label == labels[1]]
+    class_1 <- all.id[all.label == labels[2]]

# time: 2024-08-30 14:38:08 UTC
# mode: r
+num_train <- round(length(all.id) * percent.train)
+        train_indices <- sample(1:length(all.id), num_train)
+        train.id <- all.id[train_indices]
+        train.label <- all.label[train_indices]

# time: 2024-08-30 14:38:10 UTC
# mode: r
+train.label

# time: 2024-08-30 14:38:16 UTC
# mode: r
+train.id

# time: 2024-08-30 14:38:28 UTC
# mode: r
+train.label

# time: 2024-08-30 14:39:00 UTC
# mode: r
+train.id[train.label == labels[1], ]

# time: 2024-08-30 14:39:07 UTC
# mode: r
+# Subsample the resulting selection so that there are 200 samples in each class in the training set
+        # and 80 samples in each class in the test set
+        train.id <- c(
+            sample(train.id[train.label == labels[1]], 200),
+            sample(train.id[train.label == labels[2]], 200)
+        )

# time: 2024-08-30 14:39:12 UTC
# mode: r
+test.id <- c(
+            sample(test.id[test.label == labels[1]], 80),
+            sample(test.id[test.label == labels[2]], 80)
+        )

# time: 2024-08-30 14:39:20 UTC
# mode: r
+# Function to split data into training and testing sets
+split_data <- function(all.id, all.label, percent.train, kinship, kinship_threshold = NA) {
+    # Split data by class
+    labels <- unique(all.label)
+    class_0 <- all.id[all.label == labels[1]]
+    class_1 <- all.id[all.label == labels[2]]
+
+    if (is.na(kinship_threshold)) {
+        # Determine the size of the smaller class
+        min_class_size <- min(length(class_0), length(class_1))
+
+        # Undersample the majority class
+        if (length(class_0) > min_class_size) {
+            class_0 <- sample(class_0, min_class_size)
+        } else {
+            class_1 <- sample(class_1, min_class_size)
+        }
+
+        # Combine the balanced classes
+        balanced_ids <- c(class_0, class_1)
+        balanced_labels <- c(rep(labels[1], length(class_0)), rep(labels[2], length(class_1)))
+
+        # Calculate the number of samples for training
+        num_train <- round(length(balanced_ids) * percent.train)
+
+        # Ensure equal representation of both classes in train and test sets
+        num_train_per_class <- num_train %/% 2
+
+        # Randomly select samples for training from each class
+        train_indices <- c(
+            sample(1:min_class_size, num_train_per_class),
+            sample((min_class_size + 1):(2 * min_class_size), num_train_per_class)
+        )
+
+        train.id <- balanced_ids[train_indices]
+        test.id <- balanced_ids[-train_indices]
+        train.label <- balanced_labels[train_indices]
+        test.label <- balanced_labels[-train_indices]
+    } else {
+        # Randomly select training samples
+        num_train <- round(length(all.id) * percent.train)
+        train_indices <- sample(1:length(all.id), num_train)
+        train.id <- all.id[train_indices]
+        train.label <- all.label[train_indices]
+
+        # Identify kinship relationships
+        kinship_filtered <- kinship[kinship$kinship_degree <= kinship_threshold, ]
+        kinship_train <- kinship_filtered[kinship_filtered$IID1 %in% train.id | kinship_filtered$IID2 %in% train.id, ]
+
+        # Build the test set
+        test.id <- setdiff(all.id, train.id)
+        test.id <- test.id[test.id %in% unique(c(kinship_train$IID1, kinship_train$IID2))]
+        test.label <- all.label[all.id %in% test.id]
+
+        # Subsample the resulting selection so that there are 200 samples in each class in the training set
+        # and 80 samples in each class in the test set
+        train.id <- c(
+            sample(train.id[train.label == labels[1]], 200),
+            sample(train.id[train.label == labels[2]], 200)
+        )
+        test.id <- c(
+            sample(test.id[test.label == labels[1]], 80),
+            sample(test.id[test.label == labels[2]], 80)
+        )
+        train.label <- all.label[all.id %in% train.id]
+        test.label <- all.label[all.id %in% test.id]
+        
+
+    }
+
+    list(
+        train.id = train.id, test.id = test.id,
+        train.label = train.label, test.label = test.label
+    )
+    
+}

# time: 2024-08-30 14:39:22 UTC
# mode: r
+# Calculate summary statistics for the random and original models
+
+
+
+# randomForest::MDSplot(results$original_rf_models[[1]], results$original_train_labels[[1]])
+
+# rfPermute::confusionMatrix(results$original_rf_models[[1]])
+# # rfPermute::plotPredictedProbs(output.forest, bins = 20, plot = TRUE)
+# # rfPermute::plotProximity(output.forest)
+# # summary(output.forest)
+# # rfPermute::plotTrace(output.forest)
+
+# run a single random forest model:
+
+# 1 prepare data
+split <- split_data(all.id, all.label, percent.train, kinship, kinship_threshold = 0)

# time: 2024-08-30 14:40:00 UTC
# mode: r
+data <- prepare_data(
+    all.maf, split$train.id, split$test.id, split$train.label, split$test.label,
+    num.eigenvectors, num.threads
+)

# time: 2024-08-30 14:40:12 UTC
# mode: r
+# 2 train model
+rf <- train_random_forest(data$train_df, data$test_df, num.eigenvectors, FALSE)

# time: 2024-08-30 14:40:13 UTC
# mode: r
+rfPermute::plotProximity(rf)

# time: 2024-08-30 14:40:22 UTC
# mode: r
+summary(rf)

# time: 2024-08-30 14:40:45 UTC
# mode: r
+split

# time: 2024-08-30 14:40:55 UTC
# mode: r
+data

# time: 2024-08-30 14:41:22 UTC
# mode: r
+split <- split_data(all.id, all.label, percent.train, kinship, kinship_threshold = 3)
+
+data <- prepare_data(
+    all.maf, split$train.id, split$test.id, split$train.label, split$test.label,
+    num.eigenvectors, num.threads
+)
+
+# 2 train model
+rf <- train_random_forest(data$train_df, data$test_df, num.eigenvectors, FALSE)
+
+rfPermute::plotProximity(rf)
+summary(rf)

# time: 2024-08-30 14:42:28 UTC
# mode: r
+# Function to split data into training and testing sets
+split_data <- function(all.id, all.label, percent.train, kinship, kinship_threshold = NA) {
+    # Split data by class
+    labels <- unique(all.label)
+    class_0 <- all.id[all.label == labels[1]]
+    class_1 <- all.id[all.label == labels[2]]
+
+    if (is.na(kinship_threshold)) {
+        # Determine the size of the smaller class
+        min_class_size <- min(length(class_0), length(class_1))
+
+        # Undersample the majority class
+        if (length(class_0) > min_class_size) {
+            class_0 <- sample(class_0, min_class_size)
+        } else {
+            class_1 <- sample(class_1, min_class_size)
+        }
+
+        # Combine the balanced classes
+        balanced_ids <- c(class_0, class_1)
+        balanced_labels <- c(rep(labels[1], length(class_0)), rep(labels[2], length(class_1)))
+
+        # Calculate the number of samples for training
+        num_train <- round(length(balanced_ids) * percent.train)
+
+        # Ensure equal representation of both classes in train and test sets
+        num_train_per_class <- num_train %/% 2
+
+        # Randomly select samples for training from each class
+        train_indices <- c(
+            sample(1:min_class_size, num_train_per_class),
+            sample((min_class_size + 1):(2 * min_class_size), num_train_per_class)
+        )
+
+        train.id <- balanced_ids[train_indices]
+        test.id <- balanced_ids[-train_indices]
+        train.label <- balanced_labels[train_indices]
+        test.label <- balanced_labels[-train_indices]
+    } else {
+        # Randomly select training samples
+        num_train <- round(length(all.id) * percent.train)
+        train_indices <- sample(1:length(all.id), num_train)
+        train.id <- all.id[train_indices]
+        train.label <- all.label[train_indices]
+
+        # Identify kinship relationships
+        kinship_filtered <- kinship[kinship$kinship_degree <= kinship_threshold, ]
+        kinship_train <- kinship_filtered[kinship_filtered$IID1 %in% train.id | kinship_filtered$IID2 %in% train.id, ]
+
+        # Build the test set
+        test.id <- setdiff(all.id, train.id)
+        test.id <- test.id[test.id %in% unique(c(kinship_train$IID1, kinship_train$IID2))]
+        test.label <- all.label[all.id %in% test.id]
+
+        # Subsample the resulting selection so that there are 200 samples in each class in the training set
+        # and 80 samples in each class in the test set
+        train.id <- c(
+            sample(train.id[train.label == labels[1]], 200),
+            sample(train.id[train.label == labels[2]], 200)
+        )
+        test.id <- c(
+            sample(test.id[test.label == labels[1]], 40),
+            sample(test.id[test.label == labels[2]], 40)
+        )
+        train.label <- all.label[all.id %in% train.id]
+        test.label <- all.label[all.id %in% test.id]
+        
+
+    }
+
+    list(
+        train.id = train.id, test.id = test.id,
+        train.label = train.label, test.label = test.label
+    )
+    
+}

# time: 2024-08-30 14:42:35 UTC
# mode: r
+# Calculate summary statistics for the random and original models
+
+
+
+# randomForest::MDSplot(results$original_rf_models[[1]], results$original_train_labels[[1]])
+
+# rfPermute::confusionMatrix(results$original_rf_models[[1]])
+# # rfPermute::plotPredictedProbs(output.forest, bins = 20, plot = TRUE)
+# # rfPermute::plotProximity(output.forest)
+# # summary(output.forest)
+# # rfPermute::plotTrace(output.forest)
+
+# run a single random forest model:
+
+# 1 prepare data
+split <- split_data(all.id, all.label, percent.train, kinship, kinship_threshold = 3)

# time: 2024-08-30 14:42:37 UTC
# mode: r
+data <- prepare_data(
+    all.maf, split$train.id, split$test.id, split$train.label, split$test.label,
+    num.eigenvectors, num.threads
+)

# time: 2024-08-30 14:42:52 UTC
# mode: r
+# 2 train model
+rf <- train_random_forest(data$train_df, data$test_df, num.eigenvectors, FALSE)

# time: 2024-08-30 14:42:55 UTC
# mode: r
+summary(rf)

# time: 2024-08-30 14:49:28 UTC
# mode: r
+rf$test

# time: 2024-08-30 14:49:48 UTC
# mode: r
+rf$test$err.rate

# time: 2024-08-30 14:50:23 UTC
# mode: r
+rf$test$confusion

# time: 2024-08-30 14:51:11 UTC
# mode: r
+split <- split_data(all.id, all.label, percent.train, kinship, kinship_threshold = 3)
+
+data <- prepare_data(
+    all.maf, split$train.id, split$test.id, split$train.label, split$test.label,
+    num.eigenvectors, num.threads
+)
+
+# 2 train model
+rf <- train_random_forest(data$train_df, data$test_df, num.eigenvectors, FALSE)
+
+# rfPermute::plotProximity(rf)
+# summary(rf)
+
+# rf$test$err.rate
+rf$test$confusion

# time: 2024-08-30 14:52:01 UTC
# mode: r
+split <- split_data(all.id, all.label, percent.train, kinship, kinship_threshold = 0)
+
+data <- prepare_data(
+    all.maf, split$train.id, split$test.id, split$train.label, split$test.label,
+    num.eigenvectors, num.threads
+)
+
+# 2 train model
+rf <- train_random_forest(data$train_df, data$test_df, num.eigenvectors, FALSE)
+
+# rfPermute::plotProximity(rf)
+# summary(rf)
+
+# rf$test$err.rate
+rf$test$confusion

# time: 2024-08-30 14:52:57 UTC
# mode: r
+rf$test$err.rate

# time: 2024-08-30 14:55:09 UTC
# mode: r
+# Run the analysis 5 times with threshold 0
+for (i in 1:2) {
+    # Split data
+    split <- split_data(all.id, all.label, percent.train, kinship, kinship_threshold = 0)
+    
+    # Prepare data
+    data <- prepare_data(
+        all.maf, split$train.id, split$test.id, split$train.label, split$test.label,
+        num.eigenvectors, num.threads
+    )
+    
+    # Train random forest
+    rf <- train_random_forest(data$train_df, data$test_df, num.eigenvectors, FALSE)
+    
+    # Store the prederror values
+    prederror_threshold_0[[i]] <- rf$test$err.rate
+}
+
+# Run the analysis 5 times with threshold 3
+for (i in 1:2) {
+    # Split data
+    split <- split_data(all.id, all.label, percent.train, kinship, kinship_threshold = 3)
+    
+    # Prepare data
+    data <- prepare_data(
+        all.maf, split$train.id, split$test.id, split$train.label, split$test.label,
+        num.eigenvectors, num.threads
+    )
+    
+    # Train random forest
+    rf <- train_random_forest(data$train_df, data$test_df, num.eigenvectors, FALSE)
+    
+    # Store the prederror values
+    prederror_threshold_3[[i]] <- rf$test$err.rate
+}
+
+# Combine the prederror values
+prederror_combined <- cbind(
+    threshold_0 = do.call(rbind, prederror_threshold_0),
+    threshold_3 = do.call(rbind, prederror_threshold_3)
+)

# time: 2024-08-30 14:55:33 UTC
# mode: r
+prederror_threshold_0

# time: 2024-08-30 14:55:40 UTC
# mode: r
+prederror_threshold_0 <- list()
+prederror_threshold_3 <- list()
+
+# Run the analysis 5 times with threshold 0
+for (i in 1:2) {
+    # Split data
+    split <- split_data(all.id, all.label, percent.train, kinship, kinship_threshold = 0)
+    
+    # Prepare data
+    data <- prepare_data(
+        all.maf, split$train.id, split$test.id, split$train.label, split$test.label,
+        num.eigenvectors, num.threads
+    )
+    
+    # Train random forest
+    rf <- train_random_forest(data$train_df, data$test_df, num.eigenvectors, FALSE)
+    
+    # Store the prederror values
+    prederror_threshold_0[[i]] <- rf$test$err.rate
+}
+
+# Run the analysis 5 times with threshold 3
+for (i in 1:2) {
+    # Split data
+    split <- split_data(all.id, all.label, percent.train, kinship, kinship_threshold = 3)
+    
+    # Prepare data
+    data <- prepare_data(
+        all.maf, split$train.id, split$test.id, split$train.label, split$test.label,
+        num.eigenvectors, num.threads
+    )
+    
+    # Train random forest
+    rf <- train_random_forest(data$train_df, data$test_df, num.eigenvectors, FALSE)
+    
+    # Store the prederror values
+    prederror_threshold_3[[i]] <- rf$test$err.rate
+}
+
+# Combine the prederror values
+prederror_combined <- cbind(
+    threshold_0 = do.call(rbind, prederror_threshold_0),
+    threshold_3 = do.call(rbind, prederror_threshold_3)
+)

# time: 2024-08-30 14:56:27 UTC
# mode: r
+prederror_combined

# time: 2024-08-30 14:57:07 UTC
# mode: r
+# Plot the prederror values
+plot_data <- data.frame(
+    Iteration = rep(1:5, each = 2),
+    Threshold = rep(c("0", "3"), times = 5),
+    PredError = c(prederror_combined[, "immigrant"], prederror_combined[, "resident"])
+)

# time: 2024-08-30 14:57:10 UTC
# mode: r
+plot_data

# time: 2024-08-30 14:57:57 UTC
# mode: r
+# each prederror to a tibble
+prederror_threshold_0_df <- dplyr::as_tibble(do.call(rbind, prederror_threshold_0))

# time: 2024-08-30 14:57:59 UTC
# mode: r
+prederror_threshold_0_df

# time: 2024-08-30 14:58:33 UTC
# mode: r
+# each prederror to a tibble
+prederror_threshold_0_df <- dplyr::as_tibble(do.call(rbind, prederror_threshold_0)) |>
+    # add a column for the iteration number 'trees'
+    dplyr::mutate(trees = 1:nrow(.))

# time: 2024-08-30 14:58:51 UTC
# mode: r
+# each prederror to a tibble
+prederror_threshold_0_df <- dplyr::as_tibble(do.call(rbind, prederror_threshold_0)) |>
+    # add a column for the iteration number 'trees'
+    dplyr::mutate(trees = 1:nrow())

# time: 2024-08-30 14:59:54 UTC
# mode: r
+rf$test$err.rate

# time: 2024-08-30 15:00:55 UTC
# mode: r
+# Initialize empty lists to store the prederror values
+prederror_threshold_0 <- list()
+prederror_threshold_3 <- list()
+
+# Run the analysis 5 times with threshold 0
+for (i in 1:2) {
+    # Split data
+    split <- split_data(all.id, all.label, percent.train, kinship, kinship_threshold = 0)
+    
+    # Prepare data
+    data <- prepare_data(
+        all.maf, split$train.id, split$test.id, split$train.label, split$test.label,
+        num.eigenvectors, num.threads
+    )
+    
+    # Train random forest
+    rf <- train_random_forest(data$train_df, data$test_df, num.eigenvectors, FALSE)
+    
+    # Store the prederror values
+    prederror_threshold_0[[i]] <- rf$test$err.rate |> # add a 'trees' column with the row number
+        dplyr::mutate(trees = 1:nrow(rf$test$err.rate))
+}
+
+# Run the analysis 5 times with threshold 3
+for (i in 1:2) {
+    # Split data
+    split <- split_data(all.id, all.label, percent.train, kinship, kinship_threshold = 3)
+
+    # Prepare data
+    data <- prepare_data(
+        all.maf, split$train.id, split$test.id, split$train.label, split$test.label,
+        num.eigenvectors, num.threads
+    )
+
+    # Train random forest
+    rf <- train_random_forest(data$train_df, data$test_df, num.eigenvectors, FALSE)
+
+    # Store the prederror values
+    prederror_threshold_3[[i]] <- rf$test$err.rate |> # add a 'trees' column with the row number
+        dplyr::mutate(trees = 1:nrow(rf$test$err.rate))
+}

# time: 2024-08-30 15:01:28 UTC
# mode: r
+rf$test$err.rate |> dplyr::as_tibble() |>
+        dplyr::mutate(trees = 1:nrow(rf$test$err.rate))

# time: 2024-08-30 15:01:38 UTC
# mode: r
+prederror_threshold_0 <- list()
+prederror_threshold_3 <- list()
+
+# Run the analysis 5 times with threshold 0
+for (i in 1:2) {
+    # Split data
+    split <- split_data(all.id, all.label, percent.train, kinship, kinship_threshold = 0)
+    
+    # Prepare data
+    data <- prepare_data(
+        all.maf, split$train.id, split$test.id, split$train.label, split$test.label,
+        num.eigenvectors, num.threads
+    )
+    
+    # Train random forest
+    rf <- train_random_forest(data$train_df, data$test_df, num.eigenvectors, FALSE)
+    
+    # Store the prederror values
+    prederror_threshold_0[[i]] <- rf$test$err.rate |> dplyr::as_tibble() |>
+        dplyr::mutate(trees = 1:nrow(rf$test$err.rate))
+}
+
+# Run the analysis 5 times with threshold 3
+for (i in 1:2) {
+    # Split data
+    split <- split_data(all.id, all.label, percent.train, kinship, kinship_threshold = 3)
+
+    # Prepare data
+    data <- prepare_data(
+        all.maf, split$train.id, split$test.id, split$train.label, split$test.label,
+        num.eigenvectors, num.threads
+    )
+
+    # Train random forest
+    rf <- train_random_forest(data$train_df, data$test_df, num.eigenvectors, FALSE)
+
+    # Store the prederror values
+    prederror_threshold_3[[i]] <- rf$test$err.rate |>
+        dplyr::as_tibble() |>
+        dplyr::mutate(trees = 1:nrow(rf$test$err.rate))
+}

# time: 2024-08-30 15:04:09 UTC
# mode: r
+# prepare the data for plotting
+prederror_threshold_0_df <- dplyr::bind_rows(prederror_threshold_0, .id = "iteration") |>
+    dplyr::mutate(threshold = 0)

# time: 2024-08-30 15:04:19 UTC
# mode: r
+prederror_threshold_3_df <- dplyr::bind_rows(prederror_threshold_3, .id = "iteration") |>
+    dplyr::mutate(threshold = 3)

# time: 2024-08-30 15:04:23 UTC
# mode: r
+prederror_threshold_0_df

# time: 2024-08-30 15:04:45 UTC
# mode: r
+ggplot2::ggplot() +
+    ggplot2::geom_line(data = prederror_threshold_0_df, ggplot2::aes(x = trees, y = error, color = iteration)) +
+    ggplot2::geom_line(data = prederror_threshold_3_df, ggplot2::aes(x = trees, y = error, color = iteration)) +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(title = "Prediction error rate for different kinship thresholds",
+                  x = "Number of trees", y = "Prediction error rate") +
+    ggplot2::scale_color_manual(values = c("blue", "red")) +
+    ggplot2::theme(aspect.ratio = 1, text = ggplot2::element_text(size = 12))

# time: 2024-08-30 15:05:31 UTC
# mode: r
+# prepare the data for plotting
+prederror_threshold_0_df <- dplyr::bind_rows(prederror_threshold_0, .id = "iteration") |>
+    tidyr::pivot_longer(cols = starts_with("immigrant"), names_to = "class", values_to = "error") |>
+    dplyr::mutate(threshold = 0)

# time: 2024-08-30 15:05:36 UTC
# mode: r
+prederror_threshold_3_df <- dplyr::bind_rows(prederror_threshold_3, .id = "iteration") |>
+    tidyr::pivot_longer(cols = starts_with("immigrant"), names_to = "class", values_to = "error") |>
+    dplyr::mutate(threshold = 3)

# time: 2024-08-30 15:05:39 UTC
# mode: r
+ggplot2::ggplot() +
+    ggplot2::geom_line(data = prederror_threshold_0_df, ggplot2::aes(x = trees, y = error, color = iteration)) +
+    ggplot2::geom_line(data = prederror_threshold_3_df, ggplot2::aes(x = trees, y = error, color = iteration)) +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(title = "Prediction error rate for different kinship thresholds",
+                  x = "Number of trees", y = "Prediction error rate") +
+    ggplot2::scale_color_manual(values = c("blue", "red")) +
+    ggplot2::theme(aspect.ratio = 1, text = ggplot2::element_text(size = 12))

# time: 2024-08-30 15:05:50 UTC
# mode: r
+prederror_threshold_3_df

# time: 2024-08-30 15:06:32 UTC
# mode: r
+ggplot2::ggplot() +
+    ggplot2::geom_line(data = prederror_threshold_0_df, ggplot2::aes(x = trees, y = error, color = class, linetype = as.factor(threshold))) +
+    ggplot2::geom_line(data = prederror_threshold_3_df, ggplot2::aes(x = trees, y = error, color = class, linetype = as.factor(threshold))) +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(title = "Prediction error rate for different kinship thresholds",
+                  x = "Number of trees", y = "Prediction error rate") +
+    ggplot2::scale_color_manual(values = c("blue", "red")) +
+    ggplot2::theme(aspect.ratio = 1, text = ggplot2::element_text(size = 12))

# time: 2024-08-30 15:06:58 UTC
# mode: r
+prederror_threshold_0_df

# time: 2024-08-30 15:07:31 UTC
# mode: r
+# prepare the data for plotting
+prederror_threshold_0_df <- dplyr::bind_rows(prederror_threshold_0, .id = "iteration") |>
+    tidyr::pivot_longer(cols = c("immigrant", "resident"), names_to = "class", values_to = "error") |>
+    dplyr::mutate(threshold = 0)

# time: 2024-08-30 15:07:32 UTC
# mode: r
+prederror_threshold_3_df <- dplyr::bind_rows(prederror_threshold_3, .id = "iteration") |>
+    tidyr::pivot_longer(cols = c("immigrant", "resident"), names_to = "class", values_to = "error") |>
+    dplyr::mutate(threshold = 3)

# time: 2024-08-30 15:07:34 UTC
# mode: r
+ggplot2::ggplot() +
+    ggplot2::geom_line(data = prederror_threshold_0_df, ggplot2::aes(x = trees, y = error, color = class, linetype = as.factor(threshold))) +
+    ggplot2::geom_line(data = prederror_threshold_3_df, ggplot2::aes(x = trees, y = error, color = class, linetype = as.factor(threshold))) +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(title = "Prediction error rate for different kinship thresholds",
+                  x = "Number of trees", y = "Prediction error rate") +
+    ggplot2::scale_color_manual(values = c("blue", "red")) +
+    ggplot2::theme(aspect.ratio = 1, text = ggplot2::element_text(size = 12))

# time: 2024-08-30 15:08:57 UTC
# mode: r
+rfPermute::plotTrace(rf, plot = FALSE)$data

# time: 2024-08-30 15:09:35 UTC
# mode: r
+ggplot2::ggplot() +
+    ggplot2::geom_line(data = prederror_threshold_0_df, ggplot2::aes(x = trees, y = 1-error, color = class, linetype = as.factor(threshold))) +
+    ggplot2::geom_line(data = prederror_threshold_3_df, ggplot2::aes(x = trees, y = 1-error, color = class, linetype = as.factor(threshold))) +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(title = "Prediction error rate for different kinship thresholds",
+                  x = "Number of trees", y = "Prediction error rate") +
+    ggplot2::scale_color_manual(values = c("blue", "red")) +
+    ggplot2::theme(aspect.ratio = 1, text = ggplot2::element_text(size = 12))

# time: 2024-08-30 15:10:25 UTC
# mode: r
+rfPermute::plotTrace(rf, plot = FALSE)$data

# time: 2024-08-30 15:11:15 UTC
# mode: r
+rfPermute::plotTrace(rf, plot = FALSE)$data |> dplyr::as_tibble()

# time: 2024-08-30 15:12:01 UTC
# mode: r
+prederror_threshold_0 <- list()
+prederror_threshold_3 <- list()
+
+# Run the analysis 5 times with threshold 0
+for (i in 1:2) {
+    # Split data
+    split <- split_data(all.id, all.label, percent.train, kinship, kinship_threshold = 0)
+    
+    # Prepare data
+    data <- prepare_data(
+        all.maf, split$train.id, split$test.id, split$train.label, split$test.label,
+        num.eigenvectors, num.threads
+    )
+    
+    # Train random forest
+    rf <- train_random_forest(data$train_df, data$test_df, num.eigenvectors, FALSE)
+    
+    # Store the prederror values
+    prederror_threshold_0[[i]] <- rfPermute::plotTrace(rf, plot = FALSE)$data |> dplyr::as_tibble()
+}
+
+# Run the analysis 5 times with threshold 3
+for (i in 1:2) {
+    # Split data
+    split <- split_data(all.id, all.label, percent.train, kinship, kinship_threshold = 3)
+
+    # Prepare data
+    data <- prepare_data(
+        all.maf, split$train.id, split$test.id, split$train.label, split$test.label,
+        num.eigenvectors, num.threads
+    )
+
+    # Train random forest
+    rf <- train_random_forest(data$train_df, data$test_df, num.eigenvectors, FALSE)
+
+    # Store the prederror values
+    prederror_threshold_3[[i]] <- rfPermute::plotTrace(rf, plot = FALSE)$data |> dplyr::as_tibble()
+}

# time: 2024-08-30 15:13:10 UTC
# mode: r
+# prepare the data for plotting
+prederror_threshold_0_df <- dplyr::bind_rows(prederror_threshold_0) |>
+    dplyr::mutate(threshold = 0)
+
+prederror_threshold_3_df <- dplyr::bind_rows(prederror_threshold_3) |>
+    dplyr::mutate(threshold = 3)
+
+ggplot2::ggplot() +
+    ggplot2::geom_line(data = prederror_threshold_0_df, ggplot2::aes(x = trees, y = error, color = class, linetype = as.factor(threshold))) +
+    ggplot2::geom_line(data = prederror_threshold_3_df, ggplot2::aes(x = trees, y = error, color = class, linetype = as.factor(threshold))) +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(title = "Prediction error rate for different kinship thresholds",
+                  x = "Number of trees", y = "Prediction error rate") +
+    ggplot2::scale_color_manual(values = c("blue", "red")) +
+    ggplot2::theme(aspect.ratio = 1, text = ggplot2::element_text(size = 12))

# time: 2024-08-30 15:13:27 UTC
# mode: r
+prederror_threshold_0_df

# time: 2024-08-30 15:13:41 UTC
# mode: r
+# prepare the data for plotting
+prederror_threshold_0_df <- dplyr::bind_rows(prederror_threshold_0) |>
+    dplyr::mutate(threshold = 0) |> # remove OOB from the class column
+    dplyr::filter(class != "OOB")

# time: 2024-08-30 15:13:42 UTC
# mode: r
+prederror_threshold_3_df <- dplyr::bind_rows(prederror_threshold_3) |>
+    dplyr::mutate(threshold = 3) |>
+    dplyr::filter(class != "OOB")

# time: 2024-08-30 15:13:42 UTC
# mode: r
+ggplot2::ggplot() +
+    ggplot2::geom_line(data = prederror_threshold_0_df, ggplot2::aes(x = trees, y = error, color = class, linetype = as.factor(threshold))) +
+    ggplot2::geom_line(data = prederror_threshold_3_df, ggplot2::aes(x = trees, y = error, color = class, linetype = as.factor(threshold))) +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(title = "Prediction error rate for different kinship thresholds",
+                  x = "Number of trees", y = "Prediction error rate") +
+    ggplot2::scale_color_manual(values = c("blue", "red")) +
+    ggplot2::theme(aspect.ratio = 1, text = ggplot2::element_text(size = 12))

# time: 2024-08-30 15:15:08 UTC
# mode: r
+# prepare the data for plotting
+prederror_threshold_0_df <- dplyr::bind_rows(prederror_threshold_0) |>
+    dplyr::mutate(threshold = 0) |> # remove OOB from the class column
+    dplyr::filter(class != "OOB")
+
+prederror_threshold_3_df <- dplyr::bind_rows(prederror_threshold_3) |>
+    dplyr::mutate(threshold = 3) |>
+    dplyr::filter(class != "OOB")
+
+# add mean error values
+mean_prederror_threshold_0_df <- calculate_mean_error(prederror_threshold_0_df)
+mean_prederror_threshold_3_df <- calculate_mean_error(prederror_threshold_3_df)
+
+ggplot2::ggplot() +
+    ggplot2::geom_line(data = prederror_threshold_0_df, ggplot2::aes(x = trees, y = error, color = class, linetype = as.factor(threshold))) +
+    ggplot2::geom_line(data = prederror_threshold_3_df, ggplot2::aes(x = trees, y = error, color = class, linetype = as.factor(threshold))) +
+    ggplot2::geom_line(data = mean_prederror_threshold_0_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class, linetype =
+            as.factor(threshold)
+    ), size = 1.5) +
+    ggplot2::geom_line(data = mean_prederror_threshold_3_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class, linetype =
+            as.factor(threshold)
+    ), size = 1.5) +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(title = "Prediction error rate for different kinship thresholds",
+                  x = "Number of trees", y = "Prediction error rate") +
+    ggplot2::scale_color_manual(values = c("blue", "red")) +
+    ggplot2::theme(aspect.ratio = 1, text = ggplot2::element_text(size = 12))

# time: 2024-08-30 15:15:43 UTC
# mode: r
+mean_prederror_threshold_0_df

# time: 2024-08-30 15:15:57 UTC
# mode: r
+# add mean error values
+mean_prederror_threshold_0_df <- calculate_mean_error(prederror_threshold_0_df) |>
+    dplyr::mutate(threshold = 0)

# time: 2024-08-30 15:15:58 UTC
# mode: r
+mean_prederror_threshold_3_df <- calculate_mean_error(prederror_threshold_3_df) |>
+    dplyr::mutate(threshold = 3)

# time: 2024-08-30 15:15:59 UTC
# mode: r
+ggplot2::ggplot() +
+    ggplot2::geom_line(data = prederror_threshold_0_df, ggplot2::aes(
+        x = trees, y = error, color = class, linetype = as.factor(threshold))) +
+    ggplot2::geom_line(data = prederror_threshold_3_df, ggplot2::aes(
+        x = trees, y = error, color = class, linetype = as.factor(threshold))) +
+    ggplot2::geom_line(data = mean_prederror_threshold_0_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class, linetype =
+            as.factor(threshold)
+    ), size = 1.5) +
+    ggplot2::geom_line(data = mean_prederror_threshold_3_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class, linetype =
+            as.factor(threshold)
+    ), size = 1.5) +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(title = "Prediction error rate for different kinship thresholds",
+                  x = "Number of trees", y = "Prediction error rate") +
+    ggplot2::scale_color_manual(values = c("blue", "red")) +
+    ggplot2::theme(aspect.ratio = 1, text = ggplot2::element_text(size = 12))

# time: 2024-08-30 15:16:34 UTC
# mode: r
+ggplot2::ggplot() +
+    ggplot2::geom_line(data = prederror_threshold_0_df, ggplot2::aes(
+        x = trees, y = error, color = class, linetype = as.factor(threshold)
+    ), alpha = 0.1) +
+    ggplot2::geom_line(data = prederror_threshold_3_df, ggplot2::aes(
+        x = trees, y = error, color = class, linetype = as.factor(threshold)
+    ), alpha = 0.1, linetype = "dashed") +
+    ggplot2::geom_line(data = mean_prederror_threshold_0_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class, linetype = as.factor(threshold)
+    ), size = 1.5) +
+    ggplot2::geom_line(data = mean_prederror_threshold_3_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class, linetype = as.factor(threshold)
+    ), size = 1.5, linetype = "dashed") +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(
+        title = "Prediction error rate for different kinship thresholds",
+        x = "Number of trees", y = "Prediction error rate"
+    ) +
+    ggplot2::scale_color_manual(
+        values = c(
+            "blue" = "#5d8566",
+            "red" = "#c29007",
+            "immigrant" = "#5d8566",
+            "resident" = "#c29007"
+        )
+    ) +
+    ggplot2::scale_linetype_manual(
+        values = c("solid", "dashed"),
+        labels = c("Threshold 0", "Threshold 3")
+    ) +
+    ggplot2::theme(
+        aspect.ratio = 1,
+        text = ggplot2::element_text(size = 12),
+        legend.position = "bottom",
+        legend.title = ggplot2::element_blank(),
+        legend.text = ggplot2::element_text(size = 10),
+        panel.grid.major = ggplot2::element_blank(),
+        panel.grid.minor = ggplot2::element_blank()
+    )

# time: 2024-08-30 15:17:15 UTC
# mode: r
+ggplot2::ggplot() +
+    ggplot2::geom_line(data = prederror_threshold_0_df, ggplot2::aes(
+        x = trees, y = error, color = class, linetype = as.factor(threshold)
+    ), alpha = 0.1) +
+    ggplot2::geom_line(data = prederror_threshold_3_df, ggplot2::aes(
+        x = trees, y = error, color = class, linetype = as.factor(threshold)
+    ), alpha = 0.1, linetype = "dashed") +
+    ggplot2::geom_line(data = mean_prederror_threshold_0_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class, linetype = as.factor(threshold)
+    ), size = 1.5) +
+    ggplot2::geom_line(data = mean_prederror_threshold_3_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class, linetype = as.factor(threshold)
+    ), size = 1.5, linetype = "dashed") +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(
+        title = "Prediction error rate for different kinship thresholds",
+        x = "Number of trees", y = "Prediction error rate"
+    ) +
+    ggplot2::scale_color_manual(
+        values = c(
+            "immigrant" = "#5d8566",
+            "resident" = "#c29007"
+        )
+    ) +
+    ggplot2::scale_linetype_manual(
+        values = c("solid", "dashed"),
+        labels = c("Threshold 0", "Threshold 3")
+    ) +
+    ggplot2::theme(
+        aspect.ratio = 1,
+        text = ggplot2::element_text(size = 12),
+        legend.position = "bottom",
+        legend.title = ggplot2::element_blank(),
+        legend.text = ggplot2::element_text(size = 10),
+        panel.grid.major = ggplot2::element_blank(),
+        panel.grid.minor = ggplot2::element_blank()
+    )

# time: 2024-08-30 15:18:16 UTC
# mode: r
+ggplot2::ggplot() +
+    ggplot2::geom_line(data = prederror_threshold_0_df, ggplot2::aes(
+        x = trees, y = error, color = class, linetype = as.factor(threshold)
+    ), alpha = 0.1) +
+    ggplot2::geom_line(data = prederror_threshold_3_df, ggplot2::aes(
+        x = trees, y = error, color = class, linetype = as.factor(threshold)
+    ), alpha = 0.1, linetype = "dashed") +
+    ggplot2::geom_line(data = mean_prederror_threshold_0_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class, linetype = as.factor(threshold)
+    ), size = 1.5) +
+    ggplot2::geom_line(data = mean_prederror_threshold_3_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class, linetype = as.factor(threshold)
+    ), size = 1.5, linetype = "dashed") +
+    # add horizontal line at 50% error rate
+    ggplot2::geom_hline(yintercept = 0.5, linetype = "dotted", color = "red") +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(
+        title = "Prediction error rate for different kinship thresholds",
+        x = "Number of trees", y = "Prediction error rate"
+    ) +
+    ggplot2::scale_color_manual(
+        values = c(
+            "immigrant" = "#5d8566",
+            "resident" = "#c29007"
+        )
+    ) +
+    ggplot2::scale_linetype_manual(
+        values = c("solid", "dashed"),
+        labels = c("Threshold 0", "Threshold 3")
+    ) +
+    ggplot2::theme(
+        aspect.ratio = 1,
+        text = ggplot2::element_text(size = 12),
+        legend.position = "bottom",
+        legend.title = ggplot2::element_blank(),
+        legend.text = ggplot2::element_text(size = 10),
+        panel.grid.major = ggplot2::element_blank(),
+        panel.grid.minor = ggplot2::element_blank()
+    )

# time: 2024-08-30 15:18:25 UTC
# mode: r
+ggplot2::ggplot() +
+    ggplot2::geom_line(data = prederror_threshold_0_df, ggplot2::aes(
+        x = trees, y = error, color = class, linetype = as.factor(threshold)
+    ), alpha = 0.1) +
+    ggplot2::geom_line(data = prederror_threshold_3_df, ggplot2::aes(
+        x = trees, y = error, color = class, linetype = as.factor(threshold)
+    ), alpha = 0.1, linetype = "dashed") +
+    ggplot2::geom_line(data = mean_prederror_threshold_0_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class, linetype = as.factor(threshold)
+    ), size = 1.5) +
+    ggplot2::geom_line(data = mean_prederror_threshold_3_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class, linetype = as.factor(threshold)
+    ), size = 1.5, linetype = "dashed") +
+    # add horizontal line at 50% error rate
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "red") +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(
+        title = "Prediction error rate for different kinship thresholds",
+        x = "Number of trees", y = "Prediction error rate"
+    ) +
+    ggplot2::scale_color_manual(
+        values = c(
+            "immigrant" = "#5d8566",
+            "resident" = "#c29007"
+        )
+    ) +
+    ggplot2::scale_linetype_manual(
+        values = c("solid", "dashed"),
+        labels = c("Threshold 0", "Threshold 3")
+    ) +
+    ggplot2::theme(
+        aspect.ratio = 1,
+        text = ggplot2::element_text(size = 12),
+        legend.position = "bottom",
+        legend.title = ggplot2::element_blank(),
+        legend.text = ggplot2::element_text(size = 10),
+        panel.grid.major = ggplot2::element_blank(),
+        panel.grid.minor = ggplot2::element_blank()
+    )

# time: 2024-08-30 15:19:10 UTC
# mode: r
+prederror_threshold_3_df

# time: 2024-08-30 15:20:35 UTC
# mode: r
+# Calculate summary statistics for the random and original models
+
+
+
+# randomForest::MDSplot(results$original_rf_models[[1]], results$original_train_labels[[1]])
+
+# rfPermute::confusionMatrix(results$original_rf_models[[1]])
+# # rfPermute::plotPredictedProbs(output.forest, bins = 20, plot = TRUE)
+# # rfPermute::plotProximity(output.forest)
+# # summary(output.forest)
+# # rfPermute::plotTrace(output.forest)
+
+# run a single random forest model:
+
+# 1 prepare data
+# Initialize empty lists to store the prederror values
+
+
+run_random_forest <- function(all.id, all.label, all.maf, percent.train, num.eigenvectors, num.threads, kinship_threshold) {
+    # Split data
+    split <- split_data(all.id, all.label, percent.train, kinship, kinship_threshold)
+    
+    # Prepare data
+    data <- prepare_data(
+        all.maf, split$train.id, split$test.id, split$train.label, split$test.label,
+        num.eigenvectors, num.threads
+    )
+    
+    # Train random forest
+    rf <- train_random_forest(data$train_df, data$test_df, num.eigenvectors, FALSE)
+    
+    # Return the prederror values
+    return(rfPermute::plotTrace(rf, plot = FALSE)$data |> dplyr::as_tibble())
+}

# time: 2024-08-30 15:20:41 UTC
# mode: r
+# Run the analysis with different kinship thresholds
+kinship_thresholds <- c(0, 3)
+n_iterations <- 2
+
+prederror_results <- list()
+
+for (threshold in kinship_thresholds) {
+    prederror_threshold <- replicate(n_iterations,
+        run_random_forest(all.id, all.label, all.maf, percent.train, num.eigenvectors, num.threads, threshold),
+        simplify = FALSE
+    )
+    
+    prederror_results[[as.character(threshold)]] <- prederror_threshold
+}
+
+# Prepare the data for plotting
+plot_data <- lapply(prederror_results, function(prederror_threshold) {
+    prederror_df <- dplyr::bind_rows(prederror_threshold) |>
+        dplyr::mutate(threshold = as.numeric(names(prederror_results)[[1]])) |>
+        dplyr::filter(class != "OOB")
+    
+    mean_prederror_df <- calculate_mean_error(prederror_df) |>
+        dplyr::mutate(threshold = as.numeric(names(prederror_results)[[1]]))
+    
+    list(prederror_df = prederror_df, mean_prederror_df = mean_prederror_df)
+})

# time: 2024-08-30 15:21:50 UTC
# mode: r
+# Create the plot
+plot <- ggplot2::ggplot() +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(
+        title = "Prediction error rate for different kinship thresholds",
+        x = "Number of trees", y = "Prediction error rate"
+    ) +
+    ggplot2::scale_color_manual(
+        values = c(
+            "immigrant" = "#5d8566",
+            "resident" = "#c29007"
+        )
+    ) +
+    ggplot2::scale_linetype_manual(
+        values = c("solid", "dashed"),
+        labels = c("Threshold 0", "Threshold 3")
+    ) +
+    ggplot2::theme(
+        aspect.ratio = 1,
+        text = ggplot2::element_text(size = 12),
+        legend.position = "bottom",
+        legend.title = ggplot2::element_blank(),
+        legend.text = ggplot2::element_text(size = 10),
+        panel.grid.major = ggplot2::element_blank(),
+        panel.grid.minor = ggplot2::element_blank()
+    )

# time: 2024-08-30 15:21:51 UTC
# mode: r
+for (i in seq_along(plot_data)) {
+    plot <- plot +
+        ggplot2::geom_line(data = plot_data[[i]]$prederror_df, ggplot2::aes(
+            x = trees, y = error, color = class, linetype = as.factor(threshold)
+        ), alpha = 0.1) +
+        ggplot2::geom_line(data = plot_data[[i]]$mean_prederror_df, ggplot2::aes(
+            x = trees, y = mean_error, color = class, linetype = as.factor(threshold)
+        ), size = 1.5)
+}

# time: 2024-08-30 15:21:54 UTC
# mode: r
+# Add horizontal line at 50% error rate
+plot <- plot +
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "red")

# time: 2024-08-30 15:21:56 UTC
# mode: r
+plot

# time: 2024-08-30 15:22:28 UTC
# mode: r
+plot_data

# time: 2024-08-30 15:22:52 UTC
# mode: r
+# 1 prepare data
+# Initialize empty lists to store the prederror values
+prederror_threshold_0 <- list()
+prederror_threshold_3 <- list()
+
+
+for (i in 1:3) {
+    # Split data
+    split <- split_data(all.id, all.label, percent.train, kinship, kinship_threshold = 0)
+    
+    # Prepare data
+    data <- prepare_data(
+        all.maf, split$train.id, split$test.id, split$train.label, split$test.label,
+        num.eigenvectors, num.threads
+    )
+    
+    # Train random forest
+    rf <- train_random_forest(data$train_df, data$test_df, num.eigenvectors, FALSE)
+    
+    # Store the prederror values
+    prederror_threshold_0[[i]] <- rfPermute::plotTrace(rf, plot = FALSE)$data |> dplyr::as_tibble()
+}
+
+# Run the analysis 5 times with threshold 3
+for (i in 1:3) {
+    # Split data
+    split <- split_data(all.id, all.label, percent.train, kinship, kinship_threshold = 3)
+
+    # Prepare data
+    data <- prepare_data(
+        all.maf, split$train.id, split$test.id, split$train.label, split$test.label,
+        num.eigenvectors, num.threads
+    )
+
+    # Train random forest
+    rf <- train_random_forest(data$train_df, data$test_df, num.eigenvectors, FALSE)
+
+    # Store the prederror values
+    prederror_threshold_3[[i]] <- rfPermute::plotTrace(rf, plot = FALSE)$data |> dplyr::as_tibble()
+}
+
+
+# prepare the data for plotting
+prederror_threshold_0_df <- dplyr::bind_rows(prederror_threshold_0) |>
+    dplyr::mutate(threshold = 0) |> # remove OOB from the class column
+    dplyr::filter(class != "OOB")
+
+prederror_threshold_3_df <- dplyr::bind_rows(prederror_threshold_3) |>
+    dplyr::mutate(threshold = 3) |>
+    dplyr::filter(class != "OOB")
+
+# add mean error values
+mean_prederror_threshold_0_df <- calculate_mean_error(prederror_threshold_0_df) |>
+    dplyr::mutate(threshold = 0)
+mean_prederror_threshold_3_df <- calculate_mean_error(prederror_threshold_3_df) |>
+    dplyr::mutate(threshold = 3)
+
+ggplot2::ggplot() +
+    ggplot2::geom_line(data = prederror_threshold_0_df, ggplot2::aes(
+        x = trees, y = error, color = class, linetype = as.factor(threshold)
+    ), alpha = 0.1) +
+    ggplot2::geom_line(data = prederror_threshold_3_df, ggplot2::aes(
+        x = trees, y = error, color = class, linetype = as.factor(threshold)
+    ), alpha = 0.1, linetype = "dashed") +
+    ggplot2::geom_line(data = mean_prederror_threshold_0_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class, linetype = as.factor(threshold)
+    ), size = 1.5) +
+    ggplot2::geom_line(data = mean_prederror_threshold_3_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class, linetype = as.factor(threshold)
+    ), size = 1.5, linetype = "dashed") +
+    # add horizontal line at 50% error rate
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "red") +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(
+        title = "Prediction error rate for different kinship thresholds",
+        x = "Number of trees", y = "Prediction error rate"
+    ) +
+    ggplot2::scale_color_manual(
+        values = c(
+            "immigrant" = "#5d8566",
+            "resident" = "#c29007"
+        )
+    ) +
+    ggplot2::scale_linetype_manual(
+        values = c("solid", "dashed"),
+        labels = c("Threshold 0", "Threshold 3")
+    ) +
+    ggplot2::theme(
+        aspect.ratio = 1,
+        text = ggplot2::element_text(size = 12),
+        legend.position = "bottom",
+        legend.title = ggplot2::element_blank(),
+        legend.text = ggplot2::element_text(size = 10),
+        panel.grid.major = ggplot2::element_blank(),
+        panel.grid.minor = ggplot2::element_blank()
+    )

# time: 2024-08-30 15:23:38 UTC
# mode: r
+prederror_threshold_0 <- list()
+prederror_threshold_3 <- list()
+
+
+for (i in 1:3) {
+    # Split data
+    split <- split_data(all.id, all.label, percent.train, kinship, kinship_threshold = 0)
+    
+    # Prepare data
+    data <- prepare_data(
+        all.maf, split$train.id, split$test.id, split$train.label, split$test.label,
+        num.eigenvectors, num.threads
+    )
+    
+    # Train random forest
+    rf <- train_random_forest(data$train_df, data$test_df, num.eigenvectors, FALSE)
+    
+    # Store the prederror values
+    prederror_threshold_0[[i]] <- rfPermute::plotTrace(rf, plot = FALSE)$data |> dplyr::as_tibble()
+}
+
+# Run the analysis 5 times with threshold 3
+for (i in 1:3) {
+    # Split data
+    split <- split_data(all.id, all.label, percent.train, kinship, kinship_threshold = 3)
+
+    # Prepare data
+    data <- prepare_data(
+        all.maf, split$train.id, split$test.id, split$train.label, split$test.label,
+        num.eigenvectors, num.threads
+    )
+
+    # Train random forest
+    rf <- train_random_forest(data$train_df, data$test_df, num.eigenvectors, FALSE)
+
+    # Store the prederror values
+    prederror_threshold_3[[i]] <- rfPermute::plotTrace(rf, plot = FALSE)$data |> dplyr::as_tibble()
+}
+
+
+# prepare the data for plotting
+prederror_threshold_0_df <- dplyr::bind_rows(prederror_threshold_0) |>
+    dplyr::mutate(threshold = 0) |> # remove OOB from the class column
+    dplyr::filter(class != "OOB")
+
+prederror_threshold_3_df <- dplyr::bind_rows(prederror_threshold_3) |>
+    dplyr::mutate(threshold = 3) |>
+    dplyr::filter(class != "OOB")
+
+# add mean error values
+mean_prederror_threshold_0_df <- calculate_mean_error(prederror_threshold_0_df) |>
+    dplyr::mutate(threshold = 0)
+mean_prederror_threshold_3_df <- calculate_mean_error(prederror_threshold_3_df) |>
+    dplyr::mutate(threshold = 3)
+
+ggplot2::ggplot() +
+    ggplot2::geom_line(data = prederror_threshold_0_df, ggplot2::aes(
+        x = trees, y = error, color = class, linetype = as.factor(threshold)
+    ), alpha = 0.1) +
+    ggplot2::geom_line(data = prederror_threshold_3_df, ggplot2::aes(
+        x = trees, y = error, color = class, linetype = as.factor(threshold)
+    ), alpha = 0.1, linetype = "dashed") +
+    ggplot2::geom_line(data = mean_prederror_threshold_0_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class, linetype = as.factor(threshold)
+    ), size = 1.5) +
+    ggplot2::geom_line(data = mean_prederror_threshold_3_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class, linetype = as.factor(threshold)
+    ), size = 1.5, linetype = "dashed") +
+    # add horizontal line at 50% error rate
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "red") +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(
+        title = "Prediction error rate for different kinship thresholds",
+        x = "Number of trees", y = "Prediction error rate"
+    ) +
+    ggplot2::scale_color_manual(
+        values = c(
+            "immigrant" = "#5d8566",
+            "resident" = "#c29007"
+        )
+    ) +
+    ggplot2::scale_linetype_manual(
+        values = c("solid", "dashed"),
+        labels = c("Threshold 0", "Threshold 3")
+    ) +
+    ggplot2::theme(
+        aspect.ratio = 1,
+        text = ggplot2::element_text(size = 12),
+        legend.position = "bottom",
+        legend.title = ggplot2::element_blank(),
+        legend.text = ggplot2::element_text(size = 10),
+        panel.grid.major = ggplot2::element_blank(),
+        panel.grid.minor = ggplot2::element_blank()
+    )

# time: 2024-08-30 15:25:27 UTC
# mode: r
+# Function to split data into training and testing sets
+split_data <- function(all.id, all.label, percent.train, kinship, kinship_threshold = NA) {
+    # Split data by class
+    labels <- unique(all.label)
+    class_0 <- all.id[all.label == labels[1]]
+    class_1 <- all.id[all.label == labels[2]]
+
+    if (is.na(kinship_threshold)) {
+        # Determine the size of the smaller class
+        min_class_size <- min(length(class_0), length(class_1))
+
+        # Undersample the majority class
+        if (length(class_0) > min_class_size) {
+            class_0 <- sample(class_0, min_class_size)
+        } else {
+            class_1 <- sample(class_1, min_class_size)
+        }
+
+        # Combine the balanced classes
+        balanced_ids <- c(class_0, class_1)
+        balanced_labels <- c(rep(labels[1], length(class_0)), rep(labels[2], length(class_1)))
+
+        # Calculate the number of samples for training
+        num_train <- round(length(balanced_ids) * percent.train)
+
+        # Ensure equal representation of both classes in train and test sets
+        num_train_per_class <- num_train %/% 2
+
+        # Randomly select samples for training from each class
+        train_indices <- c(
+            sample(1:min_class_size, num_train_per_class),
+            sample((min_class_size + 1):(2 * min_class_size), num_train_per_class)
+        )
+
+        train.id <- balanced_ids[train_indices]
+        test.id <- balanced_ids[-train_indices]
+        train.label <- balanced_labels[train_indices]
+        test.label <- balanced_labels[-train_indices]
+    } else {
+        # Randomly select training samples
+        num_train <- round(length(all.id) * percent.train)
+        train_indices <- sample(1:length(all.id), num_train)
+        train.id <- all.id[train_indices]
+        train.label <- all.label[train_indices]
+
+        # Identify kinship relationships
+        kinship_filtered <- kinship[kinship$kinship_degree <= kinship_threshold, ]
+        kinship_train <- kinship_filtered[kinship_filtered$IID1 %in% train.id | kinship_filtered$IID2 %in% train.id, ]
+
+        # Build the test set
+        test.id <- setdiff(all.id, train.id)
+        test.id <- test.id[test.id %in% unique(c(kinship_train$IID1, kinship_train$IID2))]
+        test.label <- all.label[all.id %in% test.id]
+
+        # Subsample the resulting selection so that there are 200 samples in each class in the training set
+        # and 80 samples in each class in the test set
+        train.id <- c(
+            sample(train.id[train.label == labels[1]], 200),
+            sample(train.id[train.label == labels[2]], 200)
+        )
+        test.id <- c(
+            sample(test.id[test.label == labels[1]], 30),
+            sample(test.id[test.label == labels[2]], 30)
+        )
+        train.label <- all.label[all.id %in% train.id]
+        test.label <- all.label[all.id %in% test.id]
+        
+
+    }
+
+    list(
+        train.id = train.id, test.id = test.id,
+        train.label = train.label, test.label = test.label
+    )
+    
+}

# time: 2024-08-30 15:25:34 UTC
# mode: r
+# 1 prepare data
+# Initialize empty lists to store the prederror values
+prederror_threshold_0 <- list()
+prederror_threshold_3 <- list()
+
+
+for (i in 1:3) {
+    # Split data
+    split <- split_data(all.id, all.label, percent.train, kinship, kinship_threshold = 0)
+    
+    # Prepare data
+    data <- prepare_data(
+        all.maf, split$train.id, split$test.id, split$train.label, split$test.label,
+        num.eigenvectors, num.threads
+    )
+    
+    # Train random forest
+    rf <- train_random_forest(data$train_df, data$test_df, num.eigenvectors, FALSE)
+    
+    # Store the prederror values
+    prederror_threshold_0[[i]] <- rfPermute::plotTrace(rf, plot = FALSE)$data |> dplyr::as_tibble()
+}
+
+# Run the analysis 5 times with threshold 3
+for (i in 1:3) {
+    # Split data
+    split <- split_data(all.id, all.label, percent.train, kinship, kinship_threshold = 3)
+
+    # Prepare data
+    data <- prepare_data(
+        all.maf, split$train.id, split$test.id, split$train.label, split$test.label,
+        num.eigenvectors, num.threads
+    )
+
+    # Train random forest
+    rf <- train_random_forest(data$train_df, data$test_df, num.eigenvectors, FALSE)
+
+    # Store the prederror values
+    prederror_threshold_3[[i]] <- rfPermute::plotTrace(rf, plot = FALSE)$data |> dplyr::as_tibble()
+}
+
+
+# prepare the data for plotting
+prederror_threshold_0_df <- dplyr::bind_rows(prederror_threshold_0) |>
+    dplyr::mutate(threshold = 0) |> # remove OOB from the class column
+    dplyr::filter(class != "OOB")
+
+prederror_threshold_3_df <- dplyr::bind_rows(prederror_threshold_3) |>
+    dplyr::mutate(threshold = 3) |>
+    dplyr::filter(class != "OOB")
+
+# add mean error values
+mean_prederror_threshold_0_df <- calculate_mean_error(prederror_threshold_0_df) |>
+    dplyr::mutate(threshold = 0)
+mean_prederror_threshold_3_df <- calculate_mean_error(prederror_threshold_3_df) |>
+    dplyr::mutate(threshold = 3)
+
+ggplot2::ggplot() +
+    ggplot2::geom_line(data = prederror_threshold_0_df, ggplot2::aes(
+        x = trees, y = error, color = class, linetype = as.factor(threshold)
+    ), alpha = 0.1) +
+    ggplot2::geom_line(data = prederror_threshold_3_df, ggplot2::aes(
+        x = trees, y = error, color = class, linetype = as.factor(threshold)
+    ), alpha = 0.1, linetype = "dashed") +
+    ggplot2::geom_line(data = mean_prederror_threshold_0_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class, linetype = as.factor(threshold)
+    ), size = 1.5) +
+    ggplot2::geom_line(data = mean_prederror_threshold_3_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class, linetype = as.factor(threshold)
+    ), size = 1.5, linetype = "dashed") +
+    # add horizontal line at 50% error rate
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "red") +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(
+        title = "Prediction error rate for different kinship thresholds",
+        x = "Number of trees", y = "Prediction error rate"
+    ) +
+    ggplot2::scale_color_manual(
+        values = c(
+            "immigrant" = "#5d8566",
+            "resident" = "#c29007"
+        )
+    ) +
+    ggplot2::scale_linetype_manual(
+        values = c("solid", "dashed"),
+        labels = c("Threshold 0", "Threshold 3")
+    ) +
+    ggplot2::theme(
+        aspect.ratio = 1,
+        text = ggplot2::element_text(size = 12),
+        legend.position = "bottom",
+        legend.title = ggplot2::element_blank(),
+        legend.text = ggplot2::element_text(size = 10),
+        panel.grid.major = ggplot2::element_blank(),
+        panel.grid.minor = ggplot2::element_blank()
+    )

# time: 2024-08-30 15:35:17 UTC
# mode: r
+num_train <- round(length(all.id) * percent.train)
+    train_indices <- sample(1:length(all.id), num_train)
+    train.id <- all.id[train_indices]
+    train.label <- all.label[train_indices]
+
+    # Assign the rest to the test set and ensure that none in the test set are above the kinship threshold
+    test.id <- all.id[-train_indices]
+    test.label <- all.label[-train_indices]
+    
+    kinship_filtered <- kinship[kinship$kinship_degree <= kinship_threshold, ]
+    test.id <- test.id[test.id %in% kinship_filtered$IID1 & test.id %in% kinship_filtered$IID2]
+    test.label <- all.label[all.id %in% test.id]

# time: 2024-08-30 15:35:23 UTC
# mode: r
+kinship_threshold=3

# time: 2024-08-30 15:35:26 UTC
# mode: r
+num_train <- round(length(all.id) * percent.train)
+    train_indices <- sample(1:length(all.id), num_train)
+    train.id <- all.id[train_indices]
+    train.label <- all.label[train_indices]
+
+    # Assign the rest to the test set and ensure that none in the test set are above the kinship threshold
+    test.id <- all.id[-train_indices]
+    test.label <- all.label[-train_indices]
+    
+    kinship_filtered <- kinship[kinship$kinship_degree <= kinship_threshold, ]
+    test.id <- test.id[test.id %in% kinship_filtered$IID1 & test.id %in% kinship_filtered$IID2]
+    test.label <- all.label[all.id %in% test.id]

# time: 2024-08-30 15:35:28 UTC
# mode: r
+test.label

# time: 2024-08-30 15:35:43 UTC
# mode: r
+num_train

# time: 2024-08-30 15:35:51 UTC
# mode: r
+test.label

# time: 2024-08-30 15:35:55 UTC
# mode: r
+test.id

# time: 2024-08-30 15:37:50 UTC
# mode: r
+train.label

# time: 2024-08-30 15:37:53 UTC
# mode: r
+train.id

# time: 2024-08-30 15:38:28 UTC
# mode: r
+table(train.label)

# time: 2024-08-30 15:38:32 UTC
# mode: r
+table(test.label)

# time: 2024-08-30 15:40:26 UTC
# mode: r
+which(train.label == "immigrant")

# time: 2024-08-30 15:41:59 UTC
# mode: r
+train_immigrant_indices <- which(train.label == "immigrant")
+    train_resident_indices <- which(train.label == "resident")
+    test_immigrant_indices <- which(test.label == "immigrant")
+    test_resident_indices <- which(test.label == "resident")

# time: 2024-08-30 15:42:01 UTC
# mode: r
+test_resident_indices

# time: 2024-08-30 15:42:05 UTC
# mode: r
+train_resident_indices

# time: 2024-08-30 15:42:58 UTC
# mode: r
+# Function to split data into training and testing sets
+split_data <- function(all.id, all.label, percent.train, kinship, kinship_threshold = 3) {
+    # Randomly select training samples
+    num_train <- round(length(all.id) * percent.train)
+    train_indices <- sample(1:length(all.id), num_train)
+    train.id <- all.id[train_indices]
+    train.label <- all.label[train_indices]
+
+    # Assign the rest to the test set and ensure that none in the test set are above the kinship threshold
+    test.id <- all.id[-train_indices]
+    test.label <- all.label[-train_indices]
+
+    kinship_filtered <- kinship[kinship$kinship_degree <= kinship_threshold, ]
+    test.id <- test.id[test.id %in% kinship_filtered$IID1 & test.id %in% kinship_filtered$IID2]
+    test.label <- all.label[all.id %in% test.id]
+
+    train_immigrant_indices <- which(train.label == "immigrant")
+    train_resident_indices <- which(train.label == "resident")
+    test_immigrant_indices <- which(test.label == "immigrant")
+    test_resident_indices <- which(test.label == "resident")
+
+    # Subsample the training so that it has exactly 100 samples from each class and the test set has 20 samples from each class
+    train_immigrant_indices <- sample(which(train.label == "immigrant"), 100)
+    train_resident_indices <- sample(which(train.label == "resident"), 100)
+    test_immigrant_indices <- sample(which(test.label == "immigrant"), 20)
+    test_resident_indices <- sample(which(test.label == "resident"), 20)
+
+    train.id <- c(train.id[train_immigrant_indices], train.id[train_resident_indices])
+    train.label <- c(train.label[train_immigrant_indices], train.label[train_resident_indices])
+    test.id <- c(test.id[test_immigrant_indices], test.id[test_resident_indices])
+    test.label <- c(test.label[test_immigrant_indices], test.label[test_resident_indices])
+}

# time: 2024-08-30 15:43:07 UTC
# mode: r
+# 1 prepare data
+# Initialize empty lists to store the prederror values
+prederror_threshold_0 <- list()
+prederror_threshold_3 <- list()
+
+
+for (i in 1:3) {
+    # Split data
+    split <- split_data(all.id, all.label, percent.train, kinship, kinship_threshold = 0)
+
+    # Prepare data
+    data <- prepare_data(
+        all.maf, split$train.id, split$test.id, split$train.label, split$test.label,
+        num.eigenvectors, num.threads
+    )
+
+    # Train random forest
+    rf <- train_random_forest(data$train_df, data$test_df, num.eigenvectors, FALSE)
+
+    # Store the prederror values
+    prederror_threshold_0[[i]] <- rfPermute::plotTrace(rf, plot = FALSE)$data |> dplyr::as_tibble()
+}
+
+# Run the analysis 5 times with threshold 3
+for (i in 1:3) {
+    # Split data
+    split <- split_data(all.id, all.label, percent.train, kinship, kinship_threshold = 3)
+
+    # Prepare data
+    data <- prepare_data(
+        all.maf, split$train.id, split$test.id, split$train.label, split$test.label,
+        num.eigenvectors, num.threads
+    )
+
+    # Train random forest
+    rf <- train_random_forest(data$train_df, data$test_df, num.eigenvectors, FALSE)
+
+    # Store the prederror values
+    prederror_threshold_3[[i]] <- rfPermute::plotTrace(rf, plot = FALSE)$data |> dplyr::as_tibble()
+}
+
+
+# prepare the data for plotting
+prederror_threshold_0_df <- dplyr::bind_rows(prederror_threshold_0) |>
+    dplyr::mutate(threshold = 0) |> # remove OOB from the class column
+    dplyr::filter(class != "OOB")
+
+prederror_threshold_3_df <- dplyr::bind_rows(prederror_threshold_3) |>
+    dplyr::mutate(threshold = 3) |>
+    dplyr::filter(class != "OOB")
+
+# add mean error values
+mean_prederror_threshold_0_df <- calculate_mean_error(prederror_threshold_0_df) |>
+    dplyr::mutate(threshold = 0)
+mean_prederror_threshold_3_df <- calculate_mean_error(prederror_threshold_3_df) |>
+    dplyr::mutate(threshold = 3)
+
+ggplot2::ggplot() +
+    ggplot2::geom_line(data = prederror_threshold_0_df, ggplot2::aes(
+        x = trees, y = error, color = class, linetype = as.factor(threshold)
+    ), alpha = 0.1) +
+    ggplot2::geom_line(data = prederror_threshold_3_df, ggplot2::aes(
+        x = trees, y = error, color = class, linetype = as.factor(threshold)
+    ), alpha = 0.1, linetype = "dashed") +
+    ggplot2::geom_line(data = mean_prederror_threshold_0_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class, linetype = as.factor(threshold)
+    ), size = 1.5) +
+    ggplot2::geom_line(data = mean_prederror_threshold_3_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class, linetype = as.factor(threshold)
+    ), size = 1.5, linetype = "dashed") +
+    # add horizontal line at 50% error rate
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "red") +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(
+        title = "Prediction error rate for different kinship thresholds",
+        x = "Number of trees", y = "Prediction error rate"
+    ) +
+    ggplot2::scale_color_manual(
+        values = c(
+            "immigrant" = "#5d8566",
+            "resident" = "#c29007"
+        )
+    ) +
+    ggplot2::scale_linetype_manual(
+        values = c("solid", "dashed"),
+        labels = c("Threshold 0", "Threshold 3")
+    ) +
+    ggplot2::theme(
+        aspect.ratio = 1,
+        text = ggplot2::element_text(size = 12),
+        legend.position = "bottom",
+        legend.title = ggplot2::element_blank(),
+        legend.text = ggplot2::element_text(size = 10),
+        panel.grid.major = ggplot2::element_blank(),
+        panel.grid.minor = ggplot2::element_blank()
+    )

# time: 2024-08-30 15:43:43 UTC
# mode: r
+# Function to split data into training and testing sets
+split_data <- function(all.id, all.label, percent.train, kinship, kinship_threshold = 3) {
+    # Randomly select training samples
+    num_train <- round(length(all.id) * percent.train)
+    train_indices <- sample(1:length(all.id), num_train)
+    train.id <- all.id[train_indices]
+    train.label <- all.label[train_indices]
+
+    # Assign the rest to the test set and ensure that none in the test set are above the kinship threshold
+    test.id <- all.id[-train_indices]
+    test.label <- all.label[-train_indices]
+
+    kinship_filtered <- kinship[kinship$kinship_degree <= kinship_threshold, ]
+    test.id <- test.id[test.id %in% kinship_filtered$IID1 & test.id %in% kinship_filtered$IID2]
+    test.label <- all.label[all.id %in% test.id]
+
+    # Subsample the training so that it has exactly 100 samples from each class and the test set has 20 samples from each class
+    train_immigrant_indices <- sample(which(train.label == "immigrant"), 100)
+    train_resident_indices <- sample(which(train.label == "resident"), 100)
+    test_immigrant_indices <- sample(which(test.label == "immigrant"), 20)
+    test_resident_indices <- sample(which(test.label == "resident"), 20)
+
+    train.id <- c(train.id[train_immigrant_indices], train.id[train_resident_indices])
+    train.label <- c(train.label[train_immigrant_indices], train.label[train_resident_indices])
+    test.id <- c(test.id[test_immigrant_indices], test.id[test_resident_indices])
+    test.label <- c(test.label[test_immigrant_indices], test.label[test_resident_indices])
+}

# time: 2024-08-30 15:43:54 UTC
# mode: r
+# Calculate summary statistics for the random and original models
+
+
+
+# randomForest::MDSplot(results$original_rf_models[[1]], results$original_train_labels[[1]])
+
+# rfPermute::confusionMatrix(results$original_rf_models[[1]])
+# # rfPermute::plotPredictedProbs(output.forest, bins = 20, plot = TRUE)
+# # rfPermute::plotProximity(output.forest)
+# # summary(output.forest)
+# # rfPermute::plotTrace(output.forest)
+
+# run a single random forest model:
+
+# 1 prepare data
+# Initialize empty lists to store the prederror values
+prederror_threshold_0 <- list()

# time: 2024-08-30 15:43:54 UTC
# mode: r
+prederror_threshold_3 <- list()

# time: 2024-08-30 15:43:55 UTC
# mode: r
+for (i in 1:3) {
+    # Split data
+    split <- split_data(all.id, all.label, percent.train, kinship, kinship_threshold = 0)
+
+    # Prepare data
+    data <- prepare_data(
+        all.maf, split$train.id, split$test.id, split$train.label, split$test.label,
+        num.eigenvectors, num.threads
+    )
+
+    # Train random forest
+    rf <- train_random_forest(data$train_df, data$test_df, num.eigenvectors, FALSE)
+
+    # Store the prederror values
+    prederror_threshold_0[[i]] <- rfPermute::plotTrace(rf, plot = FALSE)$data |> dplyr::as_tibble()
+}

# time: 2024-08-30 15:44:08 UTC
# mode: r
+# Function to split data into training and testing sets
+split_data <- function(all.id, all.label, percent.train, kinship, kinship_threshold = 3) {
+    # Randomly select training samples
+    num_train <- round(length(all.id) * percent.train)
+    train_indices <- sample(1:length(all.id), num_train)
+    train.id <- all.id[train_indices]
+    train.label <- all.label[train_indices]
+
+    # Assign the rest to the test set and ensure that none in the test set are above the kinship threshold
+    test.id <- all.id[-train_indices]
+    test.label <- all.label[-train_indices]
+
+    kinship_filtered <- kinship[kinship$kinship_degree <= kinship_threshold, ]
+    test.id <- test.id[test.id %in% kinship_filtered$IID1 & test.id %in% kinship_filtered$IID2]
+    test.label <- all.label[all.id %in% test.id]
+
+    # Subsample the training so that it has exactly 100 samples from each class and the test set has 20 samples from each class
+    train_immigrant_indices <- sample(which(train.label == "immigrant"), 100)
+    train_resident_indices <- sample(which(train.label == "resident"), 100)
+    test_immigrant_indices <- sample(which(test.label == "immigrant"), 20)
+    test_resident_indices <- sample(which(test.label == "resident"), 20)
+
+    train.id <- c(train.id[train_immigrant_indices], train.id[train_resident_indices])
+    train.label <- c(train.label[train_immigrant_indices], train.label[train_resident_indices])
+    test.id <- c(test.id[test_immigrant_indices], test.id[test_resident_indices])
+    test.label <- c(test.label[test_immigrant_indices], test.label[test_resident_indices])
+    
+    return(list(train.id = train.id, test.id = test.id, train.label = train.label, test.label = test.label))
+    
+    }

# time: 2024-08-30 15:44:20 UTC
# mode: r
+# Function to split data into training and testing sets
+split_data <- function(all.id, all.label, percent.train, kinship, kinship_threshold = 3) {
+    # Randomly select training samples
+    num_train <- round(length(all.id) * percent.train)
+    train_indices <- sample(1:length(all.id), num_train)
+    train.id <- all.id[train_indices]
+    train.label <- all.label[train_indices]
+
+    # Assign the rest to the test set and ensure that none in the test set are above the kinship threshold
+    test.id <- all.id[-train_indices]
+    test.label <- all.label[-train_indices]
+
+    kinship_filtered <- kinship[kinship$kinship_degree <= kinship_threshold, ]
+    test.id <- test.id[test.id %in% kinship_filtered$IID1 & test.id %in% kinship_filtered$IID2]
+    test.label <- all.label[all.id %in% test.id]
+
+    # Subsample the training so that it has exactly 100 samples from each class and the test set has 20 samples from each class
+    train_immigrant_indices <- sample(which(train.label == "immigrant"), 100)
+    train_resident_indices <- sample(which(train.label == "resident"), 100)
+    test_immigrant_indices <- sample(which(test.label == "immigrant"), 20)
+    test_resident_indices <- sample(which(test.label == "resident"), 20)
+
+    train.id <- c(train.id[train_immigrant_indices], train.id[train_resident_indices])
+    train.label <- c(train.label[train_immigrant_indices], train.label[train_resident_indices])
+    test.id <- c(test.id[test_immigrant_indices], test.id[test_resident_indices])
+    test.label <- c(test.label[test_immigrant_indices], test.label[test_resident_indices])
+
+    return(
+        list(
+            train.id = train.id, test.id = test.id, train.label = train.label,
+            test.label = test.label
+        )
+    )
+}

# time: 2024-08-30 15:44:26 UTC
# mode: r
+prederror_threshold_0 <- list()
+prederror_threshold_3 <- list()
+
+
+for (i in 1:3) {
+    # Split data
+    split <- split_data(all.id, all.label, percent.train, kinship, kinship_threshold = 0)
+
+    # Prepare data
+    data <- prepare_data(
+        all.maf, split$train.id, split$test.id, split$train.label, split$test.label,
+        num.eigenvectors, num.threads
+    )
+
+    # Train random forest
+    rf <- train_random_forest(data$train_df, data$test_df, num.eigenvectors, FALSE)
+
+    # Store the prederror values
+    prederror_threshold_0[[i]] <- rfPermute::plotTrace(rf, plot = FALSE)$data |> dplyr::as_tibble()
+}
+
+# Run the analysis 5 times with threshold 3
+for (i in 1:3) {
+    # Split data
+    split <- split_data(all.id, all.label, percent.train, kinship, kinship_threshold = 3)
+
+    # Prepare data
+    data <- prepare_data(
+        all.maf, split$train.id, split$test.id, split$train.label, split$test.label,
+        num.eigenvectors, num.threads
+    )
+
+    # Train random forest
+    rf <- train_random_forest(data$train_df, data$test_df, num.eigenvectors, FALSE)
+
+    # Store the prederror values
+    prederror_threshold_3[[i]] <- rfPermute::plotTrace(rf, plot = FALSE)$data |> dplyr::as_tibble()
+}
+
+
+# prepare the data for plotting
+prederror_threshold_0_df <- dplyr::bind_rows(prederror_threshold_0) |>
+    dplyr::mutate(threshold = 0) |> # remove OOB from the class column
+    dplyr::filter(class != "OOB")
+
+prederror_threshold_3_df <- dplyr::bind_rows(prederror_threshold_3) |>
+    dplyr::mutate(threshold = 3) |>
+    dplyr::filter(class != "OOB")
+
+# add mean error values
+mean_prederror_threshold_0_df <- calculate_mean_error(prederror_threshold_0_df) |>
+    dplyr::mutate(threshold = 0)
+mean_prederror_threshold_3_df <- calculate_mean_error(prederror_threshold_3_df) |>
+    dplyr::mutate(threshold = 3)
+
+ggplot2::ggplot() +
+    ggplot2::geom_line(data = prederror_threshold_0_df, ggplot2::aes(
+        x = trees, y = error, color = class, linetype = as.factor(threshold)
+    ), alpha = 0.1) +
+    ggplot2::geom_line(data = prederror_threshold_3_df, ggplot2::aes(
+        x = trees, y = error, color = class, linetype = as.factor(threshold)
+    ), alpha = 0.1, linetype = "dashed") +
+    ggplot2::geom_line(data = mean_prederror_threshold_0_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class, linetype = as.factor(threshold)
+    ), size = 1.5) +
+    ggplot2::geom_line(data = mean_prederror_threshold_3_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class, linetype = as.factor(threshold)
+    ), size = 1.5, linetype = "dashed") +
+    # add horizontal line at 50% error rate
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "red") +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(
+        title = "Prediction error rate for different kinship thresholds",
+        x = "Number of trees", y = "Prediction error rate"
+    ) +
+    ggplot2::scale_color_manual(
+        values = c(
+            "immigrant" = "#5d8566",
+            "resident" = "#c29007"
+        )
+    ) +
+    ggplot2::scale_linetype_manual(
+        values = c("solid", "dashed"),
+        labels = c("Threshold 0", "Threshold 3")
+    ) +
+    ggplot2::theme(
+        aspect.ratio = 1,
+        text = ggplot2::element_text(size = 12),
+        legend.position = "bottom",
+        legend.title = ggplot2::element_blank(),
+        legend.text = ggplot2::element_text(size = 10),
+        panel.grid.major = ggplot2::element_blank(),
+        panel.grid.minor = ggplot2::element_blank()
+    )

# time: 2024-08-30 15:45:35 UTC
# mode: r
+ggplot2::ggplot() +
+    ggplot2::geom_line(data = prederror_threshold_0_df, ggplot2::aes(
+        x = trees, y = error, color = class, linetype = as.factor(threshold)
+    ), alpha = 0.1) +
+    ggplot2::geom_line(data = prederror_threshold_3_df, ggplot2::aes(
+        x = trees, y = error, color = class, linetype = as.factor(threshold)
+    ), alpha = 0.1, linetype = "dashed") +
+    ggplot2::geom_line(data = mean_prederror_threshold_0_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class, linetype = as.factor(threshold)
+    ), size = 1.5) +
+    ggplot2::geom_line(data = mean_prederror_threshold_3_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class, linetype = as.factor(threshold)
+    ), size = 1.5, linetype = "dashed") +
+    # add horizontal line at 50% error rate
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "red") +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(
+        title = "Prediction error rate for different kinship thresholds",
+        x = "Number of trees", y = "Prediction error rate"
+    ) +
+    ggplot2::scale_color_manual(
+        values = c(
+            "immigrant" = "#5d8566",
+            "resident" = "#c29007"
+        )
+    ) +
+    ggplot2::theme(
+        aspect.ratio = 1,
+        text = ggplot2::element_text(size = 12),
+        legend.position = "bottom",
+        legend.title = ggplot2::element_blank(),
+        legend.text = ggplot2::element_text(size = 10),
+        panel.grid.major = ggplot2::element_blank(),
+        panel.grid.minor = ggplot2::element_blank()
+    )

# time: 2024-08-30 15:46:24 UTC
# mode: r
+prederror_threshold_0_df

# time: 2024-08-30 15:47:42 UTC
# mode: r
+ggplot2::ggplot() +
+    ggplot2::geom_line(data = prederror_threshold_0_df, ggplot2::aes(
+        x = trees, y = error, color = class
+    ), alpha = 0.1, linetype = "dashed") +
+    ggplot2::geom_line(data = prederror_threshold_3_df, ggplot2::aes(
+        x = trees, y = error, color = class
+    ), alpha = 0.1, linetype = "solid") +
+    ggplot2::geom_line(data = mean_prederror_threshold_0_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class
+    ), size = 1.5, linetype = "dashed") +
+    ggplot2::geom_line(data = mean_prederror_threshold_3_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class
+    ), size = 1.5, linetype = "solid") +
+    # add horizontal line at 50% error rate
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "red") +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(
+        title = "Prediction error rate for different kinship thresholds",
+        x = "Number of trees", y = "Prediction error rate"
+    ) +
+    ggplot2::scale_color_manual(
+        values = c(
+            "immigrant" = "#5d8566",
+            "resident" = "#c29007"
+        )
+    ) +
+    ggplot2::theme(
+        aspect.ratio = 1,
+        text = ggplot2::element_text(size = 12),
+        legend.position = "bottom",
+        legend.title = ggplot2::element_blank(),
+        legend.text = ggplot2::element_text(size = 10),
+        panel.grid.major = ggplot2::element_blank(),
+        panel.grid.minor = ggplot2::element_blank()
+    )

# time: 2024-08-30 15:49:33 UTC
# mode: r
+# Import configuration file
+config <- config::get()
+
+# parameters
+percent.train <- 0.7
+num.threads <- 44
+num.eigenvectors <- 20
+set.seed(555)
+
+# Input files
+immigrant.info <- file.path(config$path$data, "600K_immigrants.fam")
+immigrant.vcf <- file.path(config$path$data, "600K_immigrants.vcf")
+resident.vcf <- file.path(config$path$data, "600K_residents.vcf")
+
+immigrant.gds <- file.path(config$path$data, "immigrant_recode.gds")
+resident.gds <- file.path(config$path$data, "resident_recode.gds")
+all.gds <- file.path(config$path$data, "all_recode.gds")
+
+# read in kinship CSV
+kinship <- readr::read_csv(file.path(config$path$data, "kinship.csv")) |>
+    dplyr::mutate(kinship_degree = dplyr::case_when(
+        kinship_degree == "unrelated" ~ 0,
+        kinship_degree == "third_degree" ~ 1,
+        kinship_degree == "second_degree" ~ 2,
+        kinship_degree == "first_degree" ~ 3
+    )) |>
+    # add 'Wytham_UK_' to the beginning of each IID column
+    dplyr::mutate(dplyr::across(dplyr::starts_with("IID"), ~ paste("Wytham_UK_", ., sep = "")))
+
+# Load all the data
+all.maf <- SNPRelate::snpgdsOpen(all.gds, allow.duplicate = TRUE)
+
+# Load labels
+immigrant.id <- gdsfmt::read.gdsn(gdsfmt::index.gdsn(
+    SNPRelate::snpgdsOpen(immigrant.gds),
+    "sample.id"
+))
+resident.id <- gdsfmt::read.gdsn(gdsfmt::index.gdsn(
+    SNPRelate::snpgdsOpen(resident.gds),
+    "sample.id"
+))
+
+all.id <- gdsfmt::read.gdsn(gdsfmt::index.gdsn(all.maf, "sample.id"))
+all.label <- ifelse(all.id %in% immigrant.id, "immigrant", "resident")

# time: 2024-08-30 15:49:58 UTC
# mode: r
+# 1 prepare data
+# Initialize empty lists to store the prederror values
+prederror_threshold_0 <- list()
+prederror_threshold_3 <- list()
+
+
+for (i in 1:5) {
+    # Split data
+    split <- split_data(all.id, all.label, percent.train, kinship, kinship_threshold = 0)
+
+    # Prepare data
+    data <- prepare_data(
+        all.maf, split$train.id, split$test.id, split$train.label, split$test.label,
+        num.eigenvectors, num.threads
+    )
+
+    # Train random forest
+    rf <- train_random_forest(data$train_df, data$test_df, num.eigenvectors, FALSE)
+
+    # Store the prederror values
+    prederror_threshold_0[[i]] <- rfPermute::plotTrace(rf, plot = FALSE)$data |> dplyr::as_tibble()
+}
+
+# Run the analysis 5 times with threshold 3
+for (i in 1:5) {
+    # Split data
+    split <- split_data(all.id, all.label, percent.train, kinship, kinship_threshold = 3)
+
+    # Prepare data
+    data <- prepare_data(
+        all.maf, split$train.id, split$test.id, split$train.label, split$test.label,
+        num.eigenvectors, num.threads
+    )
+
+    # Train random forest
+    rf <- train_random_forest(data$train_df, data$test_df, num.eigenvectors, FALSE)
+
+    # Store the prederror values
+    prederror_threshold_3[[i]] <- rfPermute::plotTrace(rf, plot = FALSE)$data |> dplyr::as_tibble()
+}
+
+
+# prepare the data for plotting
+prederror_threshold_0_df <- dplyr::bind_rows(prederror_threshold_0) |>
+    dplyr::mutate(threshold = 0) |> # remove OOB from the class column
+    dplyr::filter(class != "OOB")
+
+prederror_threshold_3_df <- dplyr::bind_rows(prederror_threshold_3) |>
+    dplyr::mutate(threshold = 3) |>
+    dplyr::filter(class != "OOB")
+
+# add mean error values
+mean_prederror_threshold_0_df <- calculate_mean_error(prederror_threshold_0_df) |>
+    dplyr::mutate(threshold = 0) 
+mean_prederror_threshold_3_df <- calculate_mean_error(prederror_threshold_3_df) |>
+    dplyr::mutate(threshold = 3)
+
+ggplot2::ggplot() +
+    ggplot2::geom_line(data = prederror_threshold_0_df, ggplot2::aes(
+        x = trees, y = error, color = class
+    ), alpha = 0.1, linetype = "dashed") +
+    ggplot2::geom_line(data = prederror_threshold_3_df, ggplot2::aes(
+        x = trees, y = error, color = class
+    ), alpha = 0.1, linetype = "solid") +
+    ggplot2::geom_line(data = mean_prederror_threshold_0_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class
+    ), size = 1.5, linetype = "dashed") +
+    ggplot2::geom_line(data = mean_prederror_threshold_3_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class
+    ), size = 1.5, linetype = "solid") +
+    # add horizontal line at 50% error rate
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "red") +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(
+        title = "Prediction error rate for different kinship thresholds",
+        x = "Number of trees", y = "Prediction error rate"
+    ) +
+    ggplot2::scale_color_manual(
+        values = c(
+            "immigrant" = "#5d8566",
+            "resident" = "#c29007"
+        )
+    ) +
+
+    ggplot2::theme(
+        aspect.ratio = 1,
+        text = ggplot2::element_text(size = 12),
+        legend.position = "bottom",
+        legend.title = ggplot2::element_blank(),
+        legend.text = ggplot2::element_text(size = 10),
+        panel.grid.major = ggplot2::element_blank(),
+        panel.grid.minor = ggplot2::element_blank()
+    )

# time: 2024-08-30 15:51:59 UTC
# mode: r
+# 1 prepare data
+# Initialize empty lists to store the prederror values
+prederror_threshold_0 <- list()
+prederror_threshold_3 <- list()
+
+
+for (i in 1:20) {
+    # Split data
+    split <- split_data(all.id, all.label, percent.train, kinship, kinship_threshold = 0)
+
+    # Prepare data
+    data <- prepare_data(
+        all.maf, split$train.id, split$test.id, split$train.label, split$test.label,
+        num.eigenvectors, num.threads
+    )
+
+    # Train random forest
+    rf <- train_random_forest(data$train_df, data$test_df, num.eigenvectors, FALSE)
+
+    # Store the prederror values
+    prederror_threshold_0[[i]] <- rfPermute::plotTrace(rf, plot = FALSE)$data |> dplyr::as_tibble()
+}
+
+# Run the analysis 5 times with threshold 3
+for (i in 1:20) {
+    # Split data
+    split <- split_data(all.id, all.label, percent.train, kinship, kinship_threshold = 3)
+
+    # Prepare data
+    data <- prepare_data(
+        all.maf, split$train.id, split$test.id, split$train.label, split$test.label,
+        num.eigenvectors, num.threads
+    )
+
+    # Train random forest
+    rf <- train_random_forest(data$train_df, data$test_df, num.eigenvectors, FALSE)
+
+    # Store the prederror values
+    prederror_threshold_3[[i]] <- rfPermute::plotTrace(rf, plot = FALSE)$data |> dplyr::as_tibble()
+}
+
+
+# prepare the data for plotting
+prederror_threshold_0_df <- dplyr::bind_rows(prederror_threshold_0) |>
+    dplyr::mutate(threshold = 0) |> # remove OOB from the class column
+    dplyr::filter(class != "OOB")
+
+prederror_threshold_3_df <- dplyr::bind_rows(prederror_threshold_3) |>
+    dplyr::mutate(threshold = 3) |>
+    dplyr::filter(class != "OOB")
+
+# add mean error values
+mean_prederror_threshold_0_df <- calculate_mean_error(prederror_threshold_0_df) |>
+    dplyr::mutate(threshold = 0) 
+mean_prederror_threshold_3_df <- calculate_mean_error(prederror_threshold_3_df) |>
+    dplyr::mutate(threshold = 3)
+
+ggplot2::ggplot() +
+    ggplot2::geom_line(data = prederror_threshold_0_df, ggplot2::aes(
+        x = trees, y = error, color = class
+    ), alpha = 0.1, linetype = "dashed") +
+    ggplot2::geom_line(data = prederror_threshold_3_df, ggplot2::aes(
+        x = trees, y = error, color = class
+    ), alpha = 0.1, linetype = "solid") +
+    ggplot2::geom_line(data = mean_prederror_threshold_0_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class
+    ), size = 1.5, linetype = "dashed") +
+    ggplot2::geom_line(data = mean_prederror_threshold_3_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class
+    ), size = 1.5, linetype = "solid") +
+    # add horizontal line at 50% error rate
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "red") +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(
+        title = "Prediction error rate for different kinship thresholds",
+        x = "Number of trees", y = "Prediction error rate"
+    ) +
+    ggplot2::scale_color_manual(
+        values = c(
+            "immigrant" = "#5d8566",
+            "resident" = "#c29007"
+        )
+    ) +
+
+    ggplot2::theme(
+        aspect.ratio = 1,
+        text = ggplot2::element_text(size = 12),
+        legend.position = "bottom",
+        legend.title = ggplot2::element_blank(),
+        legend.text = ggplot2::element_text(size = 10),
+        panel.grid.major = ggplot2::element_blank(),
+        panel.grid.minor = ggplot2::element_blank()
+    )

# time: 2024-08-30 15:57:54 UTC
# mode: r
+ggplot2::ggplot() +
+    ggplot2::geom_line(data = prederror_threshold_0_df, ggplot2::aes(
+        x = trees, y = error, color = class, linetype = "dashed"
+    ), alpha = 0.1, linetype = "dashed") +
+    ggplot2::geom_line(data = prederror_threshold_3_df, ggplot2::aes(
+        x = trees, y = error, color = class, linetype = "solid"
+    ), alpha = 0.1, linetype = "solid") +
+    ggplot2::geom_line(data = mean_prederror_threshold_0_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class, linetype = "dashed"
+    ), size = 1.5, linetype = "dashed") +
+    ggplot2::geom_line(data = mean_prederror_threshold_3_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class, linetype = "solid"
+    ), size = 1.5, linetype = "solid") +
+    # add horizontal line at 50% error rate
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "red") +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(
+        title = "Prediction error rate for different kinship thresholds",
+        x = "Number of trees", y = "Prediction error rate"
+    ) +
+    ggplot2::scale_color_manual(
+        values = c(
+            "immigrant" = "#5d8566",
+            "resident" = "#c29007"
+        )
+    ) +
+    ggplot2::scale_linetype_manual(
+        values = c(
+            "dashed" = "dashed",
+            "solid" = "solid"
+        )
+    ) +
+    ggplot2::theme(
+        aspect.ratio = 1,
+        text = ggplot2::element_text(size = 12),
+        legend.position = "bottom",
+        legend.title = ggplot2::element_blank(),
+        legend.text = ggplot2::element_text(size = 10),
+        panel.grid.major = ggplot2::element_blank(),
+        panel.grid.minor = ggplot2::element_blank()
+    )

# time: 2024-08-30 16:06:59 UTC
# mode: r
+# Import configuration file
+config <- config::get()
+
+# parameters
+percent.train <- 0.7
+num.threads <- 44
+num.eigenvectors <- 20
+set.seed(555)
+
+# Input files
+immigrant.info <- file.path(config$path$data, "600K_immigrants.fam")
+immigrant.vcf <- file.path(config$path$data, "600K_immigrants.vcf")
+resident.vcf <- file.path(config$path$data, "600K_residents.vcf")
+
+immigrant.gds <- file.path(config$path$data, "immigrant_recode.gds")
+resident.gds <- file.path(config$path$data, "resident_recode.gds")
+all.gds <- file.path(config$path$data, "all_recode.gds")
+
+# read in kinship CSV
+kinship <- readr::read_csv(file.path(config$path$data, "kinship.csv")) |>
+    dplyr::mutate(kinship_degree = dplyr::case_when(
+        kinship_degree == "unrelated" ~ 0,
+        kinship_degree == "third_degree" ~ 1,
+        kinship_degree == "second_degree" ~ 2,
+        kinship_degree == "first_degree" ~ 3
+    )) |>
+    # add 'Wytham_UK_' to the beginning of each IID column
+    dplyr::mutate(dplyr::across(dplyr::starts_with("IID"), ~ paste("Wytham_UK_", ., sep = "")))
+
+# Load all the data
+all.maf <- SNPRelate::snpgdsOpen(all.gds, allow.duplicate = TRUE)
+
+# Load labels
+immigrant.id <- gdsfmt::read.gdsn(gdsfmt::index.gdsn(
+    SNPRelate::snpgdsOpen(immigrant.gds),
+    "sample.id"
+))
+resident.id <- gdsfmt::read.gdsn(gdsfmt::index.gdsn(
+    SNPRelate::snpgdsOpen(resident.gds),
+    "sample.id"
+))
+library(gdsfmt)
+library(SNPRelate)
+library(randomForest)
+library(dplyr)
+library(ggplot2)
+
+# Read data
+read_gds_data <- function(gds_file, immigrant_id) {
+    all.id <- gdsfmt::read.gdsn(gdsfmt::index.gdsn(gds_file, "sample.id"))
+    all.label <- ifelse(all.id %in% immigrant_id, "immigrant", "resident")
+    list(id = all.id, label = all.label)
+}
+
+# Split data into training and testing sets
+split_data <- function(data, percent.train, kinship, kinship_threshold = 3, samples_per_class = list(train = 100, test = 20)) {
+    num_train <- round(length(data$id) * percent.train)
+    train_indices <- sample(seq_along(data$id), num_train)
+
+    train <- list(id = data$id[train_indices], label = data$label[train_indices])
+    test <- list(id = data$id[-train_indices], label = data$label[-train_indices])
+
+    kinship_filtered <- kinship[kinship$kinship_degree <= kinship_threshold, ]
+    test$id <- test$id[test$id %in% kinship_filtered$IID1 & test$id %in% kinship_filtered$IID2]
+    test$label <- data$label[data$id %in% test$id]
+
+    subsample <- function(ids, labels, n) {
+        indices <- lapply(c("immigrant", "resident"), function(class) {
+            sample(which(labels == class), n)
+        })
+        list(
+            id = unlist(Map(`[`, list(ids), indices)),
+            label = unlist(Map(`[`, list(labels), indices))
+        )
+    }
+
+    train <- subsample(train$id, train$label, samples_per_class$train)
+    test <- subsample(test$id, test$label, samples_per_class$test)
+
+    c(train, test)
+}
+
+# Perform PCA and prepare data frames
+prepare_data <- function(gds_file, train_id, test_id, num.eigenvectors, num.threads) {
+    pca <- SNPRelate::snpgdsPCA(gds_file, sample.id = train_id, num.thread = num.threads)
+    snp_loadings <- SNPRelate::snpgdsPCASNPLoading(pca, gds_file, num.thread = num.threads)
+    sample_loadings <- SNPRelate::snpgdsPCASampLoading(snp_loadings, gds_file, sample.id = test_id, num.thread = num.threads)
+
+    prepare_df <- function(ids, labels, eigenvects) {
+        data.frame(sample.id = ids, pop = labels, eigenvects[, seq_len(num.eigenvectors)])
+    }
+
+    train_df <- prepare_df(train_id, train.label, pca$eigenvect)
+    test_df <- prepare_df(test_id, test.label, sample_loadings$eigenvect)
+
+    list(train_df = train_df, test_df = test_df)
+}
+
+# Train random forest
+train_random_forest <- function(train_df, test_df, num.eigenvectors, randomize_labels = FALSE) {
+    if (randomize_labels) {
+        train_df$pop <- sample(train_df$pop)
+    }
+
+    randomForest::randomForest(
+        x = train_df[, 3:(2 + num.eigenvectors)],
+        y = as.factor(train_df$pop),
+        xtest = test_df[, 3:(2 + num.eigenvectors)],
+        ytest = as.factor(test_df$pop),
+        ntree = 500,
+        replace = FALSE,
+        proximity = TRUE
+    )
+}
+
+# Calculate mean error
+calculate_mean_error <- function(data) {
+    data %>%
+        group_by(trees, class) %>%
+        summarise(mean_error = mean(error), .groups = "drop") %>%
+        filter(class != "OOB")
+}
+
+# Run analysis multiple times
+run_analysis <- function(all_data, kinship, num_runs = 20, kinship_threshold) {
+    replicate(num_runs,
+        {
+            split <- split_data(all_data, percent.train = 0.7, kinship, kinship_threshold)
+            data <- prepare_data(all.maf, split$train.id, split$test.id, num.eigenvectors, num.threads)
+            rf <- train_random_forest(data$train_df, data$test_df, num.eigenvectors, FALSE)
+            rfPermute::plotTrace(rf, plot = FALSE)$data %>% as_tibble()
+        },
+        simplify = FALSE
+    )
+}
+
+# Main analysis
+main_analysis <- function() {
+    all_data <- read_gds_data(all.maf, immigrant.id)
+    prederror_threshold_0 <- run_analysis(all_data, kinship, num_runs = 1, kinship_threshold = 0)
+    prederror_threshold_3 <- run_analysis(all_data, kinship, num_runs = 1, kinship_threshold = 3)
+
+    prepare_plot_data <- function(prederror_data, threshold) {
+        bind_rows(prederror_data) %>%
+            mutate(threshold = threshold) %>%
+            filter(class != "OOB")
+    }
+
+    plot_data_0 <- prepare_plot_data(prederror_threshold_0, 0)
+    plot_data_3 <- prepare_plot_data(prederror_threshold_3, 3)
+
+    mean_data_0 <- calculate_mean_error(plot_data_0) %>% mutate(threshold = 0)
+    mean_data_3 <- calculate_mean_error(plot_data_3) %>% mutate(threshold = 3)
+
+    return(list(plot_data_0 = plot_data_0, plot_data_3 = plot_data_3, mean_data_0 = mean_data_0, mean_data_3 = mean_data_3))
+}
+
+
+results <- main_analysis()

# time: 2024-08-30 16:10:51 UTC
# mode: r
+# Import configuration file
+config <- config::get()
+
+# Parameters
+percent.train <- 0.7
+num.threads <- 44
+num.eigenvectors <- 20
+set.seed(555)
+
+# Input files
+data_path <- config$path$data
+immigrant.info <- file.path(data_path, "600K_immigrants.fam")
+immigrant.vcf <- file.path(data_path, "600K_immigrants.vcf")
+resident.vcf <- file.path(data_path, "600K_residents.vcf")
+immigrant.gds <- file.path(data_path, "immigrant_recode.gds")
+resident.gds <- file.path(data_path, "resident_recode.gds")
+all.gds <- file.path(data_path, "all_recode.gds")
+
+# Read in kinship CSV
+kinship <- readr::read_csv(file.path(data_path, "kinship.csv")) |>
+    dplyr::mutate(kinship_degree = dplyr::case_when(
+        kinship_degree == "unrelated" ~ 0,
+        kinship_degree == "third_degree" ~ 1,
+        kinship_degree == "second_degree" ~ 2,
+        kinship_degree == "first_degree" ~ 3
+    )) |>
+    dplyr::mutate(dplyr::across(dplyr::starts_with("IID"), ~ paste("Wytham_UK_", ., sep = "")))
+
+# Load all the data
+all.maf <- SNPRelate::snpgdsOpen(all.gds, allow.duplicate = TRUE)
+
+# Load labels
+load_labels <- function(gds_file) {
+    gdsfmt::read.gdsn(gdsfmt::index.gdsn(SNPRelate::snpgdsOpen(gds_file), "sample.id"))
+}
+
+immigrant.id <- load_labels(immigrant.gds)
+resident.id <- load_labels(resident.gds)
+all.id <- gdsfmt::read.gdsn(gdsfmt::index.gdsn(all.maf, "sample.id"))
+all.label <- ifelse(all.id %in% immigrant.id, "immigrant", "resident")
+
+# Function to split data into training and testing sets
+split_data <- function(all.id, all.label, percent.train, kinship, kinship_threshold = 3) {
+    num_train <- round(length(all.id) * percent.train)
+    train_indices <- sample(1:length(all.id), num_train)
+    train.id <- all.id[train_indices]
+    train.label <- all.label[train_indices]
+    test.id <- all.id[-train_indices]
+    test.label <- all.label[-train_indices]
+
+    kinship_filtered <- kinship[kinship$kinship_degree <= kinship_threshold, ]
+    test.id <- test.id[test.id %in% kinship_filtered$IID1 & test.id %in% kinship_filtered$IID2]
+    test.label <- all.label[all.id %in% test.id]
+
+    subsample <- function(label, count) sample(which(label == count), 100)
+    train.id <- c(train.id[subsample(train.label, "immigrant")], train.id[subsample(train.label, "resident")])
+    train.label <- c(train.label[subsample(train.label, "immigrant")], train.label[subsample(train.label, "resident")])
+    test.id <- c(test.id[subsample(test.label, "immigrant")], test.id[subsample(test.label, "resident")])
+    test.label <- c(test.label[subsample(test.label, "immigrant")], test.label[subsample(test.label, "resident")])
+
+    list(train.id = train.id, test.id = test.id, train.label = train.label, test.label = test.label)
+}
+
+# Function to perform PCA and prepare data frames
+prepare_data <- function(all.maf, train.id, test.id, train.label, test.label, num.eigenvectors, num.threads) {
+    pca <- SNPRelate::snpgdsPCA(all.maf, sample.id = train.id, num.thread = num.threads)
+    snp_loadings <- SNPRelate::snpgdsPCASNPLoading(pca, all.maf, num.thread = num.threads)
+    sample_loadings <- SNPRelate::snpgdsPCASampLoading(snp_loadings, all.maf, sample.id = test.id, num.thread = num.threads)
+    train_eigenvects <- data.frame(sample.id = pca$sample.id, pca$eigenvect[, 1:num.eigenvectors])
+    test_eigenvects <- data.frame(sample.id = sample_loadings$sample.id, sample_loadings$eigenvect[, 1:num.eigenvectors])
+    train_df <- data.frame(sample.id = train.id, pop = train.label, train_eigenvects[, -1])
+    test_df <- data.frame(sample.id = test.id, pop = test.label, test_eigenvects[, -1])
+    list(train_df = train_df, test_df = test_df)
+}
+
+# Function to train a random forest with optional randomized labels
+train_random_forest <- function(train_df, test_df, num.eigenvectors, randomize_labels = FALSE) {
+    if (randomize_labels) {
+        train_df$pop <- sample(train_df$pop)
+    }
+    randomForest::randomForest(
+        train_df[, 3:(2 + num.eigenvectors)],
+        y = as.factor(train_df$pop),
+        data = train_df,
+        xtest = test_df[, 3:(2 + num.eigenvectors)],
+        ytest = as.factor(test_df$pop),
+        ntree = 500,
+        replace = FALSE,
+        proximity = TRUE
+    )
+}
+
+calculate_mean_error <- function(data) {
+    data |>
+        dplyr::group_by(trees, class) |>
+        dplyr::summarise(mean_error = mean(error), .groups = "drop") |>
+        dplyr::filter(class != "OOB")
+}
+
+# Main analysis
+run_analysis <- function(threshold, iterations = 20) {
+    prederror_list <- vector("list", iterations)
+    for (i in seq_len(iterations)) {
+        split <- split_data(all.id, all.label, percent.train, kinship, kinship_threshold = threshold)
+        data <- prepare_data(all.maf, split$train.id, split$test.id, split$train.label, split$test.label, num.eigenvectors, num.threads)
+        rf <- train_random_forest(data$train_df, data$test_df, num.eigenvectors, FALSE)
+        prederror_list[[i]] <- rfPermute::plotTrace(rf, plot = FALSE)$data |> dplyr::as_tibble()
+    }
+    dplyr::bind_rows(prederror_list) |>
+        dplyr::mutate(threshold = threshold) |>
+        dplyr::filter(class != "OOB")
+}
+
+prederror_threshold_0_df <- run_analysis(0)
+prederror_threshold_3_df <- run_analysis(3)
+
+mean_prederror_threshold_0_df <- calculate_mean_error(prederror_threshold_0_df) |>
+    dplyr::mutate(threshold = 0)
+mean_prederror_threshold_3_df <- calculate_mean_error(prederror_threshold_3_df) |>
+    dplyr::mutate(threshold = 3)
+
+ggplot2::ggplot() +
+    ggplot2::geom_line(data = prederror_threshold_0_df, ggplot2::aes(
+        x = trees, y = error, color = class, linetype = "dashed"
+    ), alpha = 0.1, linetype = "dashed") +
+    ggplot2::geom_line(data = prederror_threshold_3_df, ggplot2::aes(
+        x = trees, y = error, color = class, linetype = "solid"
+    ), alpha = 0.1, linetype = "solid") +
+    ggplot2::geom_line(data = mean_prederror_threshold_0_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class, linetype = "dashed"
+    ), size = 1.5, linetype = "dashed") +
+    ggplot2::geom_line(data = mean_prederror_threshold_3_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class, linetype = "solid"
+    ), size = 1.5, linetype = "solid") +
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "red") +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(
+        title = "Prediction error rate for different kinship thresholds",
+        x = "Number of trees", y = "Prediction error rate"
+    ) +
+    ggplot2::scale_color_manual(
+        values = c(
+            "immigrant" = "#5d8566",
+            "resident" = "#c29007"
+        )
+    ) +
+    ggplot2::scale_linetype_manual(
+        values = c(
+            "dashed" = "dashed",
+            "solid" = "solid"
+        )
+    ) +
+    ggplot2::theme(
+        aspect.ratio = 1,
+        text = ggplot2::element_text(size = 12),
+        legend.position = "bottom",
+        legend.title = ggplot2::element_blank(),
+        legend.text = ggplot2::element_text(size = 10),
+        panel.grid.major = ggplot2::element_blank(),
+        panel.grid.minor = ggplot2::element_blank()
+    )

# time: 2024-08-30 16:12:01 UTC
# mode: r
+ggplot2::ggplot() +
+    ggplot2::geom_line(data = prederror_threshold_0_df, ggplot2::aes(
+        x = trees, y = error, color = class, linetype = "dashed"
+    ), alpha = 0.1, linetype = "dashed") +
+    ggplot2::geom_line(data = prederror_threshold_3_df, ggplot2::aes(
+        x = trees, y = error, color = class, linetype = "solid"
+    ), alpha = 0.1, linetype = "solid") +
+    ggplot2::geom_line(data = mean_prederror_threshold_0_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class, linetype = "dashed"
+    ), size = 1.5, linetype = "dashed") +
+    ggplot2::geom_line(data = mean_prederror_threshold_3_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class, linetype = "solid"
+    ), size = 1.5, linetype = "solid") +
+    # add horizontal line at 50% error rate
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "red") +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(
+        title = "Prediction error rate for different kinship thresholds",
+        x = "Number of trees", y = "Prediction error rate"
+    ) +
+    ggplot2::scale_color_manual(
+        values = c(
+            "immigrant" = "#5d8566",
+            "resident" = "#c29007"
+        )
+    ) +
+    ggplot2::scale_linetype_manual(
+        values = c(
+            "dashed" = "dashed",
+            "solid" = "solid"
+        )
+    ) +
+    ggplot2::theme(
+        aspect.ratio = 1,
+        text = ggplot2::element_text(size = 12),
+        legend.position = "bottom",
+        legend.title = ggplot2::element_blank(),
+        legend.text = ggplot2::element_text(size = 10),
+        panel.grid.major = ggplot2::element_blank(),
+        panel.grid.minor = ggplot2::element_blank()
+    )

# time: 2024-08-30 16:12:50 UTC
# mode: r
+# prepare the data for plotting
+prederror_threshold_0_df <- dplyr::bind_rows(prederror_threshold_0) |>
+    dplyr::mutate(threshold = 0) |> # remove OOB from the class column
+    dplyr::filter(class != "OOB")
+
+prederror_threshold_3_df <- dplyr::bind_rows(prederror_threshold_3) |>
+    dplyr::mutate(threshold = 3) |>
+    dplyr::filter(class != "OOB")
+
+# consolidate the data into a single dataframe
+plot_data <- dplyr::bind_rows(
+    prederror_threshold_0_df,
+    prederror_threshold_3_df,
+    mean_prederror_threshold_0_df,
+    mean_prederror_threshold_3_df
+)
+
+ggplot2::ggplot(plot_data) +
+    ggplot2::geom_line(ggplot2::aes(
+        x = trees, y = error, color = class, linetype = as.factor(threshold)
+    ), alpha = 0.1, size = 1.5) +
+    # add horizontal line at 50% error rate
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "red") +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(
+        title = "Prediction error rate for different kinship thresholds",
+        x = "Number of trees", y = "Prediction error rate"
+    ) +
+    ggplot2::scale_color_manual(
+        values = c(
+            "immigrant" = "#5d8566",
+            "resident" = "#c29007"
+        )
+    ) +
+    ggplot2::scale_linetype_manual(
+        values = c(
+            "0" = "dashed",
+            "3" = "solid"
+        )
+    ) +
+    ggplot2::theme(
+        aspect.ratio = 1,
+        text = ggplot2::element_text(size = 12),
+        legend.position = "bottom",
+        legend.title = ggplot2::element_blank(),
+        legend.text = ggplot2::element_text(size = 10),
+        panel.grid.major = ggplot2::element_blank(),
+        panel.grid.minor = ggplot2::element_blank()
+    )

# time: 2024-08-30 16:13:22 UTC
# mode: r
+# Plot mean lines separately for each kinship threshold
+ggplot2::ggplot(plot_data) +
+    ggplot2::geom_line(ggplot2::aes(
+        x = trees, y = error, color = class, linetype = as.factor(threshold)
+    ), alpha = 0.1, size = 1.5) +
+    # add horizontal line at 50% error rate
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "red") +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(
+        title = "Prediction error rate for different kinship thresholds",
+        x = "Number of trees", y = "Prediction error rate"
+    ) +
+    ggplot2::scale_color_manual(
+        values = c(
+            "immigrant" = "#5d8566",
+            "resident" = "#c29007"
+        )
+    ) +
+    ggplot2::scale_linetype_manual(
+        values = c(
+            "0" = "dashed",
+            "3" = "solid"
+        )
+    ) +
+    ggplot2::theme(
+        aspect.ratio = 1,
+        text = ggplot2::element_text(size = 12),
+        legend.position = "bottom",
+        legend.title = ggplot2::element_blank(),
+        legend.text = ggplot2::element_text(size = 10),
+        panel.grid.major = ggplot2::element_blank(),
+        panel.grid.minor = ggplot2::element_blank()
+    ) +
+    # Plot mean lines separately for each kinship threshold
+    ggplot2::facet_wrap(~ threshold, scales = "free_y") +
+    ggplot2::geom_line(ggplot2::aes(
+        x = trees, y = mean_error, color = class, linetype = as.factor(threshold)
+    ), data = calculate_mean_error(plot_data), size = 1.5)

# time: 2024-08-30 16:13:38 UTC
# mode: r
+# prepare the data for plotting
+prederror_threshold_0_df <- dplyr::bind_rows(prederror_threshold_0) |>
+    dplyr::mutate(threshold = 0) |> # remove OOB from the class column
+    dplyr::filter(class != "OOB")

# time: 2024-08-30 16:13:40 UTC
# mode: r
+prederror_threshold_0_df

# time: 2024-08-30 16:14:28 UTC
# mode: r
+ggplot2::ggplot() +
+    ggplot2::geom_line(data = prederror_threshold_0_df, ggplot2::aes(
+        x = trees, y = error, color = class, linetype = threshold
+    ), alpha = 0.1, linetype = "dashed") +
+    ggplot2::geom_line(data = prederror_threshold_3_df, ggplot2::aes(
+        x = trees, y = error, color = class, linetype = threshold
+    ), alpha = 0.1, linetype = "solid") +
+    ggplot2::geom_line(data = mean_prederror_threshold_0_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class, linetype = threshold
+    ), size = 1.5, linetype = "dashed") +
+    ggplot2::geom_line(data = mean_prederror_threshold_3_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class, linetype = threshold
+    ), size = 1.5, linetype = "solid") +
+    # add horizontal line at 50% error rate
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "red") +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(
+        title = "Prediction error rate for different kinship thresholds",
+        x = "Number of trees", y = "Prediction error rate"
+    ) +
+    ggplot2::scale_color_manual(
+        values = c(
+            "immigrant" = "#5d8566",
+            "resident" = "#c29007"
+        )
+    ) +
+    ggplot2::scale_linetype_manual(
+        values = c(
+            "0" = "dashed",
+            "3" = "solid"
+        )
+    ) +
+    ggplot2::scale_linetype_manual(
+        values = c(
+            "dashed" = "dashed",
+            "solid" = "solid"
+        )
+    ) +
+    ggplot2::theme(
+        aspect.ratio = 1,
+        text = ggplot2::element_text(size = 12),
+        legend.position = "bottom",
+        legend.title = ggplot2::element_blank(),
+        legend.text = ggplot2::element_text(size = 10),
+        panel.grid.major = ggplot2::element_blank(),
+        panel.grid.minor = ggplot2::element_blank()
+    )

# time: 2024-08-30 16:15:29 UTC
# mode: r
+# Plot the prediction error rate for different kinship thresholds
+
+ggplot2::ggplot() +
+    ggplot2::geom_line(data = prederror_threshold_0_df, ggplot2::aes(
+        x = trees, y = error, color = class, linetype = threshold
+    ), alpha = 0.1) +
+    ggplot2::geom_line(data = prederror_threshold_3_df, ggplot2::aes(
+        x = trees, y = error, color = class, linetype = threshold
+    ), alpha = 0.1) +
+    ggplot2::geom_line(data = mean_prederror_threshold_0_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class, linetype = threshold
+    ), size = 1.5) +
+    ggplot2::geom_line(data = mean_prederror_threshold_3_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class, linetype = threshold
+    ), size = 1.5) +
+    # add horizontal line at 50% error rate
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "red") +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(
+        title = "Prediction error rate for different kinship thresholds",
+        x = "Number of trees", y = "Prediction error rate"
+    ) +
+    ggplot2::scale_color_manual(
+        values = c(
+            "immigrant" = "#5d8566",
+            "resident" = "#c29007"
+        )
+    ) +
+    ggplot2::scale_linetype_manual(
+        values = c(
+            "0" = "dashed",
+            "3" = "solid"
+        )
+    ) +
+    ggplot2::scale_linetype_manual(
+        values = c(
+            "dashed" = "dashed",
+            "solid" = "solid"
+        )
+    ) +
+    ggplot2::theme(
+        aspect.ratio = 1,
+        text = ggplot2::element_text(size = 12),
+        legend.position = "bottom",
+        legend.title = ggplot2::element_blank(),
+        legend.text = ggplot2::element_text(size = 10),
+        panel.grid.major = ggplot2::element_blank(),
+        panel.grid.minor = ggplot2::element_blank()
+    )

# time: 2024-08-30 16:15:42 UTC
# mode: r
+# Plot the prediction error rate for different kinship thresholds
+
+ggplot2::ggplot() +
+    ggplot2::geom_line(data = prederror_threshold_0_df, ggplot2::aes(
+        x = trees, y = error, color = class, linetype = threshold
+    ), alpha = 0.1) +
+    ggplot2::geom_line(data = prederror_threshold_3_df, ggplot2::aes(
+        x = trees, y = error, color = class, linetype = threshold
+    ), alpha = 0.1) +
+    ggplot2::geom_line(data = mean_prederror_threshold_0_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class, linetype = threshold
+    ), size = 1.5) +
+    ggplot2::geom_line(data = mean_prederror_threshold_3_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class, linetype = threshold
+    ), size = 1.5) +
+    # add horizontal line at 50% error rate
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "red") +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(
+        title = "Prediction error rate for different kinship thresholds",
+        x = "Number of trees", y = "Prediction error rate"
+    ) +
+    ggplot2::scale_color_manual(
+        values = c(
+            "immigrant" = "#5d8566",
+            "resident" = "#c29007"
+        )
+    ) +
+    ggplot2::scale_linetype_manual(
+        values = c(
+            "0" = "dashed",
+            "3" = "solid"
+        )
+    ) +
+    ggplot2::scale_linetype_manual(
+        values = c(
+            "0" = "dashed",
+            "3" = "solid"
+        )
+    ) +
+    ggplot2::theme(
+        aspect.ratio = 1,
+        text = ggplot2::element_text(size = 12),
+        legend.position = "bottom",
+        legend.title = ggplot2::element_blank(),
+        legend.text = ggplot2::element_text(size = 10),
+        panel.grid.major = ggplot2::element_blank(),
+        panel.grid.minor = ggplot2::element_blank()
+    )

# time: 2024-08-30 16:15:47 UTC
# mode: r
+prederror_threshold_3_df

# time: 2024-08-30 16:16:43 UTC
# mode: r
+mean_prederror_df <- dplyr::bind_rows(mean_prederror_threshold_0_df, mean_prederror_threshold_3_df)

# time: 2024-08-30 16:17:02 UTC
# mode: r
+# prepare the data for plotting
+prederror_threshold_0_df <- dplyr::bind_rows(prederror_threshold_0) |>
+    dplyr::mutate(threshold = 0) |> # remove OOB from the class column
+    dplyr::filter(class != "OOB")
+
+prederror_threshold_3_df <- dplyr::bind_rows(prederror_threshold_3) |>
+    dplyr::mutate(threshold = 3) |>
+    dplyr::filter(class != "OOB")
+
+prederror_df <- dplyr::bind_rows(prederror_threshold_0_df, prederror_threshold_3_df)
+
+# add mean error values
+mean_prederror_threshold_0_df <- calculate_mean_error(prederror_threshold_0_df) |>
+    dplyr::mutate(threshold = 0) |>
+mean_prederror_threshold_3_df <- calculate_mean_error(prederror_threshold_3_df) |>
+    dplyr::mutate(threshold = 3)
+
+mean_prederror_df <- dplyr::bind_rows(mean_prederror_threshold_0_df, mean_prederror_threshold_3_df)
+
+# Plot the prediction error rate for different kinship thresholds
+
+ggplot2::ggplot() +
+    ggplot2::geom_line(data = prederror_df, ggplot2::aes(
+        x = trees, y = error, color = class, linetype = threshold
+    ), alpha = 0.1) +
+    ggplot2::geom_line(data = mean_prederror_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class, linetype = threshold
+    ), size = 1.5) +
+    # add horizontal line at 50% error rate
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "red") +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(
+        title = "Prediction error rate for different kinship thresholds",
+        x = "Number of trees", y = "Prediction error rate"
+    ) +
+    ggplot2::scale_color_manual(
+        values = c(
+            "immigrant" = "#5d8566",
+            "resident" = "#c29007"
+        )
+    ) +
+    ggplot2::scale_linetype_manual(
+        values = c(
+            "0" = "dashed",
+            "3" = "solid"
+        )
+    ) +
+    ggplot2::scale_linetype_manual(
+        values = c(
+            "0" = "dashed",
+            "3" = "solid"
+        )
+    ) +
+    ggplot2::theme(
+        aspect.ratio = 1,
+        text = ggplot2::element_text(size = 12),
+        legend.position = "bottom",
+        legend.title = ggplot2::element_blank(),
+        legend.text = ggplot2::element_text(size = 10),
+        panel.grid.major = ggplot2::element_blank(),
+        panel.grid.minor = ggplot2::element_blank()
+    )

# time: 2024-08-30 16:17:23 UTC
# mode: r
+# Plot the prediction error rate for different kinship thresholds
+
+ggplot2::ggplot() +
+    ggplot2::geom_line(data = prederror_df, ggplot2::aes(
+        x = trees, y = error, color = class, linetype = threshold
+    ), alpha = 0.1) +
+    ggplot2::geom_line(data = mean_prederror_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class, linetype = threshold
+    ), size = 1.5) +
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "red") +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(
+        title = "Prediction error rate for different kinship thresholds",
+        x = "Number of trees", y = "Prediction error rate"
+    ) +
+    ggplot2::scale_color_manual(
+        values = c(
+            "immigrant" = "#5d8566",
+            "resident" = "#c29007"
+        )
+    ) +
+    ggplot2::scale_linetype_manual(
+        values = c(
+            "0" = "dashed",
+            "3" = "solid"
+        )
+    ) +
+    ggplot2::theme(
+        aspect.ratio = 1,
+        text = ggplot2::element_text(size = 12),
+        legend.position = "bottom",
+        legend.title = ggplot2::element_blank(),
+        legend.text = ggplot2::element_text(size = 10),
+        panel.grid.major = ggplot2::element_blank(),
+        panel.grid.minor = ggplot2::element_blank()
+    )

# time: 2024-08-30 16:17:33 UTC
# mode: r
+# Plot the prediction error rate for different kinship thresholds
+
+ggplot2::ggplot() +
+    ggplot2::geom_line(data = prederror_df, ggplot2::aes(
+        x = trees, y = error, color = class, linetype = threshold
+    ), alpha = 0.1) +
+    ggplot2::geom_line(data = mean_prederror_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class, linetype = threshold
+    ), size = 1.5) +
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "red") +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(
+        title = "Prediction error rate for different kinship thresholds",
+        x = "Number of trees", y = "Prediction error rate"
+    ) +
+    ggplot2::scale_color_manual(
+        values = c(
+            "immigrant" = "#5d8566",
+            "resident" = "#c29007"
+        )
+    ) +
+    ggplot2::theme(
+        aspect.ratio = 1,
+        text = ggplot2::element_text(size = 12),
+        legend.position = "bottom",
+        legend.title = ggplot2::element_blank(),
+        legend.text = ggplot2::element_text(size = 10),
+        panel.grid.major = ggplot2::element_blank(),
+        panel.grid.minor = ggplot2::element_blank()
+    )

# time: 2024-08-30 16:18:27 UTC
# mode: r
+# prepare the data for plotting
+prederror_threshold_0_df <- dplyr::bind_rows(prederror_threshold_0) |>
+    dplyr::mutate(threshold = 0) |> # remove OOB from the class column
+    dplyr::filter(class != "OOB")
+
+prederror_threshold_3_df <- dplyr::bind_rows(prederror_threshold_3) |>
+    dplyr::mutate(threshold = 3) |>
+    dplyr::filter(class != "OOB")
+
+prederror_df <- dplyr::bind_rows(prederror_threshold_0_df, prederror_threshold_3_df) |>
+    dplyr::mutate(threshold = as.factor(threshold))
+
+# add mean error values
+mean_prederror_threshold_0_df <- calculate_mean_error(prederror_threshold_0_df) |>
+    dplyr::mutate(threshold = 0) |>
+mean_prederror_threshold_3_df <- calculate_mean_error(prederror_threshold_3_df) |>
+    dplyr::mutate(threshold = 3)
+
+mean_prederror_df <- dplyr::bind_rows(mean_prederror_threshold_0_df, mean_prederror_threshold_3_df) |>
+        dplyr::mutate(threshold = as.factor(threshold))
+
+
+# Plot the prediction error rate for different kinship thresholds
+
+ggplot2::ggplot() +
+    ggplot2::geom_line(data = prederror_df, ggplot2::aes(
+        x = trees, y = error, color = class, linetype = threshold
+    ), alpha = 0.1) +
+    ggplot2::geom_line(data = mean_prederror_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class, linetype = threshold
+    ), size = 1.5) +
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "red") +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(
+        title = "Prediction error rate for different kinship thresholds",
+        x = "Number of trees", y = "Prediction error rate"
+    ) +
+    ggplot2::scale_color_manual(
+        values = c(
+            "immigrant" = "#5d8566",
+            "resident" = "#c29007"
+        )
+    ) +
+    ggplot2::theme(
+        aspect.ratio = 1,
+        text = ggplot2::element_text(size = 12),
+        legend.position = "bottom",
+        legend.title = ggplot2::element_blank(),
+        legend.text = ggplot2::element_text(size = 10),
+        panel.grid.major = ggplot2::element_blank(),
+        panel.grid.minor = ggplot2::element_blank()
+    )

# time: 2024-08-30 16:18:38 UTC
# mode: r
+# Plot the prediction error rate for different kinship thresholds
+
+ggplot2::ggplot() +
+    ggplot2::geom_line(data = prederror_df, ggplot2::aes(
+        x = trees, y = error, color = class, linetype = threshold
+    ), alpha = 0.1) +
+    ggplot2::geom_line(data = mean_prederror_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class, linetype = threshold
+    ), size = 1.5) +
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "red") +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(
+        title = "Prediction error rate for different kinship thresholds",
+        x = "Number of trees", y = "Prediction error rate"
+    ) +
+    ggplot2::scale_color_manual(
+        values = c(
+            "immigrant" = "#5d8566",
+            "resident" = "#c29007"
+        )
+    ) +
+    ggplot2::scale_linetype_manual(
+        values = c(
+            "0" = "solid",
+            "3" = "dashed"
+        )
+    ) +
+    ggplot2::theme(
+        aspect.ratio = 1,
+        text = ggplot2::element_text(size = 12),
+        legend.position = "bottom",
+        legend.title = ggplot2::element_blank(),
+        legend.text = ggplot2::element_text(size = 10),
+        panel.grid.major = ggplot2::element_blank(),
+        panel.grid.minor = ggplot2::element_blank()
+    )

# time: 2024-08-30 16:18:51 UTC
# mode: r
+# Plot the prediction error rate for different kinship thresholds
+
+ggplot2::ggplot() +
+    ggplot2::geom_line(data = prederror_df, ggplot2::aes(
+        x = trees, y = error, color = class, linetype = threshold
+    ), alpha = 0.1) +
+    ggplot2::geom_line(data = mean_prederror_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class, linetype = threshold
+    ), size = 1.5) +
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "red") +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(
+        title = "Prediction error rate for different kinship thresholds",
+        x = "Number of trees", y = "Prediction error rate"
+    ) +
+    ggplot2::scale_color_manual(
+        values = c(
+            "immigrant" = "#5d8566",
+            "resident" = "#c29007"
+        )
+    ) +
+    ggplot2::scale_linetype_manual(
+        values = c(
+            0 = "solid",
+            3 = "dashed"
+        )
+    ) +
+    ggplot2::theme(
+        aspect.ratio = 1,
+        text = ggplot2::element_text(size = 12),
+        legend.position = "bottom",
+        legend.title = ggplot2::element_blank(),
+        legend.text = ggplot2::element_text(size = 10),
+        panel.grid.major = ggplot2::element_blank(),
+        panel.grid.minor = ggplot2::element_blank()
+    )

# time: 2024-08-30 16:19:18 UTC
# mode: r
+mean_prederror_df

# time: 2024-08-30 16:19:30 UTC
# mode: r
+# prepare the data for plotting
+prederror_threshold_0_df <- dplyr::bind_rows(prederror_threshold_0) |>
+    dplyr::mutate(threshold = 0) |> # remove OOB from the class column
+    dplyr::filter(class != "OOB")
+
+prederror_threshold_3_df <- dplyr::bind_rows(prederror_threshold_3) |>
+    dplyr::mutate(threshold = 3) |>
+    dplyr::filter(class != "OOB")
+
+prederror_df <- dplyr::bind_rows(prederror_threshold_0_df, prederror_threshold_3_df) |>
+    dplyr::mutate(threshold = as.factor(threshold))
+
+# add mean error values
+mean_prederror_threshold_0_df <- calculate_mean_error(prederror_threshold_0_df) |>
+    dplyr::mutate(threshold = 0) |>
+mean_prederror_threshold_3_df <- calculate_mean_error(prederror_threshold_3_df) |>
+    dplyr::mutate(threshold = 3)
+
+mean_prederror_df <- dplyr::bind_rows(mean_prederror_threshold_0_df, mean_prederror_threshold_3_df) |>
+        dplyr::mutate(threshold = as.factor(threshold))

# time: 2024-08-30 16:19:37 UTC
# mode: r
+prederror_threshold_0_df <- dplyr::bind_rows(prederror_threshold_0) |>
+    dplyr::mutate(threshold = 0) |> # remove OOB from the class column
+    dplyr::filter(class != "OOB")
+
+prederror_threshold_3_df <- dplyr::bind_rows(prederror_threshold_3) |>
+    dplyr::mutate(threshold = 3) |>
+    dplyr::filter(class != "OOB")
+
+prederror_df <- dplyr::bind_rows(prederror_threshold_0_df, prederror_threshold_3_df) |>
+    dplyr::mutate(threshold = as.factor(threshold))
+
+# add mean error values
+mean_prederror_threshold_0_df <- calculate_mean_error(prederror_threshold_0_df) |>
+    dplyr::mutate(threshold = 0) 
+mean_prederror_threshold_3_df <- calculate_mean_error(prederror_threshold_3_df) |>
+    dplyr::mutate(threshold = 3)
+
+mean_prederror_df <- dplyr::bind_rows(mean_prederror_threshold_0_df, mean_prederror_threshold_3_df) |>
+        dplyr::mutate(threshold = as.factor(threshold))

# time: 2024-08-30 16:19:39 UTC
# mode: r
+# Plot the prediction error rate for different kinship thresholds
+
+ggplot2::ggplot() +
+    ggplot2::geom_line(data = prederror_df, ggplot2::aes(
+        x = trees, y = error, color = class, linetype = threshold
+    ), alpha = 0.1) +
+    ggplot2::geom_line(data = mean_prederror_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class, linetype = threshold
+    ), size = 1.5) +
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "red") +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(
+        title = "Prediction error rate for different kinship thresholds",
+        x = "Number of trees", y = "Prediction error rate"
+    ) +
+    ggplot2::scale_color_manual(
+        values = c(
+            "immigrant" = "#5d8566",
+            "resident" = "#c29007"
+        )
+    ) +
+    ggplot2::scale_linetype_manual(
+        values = c(
+            "0" = "solid",
+            "3" = "dashed"
+        )
+    ) +
+    ggplot2::theme(
+        aspect.ratio = 1,
+        text = ggplot2::element_text(size = 12),
+        legend.position = "bottom",
+        legend.title = ggplot2::element_blank(),
+        legend.text = ggplot2::element_text(size = 10),
+        panel.grid.major = ggplot2::element_blank(),
+        panel.grid.minor = ggplot2::element_blank()
+    )

# time: 2024-08-30 16:19:56 UTC
# mode: r
+# Plot the prediction error rate for different kinship thresholds
+
+ggplot2::ggplot() +
+    ggplot2::geom_line(data = prederror_df, ggplot2::aes(
+        x = trees, y = error, color = class, linetype = threshold
+    ), alpha = 0.1) +
+    ggplot2::geom_line(data = mean_prederror_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class, linetype = threshold
+    ), size = 1.5) +
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "red") +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(
+        title = "Prediction error rate for different kinship thresholds",
+        x = "Number of trees", y = "Prediction error rate"
+    ) +
+    ggplot2::scale_color_manual(
+        values = c(
+            "immigrant" = "#5d8566",
+            "resident" = "#c29007"
+        )
+    ) +
+    ggplot2::scale_linetype_manual(
+        values = c(
+            "0" = "solid",
+            "3" = "dashed"
+        )
+    ) +
+    ggplot2::theme(
+        aspect.ratio = 1,
+        text = ggplot2::element_text(size = 12),
+        legend.title = ggplot2::element_blank(),
+        legend.text = ggplot2::element_text(size = 10),
+        panel.grid.major = ggplot2::element_blank(),
+        panel.grid.minor = ggplot2::element_blank()
+    )

# time: 2024-08-30 16:21:12 UTC
# mode: r
+# Prepare the data for plotting
+prederror_threshold_0_df <- dplyr::bind_rows(prederror_threshold_0) |>
+    dplyr::mutate(threshold = 0) |>
+    dplyr::filter(class != "OOB")
+
+prederror_threshold_3_df <- dplyr::bind_rows(prederror_threshold_3) |>
+    dplyr::mutate(threshold = 3) |>
+    dplyr::filter(class != "OOB")
+
+prederror_df <- dplyr::bind_rows(prederror_threshold_0_df, prederror_threshold_3_df) |>
+    dplyr::mutate(threshold = as.factor(threshold))
+
+# Add mean error values
+mean_prederror_df <- dplyr::bind_rows(
+    calculate_mean_error(prederror_threshold_0_df) |>
+        dplyr::mutate(threshold = 0),
+    calculate_mean_error(prederror_threshold_3_df) |>
+        dplyr::mutate(threshold = 3)
+) |>
+    dplyr::mutate(threshold = as.factor(threshold))

# time: 2024-08-30 16:21:14 UTC
# mode: r
+mean_prederror_df

# time: 2024-08-30 16:22:13 UTC
# mode: r
+# Prepare the data for plotting
+prederror_threshold_0_df <- dplyr::bind_rows(prederror_threshold_0) |>
+    dplyr::mutate(threshold = 0)
+
+prederror_threshold_3_df <- dplyr::bind_rows(prederror_threshold_3) |>
+    dplyr::mutate(threshold = 3) 
+
+prederror_df <- dplyr::bind_rows(prederror_threshold_0_df, prederror_threshold_3_df) |>
+    dplyr::mutate(threshold = as.factor(threshold)) |>
+        dplyr::filter(class != "OOB")
+
+# Add mean error values
+mean_prederror_df <- dplyr::bind_rows(
+    calculate_mean_error(prederror_threshold_0_df) |>
+        dplyr::mutate(threshold = 0),
+    calculate_mean_error(prederror_threshold_3_df) |>
+        dplyr::mutate(threshold = 3)
+) |>
+    dplyr::mutate(threshold = as.factor(threshold))
+
+
+# Plot the prediction error rate for different kinship thresholds
+
+ggplot2::ggplot() +
+    ggplot2::geom_line(data = prederror_df, ggplot2::aes(
+        x = trees, y = error, color = class, linetype = threshold
+    ), alpha = 0.1) +
+    ggplot2::geom_line(data = mean_prederror_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class, linetype = threshold
+    ), size = 1.5) +
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "red") +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(
+        title = "Prediction error rate for different kinship thresholds",
+        x = "Number of trees", y = "Prediction error rate"
+    ) +
+    ggplot2::scale_color_manual(
+        values = c(
+            "immigrant" = "#5d8566",
+            "resident" = "#c29007"
+        )
+    ) +
+    ggplot2::scale_linetype_manual(
+        values = c(
+            "0" = "solid",
+            "3" = "dashed"
+        )
+    ) +
+    ggplot2::theme(
+        aspect.ratio = 1,
+        text = ggplot2::element_text(size = 12),
+        legend.title = ggplot2::element_blank(),
+        legend.text = ggplot2::element_text(size = 10),
+        panel.grid.major = ggplot2::element_blank(),
+        panel.grid.minor = ggplot2::element_blank()
+    )

# time: 2024-08-30 16:23:19 UTC
# mode: r
+# Plot the prediction error rate for different kinship thresholds
+
+ggplot2::ggplot() +
+    ggplot2::geom_line(data = prederror_df, ggplot2::aes(
+        x = trees, y = error, color = class, linetype = threshold
+    ), alpha = 0.1) +
+    ggplot2::geom_line(data = mean_prederror_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class, linetype = threshold
+    ), size = 1.5) +
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "red") +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(
+        title = "Prediction error rate for different kinship thresholds",
+        x = "Number of trees", y = "Prediction error rate"
+    ) +
+    ggplot2::scale_color_manual(
+        values = c(
+            "immigrant" = "#5d8566",
+            "resident" = "#c29007"
+        )
+    ) +
+    ggplot2::scale_linetype_manual(
+        values = c(
+            "0" = "solid",
+            "3" = "dashed"
+        ),
+        labels = c(
+            "0" = "unrelated",
+            "3" = "all birds"
+        )
+    ) +
+    ggplot2::theme(
+        aspect.ratio = 1,
+        text = ggplot2::element_text(size = 12),
+        legend.title = ggplot2::element_blank(),
+        legend.text = ggplot2::element_text(size = 10),
+        panel.grid.major = ggplot2::element_blank(),
+        panel.grid.minor = ggplot2::element_blank()
+    )

# time: 2024-08-30 16:24:14 UTC
# mode: r
+# Plot the prediction error rate for different kinship thresholds
+
+ggplot2::ggplot() +
+    ggplot2::geom_line(data = prederror_df, ggplot2::aes(
+        x = trees, y = error, color = class, linetype = threshold
+    ), alpha = 0.1) +
+    ggplot2::geom_line(data = mean_prederror_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class, linetype = threshold
+    ), size = 1.5) +
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "red") +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(
+        title = "Correct classification for different kinship thresholds",
+        x = "Number of trees", y = "Correct classification (%)"
+    ) +
+    ggplot2::scale_color_manual(
+        values = c(
+            "immigrant" = "#5d8566",
+            "resident" = "#c29007"
+        )
+    ) +
+    ggplot2::scale_linetype_manual(
+        values = c(
+            "0" = "solid",
+            "3" = "dashed"
+        ),
+        labels = c(
+            "0" = "unrelated",
+            "3" = "all birds"
+        )
+    ) +
+    # y axis to percentage
+    ggplot2::scale_y_continuous(labels = scales::percent_format(scale = 1)) +
+    ggplot2::theme(
+        aspect.ratio = 1,
+        text = ggplot2::element_text(size = 12),
+        legend.title = ggplot2::element_blank(),
+        legend.text = ggplot2::element_text(size = 10),
+        panel.grid.major = ggplot2::element_blank(),
+        panel.grid.minor = ggplot2::element_blank()
+    )

# time: 2024-08-30 16:24:33 UTC
# mode: r
+# Plot the prediction error rate for different kinship thresholds
+kin_error_plot = 
+ggplot2::ggplot() +
+    ggplot2::geom_line(data = prederror_df, ggplot2::aes(
+        x = trees, y = error, color = class, linetype = threshold
+    ), alpha = 0.1) +
+    ggplot2::geom_line(data = mean_prederror_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class, linetype = threshold
+    ), size = 1.5) +
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "red") +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(
+        title = "Correct classification for different kinship thresholds",
+        x = "Number of trees", y = "Correct classification (%)"
+    ) +
+    ggplot2::scale_color_manual(
+        values = c(
+            "immigrant" = "#5d8566",
+            "resident" = "#c29007"
+        )
+    ) +
+    ggplot2::scale_linetype_manual(
+        values = c(
+            "0" = "solid",
+            "3" = "dashed"
+        ),
+        labels = c(
+            "0" = "unrelated",
+            "3" = "all birds"
+        )
+    ) +
+    # y axis to percentage
+    ggplot2::scale_y_continuous(labels = scales::percent_format(scale = 1)) +
+    ggplot2::theme(
+        aspect.ratio = 1,
+        text = ggplot2::element_text(size = 12),
+        legend.title = ggplot2::element_blank(),
+        legend.text = ggplot2::element_text(size = 10),
+        panel.grid.major = ggplot2::element_blank(),
+        panel.grid.minor = ggplot2::element_blank()
+    )

# time: 2024-08-30 16:24:38 UTC
# mode: r
+ggsave::ggsave(
+    file.path(config$path$figures, "kinship_error_plot.png"),
+    plot = kin_error_plot,
+    width = 8,
+    height = 6,
+    dpi = 300
+)

# time: 2024-08-30 16:24:42 UTC
# mode: r
+ggplot2::ggsave(
+    file.path(config$path$figures, "kinship_error_plot.png"),
+    plot = kin_error_plot,
+    width = 8,
+    height = 6,
+    dpi = 300
+)

# time: 2024-08-30 16:25:21 UTC
# mode: r
+# Plot the prediction error rate for different kinship thresholds
+kin_error_plot = 
+ggplot2::ggplot() +
+    ggplot2::geom_line(data = prederror_df, ggplot2::aes(
+        x = trees, y = error, color = class, linetype = threshold
+    ), alpha = 0.1) +
+    ggplot2::geom_line(data = mean_prederror_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class, linetype = threshold
+    ), size = 1.5) +
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "red") +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(
+        title = "Correct classification for different kinship thresholds",
+        x = "Number of trees", y = "Correct classification (%)"
+    ) +
+    ggplot2::scale_color_manual(
+        values = c(
+            "immigrant" = "#5d8566",
+            "resident" = "#c29007"
+        )
+    ) +
+    ggplot2::scale_linetype_manual(
+        values = c(
+            "0" = "solid",
+            "3" = "dashed"
+        ),
+        labels = c(
+            "0" = "unrelated",
+            "3" = "all birds"
+        )
+    ) +
+    # y axis to percentage
+    ggplot2::scale_y_continuous(labels = scales::percent_format(scale = 1)) +
+    ggplot2::theme(
+        aspect.ratio = 1,
+        text = ggplot2::element_text(size = 12),
+        legend.title = ggplot2::element_blank(),
+        legend.text = ggplot2::element_text(size = 10),
+        panel.grid.major = ggplot2::element_blank(),
+        panel.grid.minor = ggplot2::element_blank(),
+        # add white background to plot
+        panel.background = ggplot2::element_rect(fill = "white"),
+        plot.background = ggplot2::element_rect(fill = "white")
+        
+    )

# time: 2024-08-30 16:25:21 UTC
# mode: r
+ggplot2::ggsave(
+    file.path(config$path$figures, "kinship_error_plot.png"),
+    plot = kin_error_plot,
+    width = 8,
+    height = 6,
+    dpi = 300
+)

# time: 2024-08-30 16:26:50 UTC
# mode: r
+# Plot the prediction error rate for different kinship thresholds
+kin_error_plot = 
+ggplot2::ggplot() +
+    ggplot2::geom_line(data = prederror_df, ggplot2::aes(
+        x = trees, y = error, color = class, linetype = threshold
+    ), alpha = 0.1) +
+    ggplot2::geom_line(data = mean_prederror_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class, linetype = threshold
+    ), size = 1.5) +
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "red") +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(
+        title = "Correct classification for different kinship thresholds",
+        x = "Number of trees", y = "Correct classification (%)"
+    ) +
+    ggplot2::scale_color_manual(
+        values = c(
+            "immigrant" = "#5d8566",
+            "resident" = "#c29007"
+        )
+    ) +
+    ggplot2::scale_linetype_manual(
+        values = c("solid", "dashed"),
+        labels = c(
+            "0" = "unrelated",
+            "3" = "all birds"
+        )
+    ) +
+    # y axis to percentage
+    ggplot2::scale_y_continuous(labels = scales::percent_format(scale = 1)) +
+    ggplot2::theme(
+        aspect.ratio = 1,
+        text = ggplot2::element_text(size = 12),
+        legend.title = ggplot2::element_blank(),
+        legend.text = ggplot2::element_text(size = 10),
+        panel.grid.major = ggplot2::element_blank(),
+        panel.grid.minor = ggplot2::element_blank(),
+        # add white background to plot
+        panel.background = ggplot2::element_rect(fill = "white"),
+        plot.background = ggplot2::element_rect(fill = "white")
+
+    )

# time: 2024-08-30 16:26:51 UTC
# mode: r
+ggplot2::ggsave(
+    file.path(config$path$figures, "kinship_error_plot.png"),
+    plot = kin_error_plot,
+    width = 8,
+    height = 6,
+    dpi = 300
+)

# time: 2024-08-30 16:27:59 UTC
# mode: r
+# Plot the prediction error rate for different kinship thresholds
+kin_error_plot = 
+ggplot2::ggplot() +
+    ggplot2::geom_line(data = prederror_df, ggplot2::aes(
+        x = trees, y = error, color = class, group=threshold, linetype = threshold
+    ), alpha = 0.1) +
+    ggplot2::geom_line(data = mean_prederror_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class, group=threshold, linetype = threshold
+    ), size = 1.5) +
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "red") +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(
+        title = "Correct classification for different kinship thresholds",
+        x = "Number of trees", y = "Correct classification (%)"
+    ) +
+    ggplot2::scale_color_manual(
+        values = c(
+            "immigrant" = "#5d8566",
+            "resident" = "#c29007"
+        )
+    ) +
+    ggplot2::scale_linetype_manual(
+        values =  c("solid", "22"),
+        labels = c(
+            "0" = "unrelated",
+            "3" = "all birds"
+        )
+    ) +
+    # y axis to percentage
+    ggplot2::scale_y_continuous(labels = scales::percent_format(scale = 1)) +
+    ggplot2::theme(
+        aspect.ratio = 1,
+        text = ggplot2::element_text(size = 12),
+        legend.title = ggplot2::element_blank(),
+        legend.text = ggplot2::element_text(size = 10),
+        panel.grid.major = ggplot2::element_blank(),
+        panel.grid.minor = ggplot2::element_blank(),
+        # add white background to plot
+        panel.background = ggplot2::element_rect(fill = "white"),
+        plot.background = ggplot2::element_rect(fill = "white")
+
+    )

# time: 2024-08-30 16:28:00 UTC
# mode: r
+ggplot2::ggsave(
+    file.path(config$path$figures, "kinship_error_plot.png"),
+    plot = kin_error_plot,
+    width = 8,
+    height = 6,
+    dpi = 300
+)

# time: 2024-08-30 16:28:57 UTC
# mode: r
+# Plot the prediction error rate for different kinship thresholds
+kin_error_plot = 
+ggplot2::ggplot(ggplot2::aes(
+        x = trees, y = error, color = class, group=threshold, linetype = threshold
+    )) +
+    ggplot2::geom_line(data = prederror_df, alpha = 0.1) +
+    ggplot2::geom_line(data = mean_prederror_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class, group=threshold, linetype = threshold
+    ), size = 1.5) +
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "red") +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(
+        title = "Correct classification for different kinship thresholds",
+        x = "Number of trees", y = "Correct classification (%)"
+    ) +
+    ggplot2::scale_color_manual(
+        values = c(
+            "immigrant" = "#5d8566",
+            "resident" = "#c29007"
+        )
+    ) +
+    ggplot2::scale_linetype_manual(
+        values =  c("solid", "22"),
+        labels = c(
+            "0" = "unrelated",
+            "3" = "all birds"
+        )
+    ) +
+    # y axis to percentage
+    ggplot2::scale_y_continuous(labels = scales::percent_format(scale = 1)) +
+    ggplot2::theme(
+        aspect.ratio = 1,
+        text = ggplot2::element_text(size = 12),
+        legend.title = ggplot2::element_blank(),
+        legend.text = ggplot2::element_text(size = 10),
+        panel.grid.major = ggplot2::element_blank(),
+        panel.grid.minor = ggplot2::element_blank(),
+        # add white background to plot
+        panel.background = ggplot2::element_rect(fill = "white"),
+        plot.background = ggplot2::element_rect(fill = "white")
+
+    )

# time: 2024-08-30 16:29:09 UTC
# mode: r
+# Plot the prediction error rate for different kinship thresholds
+kin_error_plot = 
+ggplot2::ggplot(prederror_df, ggplot2::aes(
+        x = trees, y = error, color = class, group=threshold, linetype = threshold
+    )) +
+    ggplot2::geom_line(alpha = 0.1) +
+    ggplot2::geom_line(data = mean_prederror_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class, group=threshold, linetype = threshold
+    ), size = 1.5) +
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "red") +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(
+        title = "Correct classification for different kinship thresholds",
+        x = "Number of trees", y = "Correct classification (%)"
+    ) +
+    ggplot2::scale_color_manual(
+        values = c(
+            "immigrant" = "#5d8566",
+            "resident" = "#c29007"
+        )
+    ) +
+    ggplot2::scale_linetype_manual(
+        values =  c("solid", "22"),
+        labels = c(
+            "0" = "unrelated",
+            "3" = "all birds"
+        )
+    ) +
+    # y axis to percentage
+    ggplot2::scale_y_continuous(labels = scales::percent_format(scale = 1)) +
+    ggplot2::theme(
+        aspect.ratio = 1,
+        text = ggplot2::element_text(size = 12),
+        legend.title = ggplot2::element_blank(),
+        legend.text = ggplot2::element_text(size = 10),
+        panel.grid.major = ggplot2::element_blank(),
+        panel.grid.minor = ggplot2::element_blank(),
+        # add white background to plot
+        panel.background = ggplot2::element_rect(fill = "white"),
+        plot.background = ggplot2::element_rect(fill = "white")
+
+    )

# time: 2024-08-30 16:29:12 UTC
# mode: r
+ggplot2::ggsave(
+    file.path(config$path$figures, "kinship_error_plot.png"),
+    plot = kin_error_plot,
+    width = 8,
+    height = 6,
+    dpi = 300
+)

# time: 2024-08-30 16:30:05 UTC
# mode: r
+# Plot the prediction error rate for different kinship thresholds
+kin_error_plot <-
+    ggplot2::ggplot(prederror_df, ggplot2::aes(
+        x = trees, y = error, color = class, linetype = threshold
+    )) +
+    ggplot2::geom_line(alpha = 0.1) +
+    ggplot2::geom_line(data = mean_prederror_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class, linetype = threshold
+    ), size = 1.5) +
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "red") +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(
+        title = "Correct classification for different kinship thresholds",
+        x = "Number of trees", y = "Correct classification (%)"
+    ) +
+    ggplot2::scale_color_manual(
+        values = c(
+            "immigrant" = "#5d8566",
+            "resident" = "#c29007"
+        )
+    ) +
+    ggplot2::scale_linetype_manual(
+        values = c("solid", "dashdot"),
+        labels = c(
+            "0" = "unrelated",
+            "3" = "all birds"
+        )
+    ) +
+    # y axis to percentage
+    ggplot2::scale_y_continuous(labels = scales::percent_format(scale = 1)) +
+    ggplot2::theme(
+        aspect.ratio = 1,
+        text = ggplot2::element_text(size = 12),
+        legend.title = ggplot2::element_blank(),
+        legend.text = ggplot2::element_text(size = 10),
+        panel.grid.major = ggplot2::element_blank(),
+        panel.grid.minor = ggplot2::element_blank(),
+        # add white background to plot
+        panel.background = ggplot2::element_rect(fill = "white"),
+        plot.background = ggplot2::element_rect(fill = "white")
+    )

# time: 2024-08-30 16:30:06 UTC
# mode: r
+ggplot2::ggsave(
+    file.path(config$path$figures, "kinship_error_plot.png"),
+    plot = kin_error_plot,
+    width = 8,
+    height = 6,
+    dpi = 300
+)

# time: 2024-08-30 16:30:34 UTC
# mode: r
+# Plot the prediction error rate for different kinship thresholds
+kin_error_plot <-
+    ggplot2::ggplot(prederror_df, ggplot2::aes(
+        x = trees, y = error, color = class, linetype = threshold
+    )) +
+    ggplot2::geom_line(alpha = 0.1) +
+    ggplot2::geom_line(data = mean_prederror_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class, linetype = threshold
+    ), size = 1.5) +
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "red") +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(
+        title = "Correct classification for different kinship thresholds",
+        x = "Number of trees", y = "Correct classification (%)"
+    ) +
+    ggplot2::scale_color_manual(
+        values = c(
+            "immigrant" = "#5d8566",
+            "resident" = "#c29007"
+        )
+    ) +
+    ggplot2::scale_linetype_manual(
+        values = c("solid", "dashed"),
+        labels = c(
+            "0" = "unrelated",
+            "3" = "all birds"
+        )
+    ) +
+    # y axis to percentage
+    ggplot2::scale_y_continuous(labels = scales::percent_format(scale = 1)) +
+    ggplot2::theme(
+        aspect.ratio = 1,
+        text = ggplot2::element_text(size = 12),
+        legend.title = ggplot2::element_blank(),
+        legend.text = ggplot2::element_text(size = 10),
+        panel.grid.major = ggplot2::element_blank(),
+        panel.grid.minor = ggplot2::element_blank(),
+        # add white background to plot
+        panel.background = ggplot2::element_rect(fill = "white"),
+        plot.background = ggplot2::element_rect(fill = "white")
+    )

# time: 2024-08-30 16:30:34 UTC
# mode: r
+ggplot2::ggsave(
+    file.path(config$path$figures, "kinship_error_plot.png"),
+    plot = kin_error_plot,
+    width = 8,
+    height = 6,
+    dpi = 300
+)

# time: 2024-08-30 16:31:32 UTC
# mode: r
+# Plot the prediction error rate for different kinship thresholds
+kin_error_plot <-
+    ggplot2::ggplot(prederror_df, ggplot2::aes(
+        x = trees, y = error, color = class, linetype = threshold
+    )) +
+    ggplot2::geom_line(alpha = 0.1) +
+    ggplot2::geom_line(data = mean_prederror_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class, linetype = threshold
+    ), size = 1.5) +
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "red") +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(
+        title = "Correct classification for different kinship thresholds",
+        x = "Number of trees", y = "Correct classification (%)"
+    ) +
+    ggplot2::scale_color_manual(
+        values = c(
+            "immigrant" = "#5d8566",
+            "resident" = "#c29007"
+        )
+    ) +
+    ggplot2::scale_linetype_manual(
+        values = c(2,1),
+        labels = c(
+            "0" = "unrelated",
+            "3" = "all birds"
+        )
+    ) +
+    # y axis to percentage
+    ggplot2::scale_y_continuous(labels = scales::percent_format(scale = 1)) +
+    ggplot2::theme(
+        aspect.ratio = 1,
+        text = ggplot2::element_text(size = 12),
+        legend.title = ggplot2::element_blank(),
+        legend.text = ggplot2::element_text(size = 10),
+        panel.grid.major = ggplot2::element_blank(),
+        panel.grid.minor = ggplot2::element_blank(),
+        # add white background to plot
+        panel.background = ggplot2::element_rect(fill = "white"),
+        plot.background = ggplot2::element_rect(fill = "white")
+    )

# time: 2024-08-30 16:31:32 UTC
# mode: r
+ggplot2::ggsave(
+    file.path(config$path$figures, "kinship_error_plot.png"),
+    plot = kin_error_plot,
+    width = 8,
+    height = 6,
+    dpi = 300
+)

# time: 2024-08-30 16:32:00 UTC
# mode: r
+# Plot the prediction error rate for different kinship thresholds
+kin_error_plot <-
+    ggplot2::ggplot(prederror_df, ggplot2::aes(
+        x = trees, y = error, color = class, linetype = threshold
+    )) +
+    ggplot2::geom_line(alpha = 0.1) +
+    ggplot2::geom_line(data = mean_prederror_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class, linetype = threshold
+    ), size = 1.5) +
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "red") +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(
+        title = "Correct classification for different kinship thresholds",
+        x = "Number of trees", y = "Correct classification (%)"
+    ) +
+    ggplot2::scale_color_manual(
+        values = c(
+            "immigrant" = "#5d8566",
+            "resident" = "#c29007"
+        )
+    ) +
+    ggplot2::scale_linetype_manual(
+        values = c(3,1),
+        labels = c(
+            "0" = "unrelated",
+            "3" = "all birds"
+        )
+    ) +
+    # y axis to percentage
+    ggplot2::scale_y_continuous(labels = scales::percent_format(scale = 1)) +
+    ggplot2::theme(
+        aspect.ratio = 1,
+        text = ggplot2::element_text(size = 12),
+        legend.title = ggplot2::element_blank(),
+        legend.text = ggplot2::element_text(size = 10),
+        panel.grid.major = ggplot2::element_blank(),
+        panel.grid.minor = ggplot2::element_blank(),
+        # add white background to plot
+        panel.background = ggplot2::element_rect(fill = "white"),
+        plot.background = ggplot2::element_rect(fill = "white")
+    )

# time: 2024-08-30 16:32:01 UTC
# mode: r
+ggplot2::ggsave(
+    file.path(config$path$figures, "kinship_error_plot.png"),
+    plot = kin_error_plot,
+    width = 8,
+    height = 6,
+    dpi = 300
+)

# time: 2024-08-30 16:32:47 UTC
# mode: r
+# Plot the prediction error rate for different kinship thresholds
+kin_error_plot <-
+    ggplot2::ggplot(prederror_df, ggplot2::aes(
+        x = trees, y = error, color = class, linetype = threshold
+    )) +
+    ggplot2::geom_line(alpha = 0.1) +
+    ggplot2::geom_line(data = mean_prederror_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class, linetype = threshold
+    ), size = 1.5) +
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "red") +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(
+        title = "Correct classification for different kinship thresholds",
+        x = "Number of trees", y = "Correct classification (%)"
+    ) +
+    ggplot2::scale_color_manual(
+        values = c(
+            "immigrant" = "#5d8566",
+            "resident" = "#c29007"
+        )
+    ) +
+    ggplot2::scale_linetype_manual(
+        values = c(3,1),
+        labels = c(
+            "0" = "unrelated",
+            "3" = "all birds"
+        )
+    ) +
+    # y axis to percentage
+    ggplot2::scale_y_continuous(labels = scales::percent_format(scale = 1)) +
+    ggplot2::theme(
+        aspect.ratio = 1,
+        text = ggplot2::element_text(size = 12),
+        legend.title = ggplot2::element_blank(),
+        legend.text = ggplot2::element_text(size = 10),
+        panel.grid.major = ggplot2::element_blank(),
+        panel.grid.minor = ggplot2::element_blank(),
+        # add white background to plot
+        panel.background = ggplot2::element_rect(fill = "white"),
+        plot.background = ggplot2::element_rect(fill = "white")
+        #remove plot stroke 
+        panel.border = ggplot2::element_blank()
+    )

# time: 2024-08-30 16:32:48 UTC
# mode: r
+ggplot2::ggsave(
+    file.path(config$path$figures, "kinship_error_plot.png"),
+    plot = kin_error_plot,
+    width = 8,
+    height = 6,
+    dpi = 300
+)

# time: 2024-08-30 16:33:12 UTC
# mode: r
+# Plot the prediction error rate for different kinship thresholds
+kin_error_plot <-
+    ggplot2::ggplot(prederror_df, ggplot2::aes(
+        x = trees, y = error, color = class, linetype = threshold
+    )) +
+    ggplot2::geom_line(alpha = 0.1) +
+    ggplot2::geom_line(data = mean_prederror_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class, linetype = threshold
+    ), size = 1.5) +
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "red") +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(
+        title = "Correct classification for different kinship thresholds",
+        x = "Number of trees", y = "Correct classification (%)"
+    ) +
+    ggplot2::scale_color_manual(
+        values = c(
+            "immigrant" = "#5d8566",
+            "resident" = "#c29007"
+        )
+    ) +
+    ggplot2::scale_linetype_manual(
+        values = c(3,1),
+        labels = c(
+            "0" = "unrelated",
+            "3" = "all birds"
+        )
+    ) +
+    # y axis to percentage
+    ggplot2::scale_y_continuous(labels = scales::percent_format(scale = 1)) +
+    ggplot2::theme(
+        aspect.ratio = 1,
+        text = ggplot2::element_text(size = 12),
+        legend.title = ggplot2::element_blank(),
+        legend.text = ggplot2::element_text(size = 10),
+        panel.grid.major = ggplot2::element_blank(),
+        panel.grid.minor = ggplot2::element_blank(),
+        # add white background to plot
+        panel.background = ggplot2::element_rect(fill = "white"),
+        plot.background = ggplot2::element_rect(fill = "white"),
+        #remove plot stroke 
+        panel.border = ggplot2::element_blank()
+    )

# time: 2024-08-30 16:33:13 UTC
# mode: r
+ggplot2::ggsave(
+    file.path(config$path$figures, "kinship_error_plot.png"),
+    plot = kin_error_plot,
+    width = 8,
+    height = 6,
+    dpi = 300
+)

# time: 2024-08-30 16:33:39 UTC
# mode: r
+# Plot the prediction error rate for different kinship thresholds
+kin_error_plot <-
+    ggplot2::ggplot(prederror_df, ggplot2::aes(
+        x = trees, y = error, color = class, linetype = threshold
+    )) +
+    ggplot2::geom_line(alpha = 0.1) +
+    ggplot2::geom_line(data = mean_prederror_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class, linetype = threshold
+    ), size = 1.5) +
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "red") +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(
+        title = "Correct classification for different kinship thresholds",
+        x = "Number of trees", y = "Correct classification (%)"
+    ) +
+    ggplot2::scale_color_manual(
+        values = c(
+            "immigrant" = "#5d8566",
+            "resident" = "#c29007"
+        )
+    ) +
+    ggplot2::scale_linetype_manual(
+        values = c(3,1),
+        labels = c(
+            "0" = "unrelated",
+            "3" = "all birds"
+        )
+    ) +
+    # y axis to percentage
+    ggplot2::scale_y_continuous(labels = scales::percent_format(scale = 1)) +
+    ggplot2::theme(
+        aspect.ratio = 1,
+        text = ggplot2::element_text(size = 12),
+        legend.title = ggplot2::element_blank(),
+        legend.text = ggplot2::element_text(size = 10),
+        panel.grid.major = ggplot2::element_blank(),
+        panel.grid.minor = ggplot2::element_blank(),
+        panel.border = ggplot2::element_blank()
+    )

# time: 2024-08-30 16:33:39 UTC
# mode: r
+ggplot2::ggsave(
+    file.path(config$path$figures, "kinship_error_plot.png"),
+    plot = kin_error_plot,
+    width = 8,
+    height = 6,
+    dpi = 300,
+    #white background
+    bg = "white"
+)

# time: 2024-08-30 16:34:15 UTC
# mode: r
+# Plot the prediction error rate for different kinship thresholds
+kin_error_plot <-
+    ggplot2::ggplot(prederror_df, ggplot2::aes(
+        x = trees, y = error, color = class, linetype = threshold
+    )) +
+    ggplot2::geom_line(alpha = 0.1) +
+    ggplot2::geom_line(data = mean_prederror_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class, linetype = threshold
+    ), size = 1.5) +
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "red") +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(
+        title = "Correct classification for different kinship thresholds",
+        x = "Number of trees", y = "Correct classification (%)"
+    ) +
+    ggplot2::scale_color_manual(
+        values = c(
+            "immigrant" = "#5d8566",
+            "resident" = "#c29007"
+        )
+    ) +
+    ggplot2::scale_linetype_manual(
+        values = c(3, 1),
+        labels = c(
+            "0" = "unrelated",
+            "3" = "all birds"
+        )
+    ) +
+    # y axis to percentage
+    ggplot2::scale_y_continuous(labels = scales::percent_format(scale = 1)) +
+    ggplot2::theme(
+        aspect.ratio = 1,
+        text = ggplot2::element_text(size = 12),
+        legend.title = ggplot2::element_blank(),
+        legend.text = ggplot2::element_text(size = 10),
+        panel.grid.major = ggplot2::element_blank(),
+        panel.grid.minor = ggplot2::element_blank(),
+        # panel border 1px black
+        panel.border = ggplot2::element_rect(colour = "black", fill = NA, size = 1)
+    )

# time: 2024-08-30 16:34:17 UTC
# mode: r
+ggplot2::ggsave(
+    file.path(config$path$figures, "kinship_error_plot.png"),
+    plot = kin_error_plot,
+    width = 8,
+    height = 6,
+    dpi = 300,
+    # white background
+    bg = "white"
+)

# time: 2024-08-30 16:34:31 UTC
# mode: r
+# Plot the prediction error rate for different kinship thresholds
+kin_error_plot <-
+    ggplot2::ggplot(prederror_df, ggplot2::aes(
+        x = trees, y = error, color = class, linetype = threshold
+    )) +
+    ggplot2::geom_line(alpha = 0.1) +
+    ggplot2::geom_line(data = mean_prederror_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class, linetype = threshold
+    ), size = 1.5) +
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "red") +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(
+        title = "Correct classification for different kinship thresholds",
+        x = "Number of trees", y = "Correct classification (%)"
+    ) +
+    ggplot2::scale_color_manual(
+        values = c(
+            "immigrant" = "#5d8566",
+            "resident" = "#c29007"
+        )
+    ) +
+    ggplot2::scale_linetype_manual(
+        values = c(3, 1),
+        labels = c(
+            "0" = "unrelated",
+            "3" = "all birds"
+        )
+    ) +
+    # y axis to percentage
+    ggplot2::scale_y_continuous(labels = scales::percent_format(scale = 1)) +
+    ggplot2::theme(
+        aspect.ratio = 1,
+        text = ggplot2::element_text(size = 12),
+        legend.title = ggplot2::element_blank(),
+        legend.text = ggplot2::element_text(size = 10),
+        panel.grid.major = ggplot2::element_blank(),
+        panel.grid.minor = ggplot2::element_blank(),
+        # panel border 1px black
+        panel.border = ggplot2::element_rect(colour = "black", fill = NA, linewidth = 1)
+    )

# time: 2024-08-30 16:34:31 UTC
# mode: r
+ggplot2::ggsave(
+    file.path(config$path$figures, "kinship_error_plot.png"),
+    plot = kin_error_plot,
+    width = 8,
+    height = 6,
+    dpi = 300,
+    # white background
+    bg = "white"
+)

# time: 2024-08-30 16:35:02 UTC
# mode: r
+# Plot the prediction error rate for different kinship thresholds
+kin_error_plot <-
+    ggplot2::ggplot(prederror_df, ggplot2::aes(
+        x = trees, y = error, color = class, linetype = threshold
+    )) +
+    ggplot2::geom_line(alpha = 0.1) +
+    ggplot2::geom_line(data = mean_prederror_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class, linetype = threshold
+    ), size = 1.5) +
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "red") +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(
+        title = "Correct classification for different kinship thresholds",
+        x = "Number of trees", y = "Correct classification (%)"
+    ) +
+    ggplot2::scale_color_manual(
+        values = c(
+            "immigrant" = "#5d8566",
+            "resident" = "#c29007"
+        )
+    ) +
+    ggplot2::scale_linetype_manual(
+        values = c(3, 1),
+        labels = c(
+            "0" = "unrelated",
+            "3" = "all birds"
+        )
+    ) +
+    # y axis to percentage
+    ggplot2::scale_y_continuous(labels = scales::percent_format(scale = 1), expand = c(0, 0)) +
+    # also expand the x axis
+    ggplot2::scale_x_continuous(expand = c(0, 0)) +
+    ggplot2::theme(
+        aspect.ratio = 1,
+        text = ggplot2::element_text(size = 12),
+        legend.title = ggplot2::element_blank(),
+        legend.text = ggplot2::element_text(size = 10),
+        panel.grid.major = ggplot2::element_blank(),
+        panel.grid.minor = ggplot2::element_blank(),
+        # panel border 1px black
+        panel.border = ggplot2::element_rect(colour = "black", fill = NA, linewidth = 1)
+    )

# time: 2024-08-30 16:35:02 UTC
# mode: r
+ggplot2::ggsave(
+    file.path(config$path$figures, "kinship_error_plot.png"),
+    plot = kin_error_plot,
+    width = 8,
+    height = 6,
+    dpi = 300,
+    # white background
+    bg = "white"
+)

# time: 2024-09-18 16:34:09 UTC
# mode: r
+# Import configuration file
+config <- config::get()
+
+# parameters
+percent.train <- 0.7
+num.threads <- 44
+num.eigenvectors <- 5
+set.seed(555)
+
+# Input files
+immigrant.info <- file.path(config$path$data, "600K_immigrants.fam")
+immigrant.vcf <- file.path(config$path$data, "600K_immigrants.vcf")
+resident.vcf <- file.path(config$path$data, "600K_residents.vcf")
+
+immigrant.gds <- file.path(config$path$data, "immigrant_recode.gds")
+resident.gds <- file.path(config$path$data, "resident_recode.gds")
+all.gds <- file.path(config$path$data, "all_recode.gds")
+
+
+# Load all the data
+all.maf <- SNPRelate::snpgdsOpen(all.gds, allow.duplicate = TRUE)
+
+# Load labels
+immigrant.id <- gdsfmt::read.gdsn(gdsfmt::index.gdsn(
+    SNPRelate::snpgdsOpen(immigrant.gds),
+    "sample.id"
+))
+resident.id <- gdsfmt::read.gdsn(gdsfmt::index.gdsn(
+    SNPRelate::snpgdsOpen(resident.gds),
+    "sample.id"
+))
+
+all.id <- gdsfmt::read.gdsn(gdsfmt::index.gdsn(all.maf, "sample.id"))
+all.label <- ifelse(all.id %in% immigrant.id, "immigrant", "resident")
+
+
+# Function to split data into training and testing sets
+# TODO balence so that there are .5 per class in both train and test sets
+split_data <- function(all.id, all.label, percent.train) {
+    # Split data by class
+    labels <- unique(all.label)
+    class_0 <- all.id[all.label == labels[1]]
+    class_1 <- all.id[all.label == labels[2]]
+
+    # Determine the size of the smaller class
+    min_class_size <- min(length(class_0), length(class_1))
+
+    # Undersample the majority class
+    if (length(class_0) > min_class_size) {
+        class_0 <- sample(class_0, min_class_size)
+    } else {
+        class_1 <- sample(class_1, min_class_size)
+    }
+
+    # Combine the balanced classes
+    balanced_ids <- c(class_0, class_1)
+    balanced_labels <- c(rep(labels[1], length(class_0)), rep(labels[2], length(class_1)))
+
+    # Calculate the number of samples for training
+    num_train <- round(length(balanced_ids) * percent.train)
+
+    # Ensure equal representation of both classes in train and test sets
+    num_train_per_class <- num_train %/% 2
+
+    # Randomly select samples for training from each class
+    train_indices <- c(
+        sample(1:min_class_size, num_train_per_class),
+        sample((min_class_size + 1):(2 * min_class_size), num_train_per_class)
+    )
+
+    train.id <- balanced_ids[train_indices]
+    test.id <- balanced_ids[-train_indices]
+    train.label <- balanced_labels[train_indices]
+    test.label <- balanced_labels[-train_indices]
+
+    list(
+        train.id = train.id, test.id = test.id,
+        train.label = train.label, test.label = test.label
+    )
+}
+# Function to perform PCA and prepare data frames
+prepare_data <- function(all.maf, train.id, test.id, train.label, test.label, num.eigenvectors, num.threads) {
+    pca <- SNPRelate::snpgdsPCA(all.maf, sample.id = train.id, num.thread = num.threads)
+    snp_loadings <- SNPRelate::snpgdsPCASNPLoading(pca, all.maf, num.thread = num.threads)
+    sample_loadings <- SNPRelate::snpgdsPCASampLoading(snp_loadings, all.maf, sample.id = test.id, num.thread = num.threads)
+    train_eigenvects <- data.frame(sample.id = pca$sample.id, pca$eigenvect[, 1:num.eigenvectors])
+    test_eigenvects <- data.frame(sample.id = sample_loadings$sample.id, sample_loadings$eigenvect[, 1:num.eigenvectors])
+    train_df <- data.frame(sample.id = train.id, pop = train.label, train_eigenvects[, -1])
+    test_df <- data.frame(sample.id = test.id, pop = test.label, test_eigenvects[, -1])
+    list(train_df = train_df, test_df = test_df)
+}
+
+# Function to train a random forest with optional randomized labels
+train_random_forest <- function(
+    train_df, test_df, num.eigenvectors, randomize_labels = FALSE) {
+    if (randomize_labels) {
+        train_df$pop <- sample(train_df$pop)
+    }
+
+    return(randomForest::randomForest(
+        train_df[, 3:(2 + num.eigenvectors)],
+        y = as.factor(train_df$pop),
+        data = train_df,
+        xtest = test_df[, 3:(2 + num.eigenvectors)],
+        ytest = as.factor(test_df$pop),
+        ntree = 500,
+        replace = FALSE,
+        proximity = TRUE
+    ))
+}
+
+# Function to run a single iteration
+run_iteration <- function(
+    all.id, all.label, all.maf, percent.train, num.eigenvectors, num.threads, randomize_labels) {
+    # Split data
+    split <- split_data(all.id, all.label, percent.train)
+
+    # Prepare data
+    data <- prepare_data(
+        all.maf, split$train.id, split$test.id, split$train.label, split$test.label,
+        num.eigenvectors, num.threads
+    )
+
+    # Train random forest
+    rf <- train_random_forest(data$train_df, data$test_df, num.eigenvectors, randomize_labels)
+
+    # Extract OOB error rates
+    oob_data <- rfPermute::plotTrace(rf, plot = FALSE)$data
+
+    # Return both OOB data, the random forest model, and the train/test labels
+    return(list(oob_data = oob_data, rf_model = rf, train_labels = split$train.label, test_labels = split$test.label))
+}
+
+# Main function to run multiple iterations
+run_analysis <- function(
+    all.id, all.label, all.maf, percent.train,
+    num.eigenvectors, num.threads,
+    n_iterations = 1) {
+    set.seed(123) # For reproducibility
+
+    # Run iterations with original labels
+    original_results <- replicate(n_iterations,
+        run_iteration(
+            all.id, all.label, all.maf, percent.train,
+            num.eigenvectors, num.threads, FALSE
+        ),
+        simplify = FALSE
+    )
+
+    # Run iterations with randomized labels
+    random_results <- replicate(n_iterations,
+        run_iteration(
+            all.id, all.label, all.maf, percent.train,
+            num.eigenvectors, num.threads, TRUE
+        ),
+        simplify = FALSE
+    )
+
+    # Separate OOB data, RF models, and train/test labels
+    original_oob <- lapply(original_results, function(x) x$oob_data)
+    original_rf_models <- lapply(original_results, function(x) x$rf_model)
+    original_train_labels <- lapply(original_results, function(x) x$train_labels)
+    original_test_labels <- lapply(original_results, function(x) x$test_labels)
+
+    random_oob <- lapply(random_results, function(x) x$oob_data)
+    random_rf_models <- lapply(random_results, function(x) x$rf_model)
+    random_train_labels <- lapply(random_results, function(x) x$train_labels)
+    random_test_labels <- lapply(random_results, function(x) x$test_labels)
+
+    # Combine OOB results
+    oob_df <- dplyr::as_tibble(do.call(rbind, original_oob))
+    random_oob_df <- dplyr::as_tibble(do.call(rbind, random_oob))
+
+    list(
+        oob_df = oob_df,
+        random_oob_df = random_oob_df,
+        original_rf_models = original_rf_models,
+        random_rf_models = random_rf_models,
+        original_train_labels = original_train_labels,
+        original_test_labels = original_test_labels,
+        random_train_labels = random_train_labels,
+        random_test_labels = random_test_labels
+    )
+}
+
+calculate_mean_error <- function(data) {
+    data |>
+        dplyr::group_by(trees, class) |>
+        dplyr::summarise(mean_error = mean(error), .groups = "drop") |> # nolint: object_usage_linter.
+        dplyr::filter(class != "OOB")
+}

# time: 2024-09-18 17:01:41 UTC
# mode: r
+# Import configuration file
+config <- config::get()
+
+# parameters
+percent.train <- 0.7
+num.threads <- 44
+num.eigenvectors <- 100
+set.seed(555)
+
+# Input files
+immigrant.info <- file.path(config$path$data, "600K_immigrants.fam")
+immigrant.vcf <- file.path(config$path$data, "600K_immigrants.vcf")
+resident.vcf <- file.path(config$path$data, "600K_residents.vcf")
+
+immigrant.gds <- file.path(config$path$data, "immigrant_recode.gds")
+resident.gds <- file.path(config$path$data, "resident_recode.gds")
+all.gds <- file.path(config$path$data, "all_recode.gds")
+
+
+# Load all the data
+all.maf <- SNPRelate::snpgdsOpen(all.gds, allow.duplicate = TRUE)
+
+# Load labels
+immigrant.id <- gdsfmt::read.gdsn(gdsfmt::index.gdsn(
+    SNPRelate::snpgdsOpen(immigrant.gds),
+    "sample.id"
+))
+resident.id <- gdsfmt::read.gdsn(gdsfmt::index.gdsn(
+    SNPRelate::snpgdsOpen(resident.gds),
+    "sample.id"
+))
+
+all.id <- gdsfmt::read.gdsn(gdsfmt::index.gdsn(all.maf, "sample.id"))
+all.label <- ifelse(all.id %in% immigrant.id, "immigrant", "resident")
+
+
+# Function to split data into training and testing sets
+# TODO balance so that there are .5 per class in both train and test sets
+split_data <- function(all.id, all.label, percent.train) {
+    # Split data by class
+    labels <- unique(all.label)
+    class_0 <- all.id[all.label == labels[1]]
+    class_1 <- all.id[all.label == labels[2]]
+
+    # Determine the size of the smaller class
+    min_class_size <- min(length(class_0), length(class_1))
+
+    # Undersample the majority class
+    if (length(class_0) > min_class_size) {
+        class_0 <- sample(class_0, min_class_size)
+    } else {
+        class_1 <- sample(class_1, min_class_size)
+    }
+
+    # Combine the balanced classes
+    balanced_ids <- c(class_0, class_1)
+    balanced_labels <- c(rep(labels[1], length(class_0)), rep(labels[2], length(class_1)))
+
+    # Calculate the number of samples for training
+    num_train <- round(length(balanced_ids) * percent.train)
+
+    # Ensure equal representation of both classes in train and test sets
+    num_train_per_class <- num_train %/% 2
+
+    # Randomly select samples for training from each class
+    train_indices <- c(
+        sample(1:min_class_size, num_train_per_class),
+        sample((min_class_size + 1):(2 * min_class_size), num_train_per_class)
+    )
+
+    train.id <- balanced_ids[train_indices]
+    test.id <- balanced_ids[-train_indices]
+    train.label <- balanced_labels[train_indices]
+    test.label <- balanced_labels[-train_indices]
+
+    list(
+        train.id = train.id, test.id = test.id,
+        train.label = train.label, test.label = test.label
+    )
+}
+# Function to perform PCA and prepare data frames
+prepare_data <- function(all.maf, train.id, test.id, train.label, test.label, num.eigenvectors, num.threads) {
+    pca <- SNPRelate::snpgdsPCA(all.maf, sample.id = train.id, num.thread = num.threads)
+    snp_loadings <- SNPRelate::snpgdsPCASNPLoading(pca, all.maf, num.thread = num.threads)
+    sample_loadings <- SNPRelate::snpgdsPCASampLoading(snp_loadings, all.maf, sample.id = test.id, num.thread = num.threads)
+    train_eigenvects <- data.frame(sample.id = pca$sample.id, pca$eigenvect[, 1:num.eigenvectors])
+    test_eigenvects <- data.frame(sample.id = sample_loadings$sample.id, sample_loadings$eigenvect[, 1:num.eigenvectors])
+    train_df <- data.frame(sample.id = train.id, pop = train.label, train_eigenvects[, -1])
+    test_df <- data.frame(sample.id = test.id, pop = test.label, test_eigenvects[, -1])
+    list(train_df = train_df, test_df = test_df)
+}
+
+# Function to train a random forest with optional randomized labels
+train_random_forest <- function(
+    train_df, test_df, num.eigenvectors, randomize_labels = FALSE) {
+    if (randomize_labels) {
+        train_df$pop <- sample(train_df$pop)
+    }
+
+    return(randomForest::randomForest(
+        train_df[, 3:(2 + num.eigenvectors)],
+        y = as.factor(train_df$pop),
+        data = train_df,
+        xtest = test_df[, 3:(2 + num.eigenvectors)],
+        ytest = as.factor(test_df$pop),
+        ntree = 500,
+        replace = FALSE,
+        proximity = TRUE
+    ))
+}
+
+# Function to run a single iteration
+run_iteration <- function(
+    all.id, all.label, all.maf, percent.train, num.eigenvectors, num.threads, randomize_labels) {
+    # Split data
+    split <- split_data(all.id, all.label, percent.train)
+
+    # print the proportion of each class in the train and test sets
+    print(table(split$train.label))
+    print(table(split$test.label))
+
+
+    # Prepare data
+    data <- prepare_data(
+        all.maf, split$train.id, split$test.id, split$train.label, split$test.label,
+        num.eigenvectors, num.threads
+    )
+
+    # Train random forest
+    rf <- train_random_forest(data$train_df, data$test_df, num.eigenvectors, randomize_labels)
+
+    # Extract OOB error rates
+    oob_data <- rfPermute::plotTrace(rf, plot = FALSE)$data
+
+    # Return both OOB data, the random forest model, and the train/test labels
+    return(list(oob_data = oob_data, rf_model = rf, train_labels = split$train.label, test_labels = split$test.label))
+}
+
+# Main function to run multiple iterations
+run_analysis <- function(
+    all.id, all.label, all.maf, percent.train,
+    num.eigenvectors, num.threads,
+    n_iterations = 1) {
+    set.seed(123) # For reproducibility
+
+    # Run iterations with original labels
+    original_results <- replicate(n_iterations,
+        run_iteration(
+            all.id, all.label, all.maf, percent.train,
+            num.eigenvectors, num.threads, FALSE
+        ),
+        simplify = FALSE
+    )
+
+    # Run iterations with randomized labels
+    random_results <- replicate(n_iterations,
+        run_iteration(
+            all.id, all.label, all.maf, percent.train,
+            num.eigenvectors, num.threads, TRUE
+        ),
+        simplify = FALSE
+    )
+
+    # Separate OOB data, RF models, and train/test labels
+    original_oob <- lapply(original_results, function(x) x$oob_data)
+    original_rf_models <- lapply(original_results, function(x) x$rf_model)
+    original_train_labels <- lapply(original_results, function(x) x$train_labels)
+    original_test_labels <- lapply(original_results, function(x) x$test_labels)
+
+    random_oob <- lapply(random_results, function(x) x$oob_data)
+    random_rf_models <- lapply(random_results, function(x) x$rf_model)
+    random_train_labels <- lapply(random_results, function(x) x$train_labels)
+    random_test_labels <- lapply(random_results, function(x) x$test_labels)
+
+    # Combine OOB results
+    oob_df <- dplyr::as_tibble(do.call(rbind, original_oob))
+    random_oob_df <- dplyr::as_tibble(do.call(rbind, random_oob))
+
+    list(
+        oob_df = oob_df,
+        random_oob_df = random_oob_df,
+        original_rf_models = original_rf_models,
+        random_rf_models = random_rf_models,
+        original_train_labels = original_train_labels,
+        original_test_labels = original_test_labels,
+        random_train_labels = random_train_labels,
+        random_test_labels = random_test_labels
+    )
+}
+
+calculate_mean_error <- function(data) {
+    data |>
+        dplyr::group_by(trees, class) |>
+        dplyr::summarise(mean_error = mean(error), .groups = "drop") |> # nolint: object_usage_linter.
+        dplyr::filter(class != "OOB")
+}
+
+
+# ----------------------------------- main ----------------------------------- #
+
+
+# Run the analysis
+results <- run_analysis(all.id, all.label, all.maf, percent.train, num.eigenvectors, num.threads)

# time: 2024-09-18 17:05:02 UTC
# mode: r
+# Import configuration file
+config <- config::get()
+
+# parameters
+percent.train <- 0.7
+num.threads <- 44
+num.eigenvectors <- 50
+set.seed(555)
+
+# Input files
+immigrant.info <- file.path(config$path$data, "600K_immigrants.fam")
+immigrant.vcf <- file.path(config$path$data, "600K_immigrants.vcf")
+resident.vcf <- file.path(config$path$data, "600K_residents.vcf")
+
+immigrant.gds <- file.path(config$path$data, "immigrant_recode.gds")
+resident.gds <- file.path(config$path$data, "resident_recode.gds")
+all.gds <- file.path(config$path$data, "all_recode.gds")
+
+
+# Load all the data
+all.maf <- SNPRelate::snpgdsOpen(all.gds, allow.duplicate = TRUE)
+
+# Load labels
+immigrant.id <- gdsfmt::read.gdsn(gdsfmt::index.gdsn(
+    SNPRelate::snpgdsOpen(immigrant.gds),
+    "sample.id"
+))
+resident.id <- gdsfmt::read.gdsn(gdsfmt::index.gdsn(
+    SNPRelate::snpgdsOpen(resident.gds),
+    "sample.id"
+))
+
+all.id <- gdsfmt::read.gdsn(gdsfmt::index.gdsn(all.maf, "sample.id"))
+all.label <- ifelse(all.id %in% immigrant.id, "immigrant", "resident")
+
+
+# Function to split data into training and testing sets
+# TODO balance so that there are .5 per class in both train and test sets
+split_data <- function(all.id, all.label, percent.train) {
+    # Split data by class
+    labels <- unique(all.label)
+    class_0 <- all.id[all.label == labels[1]]
+    class_1 <- all.id[all.label == labels[2]]
+
+    # Determine the size of the smaller class
+    min_class_size <- min(length(class_0), length(class_1))
+
+    # Undersample the majority class
+    if (length(class_0) > min_class_size) {
+        class_0 <- sample(class_0, min_class_size)
+    } else {
+        class_1 <- sample(class_1, min_class_size)
+    }
+
+    # Combine the balanced classes
+    balanced_ids <- c(class_0, class_1)
+    balanced_labels <- c(rep(labels[1], length(class_0)), rep(labels[2], length(class_1)))
+
+    # Calculate the number of samples for training
+    num_train <- round(length(balanced_ids) * percent.train)
+
+    # Ensure equal representation of both classes in train and test sets
+    num_train_per_class <- num_train %/% 2
+
+    # Randomly select samples for training from each class
+    train_indices <- c(
+        sample(1:min_class_size, num_train_per_class),
+        sample((min_class_size + 1):(2 * min_class_size), num_train_per_class)
+    )
+
+    train.id <- balanced_ids[train_indices]
+    test.id <- balanced_ids[-train_indices]
+    train.label <- balanced_labels[train_indices]
+    test.label <- balanced_labels[-train_indices]
+
+    list(
+        train.id = train.id, test.id = test.id,
+        train.label = train.label, test.label = test.label
+    )
+}
+# Function to perform PCA and prepare data frames
+prepare_data <- function(all.maf, train.id, test.id, train.label, test.label, num.eigenvectors, num.threads) {
+    pca <- SNPRelate::snpgdsPCA(all.maf, sample.id = train.id, num.thread = num.threads)
+    snp_loadings <- SNPRelate::snpgdsPCASNPLoading(pca, all.maf, num.thread = num.threads)
+    sample_loadings <- SNPRelate::snpgdsPCASampLoading(snp_loadings, all.maf, sample.id = test.id, num.thread = num.threads)
+    train_eigenvects <- data.frame(sample.id = pca$sample.id, pca$eigenvect[, 1:num.eigenvectors])
+    test_eigenvects <- data.frame(sample.id = sample_loadings$sample.id, sample_loadings$eigenvect[, 1:num.eigenvectors])
+    train_df <- data.frame(sample.id = train.id, pop = train.label, train_eigenvects[, -1])
+    test_df <- data.frame(sample.id = test.id, pop = test.label, test_eigenvects[, -1])
+    list(train_df = train_df, test_df = test_df)
+}
+
+# Function to train a random forest with optional randomized labels
+train_random_forest <- function(
+    train_df, test_df, num.eigenvectors, randomize_labels = FALSE) {
+    if (randomize_labels) {
+        train_df$pop <- sample(train_df$pop)
+    }
+
+    return(randomForest::randomForest(
+        train_df[, 3:(2 + num.eigenvectors)],
+        y = as.factor(train_df$pop),
+        data = train_df,
+        xtest = test_df[, 3:(2 + num.eigenvectors)],
+        ytest = as.factor(test_df$pop),
+        ntree = 500,
+        replace = FALSE,
+        proximity = TRUE
+    ))
+}
+
+# Function to run a single iteration
+run_iteration <- function(
+    all.id, all.label, all.maf, percent.train, num.eigenvectors, num.threads, randomize_labels) {
+    # Split data
+    split <- split_data(all.id, all.label, percent.train)
+
+    # print the proportion of each class in the train and test sets
+    print(table(split$train.label))
+    print(table(split$test.label))
+
+
+    # Prepare data
+    data <- prepare_data(
+        all.maf, split$train.id, split$test.id, split$train.label, split$test.label,
+        num.eigenvectors, num.threads
+    )
+
+    # Train random forest
+    rf <- train_random_forest(data$train_df, data$test_df, num.eigenvectors, randomize_labels)
+
+    # Extract OOB error rates
+    oob_data <- rfPermute::plotTrace(rf, plot = FALSE)$data
+
+    # Return both OOB data, the random forest model, and the train/test labels
+    return(list(oob_data = oob_data, rf_model = rf, train_labels = split$train.label, test_labels = split$test.label))
+}
+
+# Main function to run multiple iterations
+run_analysis <- function(
+    all.id, all.label, all.maf, percent.train,
+    num.eigenvectors, num.threads,
+    n_iterations = 1) {
+    set.seed(123) # For reproducibility
+
+    # Run iterations with original labels
+    original_results <- replicate(n_iterations,
+        run_iteration(
+            all.id, all.label, all.maf, percent.train,
+            num.eigenvectors, num.threads, FALSE
+        ),
+        simplify = FALSE
+    )
+
+    # Run iterations with randomized labels
+    random_results <- replicate(n_iterations,
+        run_iteration(
+            all.id, all.label, all.maf, percent.train,
+            num.eigenvectors, num.threads, TRUE
+        ),
+        simplify = FALSE
+    )
+
+    # Separate OOB data, RF models, and train/test labels
+    original_oob <- lapply(original_results, function(x) x$oob_data)
+    original_rf_models <- lapply(original_results, function(x) x$rf_model)
+    original_train_labels <- lapply(original_results, function(x) x$train_labels)
+    original_test_labels <- lapply(original_results, function(x) x$test_labels)
+
+    random_oob <- lapply(random_results, function(x) x$oob_data)
+    random_rf_models <- lapply(random_results, function(x) x$rf_model)
+    random_train_labels <- lapply(random_results, function(x) x$train_labels)
+    random_test_labels <- lapply(random_results, function(x) x$test_labels)
+
+    # Combine OOB results
+    oob_df <- dplyr::as_tibble(do.call(rbind, original_oob))
+    random_oob_df <- dplyr::as_tibble(do.call(rbind, random_oob))
+
+    list(
+        oob_df = oob_df,
+        random_oob_df = random_oob_df,
+        original_rf_models = original_rf_models,
+        random_rf_models = random_rf_models,
+        original_train_labels = original_train_labels,
+        original_test_labels = original_test_labels,
+        random_train_labels = random_train_labels,
+        random_test_labels = random_test_labels
+    )
+}
+
+calculate_mean_error <- function(data) {
+    data |>
+        dplyr::group_by(trees, class) |>
+        dplyr::summarise(mean_error = mean(error), .groups = "drop") |> # nolint: object_usage_linter.
+        dplyr::filter(class != "OOB")
+}
+
+
+# ----------------------------------- main ----------------------------------- #
+
+
+# Run the analysis
+results <- run_analysis(all.id, all.label, all.maf, percent.train, num.eigenvectors, num.threads)

# time: 2024-09-18 17:06:15 UTC
# mode: r
+num.eigenvectors

# time: 2024-09-18 17:06:24 UTC
# mode: r
+# Import configuration file
+config <- config::get()
+
+# parameters
+percent.train <- 0.7
+num.threads <- 44
+num.eigenvectors <- 15
+set.seed(555)
+
+# Input files
+immigrant.info <- file.path(config$path$data, "600K_immigrants.fam")
+immigrant.vcf <- file.path(config$path$data, "600K_immigrants.vcf")
+resident.vcf <- file.path(config$path$data, "600K_residents.vcf")
+
+immigrant.gds <- file.path(config$path$data, "immigrant_recode.gds")
+resident.gds <- file.path(config$path$data, "resident_recode.gds")
+all.gds <- file.path(config$path$data, "all_recode.gds")
+
+
+# Load all the data
+all.maf <- SNPRelate::snpgdsOpen(all.gds, allow.duplicate = TRUE)
+
+# Load labels
+immigrant.id <- gdsfmt::read.gdsn(gdsfmt::index.gdsn(
+    SNPRelate::snpgdsOpen(immigrant.gds),
+    "sample.id"
+))
+resident.id <- gdsfmt::read.gdsn(gdsfmt::index.gdsn(
+    SNPRelate::snpgdsOpen(resident.gds),
+    "sample.id"
+))
+
+all.id <- gdsfmt::read.gdsn(gdsfmt::index.gdsn(all.maf, "sample.id"))
+all.label <- ifelse(all.id %in% immigrant.id, "immigrant", "resident")
+
+
+# Function to split data into training and testing sets
+# TODO balance so that there are .5 per class in both train and test sets
+split_data <- function(all.id, all.label, percent.train) {
+    # Split data by class
+    labels <- unique(all.label)
+    class_0 <- all.id[all.label == labels[1]]
+    class_1 <- all.id[all.label == labels[2]]
+
+    # Determine the size of the smaller class
+    min_class_size <- min(length(class_0), length(class_1))
+
+    # Undersample the majority class
+    if (length(class_0) > min_class_size) {
+        class_0 <- sample(class_0, min_class_size)
+    } else {
+        class_1 <- sample(class_1, min_class_size)
+    }
+
+    # Combine the balanced classes
+    balanced_ids <- c(class_0, class_1)
+    balanced_labels <- c(rep(labels[1], length(class_0)), rep(labels[2], length(class_1)))
+
+    # Calculate the number of samples for training
+    num_train <- round(length(balanced_ids) * percent.train)
+
+    # Ensure equal representation of both classes in train and test sets
+    num_train_per_class <- num_train %/% 2
+
+    # Randomly select samples for training from each class
+    train_indices <- c(
+        sample(1:min_class_size, num_train_per_class),
+        sample((min_class_size + 1):(2 * min_class_size), num_train_per_class)
+    )
+
+    train.id <- balanced_ids[train_indices]
+    test.id <- balanced_ids[-train_indices]
+    train.label <- balanced_labels[train_indices]
+    test.label <- balanced_labels[-train_indices]
+
+    list(
+        train.id = train.id, test.id = test.id,
+        train.label = train.label, test.label = test.label
+    )
+}
+# Function to perform PCA and prepare data frames
+prepare_data <- function(all.maf, train.id, test.id, train.label, test.label, num.eigenvectors, num.threads) {
+    pca <- SNPRelate::snpgdsPCA(all.maf, sample.id = train.id, num.thread = num.threads)
+    snp_loadings <- SNPRelate::snpgdsPCASNPLoading(pca, all.maf, num.thread = num.threads)
+    sample_loadings <- SNPRelate::snpgdsPCASampLoading(snp_loadings, all.maf, sample.id = test.id, num.thread = num.threads)
+    train_eigenvects <- data.frame(sample.id = pca$sample.id, pca$eigenvect[, 1:num.eigenvectors])
+    test_eigenvects <- data.frame(sample.id = sample_loadings$sample.id, sample_loadings$eigenvect[, 1:num.eigenvectors])
+    train_df <- data.frame(sample.id = train.id, pop = train.label, train_eigenvects[, -1])
+    test_df <- data.frame(sample.id = test.id, pop = test.label, test_eigenvects[, -1])
+    list(train_df = train_df, test_df = test_df)
+}
+
+# Function to train a random forest with optional randomized labels
+train_random_forest <- function(
+    train_df, test_df, num.eigenvectors, randomize_labels = FALSE) {
+    if (randomize_labels) {
+        train_df$pop <- sample(train_df$pop)
+    }
+
+    return(randomForest::randomForest(
+        train_df[, 3:(2 + num.eigenvectors)],
+        y = as.factor(train_df$pop),
+        data = train_df,
+        xtest = test_df[, 3:(2 + num.eigenvectors)],
+        ytest = as.factor(test_df$pop),
+        ntree = 500,
+        replace = FALSE,
+        proximity = TRUE
+    ))
+}
+
+# Function to run a single iteration
+run_iteration <- function(
+    all.id, all.label, all.maf, percent.train, num.eigenvectors, num.threads, randomize_labels) {
+    # Split data
+    split <- split_data(all.id, all.label, percent.train)
+
+    # print the proportion of each class in the train and test sets
+    print(table(split$train.label))
+    print(table(split$test.label))
+
+
+    # Prepare data
+    data <- prepare_data(
+        all.maf, split$train.id, split$test.id, split$train.label, split$test.label,
+        num.eigenvectors, num.threads
+    )
+
+    # Train random forest
+    rf <- train_random_forest(data$train_df, data$test_df, num.eigenvectors, randomize_labels)
+
+    # Extract OOB error rates
+    oob_data <- rfPermute::plotTrace(rf, plot = FALSE)$data
+
+    # Return both OOB data, the random forest model, and the train/test labels
+    return(list(oob_data = oob_data, rf_model = rf, train_labels = split$train.label, test_labels = split$test.label))
+}
+
+# Main function to run multiple iterations
+run_analysis <- function(
+    all.id, all.label, all.maf, percent.train,
+    num.eigenvectors, num.threads,
+    n_iterations = 1) {
+    set.seed(123) # For reproducibility
+
+    # Run iterations with original labels
+    original_results <- replicate(n_iterations,
+        run_iteration(
+            all.id, all.label, all.maf, percent.train,
+            num.eigenvectors, num.threads, FALSE
+        ),
+        simplify = FALSE
+    )
+
+    # Run iterations with randomized labels
+    random_results <- replicate(n_iterations,
+        run_iteration(
+            all.id, all.label, all.maf, percent.train,
+            num.eigenvectors, num.threads, TRUE
+        ),
+        simplify = FALSE
+    )
+
+    # Separate OOB data, RF models, and train/test labels
+    original_oob <- lapply(original_results, function(x) x$oob_data)
+    original_rf_models <- lapply(original_results, function(x) x$rf_model)
+    original_train_labels <- lapply(original_results, function(x) x$train_labels)
+    original_test_labels <- lapply(original_results, function(x) x$test_labels)
+
+    random_oob <- lapply(random_results, function(x) x$oob_data)
+    random_rf_models <- lapply(random_results, function(x) x$rf_model)
+    random_train_labels <- lapply(random_results, function(x) x$train_labels)
+    random_test_labels <- lapply(random_results, function(x) x$test_labels)
+
+    # Combine OOB results
+    oob_df <- dplyr::as_tibble(do.call(rbind, original_oob))
+    random_oob_df <- dplyr::as_tibble(do.call(rbind, random_oob))
+
+    list(
+        oob_df = oob_df,
+        random_oob_df = random_oob_df,
+        original_rf_models = original_rf_models,
+        random_rf_models = random_rf_models,
+        original_train_labels = original_train_labels,
+        original_test_labels = original_test_labels,
+        random_train_labels = random_train_labels,
+        random_test_labels = random_test_labels
+    )
+}
+
+calculate_mean_error <- function(data) {
+    data |>
+        dplyr::group_by(trees, class) |>
+        dplyr::summarise(mean_error = mean(error), .groups = "drop") |> # nolint: object_usage_linter.
+        dplyr::filter(class != "OOB")
+}

# time: 2024-09-18 17:10:38 UTC
# mode: r
+mean_oob_df <- calculate_mean_error(results$oob_df)
+mean_random_oob_df <- calculate_mean_error(results$random_oob_df)

# time: 2024-09-18 17:10:45 UTC
# mode: r
+# ----------------------------------- main ----------------------------------- #
+
+
+# Run the analysis
+results <- run_analysis(all.id, all.label, all.maf, percent.train, num.eigenvectors, num.threads)

# time: 2024-09-18 17:11:15 UTC
# mode: r
+mean_oob_df <- calculate_mean_error(results$oob_df)
+mean_random_oob_df <- calculate_mean_error(results$random_oob_df)

# time: 2024-09-18 17:11:17 UTC
# mode: r
+# Create the plot data
+plot_data <- list(
+    oob_df = results$oob_df |>
+        dplyr::filter(class != "OOB"),
+    random_oob_df = results$random_oob_df |>
+        dplyr::filter(class != "OOB"),
+    mean_oob_df = mean_oob_df,
+    mean_random_oob_df = mean_random_oob_df
+)

# time: 2024-09-18 17:11:20 UTC
# mode: r
+# Create the plot
+oobplot <- ggplot2::ggplot() +
+    ggplot2::geom_line(data = plot_data$oob_df, ggplot2::aes(
+        x = trees, y = error, color = class
+    ), alpha = 0.1) +
+    ggplot2::geom_line(data = plot_data$random_oob_df, ggplot2::aes(
+        x = trees, y = error, color = class
+    ), alpha = 0.1, linetype = "dashed") +
+    ggplot2::geom_line(data = plot_data$mean_oob_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class
+    ), linewidth = 1.5) +
+    ggplot2::geom_line(data = plot_data$mean_random_oob_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class
+    ), linewidth = 1.5, linetype = "dashed") +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(
+        title = "OOB error rate (Solid: Original, Dashed: Randomized)",
+        x = "Number of trees", y = "Percent correct"
+    ) +
+    ggplot2::scale_color_manual(values = c(
+        "OOB" = "#4e4e4e",
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    ggplot2::coord_cartesian(ylim = c(0, 100)) +
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "red") +
+    ggplot2::theme(aspect.ratio = 1, text = ggplot2::element_text(size = 12)) +
+    ggplot2::scale_y_continuous(labels = scales::percent_format(scale = 1))

# time: 2024-09-18 17:11:22 UTC
# mode: r
+oobplot

# time: 2024-09-18 17:12:43 UTC
# mode: r
+# Import configuration file
+config <- config::get()
+
+# parameters
+percent.train <- 0.7
+num.threads <- 44
+num.eigenvectors <- 15
+set.seed(555)
+
+# Input files
+immigrant.info <- file.path(config$path$data, "600K_immigrants.fam")
+immigrant.vcf <- file.path(config$path$data, "600K_immigrants.vcf")
+resident.vcf <- file.path(config$path$data, "600K_residents.vcf")
+
+immigrant.gds <- file.path(config$path$data, "immigrant_recode.gds")
+resident.gds <- file.path(config$path$data, "resident_recode.gds")
+all.gds <- file.path(config$path$data, "all_recode.gds")
+
+
+# Load all the data
+all.maf <- SNPRelate::snpgdsOpen(all.gds, allow.duplicate = TRUE)
+
+# Load labels
+immigrant.id <- gdsfmt::read.gdsn(gdsfmt::index.gdsn(
+    SNPRelate::snpgdsOpen(immigrant.gds),
+    "sample.id"
+))
+resident.id <- gdsfmt::read.gdsn(gdsfmt::index.gdsn(
+    SNPRelate::snpgdsOpen(resident.gds),
+    "sample.id"
+))
+
+all.id <- gdsfmt::read.gdsn(gdsfmt::index.gdsn(all.maf, "sample.id"))
+all.label <- ifelse(all.id %in% immigrant.id, "immigrant", "resident")
+
+
+# Function to split data into training and testing sets
+# TODO balance so that there are .5 per class in both train and test sets
+split_data <- function(all.id, all.label, percent.train) {
+    # Split data by class
+    labels <- unique(all.label)
+    class_0 <- all.id[all.label == labels[1]]
+    class_1 <- all.id[all.label == labels[2]]
+
+    # Determine the size of the smaller class
+    min_class_size <- min(length(class_0), length(class_1))
+
+    # Undersample the majority class
+    if (length(class_0) > min_class_size) {
+        class_0 <- sample(class_0, min_class_size)
+    } else {
+        class_1 <- sample(class_1, min_class_size)
+    }
+
+    # Combine the balanced classes
+    balanced_ids <- c(class_0, class_1)
+    balanced_labels <- c(rep(labels[1], length(class_0)), rep(labels[2], length(class_1)))
+
+    # Calculate the number of samples for training
+    num_train <- round(length(balanced_ids) * percent.train)
+
+    # Ensure equal representation of both classes in train and test sets
+    num_train_per_class <- num_train %/% 2
+
+    # Randomly select samples for training from each class
+    train_indices <- c(
+        sample(1:min_class_size, num_train_per_class),
+        sample((min_class_size + 1):(2 * min_class_size), num_train_per_class)
+    )
+
+    train.id <- balanced_ids[train_indices]
+    test.id <- balanced_ids[-train_indices]
+    train.label <- balanced_labels[train_indices]
+    test.label <- balanced_labels[-train_indices]
+
+    list(
+        train.id = train.id, test.id = test.id,
+        train.label = train.label, test.label = test.label
+    )
+}
+# Function to perform PCA and prepare data frames
+prepare_data <- function(all.maf, train.id, test.id, train.label, test.label, num.eigenvectors, num.threads) {
+    pca <- SNPRelate::snpgdsPCA(all.maf, sample.id = train.id, num.thread = num.threads)
+    snp_loadings <- SNPRelate::snpgdsPCASNPLoading(pca, all.maf, num.thread = num.threads)
+    sample_loadings <- SNPRelate::snpgdsPCASampLoading(snp_loadings, all.maf, sample.id = test.id, num.thread = num.threads)
+    train_eigenvects <- data.frame(sample.id = pca$sample.id, pca$eigenvect[, 1:num.eigenvectors])
+    test_eigenvects <- data.frame(sample.id = sample_loadings$sample.id, sample_loadings$eigenvect[, 1:num.eigenvectors])
+    train_df <- data.frame(sample.id = train.id, pop = train.label, train_eigenvects[, -1])
+    test_df <- data.frame(sample.id = test.id, pop = test.label, test_eigenvects[, -1])
+    list(train_df = train_df, test_df = test_df)
+}
+
+# Function to train a random forest with optional randomized labels
+train_random_forest <- function(
+    train_df, test_df, num.eigenvectors, randomize_labels = FALSE) {
+    if (randomize_labels) {
+        train_df$pop <- sample(train_df$pop)
+    }
+
+    return(randomForest::randomForest(
+        train_df[, 3:(2 + num.eigenvectors)],
+        y = as.factor(train_df$pop),
+        data = train_df,
+        xtest = test_df[, 3:(2 + num.eigenvectors)],
+        ytest = as.factor(test_df$pop),
+        ntree = 500,
+        replace = FALSE,
+        proximity = TRUE
+    ))
+}
+
+# Function to run a single iteration
+run_iteration <- function(
+    all.id, all.label, all.maf, percent.train, num.eigenvectors, num.threads, randomize_labels) {
+    # Split data
+    split <- split_data(all.id, all.label, percent.train)
+
+    # print the proportion of each class in the train and test sets
+    print(table(split$train.label))
+    print(table(split$test.label))
+
+
+    # Prepare data
+    data <- prepare_data(
+        all.maf, split$train.id, split$test.id, split$train.label, split$test.label,
+        num.eigenvectors, num.threads
+    )
+
+    # Train random forest
+    rf <- train_random_forest(data$train_df, data$test_df, num.eigenvectors, randomize_labels)
+
+    # Extract OOB error rates
+    oob_data <- rfPermute::plotTrace(rf, plot = FALSE)$data
+
+    # Return both OOB data, the random forest model, and the train/test labels
+    return(list(oob_data = oob_data, rf_model = rf, train_labels = split$train.label, test_labels = split$test.label))
+}
+
+# Main function to run multiple iterations
+run_analysis <- function(
+    all.id, all.label, all.maf, percent.train,
+    num.eigenvectors, num.threads,
+    n_iterations = 1) {
+    set.seed(123) # For reproducibility
+
+    # Initialize progress bar
+    progressr::with_progress({
+        p <- progressr::progressor(along = 1:(2 * n_iterations))
+
+        # Run iterations with original labels
+        original_results <- replicate(n_iterations, {
+            p()
+            run_iteration(
+                all.id, all.label, all.maf, percent.train,
+                num.eigenvectors, num.threads, FALSE
+            )
+        }, simplify = FALSE)
+
+        # Run iterations with randomized labels
+        random_results <- replicate(n_iterations, {
+            p()
+            run_iteration(
+                all.id, all.label, all.maf, percent.train,
+                num.eigenvectors, num.threads, TRUE
+            )
+        }, simplify = FALSE)
+    })
+
+    # Separate OOB data, RF models, and train/test labels
+    original_oob <- lapply(original_results, function(x) x$oob_data)
+    original_rf_models <- lapply(original_results, function(x) x$rf_model)
+    original_train_labels <- lapply(original_results, function(x) x$train_labels)
+    original_test_labels <- lapply(original_results, function(x) x$test_labels)
+
+    random_oob <- lapply(random_results, function(x) x$oob_data)
+    random_rf_models <- lapply(random_results, function(x) x$rf_model)
+    random_train_labels <- lapply(random_results, function(x) x$train_labels)
+    random_test_labels <- lapply(random_results, function(x) x$test_labels)
+
+    # Combine OOB results
+    oob_df <- dplyr::as_tibble(do.call(rbind, original_oob))
+    random_oob_df <- dplyr::as_tibble(do.call(rbind, random_oob))
+
+    list(
+        oob_df = oob_df,
+        random_oob_df = random_oob_df,
+        original_rf_models = original_rf_models,
+        random_rf_models = random_rf_models,
+        original_train_labels = original_train_labels,
+        original_test_labels = original_test_labels,
+        random_train_labels = random_train_labels,
+        random_test_labels = random_test_labels
+    )
+}
+
+calculate_mean_error <- function(data) {
+    data |>
+        dplyr::group_by(trees, class) |>
+        dplyr::summarise(mean_error = mean(error), .groups = "drop") |> # nolint: object_usage_linter.
+        dplyr::filter(class != "OOB")
+}
+
+
+# ----------------------------------- main ----------------------------------- #
+
+
+# Run the analysis
+results <- run_analysis(all.id, all.label, all.maf, percent.train, num.eigenvectors, num.threads, n_iterations = 10)

# time: 2024-09-18 17:16:29 UTC
# mode: r
+progressr::handlers(progressr::handler_pbcol(
+    adjust = 1.0,
+    complete = function(s) cli::bg_red(cli::col_black(s)),
+    incomplete = function(s) cli::bg_cyan(cli::col_black(s))
+))

# time: 2024-09-18 17:16:35 UTC
# mode: r
+# Import configuration file
+config <- config::get()
+
+progressr::handlers(progressr::handler_pbcol(
+    adjust = 1.0,
+    complete = function(s) cli::bg_red(cli::col_black(s)),
+    incomplete = function(s) cli::bg_cyan(cli::col_black(s))
+))
+
+# parameters
+percent.train <- 0.7
+num.threads <- 44
+num.eigenvectors <- 15
+set.seed(555)
+
+# Input files
+immigrant.info <- file.path(config$path$data, "600K_immigrants.fam")
+immigrant.vcf <- file.path(config$path$data, "600K_immigrants.vcf")
+resident.vcf <- file.path(config$path$data, "600K_residents.vcf")
+
+immigrant.gds <- file.path(config$path$data, "immigrant_recode.gds")
+resident.gds <- file.path(config$path$data, "resident_recode.gds")
+all.gds <- file.path(config$path$data, "all_recode.gds")
+
+
+# Load all the data
+all.maf <- SNPRelate::snpgdsOpen(all.gds, allow.duplicate = TRUE)
+
+# Load labels
+immigrant.id <- gdsfmt::read.gdsn(gdsfmt::index.gdsn(
+    SNPRelate::snpgdsOpen(immigrant.gds),
+    "sample.id"
+))
+resident.id <- gdsfmt::read.gdsn(gdsfmt::index.gdsn(
+    SNPRelate::snpgdsOpen(resident.gds),
+    "sample.id"
+))
+
+all.id <- gdsfmt::read.gdsn(gdsfmt::index.gdsn(all.maf, "sample.id"))
+all.label <- ifelse(all.id %in% immigrant.id, "immigrant", "resident")
+
+
+# Function to split data into training and testing sets
+split_data <- function(all.id, all.label, percent.train) {
+    # Split data by class
+    labels <- unique(all.label)
+    class_0 <- all.id[all.label == labels[1]]
+    class_1 <- all.id[all.label == labels[2]]
+
+    # Determine the size of the smaller class
+    min_class_size <- min(length(class_0), length(class_1))
+
+    # Undersample the majority class
+    if (length(class_0) > min_class_size) {
+        class_0 <- sample(class_0, min_class_size)
+    } else {
+        class_1 <- sample(class_1, min_class_size)
+    }
+
+    # Combine the balanced classes
+    balanced_ids <- c(class_0, class_1)
+    balanced_labels <- c(rep(labels[1], length(class_0)), rep(labels[2], length(class_1)))
+
+    # Calculate the number of samples for training
+    num_train <- round(length(balanced_ids) * percent.train)
+
+    # Ensure equal representation of both classes in train and test sets
+    num_train_per_class <- num_train %/% 2
+
+    # Randomly select samples for training from each class
+    train_indices <- c(
+        sample(1:min_class_size, num_train_per_class),
+        sample((min_class_size + 1):(2 * min_class_size), num_train_per_class)
+    )
+
+    train.id <- balanced_ids[train_indices]
+    test.id <- balanced_ids[-train_indices]
+    train.label <- balanced_labels[train_indices]
+    test.label <- balanced_labels[-train_indices]
+
+    list(
+        train.id = train.id, test.id = test.id,
+        train.label = train.label, test.label = test.label
+    )
+}
+# Function to perform PCA and prepare data frames
+prepare_data <- function(all.maf, train.id, test.id, train.label, test.label, num.eigenvectors, num.threads) {
+    pca <- SNPRelate::snpgdsPCA(
+        all.maf,
+        sample.id = train.id, num.thread = num.threads, verbose = FALSE
+    )
+    snp_loadings <- SNPRelate::snpgdsPCASNPLoading(
+        pca, all.maf,
+        num.thread = num.threads, verbose = FALSE
+    )
+    sample_loadings <- SNPRelate::snpgdsPCASampLoading(
+        snp_loadings, all.maf,
+        sample.id = test.id, num.thread = num.threads, verbose = FALSE
+    )
+    train_eigenvects <- data.frame(
+        sample.id = pca$sample.id, pca$eigenvect[, 1:num.eigenvectors]
+    )
+    test_eigenvects <- data.frame(
+        sample.id = sample_loadings$sample.id, sample_loadings$eigenvect[, 1:num.eigenvectors]
+    )
+    train_df <- data.frame(sample.id = train.id, pop = train.label, train_eigenvects[, -1])
+    test_df <- data.frame(sample.id = test.id, pop = test.label, test_eigenvects[, -1])
+    list(train_df = train_df, test_df = test_df)
+}
+
+# Function to train a random forest with optional randomized labels
+train_random_forest <- function(
+    train_df, test_df, num.eigenvectors, randomize_labels = FALSE) {
+    if (randomize_labels) {
+        train_df$pop <- sample(train_df$pop)
+    }
+
+    return(randomForest::randomForest(
+        train_df[, 3:(2 + num.eigenvectors)],
+        y = as.factor(train_df$pop),
+        data = train_df,
+        xtest = test_df[, 3:(2 + num.eigenvectors)],
+        ytest = as.factor(test_df$pop),
+        ntree = 500,
+        replace = FALSE,
+        proximity = TRUE
+    ))
+}
+
+# Function to run a single iteration
+run_iteration <- function(
+    all.id, all.label, all.maf, percent.train, num.eigenvectors, num.threads, randomize_labels) {
+    # Split data
+    split <- split_data(all.id, all.label, percent.train)
+
+    # Prepare data
+    data <- prepare_data(
+        all.maf, split$train.id, split$test.id, split$train.label, split$test.label,
+        num.eigenvectors, num.threads
+    )
+
+    # Train random forest
+    rf <- train_random_forest(data$train_df, data$test_df, num.eigenvectors, randomize_labels)
+
+    # Extract OOB error rates
+    oob_data <- rfPermute::plotTrace(rf, plot = FALSE)$data
+
+    # Return both OOB data, the random forest model, and the train/test labels
+    return(list(oob_data = oob_data, rf_model = rf, train_labels = split$train.label, test_labels = split$test.label))
+}
+
+# Main function to run multiple iterations
+run_analysis <- function(
+    all.id, all.label, all.maf, percent.train,
+    num.eigenvectors, num.threads,
+    n_iterations = 1) {
+    set.seed(123) # For reproducibility
+
+    # Initialize progress bar
+    progressr::with_progress({
+        p <- progressr::progressor(along = 1:(2 * n_iterations))
+
+        # Run iterations with original labels
+        original_results <- replicate(n_iterations,
+            {
+                p()
+                run_iteration(
+                    all.id, all.label, all.maf, percent.train,
+                    num.eigenvectors, num.threads, FALSE
+                )
+            },
+            simplify = FALSE
+        )
+
+        # Run iterations with randomized labels
+        random_results <- replicate(n_iterations,
+            {
+                p()
+                run_iteration(
+                    all.id, all.label, all.maf, percent.train,
+                    num.eigenvectors, num.threads, TRUE
+                )
+            },
+            simplify = FALSE
+        )
+    })
+
+    # Separate OOB data, RF models, and train/test labels
+    original_oob <- lapply(original_results, function(x) x$oob_data)
+    original_rf_models <- lapply(original_results, function(x) x$rf_model)
+    original_train_labels <- lapply(original_results, function(x) x$train_labels)
+    original_test_labels <- lapply(original_results, function(x) x$test_labels)
+
+    random_oob <- lapply(random_results, function(x) x$oob_data)
+    random_rf_models <- lapply(random_results, function(x) x$rf_model)
+    random_train_labels <- lapply(random_results, function(x) x$train_labels)
+    random_test_labels <- lapply(random_results, function(x) x$test_labels)
+
+    # Combine OOB results
+    oob_df <- dplyr::as_tibble(do.call(rbind, original_oob))
+    random_oob_df <- dplyr::as_tibble(do.call(rbind, random_oob))
+
+    list(
+        oob_df = oob_df,
+        random_oob_df = random_oob_df,
+        original_rf_models = original_rf_models,
+        random_rf_models = random_rf_models,
+        original_train_labels = original_train_labels,
+        original_test_labels = original_test_labels,
+        random_train_labels = random_train_labels,
+        random_test_labels = random_test_labels
+    )
+}
+
+calculate_mean_error <- function(data) {
+    data |>
+        dplyr::group_by(trees, class) |>
+        dplyr::summarise(mean_error = mean(error), .groups = "drop") |> # nolint: object_usage_linter.
+        dplyr::filter(class != "OOB")
+}
+
+
+# ----------------------------------- main ----------------------------------- #
+
+
+# Run the analysis
+results <- run_analysis(all.id, all.label, all.maf, percent.train, num.eigenvectors, num.threads, n_iterations = 10)

# time: 2024-09-18 17:21:13 UTC
# mode: r
+# Calculate mean error for all iterations
+mean_oob_df <- calculate_mean_error(results$oob_df)
+mean_random_oob_df <- calculate_mean_error(results$random_oob_df)
+
+# Create the plot data
+plot_data <- list(
+    oob_df = results$oob_df |>
+        dplyr::filter(class != "OOB"),
+    random_oob_df = results$random_oob_df |>
+        dplyr::filter(class != "OOB"),
+    mean_oob_df = mean_oob_df,
+    mean_random_oob_df = mean_random_oob_df
+)
+
+# Create the plot
+oobplot <- ggplot2::ggplot() +
+    ggplot2::geom_line(data = plot_data$oob_df, ggplot2::aes(
+        x = trees, y = error, color = class
+    ), alpha = 0.1) +
+    ggplot2::geom_line(data = plot_data$random_oob_df, ggplot2::aes(
+        x = trees, y = error, color = class
+    ), alpha = 0.1, linetype = "dashed") +
+    ggplot2::geom_line(data = plot_data$mean_oob_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class
+    ), linewidth = 1.5) +
+    ggplot2::geom_line(data = plot_data$mean_random_oob_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class
+    ), linewidth = 1.5, linetype = "dashed") +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(
+        title = "OOB error rate (Solid: Original, Dashed: Randomized)",
+        x = "Number of trees", y = "Percent correct"
+    ) +
+    ggplot2::scale_color_manual(values = c(
+        "OOB" = "#4e4e4e",
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    ggplot2::coord_cartesian(ylim = c(0, 100)) +
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "red") +
+    ggplot2::theme(aspect.ratio = 1, text = ggplot2::element_text(size = 12)) +
+    ggplot2::scale_y_continuous(labels = scales::percent_format(scale = 1))
+
+# Save the plot
+ggplot2::ggsave(file.path(config$path$figures, "oob_plot.jpg"),
+    plot =
+        oobplot,
+    width = 8,
+    height = 6
+)

# time: 2024-09-18 17:21:15 UTC
# mode: r
+oobplot

# time: 2024-09-18 17:22:01 UTC
# mode: r
+# save the results
+saveRDS(results, file.path(config$path$data, "rf_results.rds"))

# time: 2024-09-18 17:22:30 UTC
# mode: r
+# Check if results file exists
+results_file <- file.path(config$path$data, "rf_results.rds")
+
+if (file.exists(results_file)) {
+    # Load the results
+    results <- readRDS(results_file)
+} else {
+    # Run the analysis
+    results <- run_analysis(all.id, all.label, all.maf, percent.train,
+        num.eigenvectors, num.threads,
+        n_iterations = 10
+    )
+
+    # Save the results
+    saveRDS(results, results_file)
+}

# time: 2024-09-18 17:22:38 UTC
# mode: r
+oobplot

# time: 2024-09-18 17:30:11 UTC
# mode: r
+mean_oob_df

# time: 2024-09-19 09:29:40 UTC
# mode: r
+# Import configuration file
+config <- config::get()
+
+progressr::handlers(progressr::handler_pbcol(
+    adjust = 1.0,
+    complete = function(s) cli::bg_red(cli::col_black(s)),
+    incomplete = function(s) cli::bg_cyan(cli::col_black(s))
+))
+
+# parameters
+percent.train <- 0.7
+num.threads <- 44
+num.eigenvectors <- 15
+set.seed(555)
+
+# Input files
+immigrant.info <- file.path(config$path$data, "600K_immigrants.fam")
+immigrant.vcf <- file.path(config$path$data, "600K_immigrants.vcf")
+resident.vcf <- file.path(config$path$data, "600K_residents.vcf")
+
+immigrant.gds <- file.path(config$path$data, "immigrant_recode.gds")
+resident.gds <- file.path(config$path$data, "resident_recode.gds")
+all.gds <- file.path(config$path$data, "all_recode.gds")
+
+
+# Load all the data
+all.maf <- SNPRelate::snpgdsOpen(all.gds, allow.duplicate = TRUE)
+
+# Load labels
+immigrant.id <- gdsfmt::read.gdsn(gdsfmt::index.gdsn(
+    SNPRelate::snpgdsOpen(immigrant.gds),
+    "sample.id"
+))
+resident.id <- gdsfmt::read.gdsn(gdsfmt::index.gdsn(
+    SNPRelate::snpgdsOpen(resident.gds),
+    "sample.id"
+))
+
+all.id <- gdsfmt::read.gdsn(gdsfmt::index.gdsn(all.maf, "sample.id"))
+all.label <- ifelse(all.id %in% immigrant.id, "immigrant", "resident")
+
+
+# Function to split data into training and testing sets
+split_data <- function(all.id, all.label, percent.train) {
+    # Split data by class
+    labels <- unique(all.label)
+    class_0 <- all.id[all.label == labels[1]]
+    class_1 <- all.id[all.label == labels[2]]
+
+    # Determine the size of the smaller class
+    min_class_size <- min(length(class_0), length(class_1))
+
+    # Undersample the majority class
+    if (length(class_0) > min_class_size) {
+        class_0 <- sample(class_0, min_class_size)
+    } else {
+        class_1 <- sample(class_1, min_class_size)
+    }
+
+    # Combine the balanced classes
+    balanced_ids <- c(class_0, class_1)
+    balanced_labels <- c(
+        rep(labels[1], length(class_0)),
+        rep(labels[2], length(class_1))
+    )
+
+    # Calculate the number of samples for training
+    num_train <- round(length(balanced_ids) * percent.train)
+
+    # Ensure equal representation of both classes in train and test sets
+    num_train_per_class <- num_train %/% 2
+
+    # Randomly select samples for training from each class
+    train_indices <- c(
+        sample(1:min_class_size, num_train_per_class),
+        sample((min_class_size + 1):(2 * min_class_size), num_train_per_class)
+    )
+
+    train.id <- balanced_ids[train_indices]
+    test.id <- balanced_ids[-train_indices]
+    train.label <- balanced_labels[train_indices]
+    test.label <- balanced_labels[-train_indices]
+
+    list(
+        train.id = train.id, test.id = test.id,
+        train.label = train.label, test.label = test.label
+    )
+}
+# Function to perform PCA and prepare data frames
+prepare_data <- function(
+    all.maf, train.id, test.id,
+    train.label, test.label, num.eigenvectors, num.threads) {
+    pca <- SNPRelate::snpgdsPCA(
+        all.maf,
+        sample.id = train.id, num.thread = num.threads, verbose = FALSE
+    )
+    snp_loadings <- SNPRelate::snpgdsPCASNPLoading(
+        pca, all.maf,
+        num.thread = num.threads, verbose = FALSE
+    )
+    sample_loadings <- SNPRelate::snpgdsPCASampLoading(
+        snp_loadings, all.maf,
+        sample.id = test.id, num.thread = num.threads, verbose = FALSE
+    )
+    train_eigenvects <- data.frame(
+        sample.id = pca$sample.id, pca$eigenvect[, 1:num.eigenvectors]
+    )
+    test_eigenvects <- data.frame(
+        sample.id = sample_loadings$sample.id, sample_loadings$eigenvect[, 1:num.eigenvectors]
+    )
+    train_df <- data.frame(sample.id = train.id, pop = train.label, train_eigenvects[, -1])
+    test_df <- data.frame(sample.id = test.id, pop = test.label, test_eigenvects[, -1])
+    list(train_df = train_df, test_df = test_df)
+}
+
+# Function to train a random forest with optional randomized labels
+train_random_forest <- function(
+    train_df, test_df, num.eigenvectors, randomize_labels = FALSE) {
+    if (randomize_labels) {
+        train_df$pop <- sample(train_df$pop)
+    }
+
+    return(randomForest::randomForest(
+        train_df[, 3:(2 + num.eigenvectors)],
+        y = as.factor(train_df$pop),
+        data = train_df,
+        xtest = test_df[, 3:(2 + num.eigenvectors)],
+        ytest = as.factor(test_df$pop),
+        ntree = 500,
+        replace = FALSE,
+        proximity = TRUE
+    ))
+}
+
+# Function to run a single iteration
+run_iteration <- function(
+    all.id, all.label, all.maf, percent.train, num.eigenvectors, num.threads, randomize_labels) {
+    # Split data
+    split <- split_data(all.id, all.label, percent.train)
+
+    # Prepare data
+    data <- prepare_data(
+        all.maf, split$train.id, split$test.id, split$train.label, split$test.label,
+        num.eigenvectors, num.threads
+    )
+
+    # Train random forest
+    rf <- train_random_forest(data$train_df, data$test_df, num.eigenvectors, randomize_labels)
+
+    # Extract OOB error rates
+    oob_data <- rfPermute::plotTrace(rf, plot = FALSE)$data
+
+    # Return both OOB data, the random forest model, and the train/test labels
+    return(list(
+        oob_data = oob_data, rf_model = rf,
+        train_labels = split$train.label, test_labels = split$test.label
+    ))
+}
+
+# Main function to run multiple iterations
+run_analysis <- function(
+    all.id, all.label, all.maf, percent.train,
+    num.eigenvectors, num.threads,
+    n_iterations = 1) {
+    set.seed(123) # For reproducibility
+
+    # Initialize progress bar
+    progressr::with_progress({
+        p <- progressr::progressor(along = 1:(2 * n_iterations))
+
+        # Run iterations with original labels
+        original_results <- replicate(n_iterations,
+            {
+                p()
+                run_iteration(
+                    all.id, all.label, all.maf, percent.train,
+                    num.eigenvectors, num.threads, FALSE
+                )
+            },
+            simplify = FALSE
+        )
+
+        # Run iterations with randomized labels
+        random_results <- replicate(n_iterations,
+            {
+                p()
+                run_iteration(
+                    all.id, all.label, all.maf, percent.train,
+                    num.eigenvectors, num.threads, TRUE
+                )
+            },
+            simplify = FALSE
+        )
+    })
+
+    # Separate OOB data, RF models, and train/test labels
+    original_oob <- lapply(original_results, function(x) x$oob_data)
+    original_rf_models <- lapply(original_results, function(x) x$rf_model)
+    original_train_labels <- lapply(original_results, function(x) x$train_labels)
+    original_test_labels <- lapply(original_results, function(x) x$test_labels)
+
+    random_oob <- lapply(random_results, function(x) x$oob_data)
+    random_rf_models <- lapply(random_results, function(x) x$rf_model)
+    random_train_labels <- lapply(random_results, function(x) x$train_labels)
+    random_test_labels <- lapply(random_results, function(x) x$test_labels)
+
+    # Combine OOB results
+    oob_df <- dplyr::as_tibble(do.call(rbind, original_oob))
+    random_oob_df <- dplyr::as_tibble(do.call(rbind, random_oob))
+
+    list(
+        oob_df = oob_df,
+        random_oob_df = random_oob_df,
+        original_rf_models = original_rf_models,
+        random_rf_models = random_rf_models,
+        original_train_labels = original_train_labels,
+        original_test_labels = original_test_labels,
+        random_train_labels = random_train_labels,
+        random_test_labels = random_test_labels
+    )
+}
+
+calculate_mean_error <- function(data) {
+    data |>
+        dplyr::group_by(trees, class) |>
+        dplyr::summarise(mean_error = mean(error), .groups = "drop") |> # nolint: object_usage_linter.
+        dplyr::filter(class != "OOB")
+}
+
+
+# ----------------------------------- main ----------------------------------- #
+
+# TODO:
+# - RF error rate plot
+# - Summary statistics for random and original models
+# - MDS plot
+# - Confusion matrix
+# - Calculate some sort of distance between points and cluster centroids
+
+# Check if results file exists
+results_file <- file.path(config$path$data, "rf_results.rds")
+
+if (file.exists(results_file)) {
+    # Load the results
+    results <- readRDS(results_file)
+} else {
+    # Run the analysis
+    results <- run_analysis(all.id, all.label, all.maf, percent.train,
+        num.eigenvectors, num.threads,
+        n_iterations = 2
+    )
+
+    # Save the results
+    saveRDS(results, results_file)
+}
+
+
+# Calculate mean error for all iterations
+mean_oob_df <- calculate_mean_error(results$oob_df)
+mean_random_oob_df <- calculate_mean_error(results$random_oob_df)
+
+# Create the plot data
+plot_data <- list(
+    oob_df = results$oob_df |>
+        dplyr::filter(class != "OOB"),
+    random_oob_df = results$random_oob_df |>
+        dplyr::filter(class != "OOB"),
+    mean_oob_df = mean_oob_df,
+    mean_random_oob_df = mean_random_oob_df
+)
+
+# Create the plot
+oobplot <- ggplot2::ggplot() +
+    ggplot2::geom_line(data = plot_data$oob_df, ggplot2::aes(
+        x = trees, y = error, color = class
+    ), alpha = 0.1) +
+    ggplot2::geom_line(data = plot_data$random_oob_df, ggplot2::aes(
+        x = trees, y = error, color = class
+    ), alpha = 0.1, linetype = "dashed") +
+    ggplot2::geom_line(data = plot_data$mean_oob_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class
+    ), linewidth = 1.5) +
+    ggplot2::geom_line(data = plot_data$mean_random_oob_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class
+    ), linewidth = 1.5, linetype = "dashed") +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(
+        title = "OOB error rate (Solid: Original, Dashed: Randomized)",
+        x = "Number of trees", y = "Percent correct"
+    ) +
+    ggplot2::scale_color_manual(values = c(
+        "OOB" = "#4e4e4e",
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    ggplot2::coord_cartesian(ylim = c(0, 100)) +
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "red") +
+    ggplot2::theme(aspect.ratio = 1, text = ggplot2::element_text(size = 12)) +
+    ggplot2::scale_y_continuous(labels = scales::percent_format(scale = 1))
+
+# Save the plot
+ggplot2::ggsave(file.path(config$path$figures, "oob_plot.jpg"),
+    plot =
+        oobplot,
+    width = 8,
+    height = 6
+)

# time: 2024-09-19 09:30:11 UTC
# mode: r
+oobplot

# time: 2024-09-19 09:31:30 UTC
# mode: r
+plot_data$oob_df

# time: 2024-09-19 09:32:14 UTC
# mode: r
+# get data from tree 100 to tree 500 and plot the distribution of percent correct by class using ggdist
+
+oobdistplot <- ggdist::ggdist(plot_data$oob_df |>
+    dplyr::filter(trees >= 100) |>
+    dplyr::filter(trees <= 500), x = "error", facet.by = "class", type = "density"
+) +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(
+        title = "Distribution of OOB error rate by class",
+        x = "Percent correct", y = "Density"
+    ) +
+    ggplot2::theme(aspect.ratio = 1, text = ggplot2::element_text(size = 12))

# time: 2024-09-19 09:32:28 UTC
# mode: r
+renv::install('ggdist')

# time: 2024-09-19 09:32:59 UTC
# mode: r
+# get data from tree 100 to tree 500 and plot the distribution of percent correct by class using ggdist
+
+oobdistplot <- ggplot2::ggplot() +
+    ggdist::geom_dots(
+        data = plot_data$oob_df |>
+            dplyr::filter(trees >= 100),
+        ggplot2::aes(
+            x = error, y = trees, color = class
+        ),
+        alpha = 0.1
+    ) +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(
+        title = "Distribution of percent correct by class",
+        x = "Percent correct", y = "Number of trees"
+    )

# time: 2024-09-19 09:33:01 UTC
# mode: r
+oobdistplot

# time: 2024-09-19 09:33:56 UTC
# mode: r
+# get data from tree 100 to tree 500 and plot the distribution of percent correct by class using ggdist
+
+oobdistplot <- ggplot2::ggplot() +
+    ggdist::geom_slab(
+        data = plot_data$oob_df |>
+            dplyr::filter(trees >= 100),
+        ggplot2::aes(
+            x = error, y = trees, fill = class
+        ),
+        position = ggdist::position_nudge(x = 0.1),
+        alpha = 0.5
+    )

# time: 2024-09-19 09:33:58 UTC
# mode: r
+oobdistplot

# time: 2024-09-19 09:34:14 UTC
# mode: r
+# get data from tree 100 to tree 500 and plot the distribution of percent correct by class using ggdist
+
+oobdistplot <- ggplot2::ggplot() +
+    ggdist::geom_slab(
+        data = plot_data$oob_df |>
+            dplyr::filter(trees >= 100),
+        ggplot2::aes(
+            x = error, y = trees, fill = class
+        ),
+        position = ggdist::position_nudge(x = 0.1),
+        alpha = 0.5
+    )

# time: 2024-09-19 09:34:18 UTC
# mode: r
+# get data from tree 100 to tree 500 and plot the distribution of percent correct by class using ggdist
+
+oobdistplot <- ggplot2::ggplot() +
+    ggdist::geom_slab(
+        data = plot_data$oob_df |>
+            dplyr::filter(trees >= 100),
+        ggplot2::aes(
+            x = error, y = trees, fill = class
+        ),
+        alpha = 0.5
+    )

# time: 2024-09-19 09:34:20 UTC
# mode: r
+oobdistplot

# time: 2024-09-19 10:16:15 UTC
# mode: r
+oob_dfs <- list(
+    plot_data$oob_df,
+    plot_data$random_oob_df,
+    plot_data$mean_oob_df,
+    plot_data$mean_random_oob_df
+)
+
+oob_df <- dplyr::bind_rows(oob_dfs, .id = "source")
+
+# filter the data to include only trees 100 to 500
+oob_df <- dplyr::filter(oob_df, trees >= 100 & trees <= 500)

# time: 2024-09-19 10:16:17 UTC
# mode: r
+oob_df

# time: 2024-09-19 10:17:25 UTC
# mode: r
+# get data from tree 100 to tree 500 and plot the distribution of percent correct by class using ggdist
+
+# to do this, first consolidate the data from plot_data$oob_df, plot_data$random_oob_df, plot_data$mean_oob_df, and plot_data$mean_random_oob_df
+# into a single data frame
+
+oob_df <- dplyr::bind_rows(
+    list(
+        oob_df = plot_data$oob_df,
+        random_oob_df = plot_data$random_oob_df,
+        mean_oob_df = plot_data$mean_oob_df,
+        mean_random_oob_df = plot_data$mean_random_oob_df
+    ),
+    .id = "source"
+)

# time: 2024-09-19 10:17:27 UTC
# mode: r
+oob_df

# time: 2024-09-19 10:17:50 UTC
# mode: r
+# get data from tree 100 to tree 500 and plot the distribution of percent correct by class using ggdist
+
+# to do this, first consolidate the data from plot_data$oob_df, plot_data$random_oob_df, plot_data$mean_oob_df, and plot_data$mean_random_oob_df
+# into a single data frame
+
+oob_df <- dplyr::bind_rows(
+    list(
+        oob_df = plot_data$oob_df,
+        random_oob_df = plot_data$random_oob_df
+    ),
+    .id = "source"
+)

# time: 2024-09-19 10:18:02 UTC
# mode: r
+# get data from tree 100 to tree 500 and plot the distribution of percent correct by class using ggdist
+
+# to do this, first consolidate the data from plot_data$oob_df, plot_data$random_oob_df, plot_data$mean_oob_df, and plot_data$mean_random_oob_df
+# into a single data frame
+
+oob_df <- dplyr::bind_rows(
+    list(
+        oob_df = plot_data$oob_df,
+        random_oob_df = plot_data$random_oob_df
+    ),
+    .id = "source"
+) |>  dplyr::filter(trees >= 100 & trees <= 500)

# time: 2024-09-19 10:18:04 UTC
# mode: r
+oob_df

# time: 2024-09-19 10:18:25 UTC
# mode: r
+# plot the distribution of percent correct by class
+oob_dist_plot <- ggplot2::ggplot(oob_df) +
+    ggdist::geom_dots(
+        ggplot2::aes(x = error, fill = class),
+        position = ggdist::position_nudge(y = 0.1),
+        alpha = 0.5
+    ) +
+    ggdist::geom_density(
+        ggplot2::aes(x = error, fill = class),
+        alpha = 0.5
+    ) +
+    ggplot2::facet_wrap(~source) +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(
+        title = "Distribution of percent correct by class",
+        x = "Percent correct", y = "Density"
+    )

# time: 2024-09-19 10:18:35 UTC
# mode: r
+# plot the distribution of percent correct by class
+oob_dist_plot <- ggplot2::ggplot(oob_df) +
+    ggdist::geom_density(
+        ggplot2::aes(x = error, fill = class),
+        alpha = 0.5
+    ) +
+    ggplot2::facet_wrap(~source) +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(
+        title = "Distribution of percent correct by class",
+        x = "Percent correct", y = "Density"
+    )

# time: 2024-09-19 10:18:42 UTC
# mode: r
+# plot the distribution of percent correct by class
+oob_dist_plot <- ggplot2::ggplot(oob_df) +
+    ggplot2::geom_density(
+        ggplot2::aes(x = error, fill = class),
+        alpha = 0.5
+    ) +
+    ggplot2::facet_wrap(~source) +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(
+        title = "Distribution of percent correct by class",
+        x = "Percent correct", y = "Density"
+    )

# time: 2024-09-19 10:18:43 UTC
# mode: r
+oob_dist_plot

# time: 2024-09-19 10:19:09 UTC
# mode: r
+# plot the distribution of percent correct by class
+oob_dist_plot <- ggplot2::ggplot(oob_df) +
+    ggdist::geom_slabinterval(
+        ggplot2::aes(x = error, fill = class),
+        alpha = 0.5
+    ) +
+    ggplot2::facet_wrap(~source) +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(
+        title = "Distribution of percent correct by class",
+        x = "Percent correct", y = "Density"
+    )

# time: 2024-09-19 10:19:11 UTC
# mode: r
+oob_dist_plot

# time: 2024-09-19 10:19:59 UTC
# mode: r
+# plot the distribution of percent correct by class
+oob_dist_plot <- ggplot2::ggplot(oob_df) +
+    ggdist::stat_dist_slabinterval(
+        ggplot2::aes(x = error, fill = class),
+        position = "identity", alpha = 0.5
+    ) +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(
+        title = "Distribution of percent correct by class",
+        x = "Percent correct", y = "Density"
+    )

# time: 2024-09-19 10:20:01 UTC
# mode: r
+oob_dist_plot

# time: 2024-09-19 10:21:05 UTC
# mode: r
+oob_df

# time: 2024-09-19 10:21:12 UTC
# mode: r
+# plot the distribution of percent correct by class
+oob_dist_plot <- ggplot2::ggplot() +
+    ggdist::stat_dist_slabinterval(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(x = error, fill = class),
+        position = "identity", alpha = 0.5
+    ) +
+    ggdist::stat_dist_slabinterval(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(x = error, fill = class),
+        position = "identity", alpha = 0.5
+    ) +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(
+        title = "Distribution of percent correct by class",
+        x = "Percent correct", y = "Density"
+    )

# time: 2024-09-19 10:21:14 UTC
# mode: r
+oob_dist_plot

# time: 2024-09-19 10:22:33 UTC
# mode: r
+# plot the distribution of percent correct by class
+oob_dist_plot <- ggplot2::ggplot() +
+    ggdist::stat_slabinterval(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(x = error, fill = class),
+        position = "identity", alpha = 0.5
+    ) +
+    ggdist::stat_slabinterval(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(x = error, fill = class),
+        position = "identity", alpha = 0.5
+    ) +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(
+        title = "Distribution of percent correct by class",
+        x = "Percent correct", y = "Density"
+    )

# time: 2024-09-19 10:22:35 UTC
# mode: r
+oob_dist_plot

# time: 2024-09-19 10:23:57 UTC
# mode: r
+# plot the distribution of percent correct by class
+oob_dist_plot <- ggplot2::ggplot() +
+    ggdist::stat_slabinterval(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(x = error, fill = class),
+        position = "identity", alpha = 0.5, n = 100
+    ) +
+    ggdist::stat_slabinterval(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(x = error, fill = class),
+        position = "identity", alpha = 0.5,n = 100
+    ) +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(
+        title = "Distribution of percent correct by class",
+        x = "Percent correct", y = "Density"
+    )

# time: 2024-09-19 10:23:59 UTC
# mode: r
+oob_dist_plot

# time: 2024-09-19 10:24:47 UTC
# mode: r
+# plot the distribution of percent correct by class
+oob_dist_plot <- ggplot2::ggplot() +
+    ggdist::stat_halfeye(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(x = error, fill = class),
+        position = "identity", alpha = 0.5, n = 100
+    ) +
+    ggdist::stat_halfeye(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(x = error, fill = class),
+        position = "identity", alpha = 0.5,n = 100
+    ) +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(
+        title = "Distribution of percent correct by class",
+        x = "Percent correct", y = "Density"
+    )

# time: 2024-09-19 10:24:48 UTC
# mode: r
+oob_dist_plot

# time: 2024-09-19 10:28:21 UTC
# mode: r
+# plot the distribution of percent correct by class
+oob_dist_plot <- ggplot2::ggplot() +
+    ggdist::stat_halfeye(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(x = error, fill = class),
+        position = "identity", alpha = 0.5, density = ggdist::bandwidth_dpi(nb = 100)
+    ) +
+    ggdist::stat_halfeye(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(x = error, fill = class),
+        position = "identity", alpha = 0.5, density = ggdist::bandwidth_dpi(nb = 100)
+    ) +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(
+        title = "Distribution of percent correct by class",
+        x = "Percent correct", y = "Density"
+    )

# time: 2024-09-19 10:28:22 UTC
# mode: r
+oob_dist_plot

# time: 2024-09-19 10:29:26 UTC
# mode: r
+# plot the distribution of percent correct by class
+oob_dist_plot <- ggplot2::ggplot() +
+    ggdist::stat_halfeye(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(x = error, fill = class),
+        position = "identity", alpha = 0.5, density = ggdist::density_bounded(bandwidth = "nrd0", n=50)
+    ) +
+    ggdist::stat_halfeye(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(x = error, fill = class),
+        position = "identity", alpha = 0.5, density = ggdist::density_bounded(bandwidth = "nrd0", n=50)
+    ) +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(
+        title = "Distribution of percent correct by class",
+        x = "Percent correct", y = "Density"
+    )

# time: 2024-09-19 10:29:27 UTC
# mode: r
+oob_dist_plot

# time: 2024-09-19 10:33:04 UTC
# mode: r
+renv::install('box')

# time: 2024-09-19 10:36:52 UTC
# mode: r
+# Import configuration file
+config <- config::get()
+box::use(R / plot[titheme, titpalette, blues])

# time: 2024-09-19 10:37:08 UTC
# mode: r
+# plot the distribution of percent correct by class
+oob_dist_plot <- ggplot2::ggplot() +
+    ggdist::stat_halfeye(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(x = error, fill = class),
+        position = "identity", alpha = 0.5, density = ggdist::density_bounded(bandwidth = "nrd0", n=50)
+    ) +
+    ggdist::stat_halfeye(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(x = error, fill = class),
+        position = "identity", alpha = 0.5, density = ggdist::density_bounded(bandwidth = "nrd0", n=50)
+    ) +
+    titheme() +
+    ggplot2::labs(
+        title = "Distribution of percent correct by class",
+        x = "Percent correct", y = "Density"
+    )

# time: 2024-09-19 10:37:10 UTC
# mode: r
+oob_dist_plot

# time: 2024-09-19 10:38:34 UTC
# mode: r
+# plot the distribution of percent correct by class
+oob_dist_plot <- ggplot2::ggplot() +
+    ggdist::stat_halfeye(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(x = error, fill = class),
+        position = "identity", alpha = 0.5, density = ggdist::density_bounded(bandwidth = "nrd0", n = 50)
+    ) +
+    ggdist::stat_halfeye(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(x = error, fill = class),
+        position = "identity", alpha = 0.5, density = ggdist::density_bounded(bandwidth = "nrd0", n = 50)
+    ) +
+    titheme() +
+    ggplot2::theme(# add disconnected left and bottom axis lines
+        panel.grid.major = ggplot2::element_line(color = "black", size = 0.5),
+        panel.grid.minor = ggplot2::element_line(color = "black"
+    )) +
+    ggplot2::labs(
+        title = "Distribution of percent correct by class",
+        x = "Percent correct", y = "Density"
+    )

# time: 2024-09-19 10:38:42 UTC
# mode: r
+# plot the distribution of percent correct by class
+oob_dist_plot <- ggplot2::ggplot() +
+    ggdist::stat_halfeye(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(x = error, fill = class),
+        position = "identity", alpha = 0.5, density = ggdist::density_bounded(bandwidth = "nrd0", n = 50)
+    ) +
+    ggdist::stat_halfeye(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(x = error, fill = class),
+        position = "identity", alpha = 0.5, density = ggdist::density_bounded(bandwidth = "nrd0", n = 50)
+    ) +
+    titheme() +
+    ggplot2::theme(# add disconnected left and bottom axis lines
+        panel.grid.major = ggplot2::element_line(color = "black", linewidth = 0.5),
+        panel.grid.minor = ggplot2::element_line(color = "black"
+    )) +
+    ggplot2::labs(
+        title = "Distribution of percent correct by class",
+        x = "Percent correct", y = "Density"
+    )

# time: 2024-09-19 10:38:43 UTC
# mode: r
+oob_dist_plot

# time: 2024-09-19 10:40:31 UTC
# mode: r
+# plot the distribution of percent correct by class
+oob_dist_plot <- ggplot2::ggplot() +
+    ggdist::stat_halfeye(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(x = error, fill = class),
+        position = "identity", alpha = 0.5, density = ggdist::density_bounded(bandwidth = "nrd0", n = 50)
+    ) +
+    ggdist::stat_halfeye(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(x = error, fill = class),
+        position = "identity", alpha = 0.5, density = ggdist::density_bounded(bandwidth = "nrd0", n = 50)
+    ) +
+    titheme() +
+    ggplot2::theme(# add left and bottom axis lines
+        axis.line = ggplot2::element_line(color = "black", size = 0.5),
+        axis.ticks = ggplot2::element_line(color = "black", size = 0.5)
+
+    )+
+    ggplot2::labs(
+        title = "Distribution of percent correct by class",
+        x = "Percent correct", y = "Density"
+    )

# time: 2024-09-19 10:40:33 UTC
# mode: r
+oob_dist_plot

# time: 2024-09-19 10:44:37 UTC
# mode: r
+# plot the distribution of percent correct by class
+
+base_breaks_x <- function(x){
+  b <- pretty(x)
+  d <- data.frame(y=-Inf, yend=-Inf, x=min(b), xend=max(b))
+  list(ggplot2::geom_segment(data=d, ggplot2::aes(x=x, y=y, xend=xend, yend=yend), inherit.aes=FALSE),
+       ggplot2::scale_x_continuous(breaks=b))
+}

# time: 2024-09-19 10:44:38 UTC
# mode: r
+base_breaks_y <- function(x){
+  b <- pretty(x)
+  d <- data.frame(x=-Inf, xend=-Inf, y=min(b), yend=max(b))
+  list(ggplot2::geom_segment(data=d, ggplot2::aes(x=x, y=y, xend=xend, yend=yend), inherit.aes=FALSE),
+       ggplot2::scale_y_continuous(breaks=b))
+}

# time: 2024-09-19 10:45:26 UTC
# mode: r
+oob_dist_plot <- ggplot2::ggplot() +
+    ggdist::stat_halfeye(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(x = error, fill = class),
+        position = "identity", alpha = 0.5, density = ggdist::density_bounded(bandwidth = "nrd0", n = 50)
+    ) +
+    ggdist::stat_halfeye(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(x = error, fill = class),
+        position = "identity", alpha = 0.5, density = ggdist::density_bounded(bandwidth = "nrd0", n = 50)
+    ) +
+    titheme() +
+    +
+        base_breaks_x(oob_df$error) +
+    ggplot2::labs(
+        title = "Distribution of percent correct by class",
+        x = "Percent correct", y = "Density"
+    )

# time: 2024-09-19 10:45:32 UTC
# mode: r
+oob_dist_plot <- ggplot2::ggplot() +
+    ggdist::stat_halfeye(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(x = error, fill = class),
+        position = "identity", alpha = 0.5, density = ggdist::density_bounded(bandwidth = "nrd0", n = 50)
+    ) +
+    ggdist::stat_halfeye(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(x = error, fill = class),
+        position = "identity", alpha = 0.5, density = ggdist::density_bounded(bandwidth = "nrd0", n = 50)
+    ) +
+    titheme() +
+        base_breaks_x(oob_df$error) +
+    ggplot2::labs(
+        title = "Distribution of percent correct by class",
+        x = "Percent correct", y = "Density"
+    )

# time: 2024-09-19 10:45:33 UTC
# mode: r
+oob_dist_plot

# time: 2024-09-19 10:52:26 UTC
# mode: r
+oob_dist_plot <- ggplot2::ggplot() +
+    ggdist::stat_halfeye(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(x = error, fill = class),
+        position = "identity", alpha = 0.5, density = ggdist::density_bounded(bandwidth = "nrd0", n = 50)
+    ) +
+    ggdist::stat_halfeye(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(x = error, fill = class),
+        position = "identity", alpha = 0.5, density = ggdist::density_bounded(bandwidth = "nrd0", n = 50)
+    ) +
+    titheme() +
+    base_breaks_x(oob_df$error) +
+    base_breaks_y(0:1) +
+    ggplot2::labs(
+        title = "Distribution of percent correct by class",
+        x = "Percent correct", y = "Density"
+    )

# time: 2024-09-19 10:52:28 UTC
# mode: r
+oob_dist_plot

# time: 2024-09-19 10:53:28 UTC
# mode: r
+#' Custom ggplot2 theme
+#'
+#' This function returns a custom ggplot2 theme with a minimalistic design.
+#'
+#' @return A ggplot2 theme object.
+#' @import ggplot2
+#' @export
+#' @examples
+#' ggplot(mtcars, aes(x = wt, y = mpg)) +
+#'     geom_point() +
+#'     labs(title = "Custom ggplot2 theme", subtitle = "A minimalistic design") +
+#'     titheme()
+#'
+#' @export
+titheme <- function() {
+    ggplot2::theme(
+        text = ggplot2::element_text(
+            size = 12, family = "Roboto Condensed",
+            colour = "#272727"
+        ),
+        panel.grid.minor = ggplot2::element_blank(),
+        panel.grid.major.x = ggplot2::element_line(
+            color = "#e2e2e2",
+            linewidth = 0.5,
+            linetype = 1
+        ),
+        panel.grid.major.y = ggplot2::element_line(
+            color = "#e2e2e2",
+            linewidth = 0.5,
+            linetype = 1
+        ),
+        axis.line = ggplot2::element_blank(),
+        axis.ticks = ggplot2::element_blank(),
+        panel.border = ggplot2::element_rect(
+            fill = "transparent", colour = NA
+        ),
+        panel.background = ggplot2::element_rect(
+            fill = "transparent", colour = NA
+        ),
+        aspect.ratio = .8,
+        axis.title.y = ggplot2::element_text(
+            size = 12,
+            margin = ggplot2::margin(t = 0, r = 10, b = 0, l = 0)
+        ),
+        axis.title.x = ggplot2::element_text(
+            size = 12,
+            margin = ggplot2::margin(t = 10, r = 0, b = 0, l = 0)
+        ),
+        strip.background = ggplot2::element_rect(
+            fill = "transparent", colour = NA
+        ),
+        strip.text = ggplot2::element_text(
+            size = 12, margin = ggplot2::margin(t = 0, r = 0, b = 0, l = 10)
+        ),
+        plot.subtitle = ggplot2::element_text(
+            margin = ggplot2::margin(t = 0, r = 0, b = 5, l = 0)
+        ),
+        legend.background = ggplot2::element_rect(
+            fill = "transparent", colour = NA
+        ),
+        legend.box.background = ggplot2::element_rect(
+            fill = "transparent", colour = NA
+        ),
+        legend.key = ggplot2::element_rect(fill = "transparent", colour = NA),
+        legend.spacing.y = ggplot2::unit(0.3, "lines"),
+        # title to roboto condensed, size 12
+        plot.title = ggplot2::element_text(
+            size = 13, face = "bold", colour = "black",
+            margin = ggplot2::margin(t = 0, r = 0, b = 5, l = 0)
+        ),
+        plot.background = ggplot2::element_rect(
+            fill = "#f3f3f3", colour = NA
+        )
+    )
+}

# time: 2024-09-19 10:53:32 UTC
# mode: r
+oob_dist_plot <- ggplot2::ggplot() +
+    ggdist::stat_halfeye(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(x = error, fill = class),
+        position = "identity", alpha = 0.5, density = ggdist::density_bounded(bandwidth = "nrd0", n = 50)
+    ) +
+    ggdist::stat_halfeye(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(x = error, fill = class),
+        position = "identity", alpha = 0.5, density = ggdist::density_bounded(bandwidth = "nrd0", n = 50)
+    ) +
+    titheme() +
+    base_breaks_x(oob_df$error) +
+    base_breaks_y(0:1) +
+    ggplot2::labs(
+        title = "Distribution of percent correct by class",
+        x = "Percent correct", y = "Density"
+    )

# time: 2024-09-19 10:53:33 UTC
# mode: r
+oob_dist_plot

# time: 2024-09-19 10:53:59 UTC
# mode: r
+#' Custom ggplot2 theme
+#'
+#' This function returns a custom ggplot2 theme with a minimalistic design.
+#'
+#' @return A ggplot2 theme object.
+#' @import ggplot2
+#' @export
+#' @examples
+#' ggplot(mtcars, aes(x = wt, y = mpg)) +
+#'     geom_point() +
+#'     labs(title = "Custom ggplot2 theme", subtitle = "A minimalistic design") +
+#'     titheme()
+#'
+#' @export
+titheme <- function() {
+    ggplot2::theme(
+        text = ggplot2::element_text(
+            size = 12, family = "Roboto Condensed",
+            colour = "#272727"
+        ),
+        panel.grid.minor = ggplot2::element_blank(),
+        panel.grid.major.x = ggplot2::element_blank(),
+        panel.grid.major.y = ggplot2::element_blank(),
+        axis.line = ggplot2::element_blank(),
+        # axis.ticks = ggplot2::element_blank(),
+        panel.border = ggplot2::element_rect(
+            fill = "transparent", colour = NA
+        ),
+        panel.background = ggplot2::element_rect(
+            fill = "transparent", colour = NA
+        ),
+        aspect.ratio = .8,
+        axis.title.y = ggplot2::element_text(
+            size = 12,
+            margin = ggplot2::margin(t = 0, r = 10, b = 0, l = 0)
+        ),
+        axis.title.x = ggplot2::element_text(
+            size = 12,
+            margin = ggplot2::margin(t = 10, r = 0, b = 0, l = 0)
+        ),
+        strip.background = ggplot2::element_rect(
+            fill = "transparent", colour = NA
+        ),
+        strip.text = ggplot2::element_text(
+            size = 12, margin = ggplot2::margin(t = 0, r = 0, b = 0, l = 10)
+        ),
+        plot.subtitle = ggplot2::element_text(
+            margin = ggplot2::margin(t = 0, r = 0, b = 5, l = 0)
+        ),
+        legend.background = ggplot2::element_rect(
+            fill = "transparent", colour = NA
+        ),
+        legend.box.background = ggplot2::element_rect(
+            fill = "transparent", colour = NA
+        ),
+        legend.key = ggplot2::element_rect(fill = "transparent", colour = NA),
+        legend.spacing.y = ggplot2::unit(0.3, "lines"),
+        # title to roboto condensed, size 12
+        plot.title = ggplot2::element_text(
+            size = 13, face = "bold", colour = "black",
+            margin = ggplot2::margin(t = 0, r = 0, b = 5, l = 0)
+        ),
+        plot.background = ggplot2::element_rect(
+            fill = "#f3f3f3", colour = NA
+        )
+    )
+}

# time: 2024-09-19 10:54:02 UTC
# mode: r
+oob_dist_plot <- ggplot2::ggplot() +
+    ggdist::stat_halfeye(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(x = error, fill = class),
+        position = "identity", alpha = 0.5, density = ggdist::density_bounded(bandwidth = "nrd0", n = 50)
+    ) +
+    ggdist::stat_halfeye(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(x = error, fill = class),
+        position = "identity", alpha = 0.5, density = ggdist::density_bounded(bandwidth = "nrd0", n = 50)
+    ) +
+    titheme() +
+    base_breaks_x(oob_df$error) +
+    base_breaks_y(0:1) +
+    ggplot2::labs(
+        title = "Distribution of percent correct by class",
+        x = "Percent correct", y = "Density"
+    )

# time: 2024-09-19 10:54:03 UTC
# mode: r
+oob_dist_plot

# time: 2024-09-19 10:56:17 UTC
# mode: r
+# Save the plot
+ggplot2::ggsave(file.path(config$path$figures, "oob_dist_plot.jpg"),
+    plot =
+        oob_dist_plot,
+    width = 8,
+    height = 6
+)

# time: 2024-09-19 10:59:20 UTC
# mode: r
+oob_dist_plot <- ggplot2::ggplot() +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(x = error, fill = class),
+        position = "identity", alpha = 0.5, density = ggdist::density_bounded(bandwidth = "nrd0", n = 50)
+    ) +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(x = error, fill = class),
+        position = "identity", alpha = 0.5, density = ggdist::density_bounded(bandwidth = "nrd0", n = 50)
+    ) +
+    titheme() +
+    base_breaks_x(oob_df$error) +
+    base_breaks_y(0:1) +
+    ggplot2::labs(
+        title = "Distribution of percent correct by class",
+        x = "Percent correct", y = "Density"
+    )

# time: 2024-09-19 10:59:22 UTC
# mode: r
+# Save the plot
+ggplot2::ggsave(file.path(config$path$figures, "oob_dist_plot.jpg"),
+    plot =
+        oob_dist_plot,
+    width = 8,
+    height = 6
+)

# time: 2024-09-19 11:01:15 UTC
# mode: r
+oob_dist_plot <- ggplot2::ggplot() +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(x = error, fill = class),
+        position = "identity", alpha = 0.5, density = ggdist::density_bounded(bandwidth = "nrd0", n = 50)
+    ) +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(x = error, fill = class),
+        position = "identity", alpha = 0.5, density = ggdist::density_bounded(bandwidth = "nrd0", n = 50)
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(x = error, fill = class),
+        position = position_dodge(width = .4, preserve = "single")
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(x = error, fill = class),
+        position = position_dodge(width = .4, preserve = "single")
+    ) +
+    titheme() +
+    base_breaks_x(oob_df$error) +
+    base_breaks_y(0:1) +
+    ggplot2::labs(
+        title = "Distribution of percent correct by class",
+        x = "Percent correct", y = "Density"
+    )

# time: 2024-09-19 11:01:27 UTC
# mode: r
+oob_dist_plot <- ggplot2::ggplot() +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(x = error, fill = class),
+        position = "identity", alpha = 0.5, density = ggdist::density_bounded(bandwidth = "nrd0", n = 50)
+    ) +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(x = error, fill = class),
+        position = "identity", alpha = 0.5, density = ggdist::density_bounded(bandwidth = "nrd0", n = 50)
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(x = error, fill = class),
+        position = ggplot2::position_dodge(width = .4, preserve = "single")
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(x = error, fill = class),
+        position = ggplot2::position_dodge(width = .4, preserve = "single")
+    ) +
+    titheme() +
+    base_breaks_x(oob_df$error) +
+    base_breaks_y(0:1) +
+    ggplot2::labs(
+        title = "Distribution of percent correct by class",
+        x = "Percent correct", y = "Density"
+    )

# time: 2024-09-19 11:01:28 UTC
# mode: r
+# Save the plot
+ggplot2::ggsave(file.path(config$path$figures, "oob_dist_plot.jpg"),
+    plot =
+        oob_dist_plot,
+    width = 8,
+    height = 6
+)

# time: 2024-09-19 11:01:57 UTC
# mode: r
+oob_dist_plot <- ggplot2::ggplot() +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(x = error, fill = class),
+        position = "identity", alpha = 0.5, density = ggdist::density_bounded(bandwidth = "nrd0", n = 50)
+    ) +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(x = error, fill = class),
+        position = "identity", alpha = 0.5, density = ggdist::density_bounded(bandwidth = "nrd0", n = 50)
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(x = error, fill = class),
+        position = ggplot2::position_dodge(width = .2, preserve = "single")
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(x = error, fill = class),
+        position = ggplot2::position_dodge(width = .2, preserve = "single")
+    ) +
+    titheme() +
+    base_breaks_x(oob_df$error) +
+    base_breaks_y(0:1) +
+    ggplot2::labs(
+        title = "Distribution of percent correct by class",
+        x = "Percent correct", y = "Density"
+    )

# time: 2024-09-19 11:02:03 UTC
# mode: r
+oob_dist_plot <- ggplot2::ggplot() +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(x = error, fill = class),
+        position = "identity", alpha = 0.5, density = ggdist::density_bounded(bandwidth = "nrd0", n = 50)
+    ) +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(x = error, fill = class),
+        position = "identity", alpha = 0.5, density = ggdist::density_bounded(bandwidth = "nrd0", n = 50)
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(x = error, color = class),
+        position = ggplot2::position_dodge(width = .2, preserve = "single")
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(x = error, color = class),
+        position = ggplot2::position_dodge(width = .2, preserve = "single")
+    ) +
+    titheme() +
+    base_breaks_x(oob_df$error) +
+    base_breaks_y(0:1) +
+    ggplot2::labs(
+        title = "Distribution of percent correct by class",
+        x = "Percent correct", y = "Density"
+    )

# time: 2024-09-19 11:02:08 UTC
# mode: r
+# Save the plot
+ggplot2::ggsave(file.path(config$path$figures, "oob_dist_plot.jpg"),
+    plot =
+        oob_dist_plot,
+    width = 8,
+    height = 6
+)

# time: 2024-09-19 11:03:05 UTC
# mode: r
+oob_dist_plot <- ggplot2::ggplot() +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(x = error, fill = class),
+        position = "identity", alpha = 0.5, density = ggdist::density_bounded(bandwidth = "nrd0", n = 50)
+    ) +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(x = error),
+        position = "identity", alpha = 0.5, density = ggdist::density_bounded(bandwidth = "nrd0", n = 50)
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(x = error, color = class),
+        position = ggplot2::position_dodge(width = .2, preserve = "single")
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(x = error, color = class),
+        position = ggplot2::position_dodge(width = .2, preserve = "single")
+    ) +
+    titheme() +
+    base_breaks_x(oob_df$error) +
+    base_breaks_y(0:1) +
+    ggplot2::labs(
+        title = "Distribution of percent correct by class",
+        x = "Percent correct", y = "Density"
+    )

# time: 2024-09-19 11:03:05 UTC
# mode: r
+# Save the plot
+ggplot2::ggsave(file.path(config$path$figures, "oob_dist_plot.jpg"),
+    plot =
+        oob_dist_plot,
+    width = 8,
+    height = 6
+)

# time: 2024-09-19 11:03:14 UTC
# mode: r
+oob_dist_plot <- ggplot2::ggplot() +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(x = error, fill = class),
+        position = "identity", alpha = 0.5, density = ggdist::density_bounded(bandwidth = "nrd0", n = 50)
+    ) +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(x = error),
+        position = "identity", alpha = 0.5, density = ggdist::density_bounded(bandwidth = "nrd0", n = 50)
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(x = error, color = class),
+        position = ggplot2::position_dodge(width = .2, preserve = "single")
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(x = error),
+        position = ggplot2::position_dodge(width = .2, preserve = "single")
+    ) +
+    titheme() +
+    base_breaks_x(oob_df$error) +
+    base_breaks_y(0:1) +
+    ggplot2::labs(
+        title = "Distribution of percent correct by class",
+        x = "Percent correct", y = "Density"
+    )

# time: 2024-09-19 11:03:15 UTC
# mode: r
+# Save the plot
+ggplot2::ggsave(file.path(config$path$figures, "oob_dist_plot.jpg"),
+    plot =
+        oob_dist_plot,
+    width = 8,
+    height = 6
+)

# time: 2024-09-19 11:05:00 UTC
# mode: r
+oob_dist_plot <- ggplot2::ggplot() +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(x = error, fill = class),
+        position = "identity", alpha = 0.5, density = ggdist::density_bounded(bandwidth = "nrd0", n = 50)
+    ) +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(x = error),
+        position = "identity", alpha = 0.5, density = ggdist::density_bounded(bandwidth = "nrd0", n = 50)
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(x = error, color = class),
+        position = ggplot2::position_dodge(width = .2, preserve = "single", justification = 0.1, .width = 0.5)
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(x = error),
+        position = ggplot2::position_dodge(width = .2, preserve = "single", justification = 0.1, .width = 0.5)
+    ) +
+    titheme() +
+    base_breaks_x(oob_df$error) +
+    base_breaks_y(0:1) +
+    ggplot2::labs(
+        title = "Distribution of percent correct by class",
+        x = "Percent correct", y = "Density"
+    )

# time: 2024-09-19 11:05:07 UTC
# mode: r
+oob_dist_plot

# time: 2024-09-19 12:03:15 UTC
# mode: r
+oob_dist_plot <- ggplot2::ggplot() +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(x = error, fill = class),
+        position = "identity", alpha = 0.5, density =
+            ggdist::density_bounded(bandwidth = "nrd0", n = 50)
+    ) +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(x = error),
+        position = "identity", alpha = 0.5,
+        density = ggdist::density_bounded(bandwidth = "nrd0", n = 50)
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(x = error, color = class),
+        position = ggplot2::position_dodge(
+            width = .2, preserve = "single"),
+            justification = 0.1, .width = 0.5
+        )

# time: 2024-09-19 12:03:16 UTC
# mode: r
+) +

# time: 2024-09-19 12:03:29 UTC
# mode: r
+oob_dist_plot <- ggplot2::ggplot() +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(x = error, fill = class),
+        position = "identity", alpha = 0.5, density =
+            ggdist::density_bounded(bandwidth = "nrd0", n = 50)
+    ) +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(x = error),
+        position = "identity", alpha = 0.5,
+        density = ggdist::density_bounded(bandwidth = "nrd0", n = 50)
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(x = error, color = class),
+        position = ggplot2::position_dodge(
+            width = .2, preserve = "single"),
+            justification = 0.1, .width = 0.5
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(x = error),
+        position = ggplot2::position_dodge(
+            width = .2, preserve = "single"),
+            justification = 0.1, .width = 0.5
+        )

# time: 2024-09-19 12:03:50 UTC
# mode: r
+base_breaks_y <- function(x) {
+    b <- pretty(x)
+    d <- data.frame(x = -Inf, xend = -Inf, y = min(b), yend = max(b))
+    list(
+        ggplot2::geom_segment(data = d, ggplot2::aes(x = x, y = y, xend = xend, yend = yend), inherit.aes = FALSE),
+        ggplot2::scale_y_continuous(breaks = b)
+    )
+}

# time: 2024-09-19 12:03:51 UTC
# mode: r
+oob_dist_plot <- ggplot2::ggplot() +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(x = error, fill = class),
+        position = "identity", alpha = 0.5, density =
+            ggdist::density_bounded(bandwidth = "nrd0", n = 50)
+    ) +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(x = error),
+        position = "identity", alpha = 0.5,
+        density = ggdist::density_bounded(bandwidth = "nrd0", n = 50)
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(x = error, color = class),
+        position = ggplot2::position_dodge(
+            width = .2, preserve = "single"),
+            justification = 0.1, .width = 0.5
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(x = error),
+        position = ggplot2::position_dodge(
+            width = .2, preserve = "single"),
+            justification = 0.1, .width = 0.5
+        ) +
+    titheme() +
+    base_breaks_x(oob_df$error) +
+    base_breaks_y(0:1) +
+    ggplot2::labs(
+        title = "Distribution of percent correct by class",
+        x = "Percent correct", y = "Density"
+    )

# time: 2024-09-19 12:03:52 UTC
# mode: r
+# Save the plot
+ggplot2::ggsave(file.path(config$path$figures, "oob_dist_plot.jpg"),
+    plot =
+        oob_dist_plot,
+    width = 8,
+    height = 6
+)

# time: 2024-09-19 12:04:08 UTC
# mode: r
+oob_dist_plot <- ggplot2::ggplot() +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(x = error, fill = class),
+        position = "identity", alpha = 0.5, density =
+            ggdist::density_bounded(bandwidth = "nrd0", n = 50)
+    ) +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(x = error),
+        position = "identity", alpha = 0.5,
+        density = ggdist::density_bounded(bandwidth = "nrd0", n = 50)
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(x = error, color = class),
+        position = ggplot2::position_dodge(
+            width = .2, preserve = "single"),
+            justification = 0.4, .width = 0.5
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(x = error),
+        position = ggplot2::position_dodge(
+            width = .2, preserve = "single"),
+            justification = 0.4, .width = 0.5
+        ) +
+    titheme() +
+    base_breaks_x(oob_df$error) +
+    base_breaks_y(0:1) +
+    ggplot2::labs(
+        title = "Distribution of percent correct by class",
+        x = "Percent correct", y = "Density"
+    )

# time: 2024-09-19 12:04:08 UTC
# mode: r
+# Save the plot
+ggplot2::ggsave(file.path(config$path$figures, "oob_dist_plot.jpg"),
+    plot =
+        oob_dist_plot,
+    width = 8,
+    height = 6
+)

# time: 2024-09-19 12:04:20 UTC
# mode: r
+oob_dist_plot <- ggplot2::ggplot() +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(x = error, fill = class),
+        position = "identity", alpha = 0.5, density =
+            ggdist::density_bounded(bandwidth = "nrd0", n = 50)
+    ) +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(x = error),
+        position = "identity", alpha = 0.5,
+        density = ggdist::density_bounded(bandwidth = "nrd0", n = 50)
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(x = error, color = class),
+        position = ggplot2::position_dodge(
+            width = .2, preserve = "single"),
+            justification = -0.1, .width = 0.5
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(x = error),
+        position = ggplot2::position_dodge(
+            width = .2, preserve = "single"),
+            justification = -0.1, .width = 0.5
+        ) +
+    titheme() +
+    base_breaks_x(oob_df$error) +
+    base_breaks_y(0:1) +
+    ggplot2::labs(
+        title = "Distribution of percent correct by class",
+        x = "Percent correct", y = "Density"
+    )

# time: 2024-09-19 12:04:20 UTC
# mode: r
+# Save the plot
+ggplot2::ggsave(file.path(config$path$figures, "oob_dist_plot.jpg"),
+    plot =
+        oob_dist_plot,
+    width = 8,
+    height = 6
+)

# time: 2024-09-19 12:04:50 UTC
# mode: r
+oob_dist_plot <- ggplot2::ggplot() +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(x = error, fill = class),
+        position = "identity", alpha = 0.5, density =
+            ggdist::density_bounded(bandwidth = "nrd0", n = 50)
+    ) +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(x = error),
+        position = "identity", alpha = 0.5,
+        density = ggdist::density_bounded(bandwidth = "nrd0", n = 50)
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(x = error, color = class),
+        position = ggplot2::position_dodge(
+            width = .2, preserve = "single"),
+            justification = 0.5, .width = 0.1
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(x = error),
+        position = ggplot2::position_dodge(
+            width = .2, preserve = "single"),
+            justification = 0.5, .width = 0.1
+        ) +
+    titheme() +
+    base_breaks_x(oob_df$error) +
+    base_breaks_y(0:1) +
+    ggplot2::labs(
+        title = "Distribution of percent correct by class",
+        x = "Percent correct", y = "Density"
+    )

# time: 2024-09-19 12:04:51 UTC
# mode: r
+# Save the plot
+ggplot2::ggsave(file.path(config$path$figures, "oob_dist_plot.jpg"),
+    plot =
+        oob_dist_plot,
+    width = 8,
+    height = 6
+)

# time: 2024-09-19 12:05:07 UTC
# mode: r
+oob_dist_plot <- ggplot2::ggplot() +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(x = error, fill = class),
+        position = "identity", alpha = 0.5, density =
+            ggdist::density_bounded(bandwidth = "nrd0", n = 50)
+    ) +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(x = error),
+        position = "identity", alpha = 0.5,
+        density = ggdist::density_bounded(bandwidth = "nrd0", n = 50)
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(x = error, color = class),
+        position = ggplot2::position_dodge(
+            width = .2, preserve = "single")
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(x = error),
+        position = ggplot2::position_dodge(
+            width = .2, preserve = "single")
+        ) +
+    titheme() +
+    base_breaks_x(oob_df$error) +
+    base_breaks_y(0:1) +
+    ggplot2::labs(
+        title = "Distribution of percent correct by class",
+        x = "Percent correct", y = "Density"
+    )

# time: 2024-09-19 12:05:08 UTC
# mode: r
+# Save the plot
+ggplot2::ggsave(file.path(config$path$figures, "oob_dist_plot.jpg"),
+    plot =
+        oob_dist_plot,
+    width = 8,
+    height = 6
+)

# time: 2024-09-19 12:05:38 UTC
# mode: r
+oob_dist_plot <- ggplot2::ggplot() +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(x = error, fill = class),
+        position = "identity", alpha = 0.5, density =
+            ggdist::density_bounded(bandwidth = "nrd0", n = 50)
+    ) +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(x = error),
+        position = "identity", alpha = 0.5,
+        density = ggdist::density_bounded(bandwidth = "nrd0", n = 50)
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(x = error, color = class),
+        position = ggplot2::position_dodge(
+            width = .2, preserve = "single")
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(x = error),
+        position = ggplot2::position_dodge(
+            width = .2, preserve = "single")
+        ) +
+    titheme() +
+    base_breaks_x(oob_df$error) +
+    base_breaks_y(0:1) +
+    # push the y axis down
+    ggplot2::theme(axis.title.y = ggplot2::element_text(
+        size = 12,
+        margin = ggplot2::margin(t = 0, r = 10, b = 0, l = 0)
+    )) +
+    ggplot2::labs(
+        title = "Distribution of percent correct by class",
+        x = "Percent correct", y = "Density"
+    )

# time: 2024-09-19 12:05:39 UTC
# mode: r
+# Save the plot
+ggplot2::ggsave(file.path(config$path$figures, "oob_dist_plot.jpg"),
+    plot =
+        oob_dist_plot,
+    width = 8,
+    height = 6
+)

# time: 2024-09-19 12:06:55 UTC
# mode: r
+oob_dist_plot <- ggplot2::ggplot() +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(x = error, fill = class),
+        position = "identity", alpha = 0.5, density =
+            ggdist::density_bounded(bandwidth = "nrd0", n = 50)
+    ) +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(x = error),
+        position = "identity", alpha = 0.5,
+        density = ggdist::density_bounded(bandwidth = "nrd0", n = 50)
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(x = error, color = class),
+        position = ggplot2::position_dodge(
+            width = .2, preserve = "single")
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(x = error),
+        position = ggplot2::position_dodge(
+            width = .2, preserve = "single")
+        ) +
+    titheme() +
+    base_breaks_x(oob_df$error) +
+    base_breaks_y(0:1) +
+    ggplot2::scale_y_discrete(expand = expansion(add = 0.1))

# time: 2024-09-19 12:07:07 UTC
# mode: r
+oob_dist_plot <- ggplot2::ggplot() +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(x = error, fill = class),
+        position = "identity", alpha = 0.5, density =
+            ggdist::density_bounded(bandwidth = "nrd0", n = 50)
+    ) +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(x = error),
+        position = "identity", alpha = 0.5,
+        density = ggdist::density_bounded(bandwidth = "nrd0", n = 50)
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(x = error, color = class),
+        position = ggplot2::position_dodge(
+            width = .2, preserve = "single")
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(x = error),
+        position = ggplot2::position_dodge(
+            width = .2, preserve = "single")
+        ) +
+    titheme() +
+    base_breaks_x(oob_df$error) +
+    base_breaks_y(0:1) +
+    ggplot2::scale_y_discrete(expand = ggplot2::expansion(add = 0.1)) +
+    ggplot2::labs(
+        title = "Distribution of percent correct by class",
+        x = "Percent correct", y = "Density"
+    )

# time: 2024-09-19 12:07:08 UTC
# mode: r
+# Save the plot
+ggplot2::ggsave(file.path(config$path$figures, "oob_dist_plot.jpg"),
+    plot =
+        oob_dist_plot,
+    width = 8,
+    height = 6
+)

# time: 2024-09-19 12:07:47 UTC
# mode: r
+base_breaks_y <- function(x) {
+    b <- pretty(x)
+    d <- data.frame(x = -Inf, xend = -Inf, y = min(b), yend = max(b))
+    list(
+        ggplot2::geom_segment(data = d, ggplot2::aes(x = x, y = y, xend = xend, yend = yend), inherit.aes = FALSE),
+        ggplot2::scale_y_continuous(breaks = b, expand = ggplot2::expansion(add = 0.1))
+    )
+}

# time: 2024-09-19 12:07:52 UTC
# mode: r
+oob_dist_plot <- ggplot2::ggplot() +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(x = error, fill = class),
+        position = "identity", alpha = 0.5, density =
+            ggdist::density_bounded(bandwidth = "nrd0", n = 50)
+    ) +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(x = error),
+        position = "identity", alpha = 0.5,
+        density = ggdist::density_bounded(bandwidth = "nrd0", n = 50)
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(x = error, color = class),
+        position = ggplot2::position_dodge(
+            width = .2, preserve = "single")
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(x = error),
+        position = ggplot2::position_dodge(
+            width = .2, preserve = "single")
+        ) +
+    titheme() +
+    base_breaks_x(oob_df$error) +
+    base_breaks_y(0:1) +
+    ggplot2::labs(
+        title = "Distribution of percent correct by class",
+        x = "Percent correct", y = "Density"
+    )

# time: 2024-09-19 12:07:53 UTC
# mode: r
+# Save the plot
+ggplot2::ggsave(file.path(config$path$figures, "oob_dist_plot.jpg"),
+    plot =
+        oob_dist_plot,
+    width = 8,
+    height = 6
+)

# time: 2024-09-19 12:08:03 UTC
# mode: r
+base_breaks_y <- function(x) {
+    b <- pretty(x)
+    d <- data.frame(x = -Inf, xend = -Inf, y = min(b), yend = max(b))
+    list(
+        ggplot2::geom_segment(data = d, ggplot2::aes(x = x, y = y, xend = xend, yend = yend), inherit.aes = FALSE),
+        ggplot2::scale_y_continuous(breaks = b, expand = ggplot2::expansion(add = 0.6))
+    )
+}

# time: 2024-09-19 12:08:04 UTC
# mode: r
+oob_dist_plot <- ggplot2::ggplot() +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(x = error, fill = class),
+        position = "identity", alpha = 0.5, density =
+            ggdist::density_bounded(bandwidth = "nrd0", n = 50)
+    ) +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(x = error),
+        position = "identity", alpha = 0.5,
+        density = ggdist::density_bounded(bandwidth = "nrd0", n = 50)
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(x = error, color = class),
+        position = ggplot2::position_dodge(
+            width = .2, preserve = "single")
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(x = error),
+        position = ggplot2::position_dodge(
+            width = .2, preserve = "single")
+        ) +
+    titheme() +
+    base_breaks_x(oob_df$error) +
+    base_breaks_y(0:1) +
+    ggplot2::labs(
+        title = "Distribution of percent correct by class",
+        x = "Percent correct", y = "Density"
+    )

# time: 2024-09-19 12:08:04 UTC
# mode: r
+# Save the plot
+ggplot2::ggsave(file.path(config$path$figures, "oob_dist_plot.jpg"),
+    plot =
+        oob_dist_plot,
+    width = 8,
+    height = 6
+)

# time: 2024-09-19 12:08:23 UTC
# mode: r
+base_breaks_y <- function(x) {
+    b <- pretty(x)
+    d <- data.frame(x = -Inf, xend = -Inf, y = min(b), yend = max(b))
+    list(
+        ggplot2::geom_segment(data = d, ggplot2::aes(x = x, y = y, xend = xend, yend = yend), inherit.aes = FALSE),
+        ggplot2::scale_y_continuous(breaks = b, expand = ggplot2::expansion(add = -0.6))
+    )
+}

# time: 2024-09-19 12:08:23 UTC
# mode: r
+oob_dist_plot <- ggplot2::ggplot() +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(x = error, fill = class),
+        position = "identity", alpha = 0.5, density =
+            ggdist::density_bounded(bandwidth = "nrd0", n = 50)
+    ) +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(x = error),
+        position = "identity", alpha = 0.5,
+        density = ggdist::density_bounded(bandwidth = "nrd0", n = 50)
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(x = error, color = class),
+        position = ggplot2::position_dodge(
+            width = .2, preserve = "single")
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(x = error),
+        position = ggplot2::position_dodge(
+            width = .2, preserve = "single")
+        ) +
+    titheme() +
+    base_breaks_x(oob_df$error) +
+    base_breaks_y(0:1) +
+    ggplot2::labs(
+        title = "Distribution of percent correct by class",
+        x = "Percent correct", y = "Density"
+    )

# time: 2024-09-19 12:08:24 UTC
# mode: r
+# Save the plot
+ggplot2::ggsave(file.path(config$path$figures, "oob_dist_plot.jpg"),
+    plot =
+        oob_dist_plot,
+    width = 8,
+    height = 6
+)

# time: 2024-09-19 12:08:30 UTC
# mode: r
+base_breaks_y <- function(x) {
+    b <- pretty(x)
+    d <- data.frame(x = -Inf, xend = -Inf, y = min(b), yend = max(b))
+    list(
+        ggplot2::geom_segment(data = d, ggplot2::aes(x = x, y = y, xend = xend, yend = yend), inherit.aes = FALSE),
+        ggplot2::scale_y_continuous(breaks = b, expand = ggplot2::expansion(add = -0.1))
+    )
+}

# time: 2024-09-19 12:08:31 UTC
# mode: r
+oob_dist_plot <- ggplot2::ggplot() +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(x = error, fill = class),
+        position = "identity", alpha = 0.5, density =
+            ggdist::density_bounded(bandwidth = "nrd0", n = 50)
+    ) +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(x = error),
+        position = "identity", alpha = 0.5,
+        density = ggdist::density_bounded(bandwidth = "nrd0", n = 50)
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(x = error, color = class),
+        position = ggplot2::position_dodge(
+            width = .2, preserve = "single")
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(x = error),
+        position = ggplot2::position_dodge(
+            width = .2, preserve = "single")
+        ) +
+    titheme() +
+    base_breaks_x(oob_df$error) +
+    base_breaks_y(0:1) +
+    ggplot2::labs(
+        title = "Distribution of percent correct by class",
+        x = "Percent correct", y = "Density"
+    )

# time: 2024-09-19 12:08:31 UTC
# mode: r
+# Save the plot
+ggplot2::ggsave(file.path(config$path$figures, "oob_dist_plot.jpg"),
+    plot =
+        oob_dist_plot,
+    width = 8,
+    height = 6
+)

# time: 2024-09-19 12:09:39 UTC
# mode: r
+list(
+        ggplot2::geom_segment(data = d, ggplot2::aes(x = x, y = y, xend = xend, yend = yend), inherit.aes = FALSE),
+        ggplot2::scale_y_continuous(breaks = b, expand = ggplot2::expansion(mult = c(0.05, 0)))
+    )

# time: 2024-09-19 12:09:47 UTC
# mode: r
+base_breaks_y <- function(x) {
+    b <- pretty(x)
+    d <- data.frame(x = -Inf, xend = -Inf, y = min(b), yend = max(b))
+    list(
+        ggplot2::geom_segment(data = d, ggplot2::aes(x = x, y = y, xend = xend, yend = yend), inherit.aes = FALSE),
+        ggplot2::scale_y_continuous(breaks = b, expand = ggplot2::expansion(mult = c(0.05, 0)))
+    )
+}

# time: 2024-09-19 12:09:48 UTC
# mode: r
+oob_dist_plot <- ggplot2::ggplot() +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(x = error, fill = class),
+        position = "identity", alpha = 0.5, density =
+            ggdist::density_bounded(bandwidth = "nrd0", n = 50)
+    ) +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(x = error),
+        position = "identity", alpha = 0.5,
+        density = ggdist::density_bounded(bandwidth = "nrd0", n = 50)
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(x = error, color = class),
+        position = ggplot2::position_dodge(
+            width = .2, preserve = "single")
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(x = error),
+        position = ggplot2::position_dodge(
+            width = .2, preserve = "single")
+        ) +
+    titheme() +
+    base_breaks_x(oob_df$error) +
+    base_breaks_y(0:1) +
+    ggplot2::labs(
+        title = "Distribution of percent correct by class",
+        x = "Percent correct", y = "Density"
+    )

# time: 2024-09-19 12:09:49 UTC
# mode: r
+# Save the plot
+ggplot2::ggsave(file.path(config$path$figures, "oob_dist_plot.jpg"),
+    plot =
+        oob_dist_plot,
+    width = 8,
+    height = 6
+)

# time: 2024-09-19 12:10:05 UTC
# mode: r
+base_breaks_y <- function(x) {
+    b <- pretty(x)
+    d <- data.frame(x = -Inf, xend = -Inf, y = min(b), yend = max(b))
+    list(
+        ggplot2::geom_segment(data = d, ggplot2::aes(x = x, y = y, xend = xend, yend = yend), inherit.aes = FALSE),
+        ggplot2::scale_y_continuous(breaks = b, expand = ggplot2::expansion(add = c(0.2, 0)))
+    )
+}

# time: 2024-09-19 12:10:06 UTC
# mode: r
+oob_dist_plot <- ggplot2::ggplot() +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(x = error, fill = class),
+        position = "identity", alpha = 0.5, density =
+            ggdist::density_bounded(bandwidth = "nrd0", n = 50)
+    ) +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(x = error),
+        position = "identity", alpha = 0.5,
+        density = ggdist::density_bounded(bandwidth = "nrd0", n = 50)
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(x = error, color = class),
+        position = ggplot2::position_dodge(
+            width = .2, preserve = "single")
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(x = error),
+        position = ggplot2::position_dodge(
+            width = .2, preserve = "single")
+        ) +
+    titheme() +
+    base_breaks_x(oob_df$error) +
+    base_breaks_y(0:1) +
+    ggplot2::labs(
+        title = "Distribution of percent correct by class",
+        x = "Percent correct", y = "Density"
+    )

# time: 2024-09-19 12:10:06 UTC
# mode: r
+# Save the plot
+ggplot2::ggsave(file.path(config$path$figures, "oob_dist_plot.jpg"),
+    plot =
+        oob_dist_plot,
+    width = 8,
+    height = 6
+)

# time: 2024-09-19 12:10:13 UTC
# mode: r
+base_breaks_y <- function(x) {
+    b <- pretty(x)
+    d <- data.frame(x = -Inf, xend = -Inf, y = min(b), yend = max(b))
+    list(
+        ggplot2::geom_segment(data = d, ggplot2::aes(x = x, y = y, xend = xend, yend = yend), inherit.aes = FALSE),
+        ggplot2::scale_y_continuous(breaks = b, expand = ggplot2::expansion(add = c(-0.2, 0)))
+    )
+}

# time: 2024-09-19 12:10:13 UTC
# mode: r
+oob_dist_plot <- ggplot2::ggplot() +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(x = error, fill = class),
+        position = "identity", alpha = 0.5, density =
+            ggdist::density_bounded(bandwidth = "nrd0", n = 50)
+    ) +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(x = error),
+        position = "identity", alpha = 0.5,
+        density = ggdist::density_bounded(bandwidth = "nrd0", n = 50)
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(x = error, color = class),
+        position = ggplot2::position_dodge(
+            width = .2, preserve = "single")
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(x = error),
+        position = ggplot2::position_dodge(
+            width = .2, preserve = "single")
+        ) +
+    titheme() +
+    base_breaks_x(oob_df$error) +
+    base_breaks_y(0:1) +
+    ggplot2::labs(
+        title = "Distribution of percent correct by class",
+        x = "Percent correct", y = "Density"
+    )

# time: 2024-09-19 12:10:14 UTC
# mode: r
+# Save the plot
+ggplot2::ggsave(file.path(config$path$figures, "oob_dist_plot.jpg"),
+    plot =
+        oob_dist_plot,
+    width = 8,
+    height = 6
+)

# time: 2024-09-19 12:10:43 UTC
# mode: r
+base_breaks_y <- function(x) {
+    b <- pretty(x)
+    d <- data.frame(x = -Inf, xend = -Inf, y = min(b), yend = max(b))
+    list(
+        ggplot2::geom_segment(data = d, ggplot2::aes(x = x, y = y, xend = xend, yend = yend), inherit.aes = FALSE),
+        ggplot2::scale_y_continuous(breaks = b, expand = ggplot2::expansion(add = c(-0.1, 0.05)))
+    )
+}

# time: 2024-09-19 12:10:43 UTC
# mode: r
+oob_dist_plot <- ggplot2::ggplot() +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(x = error, fill = class),
+        position = "identity", alpha = 0.5, density =
+            ggdist::density_bounded(bandwidth = "nrd0", n = 50)
+    ) +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(x = error),
+        position = "identity", alpha = 0.5,
+        density = ggdist::density_bounded(bandwidth = "nrd0", n = 50)
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(x = error, color = class),
+        position = ggplot2::position_dodge(
+            width = .2, preserve = "single")
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(x = error),
+        position = ggplot2::position_dodge(
+            width = .2, preserve = "single")
+        ) +
+    titheme() +
+    base_breaks_x(oob_df$error) +
+    base_breaks_y(0:1) +
+    ggplot2::labs(
+        title = "Distribution of percent correct by class",
+        x = "Percent correct", y = "Density"
+    )

# time: 2024-09-19 12:10:44 UTC
# mode: r
+# Save the plot
+ggplot2::ggsave(file.path(config$path$figures, "oob_dist_plot.jpg"),
+    plot =
+        oob_dist_plot,
+    width = 8,
+    height = 6
+)

# time: 2024-09-19 12:11:44 UTC
# mode: r
+# plot the distribution of percent correct by class
+
+base_breaks_x <- function(x, expand = ggplot2::expansion(add = c(0, 0))) {
+    b <- pretty(x)
+    d <- data.frame(y = -Inf, yend = -Inf, x = min(b), xend = max(b))
+    list(
+        ggplot2::geom_segment(data = d, ggplot2::aes(x = x, y = y, xend = xend, yend = yend), inherit.aes = FALSE),
+        ggplot2::scale_x_continuous(breaks = b, expand = expand)
+    )
+}

# time: 2024-09-19 12:11:45 UTC
# mode: r
+base_breaks_y <- function(x, expand = ggplot2::expansion(add = c(-0.1, 0))) {
+    b <- pretty(x)
+    d <- data.frame(x = -Inf, xend = -Inf, y = min(b), yend = max(b))
+    list(
+        ggplot2::geom_segment(data = d, ggplot2::aes(x = x, y = y, xend = xend, yend = yend), inherit.aes = FALSE),
+        ggplot2::scale_y_continuous(breaks = b, expand = expand)
+    )
+}

# time: 2024-09-19 12:11:47 UTC
# mode: r
+oob_dist_plot <- ggplot2::ggplot() +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(x = error, fill = class),
+        position = "identity", alpha = 0.5, density =
+            ggdist::density_bounded(bandwidth = "nrd0", n = 50)
+    ) +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(x = error),
+        position = "identity", alpha = 0.5,
+        density = ggdist::density_bounded(bandwidth = "nrd0", n = 50)
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(x = error, color = class),
+        position = ggplot2::position_dodge(
+            width = .2, preserve = "single")
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(x = error),
+        position = ggplot2::position_dodge(
+            width = .2, preserve = "single")
+        ) +
+    titheme() +
+    base_breaks_x(oob_df$error) +
+    base_breaks_y(0:1) +
+    ggplot2::labs(
+        title = "Distribution of percent correct by class",
+        x = "Percent correct", y = "Density"
+    )

# time: 2024-09-19 12:11:48 UTC
# mode: r
+# Save the plot
+ggplot2::ggsave(file.path(config$path$figures, "oob_dist_plot.jpg"),
+    plot =
+        oob_dist_plot,
+    width = 8,
+    height = 6
+)

# time: 2024-09-19 12:12:13 UTC
# mode: r
+oob_dist_plot <- ggplot2::ggplot() +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(x = error, fill = class),
+        position = "identity", alpha = 0.5, density =
+            ggdist::density_bounded(bandwidth = "nrd0", n = 50)
+    ) +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(x = error),
+        position = "identity", alpha = 0.5,
+        density = ggdist::density_bounded(bandwidth = "nrd0", n = 50)
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(x = error, color = class),
+        position = ggplot2::position_dodge(
+            width = .3, preserve = "single")
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(x = error),
+        position = ggplot2::position_dodge(
+            width = .3, preserve = "single")
+        ) +
+    titheme() +
+    base_breaks_x(oob_df$error) +
+    base_breaks_y(0:1) +
+    ggplot2::labs(
+        title = "Distribution of percent correct by class",
+        x = "Percent correct", y = "Density"
+    )

# time: 2024-09-19 12:12:14 UTC
# mode: r
+# Save the plot
+ggplot2::ggsave(file.path(config$path$figures, "oob_dist_plot.jpg"),
+    plot =
+        oob_dist_plot,
+    width = 8,
+    height = 6
+)

# time: 2024-09-19 12:12:36 UTC
# mode: r
+oob_dist_plot <- ggplot2::ggplot() +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(x = error, fill = class),
+        position = "identity", alpha = 0.5, density =
+            ggdist::density_bounded(bandwidth = "nrd0", n = 50)
+    ) +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(x = error),
+        position = "identity", alpha = 0.5,
+        density = ggdist::density_bounded(bandwidth = "nrd0", n = 50)
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(x = error, color = class),
+        position = ggplot2::position_dodge(
+            width = .3, preserve = "single")
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(x = error),
+        position = ggplot2::position_dodge(
+            width = .3, preserve = "single")
+        ) +
+    titheme() +
+    base_breaks_x(oob_df$error) +
+    base_breaks_y(0:1, expand = ggplot2::expansion(add = c(-0.15, 0))) +
+    ggplot2::labs(
+        title = "Distribution of percent correct by class",
+        x = "Percent correct", y = "Density"
+    )

# time: 2024-09-19 12:12:36 UTC
# mode: r
+# Save the plot
+ggplot2::ggsave(file.path(config$path$figures, "oob_dist_plot.jpg"),
+    plot =
+        oob_dist_plot,
+    width = 8,
+    height = 6
+)

# time: 2024-09-19 12:13:31 UTC
# mode: r
+oob_dist_plot <- ggplot2::ggplot() +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(x = error, fill = class),
+        position = "identity", alpha = 0.5, density =
+            ggdist::density_bounded(bandwidth = "nrd0", n = 50)
+    ) +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(x = error, fill = class),
+        position = "identity", alpha = 0.5,
+        density = ggdist::density_bounded(bandwidth = "nrd0", n = 50),
+        linetype = "dashed"
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(x = error, color = class),
+        position = ggplot2::position_dodge(
+            width = .3, preserve = "single")
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(x = error, color = class),
+        position = ggplot2::position_dodge(
+            width = .3, preserve = "single"),
+        linetype = "dashed"
+    ) +
+    titheme() +
+    base_breaks_x(oob_df$error) +
+    base_breaks_y(0:1, expand = ggplot2::expansion(add = c(-0.15, 0))) +
+    ggplot2::labs(
+        title = "Distribution of percent correct by class",
+        x = "Percent correct", y = "Density"
+    ) +
+    ggplot2::scale_fill_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    ggplot2::scale_color_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    ))

# time: 2024-09-19 12:13:32 UTC
# mode: r
+# Save the plot
+ggplot2::ggsave(file.path(config$path$figures, "oob_dist_plot.jpg"),
+    plot =
+        oob_dist_plot,
+    width = 8,
+    height = 6
+)

# time: 2024-09-19 12:14:06 UTC
# mode: r
+oob_dist_plot <- ggplot2::ggplot() +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(x = error, fill = class),
+        position = "identity", alpha = 0.5, density =
+            ggdist::density_bounded(bandwidth = "nrd0", n = 50)
+    ) +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(x = error),
+        position = "identity", alpha = 0.5,
+        density = ggdist::density_bounded(bandwidth = "nrd0", n = 50),
+        linetype = "dashed"
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(x = error, color = class),
+        position = ggplot2::position_dodge(
+            width = .3, preserve = "single")
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(x = error, color = class),
+        position = ggplot2::position_dodge(
+            width = .3, preserve = "single"),
+        linetype = "dashed"
+    ) +
+    titheme() +
+    base_breaks_x(oob_df$error) +
+    base_breaks_y(0:1, expand = ggplot2::expansion(add = c(-0.15, 0))) +
+    ggplot2::labs(
+        title = "Distribution of percent correct by class",
+        x = "Percent correct", y = "Density"
+    ) +
+    ggplot2::scale_fill_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    ggplot2::scale_color_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    ))

# time: 2024-09-19 12:14:07 UTC
# mode: r
+# Save the plot
+ggplot2::ggsave(file.path(config$path$figures, "oob_dist_plot.jpg"),
+    plot =
+        oob_dist_plot,
+    width = 8,
+    height = 6
+)

# time: 2024-09-19 12:15:24 UTC
# mode: r
+oob_dist_plot <- ggplot2::ggplot() +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(x = error, fill = class),
+        position = "identity", alpha = 0.65, density =
+            ggdist::density_bounded(bandwidth = "nrd0", n = 50)
+    ) +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(x = error),
+        position = "identity", alpha = 0.65,
+        density = ggdist::density_bounded(bandwidth = "nrd0", n = 50),
+        linetype = "dashed"
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(x = error, color = class),
+        position = ggplot2::position_dodge(
+            width = .3, preserve = "single")
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(x = error),
+        position = ggplot2::position_dodge(
+            width = .3, preserve = "single"),
+        linetype = "dashed"
+    ) +
+    titheme() +
+    base_breaks_x(oob_df$error) +
+    base_breaks_y(0:1, expand = ggplot2::expansion(add = c(-0.15, 0))) +
+    ggplot2::labs(
+        title = "Distribution of percent correct by class",
+        x = "Percent correct", y = "Density"
+    ) +
+    ggplot2::scale_fill_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    ggplot2::scale_color_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    ))

# time: 2024-09-19 12:15:24 UTC
# mode: r
+# Save the plot
+ggplot2::ggsave(file.path(config$path$figures, "oob_dist_plot.jpg"),
+    plot =
+        oob_dist_plot,
+    width = 8,
+    height = 6
+)

# time: 2024-09-19 12:15:46 UTC
# mode: r
+oob_dist_plot <- ggplot2::ggplot() +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(x = error, fill = class),
+        position = "identity", alpha = 0.65, density =
+            ggdist::density_bounded(bandwidth = "nrd0", n = 50)
+    ) +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(x = error),
+        position = "identity", alpha = 0.65,
+        density = ggdist::density_bounded(bandwidth = "nrd0", n = 50),
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(x = error, color = class),
+        position = ggplot2::position_dodge(
+            width = .3, preserve = "single")
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(x = error),
+        position = ggplot2::position_dodge(
+            width = .3, preserve = "single")
+    ) +
+    titheme() +
+    base_breaks_x(oob_df$error) +
+    base_breaks_y(0:1, expand = ggplot2::expansion(add = c(-0.15, 0))) +
+    ggplot2::labs(
+        title = "Distribution of percent correct by class",
+        x = "Percent correct", y = "Density"
+    ) +
+    ggplot2::scale_fill_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    ggplot2::scale_color_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    ))

# time: 2024-09-19 12:15:47 UTC
# mode: r
+# Save the plot
+ggplot2::ggsave(file.path(config$path$figures, "oob_dist_plot.jpg"),
+    plot =
+        oob_dist_plot,
+    width = 8,
+    height = 6
+)

# time: 2024-09-19 12:16:51 UTC
# mode: r
+oob_dist_plot <- ggplot2::ggplot() +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(x = error, fill = class),
+        position = "identity", alpha = 0.65, density =
+            ggdist::density_bounded(bandwidth = "nrd0", n = 50)
+    ) +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(x = error),
+        position = "identity", alpha = 0.65,
+        density = ggdist::density_bounded(bandwidth = "nrd0", n = 50),
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(x = error, color = class),
+        position = ggplot2::position_dodge(
+            width = .3, preserve = "single"
+        )
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(x = error),
+        position = ggplot2::position_dodge(
+            width = .3, preserve = "single"
+        )
+    ) +
+    titheme() +
+    # add a vertical dashed line at 50% correct
+    ggplot2::geom_vline(xintercept = 50, linetype = "dotted", color = "grey") +
+    base_breaks_x(40:75) +
+    base_breaks_y(0:1, expand = ggplot2::expansion(add = c(-0.15, 0))) +
+    ggplot2::labs(
+        title = "Distribution of percent correct by class",
+        x = "Percent correct", y = "Density"
+    ) +
+    ggplot2::scale_fill_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    ggplot2::scale_color_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    ))

# time: 2024-09-19 12:16:51 UTC
# mode: r
+# Save the plot
+ggplot2::ggsave(file.path(config$path$figures, "oob_dist_plot.jpg"),
+    plot =
+        oob_dist_plot,
+    width = 8,
+    height = 6
+)

# time: 2024-09-19 12:17:00 UTC
# mode: r
+oob_dist_plot <- ggplot2::ggplot() +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(x = error, fill = class),
+        position = "identity", alpha = 0.65, density =
+            ggdist::density_bounded(bandwidth = "nrd0", n = 50)
+    ) +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(x = error),
+        position = "identity", alpha = 0.65,
+        density = ggdist::density_bounded(bandwidth = "nrd0", n = 50),
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(x = error, color = class),
+        position = ggplot2::position_dodge(
+            width = .3, preserve = "single"
+        )
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(x = error),
+        position = ggplot2::position_dodge(
+            width = .3, preserve = "single"
+        )
+    ) +
+    titheme() +
+    # add a vertical dashed line at 50% correct
+    ggplot2::geom_vline(xintercept = 50, linetype = "dotted", color = "grey") +
+    base_breaks_x(40:100) +
+    base_breaks_y(0:1, expand = ggplot2::expansion(add = c(-0.15, 0))) +
+    ggplot2::labs(
+        title = "Distribution of percent correct by class",
+        x = "Percent correct", y = "Density"
+    ) +
+    ggplot2::scale_fill_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    ggplot2::scale_color_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    ))

# time: 2024-09-19 12:17:01 UTC
# mode: r
+# Save the plot
+ggplot2::ggsave(file.path(config$path$figures, "oob_dist_plot.jpg"),
+    plot =
+        oob_dist_plot,
+    width = 8,
+    height = 6
+)

# time: 2024-09-19 12:17:31 UTC
# mode: r
+oob_dist_plot <- ggplot2::ggplot() +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(x = error, fill = class),
+        position = "identity", alpha = 0.65, density =
+            ggdist::density_bounded(bandwidth = "nrd0", n = 50)
+    ) +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(x = error),
+        position = "identity", alpha = 0.65,
+        density = ggdist::density_bounded(bandwidth = "nrd0", n = 50),
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(x = error, color = class),
+        position = ggplot2::position_dodge(
+            width = .3, preserve = "single"
+        )
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(x = error),
+        position = ggplot2::position_dodge(
+            width = .3, preserve = "single"
+        )
+    ) +
+    titheme() +
+    # add a vertical dashed line at 50% correct
+    ggplot2::geom_vline(xintercept = 50, linetype = "dotted", color = "grey") +
+    base_breaks_x(40:100) +
+    base_breaks_y(0:1, expand = ggplot2::expansion(add = c(-0.15, 0))) +
+    ggplot2::labs(
+        title = "Distribution of percent correct by class",
+        x = "Percent correct", y = "Density"
+    ) +
+    ggplot2::scale_fill_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    ggplot2::scale_color_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    # swap axes
+    ggplot2::coord_flip()

# time: 2024-09-19 12:17:31 UTC
# mode: r
+# Save the plot
+ggplot2::ggsave(file.path(config$path$figures, "oob_dist_plot.jpg"),
+    plot =
+        oob_dist_plot,
+    width = 8,
+    height = 6
+)

# time: 2024-09-19 12:17:57 UTC
# mode: r
+oob_dist_plot <- ggplot2::ggplot() +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(x = error, fill = class),
+        position = "identity", alpha = 0.65, density =
+            ggdist::density_bounded(bandwidth = "nrd0", n = 50)
+    ) +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(x = error),
+        position = "identity", alpha = 0.65,
+        density = ggdist::density_bounded(bandwidth = "nrd0", n = 50),
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(x = error, color = class),
+        position = ggplot2::position_dodge(
+            width = .3, preserve = "single"
+        )
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(x = error),
+        position = ggplot2::position_dodge(
+            width = .3, preserve = "single"
+        )
+    ) +
+    titheme() +
+    # add a vertical dashed line at 50% correct
+    ggplot2::geom_vline(xintercept = 50, linetype = "dotted", color = "grey") +
+    base_breaks_x(40:100) +
+    base_breaks_y(0:1, expand = ggplot2::expansion(add = c(-0.15, 0))) +
+    ggplot2::labs(
+        title = "Distribution of percent correct by class",
+        x = "Percent correct", y = "Density"
+    ) +
+    ggplot2::scale_fill_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    ggplot2::scale_color_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    # swap axes
+    ggplot2::coord_flip() + ggplot2::theme(aspect.ratio = 0.5)

# time: 2024-09-19 12:17:57 UTC
# mode: r
+# Save the plot
+ggplot2::ggsave(file.path(config$path$figures, "oob_dist_plot.jpg"),
+    plot =
+        oob_dist_plot,
+    width = 8,
+    height = 6
+)

# time: 2024-09-19 12:18:01 UTC
# mode: r
+oob_dist_plot <- ggplot2::ggplot() +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(x = error, fill = class),
+        position = "identity", alpha = 0.65, density =
+            ggdist::density_bounded(bandwidth = "nrd0", n = 50)
+    ) +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(x = error),
+        position = "identity", alpha = 0.65,
+        density = ggdist::density_bounded(bandwidth = "nrd0", n = 50),
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(x = error, color = class),
+        position = ggplot2::position_dodge(
+            width = .3, preserve = "single"
+        )
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(x = error),
+        position = ggplot2::position_dodge(
+            width = .3, preserve = "single"
+        )
+    ) +
+    titheme() +
+    # add a vertical dashed line at 50% correct
+    ggplot2::geom_vline(xintercept = 50, linetype = "dotted", color = "grey") +
+    base_breaks_x(40:100) +
+    base_breaks_y(0:1, expand = ggplot2::expansion(add = c(-0.15, 0))) +
+    ggplot2::labs(
+        title = "Distribution of percent correct by class",
+        x = "Percent correct", y = "Density"
+    ) +
+    ggplot2::scale_fill_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    ggplot2::scale_color_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    # swap axes
+    ggplot2::coord_flip() + ggplot2::theme(aspect.ratio = 1.5)

# time: 2024-09-19 12:18:02 UTC
# mode: r
+# Save the plot
+ggplot2::ggsave(file.path(config$path$figures, "oob_dist_plot.jpg"),
+    plot =
+        oob_dist_plot,
+    width = 8,
+    height = 6
+)

# time: 2024-09-19 12:18:24 UTC
# mode: r
+oob_dist_plot <- ggplot2::ggplot() +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(x = error, fill = class),
+        position = "identity", alpha = 0.65, density =
+            ggdist::density_bounded(bandwidth = "nrd0", n = 50)
+    ) +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(x = error),
+        position = "identity", alpha = 0.65,
+        density = ggdist::density_bounded(bandwidth = "nrd0", n = 50),
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(x = error, color = class),
+        position = ggplot2::position_dodge(
+            width = .3, preserve = "single"
+        )
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(x = error),
+        position = ggplot2::position_dodge(
+            width = .3, preserve = "single"
+        )
+    ) +
+    titheme() +
+    # add a vertical dashed line at 50% correct
+    ggplot2::geom_vline(xintercept = 50, linetype = "dotted", color = "grey") +
+    base_breaks_x(40:100) +
+    base_breaks_y(0:1, expand = ggplot2::expansion(add = c(-0.15, 0))) +
+    ggplot2::labs(
+        title = "Distribution of percent correct by class",
+        x = "Percent correct", y = "Density"
+    ) +
+    ggplot2::scale_fill_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    ggplot2::scale_color_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    # swap axes
+    ggplot2::coord_flip() + ggplot2::theme(aspect.ratio = 1.3)

# time: 2024-09-19 12:18:24 UTC
# mode: r
+# Save the plot
+ggplot2::ggsave(file.path(config$path$figures, "oob_dist_plot.jpg"),
+    plot =
+        oob_dist_plot,
+    width = 8,
+    height = 6
+)

# time: 2024-09-19 12:18:28 UTC
# mode: r
+oob_dist_plot <- ggplot2::ggplot() +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(x = error, fill = class),
+        position = "identity", alpha = 0.65, density =
+            ggdist::density_bounded(bandwidth = "nrd0", n = 50)
+    ) +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(x = error),
+        position = "identity", alpha = 0.65,
+        density = ggdist::density_bounded(bandwidth = "nrd0", n = 50),
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(x = error, color = class),
+        position = ggplot2::position_dodge(
+            width = .3, preserve = "single"
+        )
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(x = error),
+        position = ggplot2::position_dodge(
+            width = .3, preserve = "single"
+        )
+    ) +
+    titheme() +
+    # add a vertical dashed line at 50% correct
+    ggplot2::geom_vline(xintercept = 50, linetype = "dotted", color = "grey") +
+    base_breaks_x(40:100) +
+    base_breaks_y(0:1, expand = ggplot2::expansion(add = c(-0.15, 0))) +
+    ggplot2::labs(
+        title = "Distribution of percent correct by class",
+        x = "Percent correct", y = "Density"
+    ) +
+    ggplot2::scale_fill_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    ggplot2::scale_color_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    # swap axes
+    ggplot2::coord_flip() + ggplot2::theme(aspect.ratio = 1.8)

# time: 2024-09-19 12:18:29 UTC
# mode: r
+# Save the plot
+ggplot2::ggsave(file.path(config$path$figures, "oob_dist_plot.jpg"),
+    plot =
+        oob_dist_plot,
+    width = 8,
+    height = 6
+)

# time: 2024-09-19 12:18:36 UTC
# mode: r
+oob_dist_plot <- ggplot2::ggplot() +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(x = error, fill = class),
+        position = "identity", alpha = 0.65, density =
+            ggdist::density_bounded(bandwidth = "nrd0", n = 50)
+    ) +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(x = error),
+        position = "identity", alpha = 0.65,
+        density = ggdist::density_bounded(bandwidth = "nrd0", n = 50),
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(x = error, color = class),
+        position = ggplot2::position_dodge(
+            width = .3, preserve = "single"
+        )
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(x = error),
+        position = ggplot2::position_dodge(
+            width = .3, preserve = "single"
+        )
+    ) +
+    titheme() +
+    # add a vertical dashed line at 50% correct
+    ggplot2::geom_vline(xintercept = 50, linetype = "dotted", color = "grey") +
+    base_breaks_x(40:100) +
+    base_breaks_y(0:1, expand = ggplot2::expansion(add = c(-0.15, 0))) +
+    ggplot2::labs(
+        title = "Distribution of percent correct by class",
+        x = "Percent correct", y = "Density"
+    ) +
+    ggplot2::scale_fill_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    ggplot2::scale_color_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    # swap axes
+    ggplot2::coord_flip() + ggplot2::theme(aspect.ratio = 2.3)

# time: 2024-09-19 12:18:37 UTC
# mode: r
+# Save the plot
+ggplot2::ggsave(file.path(config$path$figures, "oob_dist_plot.jpg"),
+    plot =
+        oob_dist_plot,
+    width = 8,
+    height = 6
+)

# time: 2024-09-19 12:19:23 UTC
# mode: r
+oob_dist_plot <- ggplot2::ggplot() +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(y = error, fill = class),
+        position = "identity", alpha = 0.65, density =
+            ggdist::density_bounded(bandwidth = "nrd0", n = 50)
+    ) +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(y = error),
+        position = "identity", alpha = 0.65,
+        density = ggdist::density_bounded(bandwidth = "nrd0", n = 50),
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(y = error, color = class),
+        position = ggplot2::position_dodge(
+            width = .3, preserve = "single"
+        )
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(y = error),
+        position = ggplot2::position_dodge(
+            width = .3, preserve = "single"
+        )
+    ) +
+    titheme() +
+    # add a horizontal dashed line at 50% correct
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "grey") +
+    base_breaks_y(40:100) +
+    base_breaks_x(0:1, expand = ggplot2::expansion(add = c(-0.15, 0))) +
+    ggplot2::labs(
+        title = "Distribution of percent correct by class",
+        y = "Percent correct", x = "Density"
+    ) +
+    ggplot2::scale_fill_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    ggplot2::scale_color_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    ggplot2::theme(aspect.ratio = 2.3)

# time: 2024-09-19 12:19:23 UTC
# mode: r
+# Save the plot
+ggplot2::ggsave(file.path(config$path$figures, "oob_dist_plot.jpg"),
+    plot =
+        oob_dist_plot,
+    width = 8,
+    height = 6
+)

# time: 2024-09-19 12:20:21 UTC
# mode: r
+oob_dist_plot <- ggplot2::ggplot() +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(y = error, fill = class),
+        position = "identity", alpha = 0.65, density =
+            ggdist::density_bounded(bandwidth = "nrd0", n = 50)
+    ) +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(y = error),
+        position = "identity", alpha = 0.65,
+        density = ggdist::density_bounded(bandwidth = "nrd0", n = 50),
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(y = error, color = class),
+        position = ggplot2::position_dodge(
+            width = .3, preserve = "single"
+        )
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(y = error),
+        position = ggplot2::position_dodge(
+            width = .3, preserve = "single"
+        )
+    ) +
+    titheme() +
+    # add a horizontal dashed line at 50% correct
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "grey") +
+    base_breaks_y(39:100) +
+    base_breaks_x(0:1, expand = ggplot2::expansion(add = c(-0.15, 0))) +
+    ggplot2::labs(
+        title = "Distribution of percent correct by class",
+        y = "Percent correct", x = "Density"
+    ) +
+    ggplot2::scale_fill_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    ggplot2::scale_color_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    ggplot2::theme(aspect.ratio = 2.3)

# time: 2024-09-19 12:20:21 UTC
# mode: r
+# Save the plot
+ggplot2::ggsave(file.path(config$path$figures, "oob_dist_plot.jpg"),
+    plot = oob_dist_plot,
+    width = 8,
+    height = 6
+)

# time: 2024-09-19 12:21:04 UTC
# mode: r
+oob_dist_plot <- ggplot2::ggplot() +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(y = error, fill = class),
+        position = "identity", alpha = 0.65, density =
+            ggdist::density_bounded(bandwidth = "nrd0", n = 50)
+    ) +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(y = error),
+        position = "identity", alpha = 0.65,
+        density = ggdist::density_bounded(bandwidth = "nrd0", n = 50),
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(y = error, color = class),
+        position = ggplot2::position_dodge(
+            width = .3, preserve = "single"
+        )
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(y = error),
+        position = ggplot2::position_dodge(
+            width = .3, preserve = "single"
+        )
+    ) +
+    titheme() +
+    # add a horizontal dashed line at 50% correct
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "grey") +
+    base_breaks_y(40:100,  expand = ggplot2::expansion(add = c(-0.15, 0)) ) +
+    base_breaks_x(0:1, expand = ggplot2::expansion(add = c(0.05, 0.05)) ) +
+    ggplot2::labs(
+        title = "Distribution of percent correct by class",
+        y = "Percent correct", x = "Density"
+    ) +
+    ggplot2::scale_fill_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    ggplot2::scale_color_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    ggplot2::theme(aspect.ratio = 2.3)

# time: 2024-09-19 12:21:05 UTC
# mode: r
+# Save the plot
+ggplot2::ggsave(file.path(config$path$figures, "oob_dist_plot.jpg"),
+    plot = oob_dist_plot,
+    width = 8,
+    height = 6
+)

# time: 2024-09-19 12:21:45 UTC
# mode: r
+oob_dist_plot <- ggplot2::ggplot() +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(y = error, fill = class),
+        position = "identity", alpha = 0.65, density =
+            ggdist::density_bounded(bandwidth = "nrd0", n = 50)
+    ) +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(y = error),
+        position = "identity", alpha = 0.65,
+        density = ggdist::density_bounded(bandwidth = "nrd0", n = 50),
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(y = error, color = class),
+        position = ggplot2::position_dodge(
+            width = .3, preserve = "single"
+        )
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(y = error),
+        position = ggplot2::position_dodge(
+            width = .3, preserve = "single"
+        )
+    ) +
+    titheme() +
+    # add a horizontal dashed line at 50% correct
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "grey") +
+    base_breaks_y(40:100,  expand = ggplot2::expansion(add = c(0, 0))) +
+    base_breaks_x(0:1, expand = ggplot2::expansion(add = c(-0.15, 0))) +
+    ggplot2::labs(
+        title = "Distribution of percent correct by class",
+        y = "Percent correct", x = "Density"
+    ) +
+    ggplot2::scale_fill_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    ggplot2::scale_color_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    ggplot2::theme(aspect.ratio = 2.3)

# time: 2024-09-19 12:21:45 UTC
# mode: r
+# Save the plot
+ggplot2::ggsave(file.path(config$path$figures, "oob_dist_plot.jpg"),
+    plot = oob_dist_plot,
+    width = 8,
+    height = 6
+)

# time: 2024-09-19 12:22:06 UTC
# mode: r
+oob_dist_plot <- ggplot2::ggplot() +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(y = error, fill = class),
+        position = "identity", alpha = 0.65, density =
+            ggdist::density_bounded(bandwidth = "nrd0", n = 50)
+    ) +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(y = error),
+        position = "identity", alpha = 0.65,
+        density = ggdist::density_bounded(bandwidth = "nrd0", n = 50),
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(y = error, color = class),
+        position = ggplot2::position_dodge(
+            width = .3, preserve = "single"
+        )
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(y = error),
+        position = ggplot2::position_dodge(
+            width = .3, preserve = "single"
+        )
+    ) +
+    titheme() +
+    # add a horizontal dashed line at 50% correct
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "grey") +
+    base_breaks_y(40:100,  expand = ggplot2::expansion(add = c(0.1, 0))) +
+    base_breaks_x(0:1, expand = ggplot2::expansion(add = c(-0.15, 0))) +
+    ggplot2::labs(
+        title = "Distribution of percent correct by class",
+        y = "Percent correct", x = "Density"
+    ) +
+    ggplot2::scale_fill_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    ggplot2::scale_color_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    ggplot2::theme(aspect.ratio = 2.3)

# time: 2024-09-19 12:22:06 UTC
# mode: r
+# Save the plot
+ggplot2::ggsave(file.path(config$path$figures, "oob_dist_plot.jpg"),
+    plot = oob_dist_plot,
+    width = 8,
+    height = 6
+)

# time: 2024-09-19 12:22:15 UTC
# mode: r
+oob_dist_plot <- ggplot2::ggplot() +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(y = error, fill = class),
+        position = "identity", alpha = 0.65, density =
+            ggdist::density_bounded(bandwidth = "nrd0", n = 50)
+    ) +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(y = error),
+        position = "identity", alpha = 0.65,
+        density = ggdist::density_bounded(bandwidth = "nrd0", n = 50),
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(y = error, color = class),
+        position = ggplot2::position_dodge(
+            width = .3, preserve = "single"
+        )
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(y = error),
+        position = ggplot2::position_dodge(
+            width = .3, preserve = "single"
+        )
+    ) +
+    titheme() +
+    # add a horizontal dashed line at 50% correct
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "grey") +
+    base_breaks_y(40:100,  expand = ggplot2::expansion(add = c(5, 0))) +
+    base_breaks_x(0:1, expand = ggplot2::expansion(add = c(-0.15, 0))) +
+    ggplot2::labs(
+        title = "Distribution of percent correct by class",
+        y = "Percent correct", x = "Density"
+    ) +
+    ggplot2::scale_fill_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    ggplot2::scale_color_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    ggplot2::theme(aspect.ratio = 2.3)

# time: 2024-09-19 12:22:15 UTC
# mode: r
+# Save the plot
+ggplot2::ggsave(file.path(config$path$figures, "oob_dist_plot.jpg"),
+    plot = oob_dist_plot,
+    width = 8,
+    height = 6
+)

# time: 2024-09-19 12:22:41 UTC
# mode: r
+oob_dist_plot <- ggplot2::ggplot() +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(y = error, fill = class),
+        position = "identity", alpha = 0.65, density =
+            ggdist::density_bounded(bandwidth = "nrd0", n = 50)
+    ) +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(y = error),
+        position = "identity", alpha = 0.65,
+        density = ggdist::density_bounded(bandwidth = "nrd0", n = 50),
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(y = error, color = class),
+        position = ggplot2::position_dodge(
+            width = .3, preserve = "single"
+        )
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(y = error),
+        position = ggplot2::position_dodge(
+            width = .3, preserve = "single"
+        )
+    ) +
+    titheme() +
+    # add a horizontal dashed line at 50% correct
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "grey") +
+    base_breaks_y(40:100,  expand = ggplot2::expansion(add = c(3, 0))) +
+    base_breaks_x(0:1, expand = ggplot2::expansion(add = c(-0.1, 0))) +
+    ggplot2::labs(
+        title = "Distribution of percent correct by class",
+        y = "Percent correct", x = "Density"
+    ) +
+    ggplot2::scale_fill_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    ggplot2::scale_color_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    ggplot2::theme(aspect.ratio = 2.3)

# time: 2024-09-19 12:22:42 UTC
# mode: r
+# Save the plot
+ggplot2::ggsave(file.path(config$path$figures, "oob_dist_plot.jpg"),
+    plot = oob_dist_plot,
+    width = 8,
+    height = 6
+)

# time: 2024-09-19 12:23:51 UTC
# mode: r
+oob_dist_plot <- ggplot2::ggplot() +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(y = error, fill = class),
+        position = "identity", alpha = 0.65, density =
+            ggdist::density_bounded(bandwidth = "nrd0", n = 50)
+    ) +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(y = error),
+        position = "identity", alpha = 0.65,
+        density = ggdist::density_bounded(bandwidth = "nrd0", n = 50),
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(y = error, color = class),
+        position = ggplot2::position_dodge(
+            width = .3, preserve = "single"
+        )
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(y = error),
+        position = ggplot2::position_dodge(
+            width = .3, preserve = "single"
+        )
+    ) +
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "grey") +
+    ggplot2::labs(
+        title = "Distribution of percent correct by class",
+        y = "Percent correct", x = "Density"
+    ) +
+    ggplot2::scale_fill_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    ggplot2::scale_color_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    base_breaks_y(40:100, expand = ggplot2::expansion(add = c(3, 0))) +
+    base_breaks_x(0:1, expand = ggplot2::expansion(add = c(-0.1, 0))) +
+    titheme() +
+    ggplot2::theme(aspect.ratio = 2.3)

# time: 2024-09-19 12:23:51 UTC
# mode: r
+# Save the plot
+ggplot2::ggsave(file.path(config$path$figures, "oob_dist_plot.jpg"),
+    plot = oob_dist_plot,
+    width = 8,
+    height = 6
+)

# time: 2024-09-19 12:28:00 UTC
# mode: r
+oob_dist_plot <- ggplot2::ggplot() +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(y = error, fill = class),
+        position = "identity", alpha = 0.65, density =
+            ggdist::density_bounded(bandwidth = "nrd0", n = 20)
+    ) +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(y = error),
+        position = "identity", alpha = 0.65,
+        density = ggdist::density_bounded(bandwidth = "nrd0", n = 20),
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(y = error, color = class),
+        position = ggplot2::position_dodge(
+            width = .3, preserve = "single"
+        )
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(y = error),
+        position = ggplot2::position_dodge(
+            width = .3, preserve = "single"
+        )
+    ) +
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "grey") +
+    ggplot2::labs(
+        title = "Distribution of percent correct by class",
+        y = "Percent correct", x = "Density"
+    ) +
+    ggplot2::scale_fill_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    ggplot2::scale_color_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    base_breaks_y(40:100, expand = ggplot2::expansion(add = c(3, 0))) +
+    base_breaks_x(0:1, expand = ggplot2::expansion(add = c(-0.1, 0))) +
+    titheme() +
+    ggplot2::theme(aspect.ratio = 2.3)

# time: 2024-09-19 12:28:08 UTC
# mode: r
+# Save the plot
+ggplot2::ggsave(file.path(config$path$figures, "oob_dist_plot.jpg"),
+    plot = oob_dist_plot,
+    width = 8,
+    height = 6
+)

# time: 2024-09-19 12:28:17 UTC
# mode: r
+oob_dist_plot <- ggplot2::ggplot() +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(y = error, fill = class),
+        position = "identity", alpha = 0.65, density =
+            ggdist::density_bounded(bandwidth = "nrd0", n = 5)
+    ) +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(y = error),
+        position = "identity", alpha = 0.65,
+        density = ggdist::density_bounded(bandwidth = "nrd0", n = 5),
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(y = error, color = class),
+        position = ggplot2::position_dodge(
+            width = .3, preserve = "single"
+        )
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(y = error),
+        position = ggplot2::position_dodge(
+            width = .3, preserve = "single"
+        )
+    ) +
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "grey") +
+    ggplot2::labs(
+        title = "Distribution of percent correct by class",
+        y = "Percent correct", x = "Density"
+    ) +
+    ggplot2::scale_fill_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    ggplot2::scale_color_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    base_breaks_y(40:100, expand = ggplot2::expansion(add = c(3, 0))) +
+    base_breaks_x(0:1, expand = ggplot2::expansion(add = c(-0.1, 0))) +
+    titheme() +
+    ggplot2::theme(aspect.ratio = 2.3)

# time: 2024-09-19 12:28:18 UTC
# mode: r
+# Save the plot
+ggplot2::ggsave(file.path(config$path$figures, "oob_dist_plot.jpg"),
+    plot = oob_dist_plot,
+    width = 8,
+    height = 6
+)

# time: 2024-09-19 12:28:37 UTC
# mode: r
+oob_dist_plot <- ggplot2::ggplot() +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(y = error, fill = class),
+        position = "identity", alpha = 0.65, density =
+            ggdist::density_bounded(bandwidth = "nrd0", n = 200)
+    ) +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(y = error),
+        position = "identity", alpha = 0.65,
+        density = ggdist::density_bounded(bandwidth = "nrd0", n = 200),
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(y = error, color = class),
+        position = ggplot2::position_dodge(
+            width = .3, preserve = "single"
+        )
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(y = error),
+        position = ggplot2::position_dodge(
+            width = .3, preserve = "single"
+        )
+    ) +
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "grey") +
+    ggplot2::labs(
+        title = "Distribution of percent correct by class",
+        y = "Percent correct", x = "Density"
+    ) +
+    ggplot2::scale_fill_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    ggplot2::scale_color_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    base_breaks_y(40:100, expand = ggplot2::expansion(add = c(3, 0))) +
+    base_breaks_x(0:1, expand = ggplot2::expansion(add = c(-0.1, 0))) +
+    titheme() +
+    ggplot2::theme(aspect.ratio = 2.3)

# time: 2024-09-19 12:28:38 UTC
# mode: r
+# Save the plot
+ggplot2::ggsave(file.path(config$path$figures, "oob_dist_plot.jpg"),
+    plot = oob_dist_plot,
+    width = 8,
+    height = 6
+)

# time: 2024-09-19 12:28:59 UTC
# mode: r
+oob_dist_plot <- ggplot2::ggplot() +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(y = error, fill = class),
+        position = "identity", alpha = 0.65, density =
+            ggdist::density_bounded(bandwidth = "nrd0")
+    ) +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(y = error),
+        position = "identity", alpha = 0.65,
+        density = ggdist::density_bounded(bandwidth = "nrd0"),
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(y = error, color = class),
+        position = ggplot2::position_dodge(
+            width = .3, preserve = "single"
+        )
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(y = error),
+        position = ggplot2::position_dodge(
+            width = .3, preserve = "single"
+        )
+    ) +
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "grey") +
+    ggplot2::labs(
+        title = "Distribution of percent correct by class",
+        y = "Percent correct", x = "Density"
+    ) +
+    ggplot2::scale_fill_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    ggplot2::scale_color_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    base_breaks_y(40:100, expand = ggplot2::expansion(add = c(3, 0))) +
+    base_breaks_x(0:1, expand = ggplot2::expansion(add = c(-0.1, 0))) +
+    titheme() +
+    ggplot2::theme(aspect.ratio = 2.3)

# time: 2024-09-19 12:29:00 UTC
# mode: r
+# Save the plot
+ggplot2::ggsave(file.path(config$path$figures, "oob_dist_plot.jpg"),
+    plot = oob_dist_plot,
+    width = 8,
+    height = 6
+)

# time: 2024-09-19 12:29:07 UTC
# mode: r
+oob_dist_plot

# time: 2024-09-19 12:29:28 UTC
# mode: r
+oob_dist_plot <- ggplot2::ggplot() +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(y = error, fill = class),
+        position = "identity", alpha = 0.65
+    ) +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(y = error),
+        position = "identity", alpha = 0.65
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(y = error, color = class),
+        position = ggplot2::position_dodge(
+            width = .3, preserve = "single"
+        )
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(y = error),
+        position = ggplot2::position_dodge(
+            width = .3, preserve = "single"
+        )
+    ) +
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "grey") +
+    ggplot2::labs(
+        title = "Distribution of percent correct by class",
+        y = "Percent correct", x = "Density"
+    ) +
+    ggplot2::scale_fill_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    ggplot2::scale_color_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    base_breaks_y(40:100, expand = ggplot2::expansion(add = c(3, 0))) +
+    base_breaks_x(0:1, expand = ggplot2::expansion(add = c(-0.1, 0))) +
+    titheme() +
+    ggplot2::theme(aspect.ratio = 2.3)

# time: 2024-09-19 12:29:28 UTC
# mode: r
+# Save the plot
+ggplot2::ggsave(file.path(config$path$figures, "oob_dist_plot.jpg"),
+    plot = oob_dist_plot,
+    width = 8,
+    height = 6
+)

# time: 2024-09-19 12:32:25 UTC
# mode: r
+# Import configuration file # nolint
+config <- config::get()
+box::use(R / plot[titheme, titpalette, blues])
+
+progressr::handlers(progressr::handler_pbcol(
+    adjust = 1.0,
+    complete = function(s) cli::bg_red(cli::col_black(s)),
+    incomplete = function(s) cli::bg_cyan(cli::col_black(s))
+))
+
+# parameters
+percent.train <- 0.7
+num.threads <- 44
+num.eigenvectors <- 15
+set.seed(555)
+
+# Input files
+immigrant.info <- file.path(config$path$data, "600K_immigrants.fam")
+immigrant.vcf <- file.path(config$path$data, "600K_immigrants.vcf")
+resident.vcf <- file.path(config$path$data, "600K_residents.vcf")
+
+immigrant.gds <- file.path(config$path$data, "immigrant_recode.gds")
+resident.gds <- file.path(config$path$data, "resident_recode.gds")
+all.gds <- file.path(config$path$data, "all_recode.gds")
+
+
+# Load all the data
+all.maf <- SNPRelate::snpgdsOpen(all.gds, allow.duplicate = TRUE)
+
+# Load labels
+immigrant.id <- gdsfmt::read.gdsn(gdsfmt::index.gdsn(
+    SNPRelate::snpgdsOpen(immigrant.gds),
+    "sample.id"
+))
+resident.id <- gdsfmt::read.gdsn(gdsfmt::index.gdsn(
+    SNPRelate::snpgdsOpen(resident.gds),
+    "sample.id"
+))
+
+all.id <- gdsfmt::read.gdsn(gdsfmt::index.gdsn(all.maf, "sample.id"))
+all.label <- ifelse(all.id %in% immigrant.id, "immigrant", "resident")
+
+
+# Function to split data into training and testing sets
+split_data <- function(all.id, all.label, percent.train) {
+    # Split data by class
+    labels <- unique(all.label)
+    class_0 <- all.id[all.label == labels[1]]
+    class_1 <- all.id[all.label == labels[2]]
+
+    # Determine the size of the smaller class
+    min_class_size <- min(length(class_0), length(class_1))
+
+    # Undersample the majority class
+    if (length(class_0) > min_class_size) {
+        class_0 <- sample(class_0, min_class_size)
+    } else {
+        class_1 <- sample(class_1, min_class_size)
+    }
+
+    # Combine the balanced classes
+    balanced_ids <- c(class_0, class_1)
+    balanced_labels <- c(
+        rep(labels[1], length(class_0)),
+        rep(labels[2], length(class_1))
+    )
+
+    # Calculate the number of samples for training
+    num_train <- round(length(balanced_ids) * percent.train)
+
+    # Ensure equal representation of both classes in train and test sets
+    num_train_per_class <- num_train %/% 2
+
+    # Randomly select samples for training from each class
+    train_indices <- c(
+        sample(1:min_class_size, num_train_per_class),
+        sample((min_class_size + 1):(2 * min_class_size), num_train_per_class)
+    )
+
+    train.id <- balanced_ids[train_indices]
+    test.id <- balanced_ids[-train_indices]
+    train.label <- balanced_labels[train_indices]
+    test.label <- balanced_labels[-train_indices]
+
+    list(
+        train.id = train.id, test.id = test.id,
+        train.label = train.label, test.label = test.label
+    )
+}
+# Function to perform PCA and prepare data frames
+prepare_data <- function(
+    all.maf, train.id, test.id,
+    train.label, test.label, num.eigenvectors, num.threads) {
+    pca <- SNPRelate::snpgdsPCA(
+        all.maf,
+        sample.id = train.id, num.thread = num.threads, verbose = FALSE
+    )
+    snp_loadings <- SNPRelate::snpgdsPCASNPLoading(
+        pca, all.maf,
+        num.thread = num.threads, verbose = FALSE
+    )
+    sample_loadings <- SNPRelate::snpgdsPCASampLoading(
+        snp_loadings, all.maf,
+        sample.id = test.id, num.thread = num.threads, verbose = FALSE
+    )
+    train_eigenvects <- data.frame(
+        sample.id = pca$sample.id, pca$eigenvect[, 1:num.eigenvectors]
+    )
+    test_eigenvects <- data.frame(
+        sample.id = sample_loadings$sample.id, sample_loadings$eigenvect[, 1:num.eigenvectors]
+    )
+    train_df <- data.frame(sample.id = train.id, pop = train.label, train_eigenvects[, -1])
+    test_df <- data.frame(sample.id = test.id, pop = test.label, test_eigenvects[, -1])
+    list(train_df = train_df, test_df = test_df)
+}
+
+# Function to train a random forest with optional randomized labels
+train_random_forest <- function(
+    train_df, test_df, num.eigenvectors, randomize_labels = FALSE) {
+    if (randomize_labels) {
+        train_df$pop <- sample(train_df$pop)
+    }
+
+    return(randomForest::randomForest(
+        train_df[, 3:(2 + num.eigenvectors)],
+        y = as.factor(train_df$pop),
+        data = train_df,
+        xtest = test_df[, 3:(2 + num.eigenvectors)],
+        ytest = as.factor(test_df$pop),
+        ntree = 500,
+        replace = FALSE,
+        proximity = TRUE
+    ))
+}
+
+# Function to run a single iteration
+run_iteration <- function(
+    all.id, all.label, all.maf, percent.train, num.eigenvectors, num.threads, randomize_labels) {
+    # Split data
+    split <- split_data(all.id, all.label, percent.train)
+
+    # Prepare data
+    data <- prepare_data(
+        all.maf, split$train.id, split$test.id, split$train.label, split$test.label,
+        num.eigenvectors, num.threads
+    )
+
+    # Train random forest
+    rf <- train_random_forest(data$train_df, data$test_df, num.eigenvectors, randomize_labels)
+
+    # Extract OOB error rates
+    oob_data <- rfPermute::plotTrace(rf, plot = FALSE)$data
+
+    # Return both OOB data, the random forest model, and the train/test labels
+    return(list(
+        oob_data = oob_data, rf_model = rf,
+        train_labels = split$train.label, test_labels = split$test.label
+    ))
+}
+
+# Main function to run multiple iterations
+run_analysis <- function(
+    all.id, all.label, all.maf, percent.train,
+    num.eigenvectors, num.threads,
+    n_iterations = 1) {
+    set.seed(123) # For reproducibility
+
+    # Initialize progress bar
+    progressr::with_progress({
+        p <- progressr::progressor(along = 1:(2 * n_iterations))
+
+        # Run iterations with original labels
+        original_results <- replicate(n_iterations,
+            {
+                p()
+                run_iteration(
+                    all.id, all.label, all.maf, percent.train,
+                    num.eigenvectors, num.threads, FALSE
+                )
+            },
+            simplify = FALSE
+        )
+
+        # Run iterations with randomized labels
+        random_results <- replicate(n_iterations,
+            {
+                p()
+                run_iteration(
+                    all.id, all.label, all.maf, percent.train,
+                    num.eigenvectors, num.threads, TRUE
+                )
+            },
+            simplify = FALSE
+        )
+    })
+
+    # Separate OOB data, RF models, and train/test labels
+    original_oob <- lapply(original_results, function(x) x$oob_data)
+    original_rf_models <- lapply(original_results, function(x) x$rf_model)
+    original_train_labels <- lapply(original_results, function(x) x$train_labels)
+    original_test_labels <- lapply(original_results, function(x) x$test_labels)
+
+    random_oob <- lapply(random_results, function(x) x$oob_data)
+    random_rf_models <- lapply(random_results, function(x) x$rf_model)
+    random_train_labels <- lapply(random_results, function(x) x$train_labels)
+    random_test_labels <- lapply(random_results, function(x) x$test_labels)
+
+    # Combine OOB results
+    oob_df <- dplyr::as_tibble(do.call(rbind, original_oob))
+    random_oob_df <- dplyr::as_tibble(do.call(rbind, random_oob))
+
+    list(
+        oob_df = oob_df,
+        random_oob_df = random_oob_df,
+        original_rf_models = original_rf_models,
+        random_rf_models = random_rf_models,
+        original_train_labels = original_train_labels,
+        original_test_labels = original_test_labels,
+        random_train_labels = random_train_labels,
+        random_test_labels = random_test_labels
+    )
+}
+
+calculate_mean_error <- function(data) {
+    data |>
+        dplyr::group_by(trees, class) |>
+        dplyr::summarise(mean_error = mean(error), .groups = "drop") |> # nolint: object_usage_linter.
+        dplyr::filter(class != "OOB")
+}
+
+
+# ----------------------------------- main ----------------------------------- #
+
+# TODO:
+# - RF error rate plot
+# - Summary statistics for random and original models
+# - MDS plot
+# - Confusion matrix
+# - Calculate some sort of distance between points and cluster centroids
+
+# Check if results file exists
+results_file <- file.path(config$path$data, "rf_results.rds")
+
+if (file.exists(results_file)) {
+    # Load the results
+    results <- readRDS(results_file)
+} else {
+    # Run the analysis
+    results <- run_analysis(all.id, all.label, all.maf, percent.train,
+        num.eigenvectors, num.threads,
+        n_iterations = 2
+    )
+
+    # Save the results
+    saveRDS(results, results_file)
+}
+
+
+# Calculate mean error for all iterations
+mean_oob_df <- calculate_mean_error(results$oob_df)
+mean_random_oob_df <- calculate_mean_error(results$random_oob_df)
+
+# Create the plot data
+plot_data <- list(
+    oob_df = results$oob_df |>
+        dplyr::filter(class != "OOB"),
+    random_oob_df = results$random_oob_df |>
+        dplyr::filter(class != "OOB"),
+    mean_oob_df = mean_oob_df,
+    mean_random_oob_df = mean_random_oob_df
+)
+
+# Create the plot
+oobplot <- ggplot2::ggplot() +
+    ggplot2::geom_line(data = plot_data$oob_df, ggplot2::aes(
+        x = trees, y = error, color = class
+    ), alpha = 0.1) +
+    ggplot2::geom_line(data = plot_data$random_oob_df, ggplot2::aes(
+        x = trees, y = error, color = class
+    ), alpha = 0.1, linetype = "dashed") +
+    ggplot2::geom_line(data = plot_data$mean_oob_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class
+    ), linewidth = 1.5) +
+    ggplot2::geom_line(data = plot_data$mean_random_oob_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class
+    ), linewidth = 1.5, linetype = "dashed") +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(
+        title = "OOB error rate (Solid: Original, Dashed: Randomized)",
+        x = "Number of trees", y = "Percent correct"
+    ) +
+    ggplot2::scale_color_manual(values = c(
+        "OOB" = "#4e4e4e",
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    ggplot2::coord_cartesian(ylim = c(0, 100)) +
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "red") +
+    ggplot2::theme(aspect.ratio = 1, text = ggplot2::element_text(size = 12)) +
+    ggplot2::scale_y_continuous(labels = scales::percent_format(scale = 1))
+
+# Save the plot
+ggplot2::ggsave(file.path(config$path$figures, "oob_plot.jpg"),
+    plot =
+        oobplot,
+    width = 8,
+    height = 6
+)

# time: 2024-09-19 12:32:34 UTC
# mode: r
+oob_df <- dplyr::bind_rows(
+    list(
+        oob_df = plot_data$oob_df,
+        random_oob_df = plot_data$random_oob_df
+    ),
+    .id = "source"
+) |>
+    dplyr::filter(trees >= 100 & trees <= 500) |>
+
+# plot the distribution of percent correct by class
+
+base_breaks_x <- function(x, expand = ggplot2::expansion(add = c(0, 0))) {
+    b <- pretty(x)
+    d <- data.frame(y = -Inf, yend = -Inf, x = min(b), xend = max(b))
+    list(
+        ggplot2::geom_segment(data = d, ggplot2::aes(x = x, y = y, xend = xend, yend = yend), inherit.aes = FALSE),
+        ggplot2::scale_x_continuous(breaks = b, expand = expand)
+    )
+}
+
+base_breaks_y <- function(x, expand = ggplot2::expansion(add = c(-0.1, 0))) {
+    b <- pretty(x)
+    d <- data.frame(x = -Inf, xend = -Inf, y = min(b), yend = max(b))
+    list(
+        ggplot2::geom_segment(data = d, ggplot2::aes(x = x, y = y, xend = xend, yend = yend), inherit.aes = FALSE),
+        ggplot2::scale_y_continuous(breaks = b, expand = expand)
+    )
+}
+
+oob_dist_plot <- ggplot2::ggplot() +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(y = error, fill = class),
+        position = "identity", alpha = 0.65, 
+        density =    ggdist::density_bounded(bandwidth = "nrd0")
+    ) +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(y = error),
+        position = "identity", alpha = 0.65,
+        density = ggdist::density_bounded(bandwidth = "nrd0"),
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(y = error, color = class),
+        position = ggplot2::position_dodge(
+            width = .3, preserve = "single"
+        )
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(y = error),
+        position = ggplot2::position_dodge(
+            width = .3, preserve = "single"
+        )
+    ) +
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "black") +
+    ggplot2::labs(
+        title = "Distribution of percent correct by class",
+        y = "Percent correct", x = "Density"
+    ) +
+    ggplot2::scale_fill_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    ggplot2::scale_color_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    base_breaks_y(40:100, expand = ggplot2::expansion(add = c(3, 0))) +
+    base_breaks_x(0:1, expand = ggplot2::expansion(add = c(-0.1, 0))) +
+    titheme() +
+    ggplot2::theme(aspect.ratio = 2.3)
+
+# Save the plot
+ggplot2::ggsave(file.path(config$path$figures, "oob_dist_plot.jpg"),
+    plot = oob_dist_plot,
+    width = 8,
+    height = 6
+)

# time: 2024-09-19 12:32:48 UTC
# mode: r
+oob_dist_plot <- ggplot2::ggplot() +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(y = error, fill = class),
+        position = "identity", alpha = 0.65, 
+        density =    ggdist::density_bounded(bandwidth = "nrd0")
+    ) +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(y = error),
+        position = "identity", alpha = 0.65,
+        density = ggdist::density_bounded(bandwidth = "nrd0"),
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(y = error, color = class),
+        position = ggplot2::position_dodge(
+            width = .3, preserve = "single"
+        )
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(y = error),
+        position = ggplot2::position_dodge(
+            width = .3, preserve = "single"
+        )
+    ) +
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "black") +
+    ggplot2::labs(
+        title = "Distribution of percent correct by class",
+        y = "Percent correct", x = "Density"
+    ) +
+    ggplot2::scale_fill_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    ggplot2::scale_color_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    base_breaks_y(40:100, expand = ggplot2::expansion(add = c(3, 0))) +
+    base_breaks_x(0:1, expand = ggplot2::expansion(add = c(-0.1, 0))) +
+    titheme() +
+    ggplot2::theme(aspect.ratio = 2.3)

# time: 2024-09-19 12:32:49 UTC
# mode: r
+# Save the plot
+ggplot2::ggsave(file.path(config$path$figures, "oob_dist_plot.jpg"),
+    plot = oob_dist_plot,
+    width = 8,
+    height = 6
+)

# time: 2024-09-19 12:32:50 UTC
# mode: r
+# run a single random forest model:
+
+# 1 prepare data
+split <- split_data(all.id, all.label, percent.train)

# time: 2024-09-19 12:32:53 UTC
# mode: r
+oob_dist_plot

# time: 2024-09-19 12:33:36 UTC
# mode: r
+oob_dist_plot <- ggplot2::ggplot() +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(y = error, fill = class),
+        position = "identity", alpha = 0.65, 
+        density =    ggdist::density_bounded(bandwidth = "nrd0")
+    ) +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(y = error),
+        position = "identity", alpha = 0.65,
+        density = ggdist::density_bounded(bandwidth = "nrd0"),
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(y = error, color = class),
+        position = ggplot2::position_dodge(
+            width = .3, preserve = "single"
+        )
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(y = error),
+        position = ggplot2::position_dodge(
+            width = .3, preserve = "single"
+        )
+    ) +
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "black") +
+    ggplot2::labs(
+        title = "Distribution of percent correct by class",
+        y = "Percent correct", x = "Density"
+    ) +
+    ggplot2::scale_fill_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    ggplot2::scale_color_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    base_breaks_y(40:100, expand = ggplot2::expansion(add = c(3, 0))) +
+    base_breaks_x(0:1, expand = ggplot2::expansion(add = c(-0.1, 0))) +
+    titheme() +
+    ggplot2::theme(aspect.ratio = 2.3) +
+    ggplot2::theme(legend.position = "top")

# time: 2024-09-19 12:33:36 UTC
# mode: r
+# Save the plot
+ggplot2::ggsave(file.path(config$path$figures, "oob_dist_plot.jpg"),
+    plot = oob_dist_plot,
+    width = 8,
+    height = 6
+)

# time: 2024-09-19 12:33:46 UTC
# mode: r
+oob_dist_plot <- ggplot2::ggplot() +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(y = error, fill = class),
+        position = "identity", alpha = 0.65, 
+        density =    ggdist::density_bounded(bandwidth = "nrd0")
+    ) +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(y = error),
+        position = "identity", alpha = 0.65,
+        density = ggdist::density_bounded(bandwidth = "nrd0"),
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(y = error, color = class),
+        position = ggplot2::position_dodge(
+            width = .3, preserve = "single"
+        )
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(y = error),
+        position = ggplot2::position_dodge(
+            width = .3, preserve = "single"
+        )
+    ) +
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "black") +
+    ggplot2::labs(
+        title = "Distribution of percent correct by class",
+        y = "Percent correct", x = "Density"
+    ) +
+    ggplot2::scale_fill_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    ggplot2::scale_color_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    base_breaks_y(40:100, expand = ggplot2::expansion(add = c(3, 0))) +
+    base_breaks_x(0:1, expand = ggplot2::expansion(add = c(-0.1, 0))) +
+    titheme() +
+    ggplot2::theme(aspect.ratio = 2.3) +
+    ggplot2::theme(legend.position = "top")

# time: 2024-09-19 12:33:47 UTC
# mode: r
+# Save the plot
+ggplot2::ggsave(file.path(config$path$figures, "oob_dist_plot.jpg"),
+    plot = oob_dist_plot,
+    width = 8,
+    height = 6
+)

# time: 2024-09-19 12:35:25 UTC
# mode: r
+oob_dist_plot <- ggplot2::ggplot() +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(y = error, fill = class),
+        position = "identity", alpha = 0.65,
+        density = ggdist::density_bounded(bandwidth = "nrd0")
+    ) +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(y = error),
+        position = "identity", alpha = 0.65,
+        density = ggdist::density_bounded(bandwidth = "nrd0"),
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(y = error, color = class),
+        position = ggplot2::position_dodge(
+            width = .3, preserve = "single"
+        )
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(y = error),
+        position = ggplot2::position_dodge(
+            width = .3, preserve = "single"
+        )
+    ) +
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "black") +
+    ggplot2::labs(
+        title = "Distribution of percent correct by class",
+        y = "Percent correct", x = "Density"
+    ) +
+    ggplot2::scale_fill_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    ggplot2::scale_color_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    base_breaks_y(40:100, expand = ggplot2::expansion(add = c(3, 0))) +
+    base_breaks_x(0:1, expand = ggplot2::expansion(add = c(-0.1, 0))) +
+    titheme() +
+    ggplot2::theme(
+        aspect.ratio = 2.3,
+        legend.position = c(0.95, 0.95),
+        legend.justification = c("right", "top")
+    )

# time: 2024-09-19 12:35:25 UTC
# mode: r
+# Save the plot
+ggplot2::ggsave(file.path(config$path$figures, "oob_dist_plot.jpg"),
+    plot = oob_dist_plot,
+    width = 8,
+    height = 6
+)

# time: 2024-09-19 12:37:25 UTC
# mode: r
+oob_dist_plot <- ggplot2::ggplot() +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(y = error, fill = class),
+        position = "identity", alpha = 0.65,
+        density = ggdist::density_bounded(bandwidth = "nrd0")
+    ) +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(y = error, fill = "randomised"),
+        position = "identity", alpha = 0.65,
+        density = ggdist::density_bounded(bandwidth = "nrd0"),
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(y = error, color = class),
+        position = ggplot2::position_dodge(
+            width = .3, preserve = "single"
+        )
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(y = error, color = "randomised"),
+        position = ggplot2::position_dodge(
+            width = .3, preserve = "single"
+        )
+    ) +
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "black") +
+    ggplot2::labs(
+        title = "Distribution of percent correct by class",
+        y = "Percent correct", x = "Density"
+    ) +
+    ggplot2::scale_fill_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007", "randomised" = "grey"
+    )) +
+    ggplot2::scale_color_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007", "randomised" = "grey"
+    )) +
+    base_breaks_y(40:100, expand = ggplot2::expansion(add = c(3, 0))) +
+    base_breaks_x(0:1, expand = ggplot2::expansion(add = c(-0.1, 0))) +
+    titheme() +
+    ggplot2::theme(
+        aspect.ratio = 2.3,
+        legend.position = c(0.95, 0.95),
+        legend.justification = c("right", "top")
+    )

# time: 2024-09-19 12:37:25 UTC
# mode: r
+# Save the plot
+ggplot2::ggsave(file.path(config$path$figures, "oob_dist_plot.jpg"),
+    plot = oob_dist_plot,
+    width = 8,
+    height = 6
+)

# time: 2024-09-19 12:38:51 UTC
# mode: r
+oob_dist_plot <- ggplot2::ggplot() +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(y = error, fill = class),
+        position = "identity", alpha = 0.65,
+        density = ggdist::density_bounded(bandwidth = "nrd0")
+    ) +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(y = error, fill = "randomised"),
+        position = "identity", alpha = 0.65,
+        density = ggdist::density_bounded(bandwidth = "nrd0"),
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(y = error, color = class),
+        position = ggplot2::position_dodge(
+            width = .3, preserve = "single"
+        )
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(y = error, color = "randomised"),
+        position = ggplot2::position_dodge(
+            width = .3, preserve = "single"
+        )
+    ) +
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "black") +
+    ggplot2::labs(
+        title = "Distribution of percent correct by class",
+        y = "Percent correct", x = "Density"
+    ) +
+    ggplot2::scale_fill_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007", "randomised" = "grey"
+    )) +
+    ggplot2::scale_color_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007", "randomised" = "grey"
+    )) +
+    base_breaks_y(40:100, expand = ggplot2::expansion(add = c(3, 0))) +
+    base_breaks_x(0:1, expand = ggplot2::expansion(add = c(-0.1, 0))) +
+    titheme() +
+    ggplot2::theme(
+        aspect.ratio = 2.3,
+        legend.position = c(0.95, 0.95),
+        legend.justification = c("right", "top")
+    ) +
+    ggplot2::guides(fill = ggplot2::guide_legend(
+        title = "Class",
+        label.position = "left", label.hjust = 1
+    ))

# time: 2024-09-19 12:38:51 UTC
# mode: r
+# Save the plot
+ggplot2::ggsave(file.path(config$path$figures, "oob_dist_plot.jpg"),
+    plot = oob_dist_plot,
+    width = 8,
+    height = 6
+)

# time: 2024-09-19 12:39:16 UTC
# mode: r
+oob_dist_plot <- ggplot2::ggplot() +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(y = error, fill = class),
+        position = "identity", alpha = 0.65,
+        density = ggdist::density_bounded(bandwidth = "nrd0")
+    ) +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(y = error, fill = "randomised"),
+        position = "identity", alpha = 0.65,
+        density = ggdist::density_bounded(bandwidth = "nrd0"),
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(y = error, color = class),
+        position = ggplot2::position_dodge(
+            width = .3, preserve = "single"
+        )
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(y = error, color = "randomised"),
+        position = ggplot2::position_dodge(
+            width = .3, preserve = "single"
+        )
+    ) +
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "black") +
+    ggplot2::labs(
+        title = "Distribution of percent correct by class",
+        y = "Percent correct", x = "Density"
+    ) +
+    ggplot2::scale_fill_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007", "randomised" = "grey"
+    )) +
+    ggplot2::scale_color_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007", "randomised" = "grey"
+    )) +
+    base_breaks_y(40:100, expand = ggplot2::expansion(add = c(3, 0))) +
+    base_breaks_x(0:1, expand = ggplot2::expansion(add = c(-0.1, 0))) +
+    titheme() +
+    ggplot2::theme(
+        aspect.ratio = 2.3,
+        legend.position = c(0.95, 0.95),
+        legend.justification = c("right", "top")
+    ) +
+    ggplot2::guides(
+        fill = ggplot2::guide_legend(
+            title = "Class",
+            label.position = "left", label.hjust = 1
+        ), color = NULL
+    )

# time: 2024-09-19 12:39:17 UTC
# mode: r
+# Save the plot
+ggplot2::ggsave(file.path(config$path$figures, "oob_dist_plot.jpg"),
+    plot = oob_dist_plot,
+    width = 8,
+    height = 6
+)

# time: 2024-09-19 12:39:29 UTC
# mode: r
+oob_dist_plot <- ggplot2::ggplot() +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(y = error, fill = class),
+        position = "identity", alpha = 0.65,
+        density = ggdist::density_bounded(bandwidth = "nrd0")
+    ) +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(y = error, fill = "randomised"),
+        position = "identity", alpha = 0.65,
+        density = ggdist::density_bounded(bandwidth = "nrd0"),
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(y = error, color = class),
+        position = ggplot2::position_dodge(
+            width = .3, preserve = "single"
+        )
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(y = error, color = "randomised"),
+        position = ggplot2::position_dodge(
+            width = .3, preserve = "single"
+        )
+    ) +
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "black") +
+    ggplot2::labs(
+        title = "Distribution of percent correct by class",
+        y = "Percent correct", x = "Density"
+    ) +
+    ggplot2::scale_fill_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007", "randomised" = "grey"
+    )) +
+    ggplot2::scale_color_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007", "randomised" = "grey"
+    )) +
+    base_breaks_y(40:100, expand = ggplot2::expansion(add = c(3, 0))) +
+    base_breaks_x(0:1, expand = ggplot2::expansion(add = c(-0.1, 0))) +
+    titheme() +
+    ggplot2::theme(
+        aspect.ratio = 2.3,
+        legend.position = c(0.95, 0.95),
+        legend.justification = c("right", "top")
+    ) +
+    ggplot2::guides(
+        fill = ggplot2::guide_legend(
+            title = "Class",
+            label.position = "left", label.hjust = 1
+        ), color = NA
+    )

# time: 2024-09-19 12:39:30 UTC
# mode: r
+# Save the plot
+ggplot2::ggsave(file.path(config$path$figures, "oob_dist_plot.jpg"),
+    plot = oob_dist_plot,
+    width = 8,
+    height = 6
+)

# time: 2024-09-19 12:39:51 UTC
# mode: r
+oob_dist_plot <- ggplot2::ggplot() +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(y = error, fill = class),
+        position = "identity", alpha = 0.65,
+        density = ggdist::density_bounded(bandwidth = "nrd0")
+    ) +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(y = error, fill = "randomised"),
+        position = "identity", alpha = 0.65,
+        density = ggdist::density_bounded(bandwidth = "nrd0"),
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(y = error, color = class),
+        position = ggplot2::position_dodge(
+            width = .3, preserve = "single"
+        )
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(y = error, color = "randomised"),
+        position = ggplot2::position_dodge(
+            width = .3, preserve = "single"
+        )
+    ) +
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "black") +
+    ggplot2::labs(
+        title = "Distribution of percent correct by class",
+        y = "Percent correct", x = "Density"
+    ) +
+    ggplot2::scale_fill_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007", "randomised" = "grey"
+    )) +
+    ggplot2::scale_color_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007", "randomised" = "grey"
+    )) +
+    base_breaks_y(40:100, expand = ggplot2::expansion(add = c(3, 0))) +
+    base_breaks_x(0:1, expand = ggplot2::expansion(add = c(-0.1, 0))) +
+    titheme() +
+    ggplot2::theme(
+        aspect.ratio = 2.3,
+        legend.position = c(0.95, 0.95),
+        legend.justification = c("right", "top")
+    ) +
+    ggplot2::guides(
+        fill = ggplot2::guide_legend(
+            title = "Class",
+            label.position = "left", label.hjust = 1
+        ), color = NULL
+    )

# time: 2024-09-19 12:39:52 UTC
# mode: r
+# Save the plot
+ggplot2::ggsave(file.path(config$path$figures, "oob_dist_plot.jpg"),
+    plot = oob_dist_plot,
+    width = 8,
+    height = 6
+)

# time: 2024-09-19 12:40:09 UTC
# mode: r
+oob_dist_plot <- ggplot2::ggplot() +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(y = error, fill = class),
+        position = "identity", alpha = 0.65,
+        density = ggdist::density_bounded(bandwidth = "nrd0")
+    ) +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(y = error, fill = "randomised"),
+        position = "identity", alpha = 0.65,
+        density = ggdist::density_bounded(bandwidth = "nrd0"),
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(y = error, color = class),
+        position = ggplot2::position_dodge(
+            width = .3, preserve = "single"
+        )
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(y = error, color = "randomised"),
+        position = ggplot2::position_dodge(
+            width = .3, preserve = "single"
+        )
+    ) +
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "black") +
+    ggplot2::labs(
+        title = "Distribution of percent correct by class",
+        y = "Percent correct", x = "Density"
+    ) +
+    ggplot2::scale_fill_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007", "randomised" = "grey"
+    )) +
+    ggplot2::scale_color_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007", "randomised" = "grey"
+    )) +
+    base_breaks_y(40:100, expand = ggplot2::expansion(add = c(3, 0))) +
+    base_breaks_x(0:1, expand = ggplot2::expansion(add = c(-0.1, 0))) +
+    titheme() +
+    ggplot2::theme(
+        aspect.ratio = 2.3,
+        legend.position = c(0.95, 0.95),
+        legend.justification = c("right", "top")
+    ) +
+    ggplot2::guides(
+        fill = ggplot2::guide_legend(
+            title = "Class",
+            label.position = "left", label.hjust = 1
+        ), color = "none"
+    )

# time: 2024-09-19 12:40:09 UTC
# mode: r
+# Save the plot
+ggplot2::ggsave(file.path(config$path$figures, "oob_dist_plot.jpg"),
+    plot = oob_dist_plot,
+    width = 8,
+    height = 6
+)

# time: 2024-09-19 12:40:38 UTC
# mode: r
+oob_dist_plot <- ggplot2::ggplot() +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(y = error, fill = class),
+        position = "identity", alpha = 0.65,
+        density = ggdist::density_bounded(bandwidth = "nrd0")
+    ) +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(y = error, fill = "randomised"),
+        position = "identity", alpha = 0.65,
+        density = ggdist::density_bounded(bandwidth = "nrd0"),
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(y = error, color = class),
+        position = ggplot2::position_dodge(
+            width = .3, preserve = "single"
+        )
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(y = error, color = "randomised"),
+        position = ggplot2::position_dodge(
+            width = .3, preserve = "single"
+        )
+    ) +
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "black") +
+    ggplot2::labs(
+        title = "Distribution of percent correct by class",
+        y = "Percent correct", x = "Density"
+    ) +
+    ggplot2::scale_fill_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007", "randomised" = "grey"
+    )) +
+    ggplot2::scale_color_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007", "randomised" = "grey"
+    )) +
+    base_breaks_y(40:100, expand = ggplot2::expansion(add = c(3, 0))) +
+    base_breaks_x(0:1, expand = ggplot2::expansion(add = c(-0.1, 0))) +
+    titheme() +
+    ggplot2::theme(
+        aspect.ratio = 2.3,
+        legend.position = c(0.95, 0.95),
+        legend.justification = c("right", "top"), # right align the legend title
+        legend.title = ggplot2::element_text(hjust = 1)
+    ) +
+    ggplot2::guides(
+        fill = ggplot2::guide_legend(
+            title = "Class",
+            label.position = "left", label.hjust = 1
+        ), color = "none"
+    )

# time: 2024-09-19 12:40:39 UTC
# mode: r
+# Save the plot
+ggplot2::ggsave(file.path(config$path$figures, "oob_dist_plot.jpg"),
+    plot = oob_dist_plot,
+    width = 8,
+    height = 6
+)

# time: 2024-09-19 12:41:11 UTC
# mode: r
+oob_dist_plot <- ggplot2::ggplot() +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(y = error, fill = class),
+        position = "identity", alpha = 0.65,
+        density = ggdist::density_bounded(bandwidth = "nrd0")
+    ) +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(y = error, fill = "randomised"),
+        position = "identity", alpha = 0.65,
+        density = ggdist::density_bounded(bandwidth = "nrd0"),
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(y = error, color = class),
+        position = ggplot2::position_dodge(
+            width = .3, preserve = "single"
+        )
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(y = error, color = "random\nperformance"),
+        position = ggplot2::position_dodge(
+            width = .3, preserve = "single"
+        )
+    ) +
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "black") +
+    ggplot2::labs(
+        title = "Distribution of percent correct by class",
+        y = "Percent correct", x = "Density"
+    ) +
+    ggplot2::scale_fill_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007", "random\nperformance" = "grey"
+    )) +
+    ggplot2::scale_color_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007", "random\nperformance" = "grey"
+    )) +
+    base_breaks_y(40:100, expand = ggplot2::expansion(add = c(3, 0))) +
+    base_breaks_x(0:1, expand = ggplot2::expansion(add = c(-0.1, 0))) +
+    titheme() +
+    ggplot2::theme(
+        aspect.ratio = 2.3,
+        legend.position = c(0.95, 0.95),
+        legend.justification = c("right", "top"), # right align the legend title
+        legend.title = ggplot2::element_text(hjust = 1)
+    ) +
+    ggplot2::guides(
+        fill = ggplot2::guide_legend(
+            title = "Class",
+            label.position = "left", label.hjust = 1
+        ), color = "none"
+    )

# time: 2024-09-19 12:41:12 UTC
# mode: r
+# Save the plot
+ggplot2::ggsave(file.path(config$path$figures, "oob_dist_plot.jpg"),
+    plot = oob_dist_plot,
+    width = 8,
+    height = 6
+)

# time: 2024-09-19 12:42:31 UTC
# mode: r
+oob_dist_plot <- ggplot2::ggplot() +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(y = error, fill = class),
+        position = "identity", alpha = 0.65,
+        density = ggdist::density_bounded(bandwidth = "nrd0")
+    ) +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(y = error, fill = "randomised"),
+        position = "identity", alpha = 0.65,
+        density = ggdist::density_bounded(bandwidth = "nrd0"),
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(y = error, color = class),
+        position = ggplot2::position_dodge(
+            width = .3, preserve = "single"
+        )
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(y = error, color = "randomised"),
+        position = ggplot2::position_dodge(
+            width = .3, preserve = "single"
+        )
+    ) +
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "black") +
+    ggplot2::labs(
+        title = "Distribution of percent correct by class",
+        y = "Percent correct", x = "Density"
+    ) +
+    ggplot2::scale_fill_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007", "random\nperformance" = "grey"
+    )) +
+    ggplot2::scale_color_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007", "randomised" = "grey"
+    )) +
+    base_breaks_y(40:100, expand = ggplot2::expansion(add = c(3, 0))) +
+    base_breaks_x(0:1, expand = ggplot2::expansion(add = c(-0.1, 0))) +
+    titheme() +
+    ggplot2::theme(
+        aspect.ratio = 2.3,
+        legend.position = c(0.95, 0.95),
+        legend.justification = c("right", "top"), # right align the legend title
+        legend.title = ggplot2::element_text(hjust = 1)
+    ) +
+    ggplot2::guides(
+        fill = ggplot2::guide_legend(
+            title = "Class",
+            label.position = "left", label.hjust = 1
+        ), color = "none"
+    )

# time: 2024-09-19 12:42:32 UTC
# mode: r
+# Save the plot
+ggplot2::ggsave(file.path(config$path$figures, "oob_dist_plot.jpg"),
+    plot = oob_dist_plot,
+    width = 8,
+    height = 6
+)

# time: 2024-09-19 12:43:49 UTC
# mode: r
+oob_dist_plot <- ggplot2::ggplot() +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(y = error, fill = class),
+        position = "identity", alpha = 0.65,
+        density = ggdist::density_bounded(bandwidth = "nrd0")
+    ) +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(y = error, fill = "randomised"),
+        position = "identity", alpha = 0.65,
+        density = ggdist::density_bounded(bandwidth = "nrd0"),
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(y = error, color = class),
+        position = ggplot2::position_dodge(
+            width = .3, preserve = "single"
+        )
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(y = error, color = "randomised"),
+        position = ggplot2::position_dodge(
+            width = .3, preserve = "single"
+        )
+    ) +
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "black") +
+    ggplot2::labs(
+        title = "Distribution of percent correct by class",
+        y = "Percent correct", x = "Density"
+    ) +
+    ggplot2::scale_fill_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007", "randomised" = "grey"
+    ), labels =  c("immigrant",  "resident", "random\performance")) +
+    ggplot2::scale_color_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007", "randomised" = "grey"
+    )) +
+    base_breaks_y(40:100, expand = ggplot2::expansion(add = c(3, 0))) +
+    base_breaks_x(0:1, expand = ggplot2::expansion(add = c(-0.1, 0))) +
+    titheme() +
+    ggplot2::theme(
+        aspect.ratio = 2.3,
+        legend.position = c(0.95, 0.95),
+        legend.justification = c("right", "top"), # right align the legend title
+        legend.title = ggplot2::element_text(hjust = 1)
+    ) +
+    ggplot2::guides(
+        fill = ggplot2::guide_legend(
+            title = "Class",
+            label.position = "left", label.hjust = 1
+        ), color = "none"
+    )

# time: 2024-09-19 12:43:50 UTC
# mode: r
+# Save the plot
+ggplot2::ggsave(file.path(config$path$figures, "oob_dist_plot.jpg"),
+    plot = oob_dist_plot,
+    width = 8,
+    height = 6
+)

# time: 2024-09-19 12:43:55 UTC
# mode: r
+oob_dist_plot <- ggplot2::ggplot() +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(y = error, fill = class),
+        position = "identity", alpha = 0.65,
+        density = ggdist::density_bounded(bandwidth = "nrd0")
+    ) +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(y = error, fill = "randomised"),
+        position = "identity", alpha = 0.65,
+        density = ggdist::density_bounded(bandwidth = "nrd0"),
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(y = error, color = class),
+        position = ggplot2::position_dodge(
+            width = .3, preserve = "single"
+        )
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(y = error, color = "randomised"),
+        position = ggplot2::position_dodge(
+            width = .3, preserve = "single"
+        )
+    ) +
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "black") +
+    ggplot2::labs(
+        title = "Distribution of percent correct by class",
+        y = "Percent correct", x = "Density"
+    ) +
+    ggplot2::scale_fill_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007", "randomised" = "grey"
+    ), labels =  c("immigrant",  "resident", "random\nperformance")) +
+    ggplot2::scale_color_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007", "randomised" = "grey"
+    )) +
+    base_breaks_y(40:100, expand = ggplot2::expansion(add = c(3, 0))) +
+    base_breaks_x(0:1, expand = ggplot2::expansion(add = c(-0.1, 0))) +
+    titheme() +
+    ggplot2::theme(
+        aspect.ratio = 2.3,
+        legend.position = c(0.95, 0.95),
+        legend.justification = c("right", "top"), # right align the legend title
+        legend.title = ggplot2::element_text(hjust = 1)
+    ) +
+    ggplot2::guides(
+        fill = ggplot2::guide_legend(
+            title = "Class",
+            label.position = "left", label.hjust = 1
+        ), color = "none"
+    )

# time: 2024-09-19 12:43:56 UTC
# mode: r
+# Save the plot
+ggplot2::ggsave(file.path(config$path$figures, "oob_dist_plot.jpg"),
+    plot = oob_dist_plot,
+    width = 8,
+    height = 6
+)

# time: 2024-09-19 12:44:34 UTC
# mode: r
+length(plot_data$oob_df)

# time: 2024-09-19 12:44:41 UTC
# mode: r
+nrow(plot_data$oob_df)

# time: 2024-09-19 12:45:38 UTC
# mode: r
+# Import configuration file # nolint
+config <- config::get()
+box::use(R / plot[titheme, titpalette, blues])
+
+progressr::handlers(progressr::handler_pbcol(
+    adjust = 1.0,
+    complete = function(s) cli::bg_red(cli::col_black(s)),
+    incomplete = function(s) cli::bg_cyan(cli::col_black(s))
+))
+
+# parameters
+percent.train <- 0.7
+num.threads <- 44
+num.eigenvectors <- 15
+set.seed(555)
+
+# Input files
+immigrant.info <- file.path(config$path$data, "600K_immigrants.fam")
+immigrant.vcf <- file.path(config$path$data, "600K_immigrants.vcf")
+resident.vcf <- file.path(config$path$data, "600K_residents.vcf")
+
+immigrant.gds <- file.path(config$path$data, "immigrant_recode.gds")
+resident.gds <- file.path(config$path$data, "resident_recode.gds")
+all.gds <- file.path(config$path$data, "all_recode.gds")
+
+
+# Load all the data
+all.maf <- SNPRelate::snpgdsOpen(all.gds, allow.duplicate = TRUE)
+
+# Load labels
+immigrant.id <- gdsfmt::read.gdsn(gdsfmt::index.gdsn(
+    SNPRelate::snpgdsOpen(immigrant.gds),
+    "sample.id"
+))
+resident.id <- gdsfmt::read.gdsn(gdsfmt::index.gdsn(
+    SNPRelate::snpgdsOpen(resident.gds),
+    "sample.id"
+))
+
+all.id <- gdsfmt::read.gdsn(gdsfmt::index.gdsn(all.maf, "sample.id"))
+all.label <- ifelse(all.id %in% immigrant.id, "immigrant", "resident")
+
+
+# Function to split data into training and testing sets
+split_data <- function(all.id, all.label, percent.train) {
+    # Split data by class
+    labels <- unique(all.label)
+    class_0 <- all.id[all.label == labels[1]]
+    class_1 <- all.id[all.label == labels[2]]
+
+    # Determine the size of the smaller class
+    min_class_size <- min(length(class_0), length(class_1))
+
+    # Undersample the majority class
+    if (length(class_0) > min_class_size) {
+        class_0 <- sample(class_0, min_class_size)
+    } else {
+        class_1 <- sample(class_1, min_class_size)
+    }
+
+    # Combine the balanced classes
+    balanced_ids <- c(class_0, class_1)
+    balanced_labels <- c(
+        rep(labels[1], length(class_0)),
+        rep(labels[2], length(class_1))
+    )
+
+    # Calculate the number of samples for training
+    num_train <- round(length(balanced_ids) * percent.train)
+
+    # Ensure equal representation of both classes in train and test sets
+    num_train_per_class <- num_train %/% 2
+
+    # Randomly select samples for training from each class
+    train_indices <- c(
+        sample(1:min_class_size, num_train_per_class),
+        sample((min_class_size + 1):(2 * min_class_size), num_train_per_class)
+    )
+
+    train.id <- balanced_ids[train_indices]
+    test.id <- balanced_ids[-train_indices]
+    train.label <- balanced_labels[train_indices]
+    test.label <- balanced_labels[-train_indices]
+
+    list(
+        train.id = train.id, test.id = test.id,
+        train.label = train.label, test.label = test.label
+    )
+}
+# Function to perform PCA and prepare data frames
+prepare_data <- function(
+    all.maf, train.id, test.id,
+    train.label, test.label, num.eigenvectors, num.threads) {
+    pca <- SNPRelate::snpgdsPCA(
+        all.maf,
+        sample.id = train.id, num.thread = num.threads, verbose = FALSE
+    )
+    snp_loadings <- SNPRelate::snpgdsPCASNPLoading(
+        pca, all.maf,
+        num.thread = num.threads, verbose = FALSE
+    )
+    sample_loadings <- SNPRelate::snpgdsPCASampLoading(
+        snp_loadings, all.maf,
+        sample.id = test.id, num.thread = num.threads, verbose = FALSE
+    )
+    train_eigenvects <- data.frame(
+        sample.id = pca$sample.id, pca$eigenvect[, 1:num.eigenvectors]
+    )
+    test_eigenvects <- data.frame(
+        sample.id = sample_loadings$sample.id, sample_loadings$eigenvect[, 1:num.eigenvectors]
+    )
+    train_df <- data.frame(sample.id = train.id, pop = train.label, train_eigenvects[, -1])
+    test_df <- data.frame(sample.id = test.id, pop = test.label, test_eigenvects[, -1])
+    list(train_df = train_df, test_df = test_df)
+}
+
+# Function to train a random forest with optional randomized labels
+train_random_forest <- function(
+    train_df, test_df, num.eigenvectors, randomize_labels = FALSE) {
+    if (randomize_labels) {
+        train_df$pop <- sample(train_df$pop)
+    }
+
+    return(randomForest::randomForest(
+        train_df[, 3:(2 + num.eigenvectors)],
+        y = as.factor(train_df$pop),
+        data = train_df,
+        xtest = test_df[, 3:(2 + num.eigenvectors)],
+        ytest = as.factor(test_df$pop),
+        ntree = 500,
+        replace = FALSE,
+        proximity = TRUE
+    ))
+}
+
+# Function to run a single iteration
+run_iteration <- function(
+    all.id, all.label, all.maf, percent.train, num.eigenvectors, num.threads, randomize_labels) {
+    # Split data
+    split <- split_data(all.id, all.label, percent.train)
+
+    # Prepare data
+    data <- prepare_data(
+        all.maf, split$train.id, split$test.id, split$train.label, split$test.label,
+        num.eigenvectors, num.threads
+    )
+
+    # Train random forest
+    rf <- train_random_forest(data$train_df, data$test_df, num.eigenvectors, randomize_labels)
+
+    # Extract OOB error rates
+    oob_data <- rfPermute::plotTrace(rf, plot = FALSE)$data
+
+    # Return both OOB data, the random forest model, and the train/test labels
+    return(list(
+        oob_data = oob_data, rf_model = rf,
+        train_labels = split$train.label, test_labels = split$test.label
+    ))
+}
+
+# Main function to run multiple iterations
+run_analysis <- function(
+    all.id, all.label, all.maf, percent.train,
+    num.eigenvectors, num.threads,
+    n_iterations = 1) {
+    set.seed(123) # For reproducibility
+
+    # Initialize progress bar
+    progressr::with_progress({
+        p <- progressr::progressor(along = 1:(2 * n_iterations))
+
+        # Run iterations with original labels
+        original_results <- replicate(n_iterations,
+            {
+                p()
+                run_iteration(
+                    all.id, all.label, all.maf, percent.train,
+                    num.eigenvectors, num.threads, FALSE
+                )
+            },
+            simplify = FALSE
+        )
+
+        # Run iterations with randomized labels
+        random_results <- replicate(n_iterations,
+            {
+                p()
+                run_iteration(
+                    all.id, all.label, all.maf, percent.train,
+                    num.eigenvectors, num.threads, TRUE
+                )
+            },
+            simplify = FALSE
+        )
+    })
+
+    # Separate OOB data, RF models, and train/test labels
+    original_oob <- lapply(original_results, function(x) x$oob_data)
+    original_rf_models <- lapply(original_results, function(x) x$rf_model)
+    original_train_labels <- lapply(original_results, function(x) x$train_labels)
+    original_test_labels <- lapply(original_results, function(x) x$test_labels)
+
+    random_oob <- lapply(random_results, function(x) x$oob_data)
+    random_rf_models <- lapply(random_results, function(x) x$rf_model)
+    random_train_labels <- lapply(random_results, function(x) x$train_labels)
+    random_test_labels <- lapply(random_results, function(x) x$test_labels)
+
+    # Combine OOB results
+    oob_df <- dplyr::as_tibble(do.call(rbind, original_oob))
+    random_oob_df <- dplyr::as_tibble(do.call(rbind, random_oob))
+
+    list(
+        oob_df = oob_df,
+        random_oob_df = random_oob_df,
+        original_rf_models = original_rf_models,
+        random_rf_models = random_rf_models,
+        original_train_labels = original_train_labels,
+        original_test_labels = original_test_labels,
+        random_train_labels = random_train_labels,
+        random_test_labels = random_test_labels
+    )
+}
+
+calculate_mean_error <- function(data) {
+    data |>
+        dplyr::group_by(trees, class) |>
+        dplyr::summarise(mean_error = mean(error), .groups = "drop") |> # nolint: object_usage_linter.
+        dplyr::filter(class != "OOB")
+}
+
+
+# ----------------------------------- main ----------------------------------- #
+
+# TODO:
+# - RF error rate plot
+# - Summary statistics for random and original models
+# - MDS plot
+# - Confusion matrix
+# - Calculate some sort of distance between points and cluster centroids
+
+# Check if results file exists
+results_file <- file.path(config$path$data, "rf_results.rds")

# time: 2024-09-19 12:47:25 UTC
# mode: r
+oob_dist_plot <- ggplot2::ggplot() +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(y = error, fill = class),
+        position = "identity", alpha = 0.65,
+        density = ggdist::density_bounded(bandwidth = "nrd0"n=20)
+    ) +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(y = error, fill = "randomised"),
+        position = "identity", alpha = 0.65,
+        density = ggdist::density_bounded(bandwidth = "nrd0"n=20),
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(y = error, color = class),
+        position = ggplot2::position_dodge(
+            width = .3, preserve = "single"
+        )
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(y = error, color = "randomised"),
+        position = ggplot2::position_dodge(
+            width = .3, preserve = "single"
+        )
+    ) +
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "black") +
+    ggplot2::labs(
+        title = "Distribution of percent correct by class",
+        y = "Percent correct", x = "Density"
+    ) +
+    ggplot2::scale_fill_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007", "randomised" = "grey"
+    ), labels =  c("immigrant",  "resident", "random\nperformance")) +
+    ggplot2::scale_color_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007", "randomised" = "grey"
+    )) +
+    base_breaks_y(40:100, expand = ggplot2::expansion(add = c(3, 0))) +
+    base_breaks_x(0:1, expand = ggplot2::expansion(add = c(-0.1, 0))) +
+    titheme() +
+    ggplot2::theme(
+        aspect.ratio = 2.3,
+        legend.position = c(0.95, 0.95),
+        legend.justification = c("right", "top"), # right align the legend title
+        legend.title = ggplot2::element_text(hjust = 1)
+    ) +
+    ggplot2::guides(
+        fill = ggplot2::guide_legend(
+            title = "Class",
+            label.position = "left", label.hjust = 1
+        ), color = "none"
+    )

# time: 2024-09-19 12:47:26 UTC
# mode: r
+# Save the plot
+ggplot2::ggsave(file.path(config$path$figures, "oob_dist_plot.jpg"),
+    plot = oob_dist_plot,
+    width = 8,
+    height = 6
+)

# time: 2024-09-19 12:47:27 UTC
# mode: r
+# run a single random forest model:
+
+# 1 prepare data
+split <- split_data(all.id, all.label, percent.train)

# time: 2024-09-19 12:47:36 UTC
# mode: r
+oob_dist_plot <- ggplot2::ggplot() +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(y = error, fill = class),
+        position = "identity", alpha = 0.65,
+        density = ggdist::density_bounded(bandwidth = "nrd0",n=20)
+    ) +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(y = error, fill = "randomised"),
+        position = "identity", alpha = 0.65,
+        density = ggdist::density_bounded(bandwidth = "nrd0",n=20),
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(y = error, color = class),
+        position = ggplot2::position_dodge(
+            width = .3, preserve = "single"
+        )
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(y = error, color = "randomised"),
+        position = ggplot2::position_dodge(
+            width = .3, preserve = "single"
+        )
+    ) +
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "black") +
+    ggplot2::labs(
+        title = "Distribution of percent correct by class",
+        y = "Percent correct", x = "Density"
+    ) +
+    ggplot2::scale_fill_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007", "randomised" = "grey"
+    ), labels =  c("immigrant",  "resident", "random\nperformance")) +
+    ggplot2::scale_color_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007", "randomised" = "grey"
+    )) +
+    base_breaks_y(40:100, expand = ggplot2::expansion(add = c(3, 0))) +
+    base_breaks_x(0:1, expand = ggplot2::expansion(add = c(-0.1, 0))) +
+    titheme() +
+    ggplot2::theme(
+        aspect.ratio = 2.3,
+        legend.position = c(0.95, 0.95),
+        legend.justification = c("right", "top"), # right align the legend title
+        legend.title = ggplot2::element_text(hjust = 1)
+    ) +
+    ggplot2::guides(
+        fill = ggplot2::guide_legend(
+            title = "Class",
+            label.position = "left", label.hjust = 1
+        ), color = "none"
+    )

# time: 2024-09-19 12:47:36 UTC
# mode: r
+# Save the plot
+ggplot2::ggsave(file.path(config$path$figures, "oob_dist_plot.jpg"),
+    plot = oob_dist_plot,
+    width = 8,
+    height = 6
+)

# time: 2024-09-19 12:48:54 UTC
# mode: r
+oob_dist_plot <- ggplot2::ggplot() +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(y = error, fill = class),
+        position = "identity", alpha = 0.65,
+        density = ggdist::density_bounded(bandwidth = 20)
+    ) +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(y = error, fill = "randomised"),
+        position = "identity", alpha = 0.65,
+        density = ggdist::density_bounded(bandwidth = 20),
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(y = error, color = class),
+        position = ggplot2::position_dodge(
+            width = .3, preserve = "single"
+        )
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(y = error, color = "randomised"),
+        position = ggplot2::position_dodge(
+            width = .3, preserve = "single"
+        )
+    ) +
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "black") +
+    ggplot2::labs(
+        title = "Distribution of percent correct by class",
+        y = "Percent correct", x = "Density"
+    ) +
+    ggplot2::scale_fill_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007", "randomised" = "grey"
+    ), labels =  c("immigrant",  "resident", "random\nperformance")) +
+    ggplot2::scale_color_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007", "randomised" = "grey"
+    )) +
+    base_breaks_y(40:100, expand = ggplot2::expansion(add = c(3, 0))) +
+    base_breaks_x(0:1, expand = ggplot2::expansion(add = c(-0.1, 0))) +
+    titheme() +
+    ggplot2::theme(
+        aspect.ratio = 2.3,
+        legend.position = c(0.95, 0.95),
+        legend.justification = c("right", "top"), # right align the legend title
+        legend.title = ggplot2::element_text(hjust = 1)
+    ) +
+    ggplot2::guides(
+        fill = ggplot2::guide_legend(
+            title = "Class",
+            label.position = "left", label.hjust = 1
+        ), color = "none"
+    )

# time: 2024-09-19 12:48:54 UTC
# mode: r
+# Save the plot
+ggplot2::ggsave(file.path(config$path$figures, "oob_dist_plot.jpg"),
+    plot = oob_dist_plot,
+    width = 8,
+    height = 6
+)

# time: 2024-09-19 12:49:01 UTC
# mode: r
+oob_dist_plot <- ggplot2::ggplot() +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(y = error, fill = class),
+        position = "identity", alpha = 0.65,
+        density = ggdist::density_bounded(bandwidth = 2)
+    ) +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(y = error, fill = "randomised"),
+        position = "identity", alpha = 0.65,
+        density = ggdist::density_bounded(bandwidth = 2),
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(y = error, color = class),
+        position = ggplot2::position_dodge(
+            width = .3, preserve = "single"
+        )
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(y = error, color = "randomised"),
+        position = ggplot2::position_dodge(
+            width = .3, preserve = "single"
+        )
+    ) +
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "black") +
+    ggplot2::labs(
+        title = "Distribution of percent correct by class",
+        y = "Percent correct", x = "Density"
+    ) +
+    ggplot2::scale_fill_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007", "randomised" = "grey"
+    ), labels =  c("immigrant",  "resident", "random\nperformance")) +
+    ggplot2::scale_color_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007", "randomised" = "grey"
+    )) +
+    base_breaks_y(40:100, expand = ggplot2::expansion(add = c(3, 0))) +
+    base_breaks_x(0:1, expand = ggplot2::expansion(add = c(-0.1, 0))) +
+    titheme() +
+    ggplot2::theme(
+        aspect.ratio = 2.3,
+        legend.position = c(0.95, 0.95),
+        legend.justification = c("right", "top"), # right align the legend title
+        legend.title = ggplot2::element_text(hjust = 1)
+    ) +
+    ggplot2::guides(
+        fill = ggplot2::guide_legend(
+            title = "Class",
+            label.position = "left", label.hjust = 1
+        ), color = "none"
+    )

# time: 2024-09-19 12:49:02 UTC
# mode: r
+# Save the plot
+ggplot2::ggsave(file.path(config$path$figures, "oob_dist_plot.jpg"),
+    plot = oob_dist_plot,
+    width = 8,
+    height = 6
+)

# time: 2024-09-19 12:49:13 UTC
# mode: r
+oob_dist_plot <- ggplot2::ggplot() +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(y = error, fill = class),
+        position = "identity", alpha = 0.65,
+        density = ggdist::density_bounded(bandwidth = 1)
+    ) +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(y = error, fill = "randomised"),
+        position = "identity", alpha = 0.65,
+        density = ggdist::density_bounded(bandwidth = 1),
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(y = error, color = class),
+        position = ggplot2::position_dodge(
+            width = .3, preserve = "single"
+        )
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(y = error, color = "randomised"),
+        position = ggplot2::position_dodge(
+            width = .3, preserve = "single"
+        )
+    ) +
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "black") +
+    ggplot2::labs(
+        title = "Distribution of percent correct by class",
+        y = "Percent correct", x = "Density"
+    ) +
+    ggplot2::scale_fill_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007", "randomised" = "grey"
+    ), labels =  c("immigrant",  "resident", "random\nperformance")) +
+    ggplot2::scale_color_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007", "randomised" = "grey"
+    )) +
+    base_breaks_y(40:100, expand = ggplot2::expansion(add = c(3, 0))) +
+    base_breaks_x(0:1, expand = ggplot2::expansion(add = c(-0.1, 0))) +
+    titheme() +
+    ggplot2::theme(
+        aspect.ratio = 2.3,
+        legend.position = c(0.95, 0.95),
+        legend.justification = c("right", "top"), # right align the legend title
+        legend.title = ggplot2::element_text(hjust = 1)
+    ) +
+    ggplot2::guides(
+        fill = ggplot2::guide_legend(
+            title = "Class",
+            label.position = "left", label.hjust = 1
+        ), color = "none"
+    )

# time: 2024-09-19 12:49:13 UTC
# mode: r
+# Save the plot
+ggplot2::ggsave(file.path(config$path$figures, "oob_dist_plot.jpg"),
+    plot = oob_dist_plot,
+    width = 8,
+    height = 6
+)

# time: 2024-09-19 12:49:32 UTC
# mode: r
+oob_dist_plot <- ggplot2::ggplot() +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(y = error, fill = class),
+        position = "identity", alpha = 0.65,
+        density = ggdist::density_unbounded(bandwidth = 1)
+    ) +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(y = error, fill = "randomised"),
+        position = "identity", alpha = 0.65,
+        density = ggdist::density_unbounded(bandwidth = 1),
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(y = error, color = class),
+        position = ggplot2::position_dodge(
+            width = .3, preserve = "single"
+        )
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(y = error, color = "randomised"),
+        position = ggplot2::position_dodge(
+            width = .3, preserve = "single"
+        )
+    ) +
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "black") +
+    ggplot2::labs(
+        title = "Distribution of percent correct by class",
+        y = "Percent correct", x = "Density"
+    ) +
+    ggplot2::scale_fill_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007", "randomised" = "grey"
+    ), labels =  c("immigrant",  "resident", "random\nperformance")) +
+    ggplot2::scale_color_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007", "randomised" = "grey"
+    )) +
+    base_breaks_y(40:100, expand = ggplot2::expansion(add = c(3, 0))) +
+    base_breaks_x(0:1, expand = ggplot2::expansion(add = c(-0.1, 0))) +
+    titheme() +
+    ggplot2::theme(
+        aspect.ratio = 2.3,
+        legend.position = c(0.95, 0.95),
+        legend.justification = c("right", "top"), # right align the legend title
+        legend.title = ggplot2::element_text(hjust = 1)
+    ) +
+    ggplot2::guides(
+        fill = ggplot2::guide_legend(
+            title = "Class",
+            label.position = "left", label.hjust = 1
+        ), color = "none"
+    )

# time: 2024-09-19 12:49:33 UTC
# mode: r
+# Save the plot
+ggplot2::ggsave(file.path(config$path$figures, "oob_dist_plot.jpg"),
+    plot = oob_dist_plot,
+    width = 8,
+    height = 6
+)

# time: 2024-09-19 12:50:19 UTC
# mode: r
+oob_dist_plot <- ggplot2::ggplot() +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(y = error, fill = class),
+        position = "identity", alpha = 0.65,
+        density = ggdist::density_bounded(bandwidth = 1, trim=FALSE)
+    ) +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(y = error, fill = "randomised"),
+        position = "identity", alpha = 0.65,
+        density = ggdist::density_bounded(bandwidth = 1,  trim=FALSE),
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(y = error, color = class),
+        position = ggplot2::position_dodge(
+            width = .3, preserve = "single"
+        )
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(y = error, color = "randomised"),
+        position = ggplot2::position_dodge(
+            width = .3, preserve = "single"
+        )
+    ) +
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "black") +
+    ggplot2::labs(
+        title = "Distribution of percent correct by class",
+        y = "Percent correct", x = "Density"
+    ) +
+    ggplot2::scale_fill_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007", "randomised" = "grey"
+    ), labels =  c("immigrant",  "resident", "random\nperformance")) +
+    ggplot2::scale_color_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007", "randomised" = "grey"
+    )) +
+    base_breaks_y(40:100, expand = ggplot2::expansion(add = c(3, 0))) +
+    base_breaks_x(0:1, expand = ggplot2::expansion(add = c(-0.1, 0))) +
+    titheme() +
+    ggplot2::theme(
+        aspect.ratio = 2.3,
+        legend.position = c(0.95, 0.95),
+        legend.justification = c("right", "top"), # right align the legend title
+        legend.title = ggplot2::element_text(hjust = 1)
+    ) +
+    ggplot2::guides(
+        fill = ggplot2::guide_legend(
+            title = "Class",
+            label.position = "left", label.hjust = 1
+        ), color = "none"
+    )

# time: 2024-09-19 12:50:20 UTC
# mode: r
+# Save the plot
+ggplot2::ggsave(file.path(config$path$figures, "oob_dist_plot.jpg"),
+    plot = oob_dist_plot,
+    width = 8,
+    height = 6
+)

# time: 2024-09-19 12:50:42 UTC
# mode: r
+oob_dist_plot <- ggplot2::ggplot() +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(y = error, fill = class),
+        position = "identity", alpha = 0.65,
+        density = ggdist::density_bounded(bandwidth = .5, trim=FALSE)
+    ) +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(y = error, fill = "randomised"),
+        position = "identity", alpha = 0.65,
+        density = ggdist::density_bounded(bandwidth = .5,  trim=FALSE),
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(y = error, color = class),
+        position = ggplot2::position_dodge(
+            width = .3, preserve = "single"
+        )
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(y = error, color = "randomised"),
+        position = ggplot2::position_dodge(
+            width = .3, preserve = "single"
+        )
+    ) +
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "black") +
+    ggplot2::labs(
+        title = "Distribution of percent correct by class",
+        y = "Percent correct", x = "Density"
+    ) +
+    ggplot2::scale_fill_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007", "randomised" = "grey"
+    ), labels =  c("immigrant",  "resident", "random\nperformance")) +
+    ggplot2::scale_color_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007", "randomised" = "grey"
+    )) +
+    base_breaks_y(40:100, expand = ggplot2::expansion(add = c(3, 0))) +
+    base_breaks_x(0:1, expand = ggplot2::expansion(add = c(-0.1, 0))) +
+    titheme() +
+    ggplot2::theme(
+        aspect.ratio = 2.3,
+        legend.position = c(0.95, 0.95),
+        legend.justification = c("right", "top"), # right align the legend title
+        legend.title = ggplot2::element_text(hjust = 1)
+    ) +
+    ggplot2::guides(
+        fill = ggplot2::guide_legend(
+            title = "Class",
+            label.position = "left", label.hjust = 1
+        ), color = "none"
+    )

# time: 2024-09-19 12:50:43 UTC
# mode: r
+# Save the plot
+ggplot2::ggsave(file.path(config$path$figures, "oob_dist_plot.jpg"),
+    plot = oob_dist_plot,
+    width = 8,
+    height = 6
+)

# time: 2024-09-19 12:53:14 UTC
# mode: r
+oob_dist_plot <- ggplot2::ggplot() +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(y = error, fill = class),
+        position = "identity", alpha = 0.65,
+        density = ggdist::density_bounded(bandwidth = .5, trim=FALSE)
+    ) +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(y = error, fill = "randomised"),
+        position = "identity", alpha = 0.65,
+        density = ggdist::density_bounded(bandwidth = .5,  trim=FALSE),
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(y = error, color = class),
+        position = ggplot2::position_dodge(
+            width = .3, preserve = "single"
+        )
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(y = error, color = "randomised"),
+        position = ggplot2::position_dodge(
+            width = .3, preserve = "single"
+        )
+    ) +
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "black") +
+    ggplot2::labs(
+        title = "Distribution of percent correct by class",
+        y = "Percent correct", x = "Density"
+    ) +
+    ggplot2::scale_fill_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007", "randomised" = "#5a5a5a"
+    ), labels =  c("immigrant",  "resident", "random\nperformance")) +
+    ggplot2::scale_color_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007", "randomised" = "grey"
+    )) +
+    base_breaks_y(40:100, expand = ggplot2::expansion(add = c(3, 0))) +
+    base_breaks_x(0:1, expand = ggplot2::expansion(add = c(-0.1, 0))) +
+    titheme() +
+    ggplot2::theme(
+        aspect.ratio = 2.3,
+        legend.position = c(0.95, 0.95),
+        legend.justification = c("right", "top"), # right align the legend title
+        legend.title = ggplot2::element_text(hjust = 1)
+    ) +
+    ggplot2::guides(
+        fill = ggplot2::guide_legend(
+            title = "Class",
+            label.position = "left", label.hjust = 1
+        ), color = "none"
+    )

# time: 2024-09-19 12:53:14 UTC
# mode: r
+# Save the plot
+ggplot2::ggsave(file.path(config$path$figures, "oob_dist_plot.jpg"),
+    plot = oob_dist_plot,
+    width = 8,
+    height = 6
+)

# time: 2024-09-19 12:54:23 UTC
# mode: r
+# 1 prepare data
+split <- split_data(all.id, all.label, percent.train)
+
+data <- prepare_data(
+    all.maf, split$train.id, split$test.id, split$train.label, split$test.label,
+    num.eigenvectors, num.threads
+)
+
+# 2 train model
+rf <- train_random_forest(data$train_df, data$test_df, num.eigenvectors, FALSE)
+
+prox <- rfPermute::plotProximity(rf, plot = FALSE)
+
+
+# cmd the proximity matrix from the model and plot
+prox <- 1 - rf$proximity
+mds <- stats::cmdscale(prox, k = 2)
+
+# plot the MDS
+mds_df <- data.frame(mds, class = rf$y, predicted = rf$predicted)
+
+mds_plot <- ggplot2::ggplot(mds_df) +
+    ggplot2::geom_point(ggplot2::aes(x = `1`, y = `2`, color = class, shape = predicted)) +
+    ggplot2::labs(
+        title = "MDS plot of random forest proximity matrix",
+        x = "MDS1", y = "MDS2"
+    )

# time: 2024-09-19 12:54:36 UTC
# mode: r
+mds_plot

# time: 2024-09-19 12:54:43 UTC
# mode: r
+mds_df

# time: 2024-09-19 12:55:04 UTC
# mode: r
+ggplot2::ggplot(mds_df) +
+    ggplot2::geom_point(ggplot2::aes(x = X1, y = X2, color = class, shape = predicted)) +
+    ggplot2::labs(
+        title = "MDS plot of random forest proximity matrix",
+        x = "MDS1", y = "MDS2"
+    )

# time: 2024-09-19 12:55:50 UTC
# mode: r
+ggplot2::ggplot(mds_df) +
+    ggplot2::geom_point(ggplot2::aes(x = X1, y = X2, color = class, shape = predicted))

# time: 2024-09-19 12:56:09 UTC
# mode: r
+mds_plot <-
+ggplot2::ggplot(mds_df) +
+    ggplot2::geom_point(ggplot2::aes(x = X1, y = X2, color = class, shape = predicted))

# time: 2024-09-19 12:56:10 UTC
# mode: r
+# save the plot
+ggplot2::ggsave(file.path(config$path$figures, "mds_plot.jpg"),
+    plot = mds_plot,
+    width = 8,
+    height = 6
+)

# time: 2024-09-19 12:56:48 UTC
# mode: r
+prox <- rfPermute::plotProximity(rf, plot = TRUE)

# time: 2024-09-19 12:56:50 UTC
# mode: r
+prox

# time: 2024-09-19 12:58:41 UTC
# mode: r
+.vsc.attach()

# time: 2024-09-19 13:03:24 UTC
# mode: r
+ggplot2::geom_point(ggplot2::aes()) +
+        ggplot2::geom_point(
+            ggplot2::aes(color = predicted),
+            shape = 21,
+            size = circle.size,
+            stroke = circle.border,
+            show.legend = FALSE
+        )

# time: 2024-09-19 13:03:42 UTC
# mode: r
+mds_plot <-
+    ggplot2::ggplot(mds_df, ggplot2::aes(x = X1, y = X2)) +
+    +ggplot2::geom_point(
+        ggplot2::aes(color = class),
+        size = point.size,
+        show.legend = legend.type == "legend"
+    )

# time: 2024-09-19 13:03:49 UTC
# mode: r
+mds_plot <-
+    ggplot2::ggplot(mds_df, ggplot2::aes(x = X1, y = X2)) +
+    ggplot2::geom_point(
+        ggplot2::aes(color = class),
+        size = point.size,
+        show.legend = legend.type == "legend"
+    ) +
+    ggplot2::geom_point(ggplot2::aes()) +
+        ggplot2::geom_point(
+            ggplot2::aes(color = predicted),
+            shape = 21,
+            size = 3,
+            stroke = 5,
+            show.legend = FALSE
+        )

# time: 2024-09-19 13:03:56 UTC
# mode: r
+mds_plot <-
+    ggplot2::ggplot(mds_df, ggplot2::aes(x = X1, y = X2)) +
+    ggplot2::geom_point(
+        ggplot2::aes(color = class),
+        size = 3,
+        show.legend = legend.type == "legend"
+    ) +
+    ggplot2::geom_point(ggplot2::aes()) +
+        ggplot2::geom_point(
+            ggplot2::aes(color = predicted),
+            shape = 21,
+            size = 3,
+            stroke = 5,
+            show.legend = FALSE
+        )

# time: 2024-09-19 13:04:10 UTC
# mode: r
+mds_plot <-
+    ggplot2::ggplot(mds_df, ggplot2::aes(x = X1, y = X2)) +
+    ggplot2::geom_point(
+        ggplot2::aes(color = class),
+        size = 3
+    ) +
+    ggplot2::geom_point(ggplot2::aes()) +
+        ggplot2::geom_point(
+            ggplot2::aes(color = predicted),
+            shape = 21,
+            size = 3,
+            stroke = 5,
+            show.legend = FALSE
+        )

# time: 2024-09-19 13:04:11 UTC
# mode: r
+# save the plot
+ggplot2::ggsave(file.path(config$path$figures, "mds_plot.jpg"),
+    plot = mds_plot,
+    width = 8,
+    height = 6
+)

# time: 2024-09-19 13:04:40 UTC
# mode: r
+mds_plot <-
+    ggplot2::ggplot(mds_df, ggplot2::aes(x = X1, y = X2)) +
+    ggplot2::geom_point(
+        ggplot2::aes(color = class),
+        size = 3
+    ) +
+    ggplot2::geom_point(ggplot2::aes()) +
+        ggplot2::geom_point(
+            ggplot2::aes(color = predicted),
+            shape = 21,
+            size = 3,
+            stroke = 1,
+            show.legend = FALSE
+        )

# time: 2024-09-19 13:04:41 UTC
# mode: r
+# save the plot
+ggplot2::ggsave(file.path(config$path$figures, "mds_plot.jpg"),
+    plot = mds_plot,
+    width = 8,
+    height = 6
+)

# time: 2024-09-19 13:04:50 UTC
# mode: r
+mds_plot <-
+    ggplot2::ggplot(mds_df, ggplot2::aes(x = X1, y = X2)) +
+    ggplot2::geom_point(
+        ggplot2::aes(fill = class),
+        size = 3
+    ) +
+    ggplot2::geom_point(ggplot2::aes()) +
+        ggplot2::geom_point(
+            ggplot2::aes(color = predicted),
+            shape = 21,
+            size = 3,
+            stroke = 1,
+            show.legend = FALSE
+        )

# time: 2024-09-19 13:04:51 UTC
# mode: r
+# save the plot
+ggplot2::ggsave(file.path(config$path$figures, "mds_plot.jpg"),
+    plot = mds_plot,
+    width = 8,
+    height = 6
+)

# time: 2024-09-19 13:06:58 UTC
# mode: r
+mds_plot <-
+    ggplot2::ggplot(mds_df, ggplot2::aes(x = X1, y = X2, color = class)) +
+    ggplot2::geom_point(
+        size = point.size
+    ) +
+    ggplot2::geom_point(ggplot2::aes()) +
+        ggplot2::geom_point(
+            ggplot2::aes(color = predicted),
+            shape = 21,
+            size = circle.size,
+            stroke = circle.border,
+            show.legend = FALSE
+        )

# time: 2024-09-19 13:07:04 UTC
# mode: r
+point.size = 2
+circle.size = 8
+circle.border = 1
+
+
+mds_plot <-
+    ggplot2::ggplot(mds_df, ggplot2::aes(x = X1, y = X2, color = class)) +
+    ggplot2::geom_point(
+        size = point.size
+    ) +
+    ggplot2::geom_point(ggplot2::aes()) +
+        ggplot2::geom_point(
+            ggplot2::aes(color = predicted),
+            shape = 21,
+            size = circle.size,
+            stroke = circle.border,
+            show.legend = FALSE
+        )

# time: 2024-09-19 13:07:06 UTC
# mode: r
+# save the plot
+ggplot2::ggsave(file.path(config$path$figures, "mds_plot.jpg"),
+    plot = mds_plot,
+    width = 8,
+    height = 6
+)

# time: 2024-09-19 13:07:41 UTC
# mode: r
+data

# time: 2024-09-19 13:08:19 UTC
# mode: r
+names(data)

# time: 2024-09-19 13:09:53 UTC
# mode: r
+names(rf)

# time: 2024-09-19 13:10:29 UTC
# mode: r
+# 1 prepare data
+split <- split_data(all.id, all.label, percent.train)
+
+data <- prepare_data(
+    all.maf, split$train.id, split$test.id, split$train.label, split$test.label,
+    num.eigenvectors, num.threads
+)
+
+# 2 train model
+rf <- train_random_forest(data$train_df, data$test_df, num.eigenvectors, FALSE)
+# just
+
+# cmd the proximity matrix from the model and plot
+prox <- 1 - rf$proximity
+mds <- stats::cmdscale(prox, k = 2)
+
+# plot the MDS
+mds_df <- data.frame(mds, class = rf$y, predicted = rf$predicted)
+
+point.size = 2
+circle.size = 8
+circle.border = 1
+
+
+mds_plot <-
+    ggplot2::ggplot(mds_df, ggplot2::aes(x = X1, y = X2, color = class)) +
+    ggplot2::geom_point(
+        size = point.size
+    ) +
+    ggplot2::geom_point(ggplot2::aes()) +
+        ggplot2::geom_point(
+            ggplot2::aes(color = predicted),
+            shape = 21,
+            size = circle.size,
+            stroke = circle.border,
+            show.legend = FALSE
+        )
+
+# save the plot
+ggplot2::ggsave(file.path(config$path$figures, "mds_plot.jpg"),
+    plot = mds_plot,
+    width = 8,
+    height = 6
+)

# time: 2024-09-19 13:14:33 UTC
# mode: r
+split

# time: 2024-09-19 13:14:42 UTC
# mode: r
+all.id

# time: 2024-09-19 13:14:48 UTC
# mode: r
+all

# time: 2024-09-19 13:15:01 UTC
# mode: r
+all.maf

# time: 2024-09-19 13:16:03 UTC
# mode: r
+# now do the same but with an unsupervised random forest model
+
+# combine all data into the same df
+all_data =  data$train_df |>
+    dplyr::bind_rows(data$test_df) |>
+    dplyr::select(-sample.id)

# time: 2024-09-19 13:16:05 UTC
# mode: r
+all_data

# time: 2024-09-19 13:16:20 UTC
# mode: r
+# now do the same but with an unsupervised random forest model
+
+# combine all data into the same df
+all_data = data$train_df |>
+    dplyr::bind_rows(data$test_df) |>
+    dplyr::select(-sample.id) |>
+    dplyr::as_tibble()

# time: 2024-09-19 13:16:25 UTC
# mode: r
+all_data

# time: 2024-09-19 13:16:56 UTC
# mode: r
+# now do the same but with an unsupervised random forest model
+
+# combine all data into the same df
+all_data = data$train_df |>
+    dplyr::bind_rows(data$test_df) |>
+    dplyr::as_tibble()

# time: 2024-09-19 13:17:24 UTC
# mode: r
+# remove pop and sample.id columns and train the model
+unsupervised_rf <- randomForest::randomForest(
+    all_data[, 3:(2 + num.eigenvectors)],
+    data = all_data,
+    ntree = 500,
+    replace = FALSE,
+    proximity = TRUE
+)

# time: 2024-09-19 13:17:53 UTC
# mode: r
+unsupervised_mds_plot <-
+    ggplot2::ggplot(unsupervised_mds_df, ggplot2::aes(x = X1, y = X2, color = class)) +
+    ggplot2::geom_point(
+        size = point.size
+    ) +
+    ggplot2::geom_point(ggplot2::aes()) +
+        ggplot2::geom_point(
+            ggplot2::aes(),
+            shape = 21,
+            size = circle.size,
+            stroke = circle.border,
+            show.legend = FALSE
+        )

# time: 2024-09-19 13:17:55 UTC
# mode: r
+# plot the MDS
+unsupervised_prox <- 1 - unsupervised_rf$proximity
+unsupervised_mds <- stats::cmdscale(unsupervised_prox, k = 2)
+
+unsupervised_mds_df <- data.frame(unsupervised_mds, class = all_data$pop)
+
+unsupervised_mds_plot <-
+    ggplot2::ggplot(unsupervised_mds_df, ggplot2::aes(x = X1, y = X2, color = class)) +
+    ggplot2::geom_point(
+        size = point.size
+    ) +
+    ggplot2::geom_point(ggplot2::aes()) +
+        ggplot2::geom_point(
+            ggplot2::aes(),
+            shape = 21,
+            size = circle.size,
+            stroke = circle.border,
+            show.legend = FALSE
+        )

# time: 2024-09-19 13:17:58 UTC
# mode: r
+unsupervised_mds_plot

# time: 2024-09-19 13:18:38 UTC
# mode: r
+# remove pop and sample.id columns and train the model
+unsupervised_rf <- randomForest::randomForest(
+    all_data[, 3:(2 + num.eigenvectors)],
+    data = all_data,
+    ntree = 1000,
+    replace = FALSE,
+    proximity = TRUE
+)

# time: 2024-09-19 13:18:43 UTC
# mode: r
+unsupervised_prox <- 1 - unsupervised_rf$proximity
+unsupervised_mds <- stats::cmdscale(unsupervised_prox, k = 2)
+
+unsupervised_mds_df <- data.frame(unsupervised_mds, class = all_data$pop)
+
+unsupervised_mds_plot <-
+    ggplot2::ggplot(unsupervised_mds_df, ggplot2::aes(x = X1, y = X2, color = class)) +
+    ggplot2::geom_point(
+        size = point.size
+    ) +
+    ggplot2::geom_point(ggplot2::aes()) +
+        ggplot2::geom_point(
+            ggplot2::aes(),
+            shape = 21,
+            size = circle.size,
+            stroke = circle.border,
+            show.legend = FALSE
+        )

# time: 2024-09-19 13:18:48 UTC
# mode: r
+unsupervised_mds_plot

# time: 2024-09-19 13:19:35 UTC
# mode: r
+# remove pop and sample.id columns and train the model
+unsupervised_rf <- randomForest::randomForest(
+    all_data[, 3:(2 + num.eigenvectors)],
+    y = as.factor(all_data$pop),
+    data = all_data,
+    ntree = 1000,
+    replace = FALSE,
+    proximity = TRUE
+)

# time: 2024-09-19 13:19:38 UTC
# mode: r
+unsupervised_prox <- 1 - unsupervised_rf$proximity
+unsupervised_mds <- stats::cmdscale(unsupervised_prox, k = 2)
+
+unsupervised_mds_df <- data.frame(unsupervised_mds, class = all_data$pop)
+
+unsupervised_mds_plot <-
+    ggplot2::ggplot(unsupervised_mds_df, ggplot2::aes(x = X1, y = X2, color = class)) +
+    ggplot2::geom_point(
+        size = point.size
+    ) +
+    ggplot2::geom_point(ggplot2::aes()) +
+        ggplot2::geom_point(
+            ggplot2::aes(),
+            shape = 21,
+            size = circle.size,
+            stroke = circle.border,
+            show.legend = FALSE
+        )

# time: 2024-09-19 13:19:40 UTC
# mode: r
+unsupervised_mds_plot

# time: 2024-09-19 13:20:15 UTC
# mode: r
+nrow(mds_df)

# time: 2024-09-19 13:20:40 UTC
# mode: r
+colnames(data$train_df)

# time: 2024-09-19 13:21:09 UTC
# mode: r
+# 1 prepare data
+split <- split_data(all.id, all.label, percent.train)
+
+data <- prepare_data(
+    all.maf, split$train.id, split$test.id, split$train.label, split$test.label,
+    num.eigenvectors, num.threads
+)
+
+# 2 train model
+rf <- train_random_forest(data$train_df |> dplyr::bind_rows(data$test_df), data$test_df, num.eigenvectors, FALSE)
+# just
+
+# cmd the proximity matrix from the model and plot
+prox <- 1 - rf$proximity
+mds <- stats::cmdscale(prox, k = 2)
+
+# plot the MDS
+mds_df <- data.frame(mds, class = rf$y, predicted = rf$predicted)
+
+point.size = 2
+circle.size = 8
+circle.border = 1
+
+
+mds_plot <-
+    ggplot2::ggplot(mds_df, ggplot2::aes(x = X1, y = X2, color = class)) +
+    ggplot2::geom_point(
+        size = point.size
+    ) +
+    ggplot2::geom_point(ggplot2::aes()) +
+        ggplot2::geom_point(
+            ggplot2::aes(color = predicted),
+            shape = 21,
+            size = circle.size,
+            stroke = circle.border,
+            show.legend = FALSE
+        )
+
+# save the plot
+ggplot2::ggsave(file.path(config$path$figures, "mds_plot.jpg"),
+    plot = mds_plot,
+    width = 8,
+    height = 6
+)

# time: 2024-09-19 13:22:06 UTC
# mode: r
+nrow(mds_df)

# time: 2024-09-19 13:23:07 UTC
# mode: r
+mds_plot <-
+    ggplot2::ggplot(mds_df, ggplot2::aes(x = X1, y = X2, color = class)) +
+    ggplot2::geom_point(
+        size = point.size
+    ) +
+    ggplot2::geom_point(ggplot2::aes()) +
+        ggplot2::geom_point(
+            ggplot2::aes(color = predicted),
+            shape = 21,
+            size = circle.size,
+            stroke = circle.border,
+            show.legend = FALSE
+        ) +
+    ggplot2::scale_color_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    ))

# time: 2024-09-19 13:23:08 UTC
# mode: r
+# save the plot
+ggplot2::ggsave(file.path(config$path$figures, "mds_plot.jpg"),
+    plot = mds_plot,
+    width = 8,
+    height = 6
+)

# time: 2024-09-19 13:29:22 UTC
# mode: r
+# 1 prepare data
+split <- split_data(all.id, all.label, percent.train)
+
+data <- prepare_data(
+    all.maf, split$train.id, split$test.id, split$train.label, split$test.label,
+    num.eigenvectors, num.threads
+)
+# Use all available data as here we are not interested in the model's performance
+data = data$train_df |> dplyr::bind_rows(data$test_df)
+
+randomForest::randomForest(
+    data[, 3:(2 + num.eigenvectors)],
+    y = as.factor(data$pop),
+    ntree = 500,
+    replace = FALSE,
+    proximity = TRUE
+)

# time: 2024-09-19 13:31:34 UTC
# mode: r
+split <- split_data(all.id, all.label, percent.train)
+data <- prepare_data(
+    all.maf, split$train.id, split$test.id, split$train.label, split$test.label,
+    num.eigenvectors, num.threads
+)
+
+# Use all available data as here we are not interested in the model's performance
+data = data$train_df |> dplyr::bind_rows(data$test_df)
+
+set.seed(555)
+rf = randomForest::randomForest(
+    data[, 3:(2 + num.eigenvectors)],
+    y = as.factor(data$pop),
+    ntree = 500,
+    replace = FALSE,
+    proximity = TRUE
+)
+
+# just
+
+# cmd the proximity matrix from the model and plot
+prox <- 1 - rf$proximity
+mds <- stats::cmdscale(prox, k = 2)
+
+# plot the MDS
+mds_df <- data.frame(mds, class = rf$y, predicted = rf$predicted)
+
+point.size = 2
+circle.size = 8
+circle.border = 1
+
+
+mds_plot <-
+    ggplot2::ggplot(mds_df, ggplot2::aes(x = X1, y = X2, color = class)) +
+    ggplot2::geom_point(
+        size = point.size
+    ) +
+    ggplot2::geom_point(ggplot2::aes()) +
+        ggplot2::geom_point(
+            ggplot2::aes(color = predicted),
+            shape = 21,
+            size = circle.size,
+            stroke = circle.border,
+            show.legend = FALSE
+        ) +
+    ggplot2::scale_color_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    ))
+
+# save the plot
+ggplot2::ggsave(file.path(config$path$figures, "mds_plot.jpg"),
+    plot = mds_plot,
+    width = 8,
+    height = 6
+)

# time: 2024-09-19 13:32:25 UTC
# mode: r
+split <- split_data(all.id, all.label, percent.train)
+data <- prepare_data(
+    all.maf, split$train.id, split$test.id, split$train.label, split$test.label,
+    num.eigenvectors, num.threads
+)
+
+# Use all available data as here we are not interested in the model's performance
+data = data$train_df |> dplyr::bind_rows(data$test_df)
+
+set.seed(555)
+rf = randomForest::randomForest(
+    data[, 3:(2 + num.eigenvectors)],
+    y = as.factor(data$pop),
+    ntree = 500,
+    replace = FALSE,
+    proximity = TRUE,
+    oob.prox = FALSE
+)
+
+# cmd the proximity matrix from the model and plot
+prox <- 1 - rf$proximity
+mds <- stats::cmdscale(prox, k = 2)
+
+# plot the MDS
+mds_df <- data.frame(mds, class = rf$y, predicted = rf$predicted)
+
+point.size = 2
+circle.size = 8
+circle.border = 1
+
+mds_plot <-
+    ggplot2::ggplot(mds_df, ggplot2::aes(x = X1, y = X2, color = class)) +
+    ggplot2::geom_point(
+        size = point.size
+    ) +
+    ggplot2::geom_point(ggplot2::aes()) +
+        ggplot2::geom_point(
+            ggplot2::aes(color = predicted),
+            shape = 21,
+            size = circle.size,
+            stroke = circle.border,
+            show.legend = FALSE
+        ) +
+    ggplot2::scale_color_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    ))
+
+# save the plot
+ggplot2::ggsave(file.path(config$path$figures, "mds_plot.jpg"),
+    plot = mds_plot,
+    width = 8,
+    height = 6
+)

# time: 2024-09-19 13:32:59 UTC
# mode: r
+split <- split_data(all.id, all.label, percent.train)
+data <- prepare_data(
+    all.maf, split$train.id, split$test.id, split$train.label, split$test.label,
+    num.eigenvectors, num.threads
+)
+
+# Use all available data as here we are not interested in the model's performance
+data = data$train_df |> dplyr::bind_rows(data$test_df)
+
+set.seed(42)
+rf = randomForest::randomForest(
+    data[, 3:(2 + num.eigenvectors)],
+    y = as.factor(data$pop),
+    ntree = 500,
+    replace = FALSE,
+    proximity = TRUE,
+    oob.prox = TRUE
+)
+
+# cmd the proximity matrix from the model and plot
+prox <- 1 - rf$proximity
+mds <- stats::cmdscale(prox, k = 2)
+
+# plot the MDS
+mds_df <- data.frame(mds, class = rf$y, predicted = rf$predicted)
+
+point.size = 2
+circle.size = 8
+circle.border = 1
+
+mds_plot <-
+    ggplot2::ggplot(mds_df, ggplot2::aes(x = X1, y = X2, color = class)) +
+    ggplot2::geom_point(
+        size = point.size
+    ) +
+    ggplot2::geom_point(ggplot2::aes()) +
+        ggplot2::geom_point(
+            ggplot2::aes(color = predicted),
+            shape = 21,
+            size = circle.size,
+            stroke = circle.border,
+            show.legend = FALSE
+        ) +
+    ggplot2::scale_color_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    ))
+
+# save the plot
+ggplot2::ggsave(file.path(config$path$figures, "mds_plot.jpg"),
+    plot = mds_plot,
+    width = 8,
+    height = 6
+)

# time: 2024-09-19 13:34:47 UTC
# mode: r
+split <- split_data(all.id, all.label, percent.train)
+data <- prepare_data(
+    all.maf, split$train.id, split$test.id, split$train.label, split$test.label,
+    num.eigenvectors, num.threads
+)
+
+# Use all available data as here we are not interested in the model's performance
+data = data$train_df |> dplyr::bind_rows(data$test_df)
+
+set.seed(42)
+rf = randomForest::randomForest(
+    data[, 3:(2 + num.eigenvectors)],
+    y = as.factor(data$pop),
+    ntree = 500,
+    replace = FALSE,
+    proximity = TRUE,
+    oob.prox = TRUE
+)
+
+# cmd the proximity matrix from the model and plot
+prox <- 1 - rf$proximity
+mds <- stats::cmdscale(prox, k = 2)
+
+# plot the MDS
+mds_df <- data.frame(mds, class = rf$y, predicted = rf$predicted)
+
+point.size = 2
+circle.size = 8
+circle.border = 1
+
+mds_plot <-
+    ggplot2::ggplot(mds_df, ggplot2::aes(x = X1, y = X2, color = class)) +
+    ggplot2::geom_point(
+        size = 1.5
+    ) +
+    ggplot2::geom_point(ggplot2::aes()) +
+        ggplot2::geom_point(
+            ggplot2::aes(color = predicted),
+            shape = 21,
+            size = 5,
+            stroke = 0.5,
+            show.legend = FALSE
+        ) +
+    ggplot2::scale_color_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    ))
+
+# save the plot
+ggplot2::ggsave(file.path(config$path$figures, "mds_plot.jpg"),
+    plot = mds_plot,
+    width = 8,
+    height = 6
+)

# time: 2024-09-19 13:36:48 UTC
# mode: r
+# run a single random forest model:
+split <- split_data(all.id, all.label, percent.train)
+data <- prepare_data(
+    all.maf, split$train.id, split$test.id, split$train.label, split$test.label,
+    num.eigenvectors, num.threads
+)
+
+# Use all available data as here we are not interested in the model's performance
+data = data$train_df |> dplyr::bind_rows(data$test_df)
+
+set.seed(42)
+rf = randomForest::randomForest(
+    data[, 3:(2 + num.eigenvectors)],
+    y = as.factor(data$pop),
+    ntree = 500,
+    replace = FALSE,
+    proximity = TRUE,
+    oob.prox = TRUE
+)
+
+# cmd the proximity matrix from the model and plot
+prox <- 1 - rf$proximity
+mds <- stats::cmdscale(prox, k = 3)  # Change k to 3 to get three dimensions
+
+# plot the MDS
+mds_df <- data.frame(mds, class = rf$y, predicted = rf$predicted)
+
+point.size = 2
+circle.size = 8
+circle.border = 1
+
+# Plot for Axis 1 vs Axis 2
+mds_plot_1_2 <-
+    ggplot2::ggplot(mds_df, ggplot2::aes(x = X1, y = X2, color = class)) +
+    ggplot2::geom_point(
+        size = 1.5
+    ) +
+    ggplot2::geom_point(ggplot2::aes()) +
+        ggplot2::geom_point(
+            ggplot2::aes(color = predicted),
+            shape = 21,
+            size = 5,
+            stroke = 0.5,
+            show.legend = FALSE
+        ) +
+    ggplot2::scale_color_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    ggplot2::labs(
+        title = "MDS Plot (Axis 1 vs Axis 2)",
+        x = "Axis 1", y = "Axis 2"
+    )
+
+# Plot for Axis 1 vs Axis 3
+mds_plot_1_3 <-
+    ggplot2::ggplot(mds_df, ggplot2::aes(x = X1, y = X3, color = class)) +
+    ggplot2::geom_point(
+        size = 1.5
+    ) +
+    ggplot2::geom_point(ggplot2::aes()) +
+        ggplot2::geom_point(
+            ggplot2::aes(color = predicted),
+            shape = 21,
+            size = 5,
+            stroke = 0.5,
+            show.legend = FALSE
+        ) +
+    ggplot2::scale_color_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    ggplot2::labs(
+        title = "MDS Plot (Axis 1 vs Axis 3)",
+        x = "Axis 1", y = "Axis 3"
+    )
+
+# save the plots
+ggplot2::ggsave(file.path(config$path$figures, "mds_plot_1_2.jpg"),
+    plot = mds_plot_1_2,
+    width = 8,
+    height = 6
+)
+
+ggplot2::ggsave(file.path(config$path$figures, "mds_plot_1_3.jpg"),
+    plot = mds_plot_1_3,
+    width = 8,
+    height = 6
+)

# time: 2024-09-19 13:39:35 UTC
# mode: r
+split <- split_data(all.id, all.label, percent.train)
+data <- prepare_data(
+    all.maf, split$train.id, split$test.id, split$train.label, split$test.label,
+    num.eigenvectors, num.threads
+)
+
+# Use all available data as here we are not interested in the model's performance
+data = data$train_df |> dplyr::bind_rows(data$test_df)
+
+set.seed(42)
+rf = randomForest::randomForest(
+    data[, 3:(2 + num.eigenvectors)],
+    y = as.factor(data$pop),
+    ntree = 300,
+    replace = FALSE,
+    proximity = TRUE,
+    oob.prox = TRUE
+)
+
+# cmd the proximity matrix from the model and plot
+prox <- 1 - rf$proximity
+mds <- stats::cmdscale(prox, k = 2)
+
+# plot the MDS
+mds_df <- data.frame(mds, class = rf$y, predicted = rf$predicted)
+
+point.size = 2
+circle.size = 8
+circle.border = 1
+
+mds_plot <-
+    ggplot2::ggplot(mds_df, ggplot2::aes(x = X1, y = X2, color = class)) +
+    ggplot2::geom_point(
+        size = 1.5
+    ) +
+    ggplot2::geom_point(ggplot2::aes()) +
+        ggplot2::geom_point(
+            ggplot2::aes(color = predicted),
+            shape = 21,
+            size = 5,
+            stroke = 0.5,
+            show.legend = FALSE
+        ) +
+    ggplot2::scale_color_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    ))
+
+# save the plot
+ggplot2::ggsave(file.path(config$path$figures, "mds_plot.jpg"),
+    plot = mds_plot,
+    width = 8,
+    height = 6
+)

# time: 2024-09-19 13:40:54 UTC
# mode: r
+set.seed(42)
+split <- split_data(all.id, all.label, percent.train)
+data <- prepare_data(
+    all.maf, split$train.id, split$test.id, split$train.label, split$test.label,
+    num.eigenvectors, num.threads
+)
+
+# Use all available data as here we are not interested in the model's performance
+data = data$train_df |> dplyr::bind_rows(data$test_df)
+
+set.seed(42)
+rf = randomForest::randomForest(
+    data[, 3:(2 + num.eigenvectors)],
+    y = as.factor(data$pop),
+    ntree = 300,
+    replace = FALSE,
+    proximity = TRUE,
+    oob.prox = TRUE
+)
+
+# cmd the proximity matrix from the model and plot
+prox <- 1 - rf$proximity
+mds <- stats::cmdscale(prox, k = 2)
+
+# plot the MDS
+mds_df <- data.frame(mds, class = rf$y, predicted = rf$predicted)
+
+point.size = 2
+circle.size = 8
+circle.border = 1
+
+mds_plot <-
+    ggplot2::ggplot(mds_df, ggplot2::aes(x = X1, y = X2, color = class)) +
+    ggplot2::geom_point(
+        size = 1.5
+    ) +
+    ggplot2::geom_point(ggplot2::aes()) +
+        ggplot2::geom_point(
+            ggplot2::aes(color = predicted),
+            shape = 21,
+            size = 5,
+            stroke = 0.5,
+            show.legend = FALSE
+        ) +
+    ggplot2::scale_color_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    ))
+
+# save the plot
+ggplot2::ggsave(file.path(config$path$figures, "mds_plot.jpg"),
+    plot = mds_plot,
+    width = 8,
+    height = 6
+)

# time: 2024-09-19 13:41:50 UTC
# mode: r
+set.seed(555)
+split <- split_data(all.id, all.label, percent.train)
+data <- prepare_data(
+    all.maf, split$train.id, split$test.id, split$train.label, split$test.label,
+    num.eigenvectors, num.threads
+)
+
+# Use all available data as here we are not interested in the model's performance
+data = data$train_df |> dplyr::bind_rows(data$test_df)
+
+set.seed(555)
+rf = randomForest::randomForest(
+    data[, 3:(2 + num.eigenvectors)],
+    y = as.factor(data$pop),
+    ntree = 300,
+    replace = FALSE,
+    proximity = TRUE,
+    oob.prox = TRUE
+)
+
+# cmd the proximity matrix from the model and plot
+prox <- 1 - rf$proximity
+mds <- stats::cmdscale(prox, k = 2)
+
+# plot the MDS
+mds_df <- data.frame(mds, class = rf$y, predicted = rf$predicted)
+
+point.size = 2
+circle.size = 8
+circle.border = 1
+
+mds_plot <-
+    ggplot2::ggplot(mds_df, ggplot2::aes(x = X1, y = X2, color = class)) +
+    ggplot2::geom_point(
+        size = 1.5
+    ) +
+    ggplot2::geom_point(ggplot2::aes()) +
+        ggplot2::geom_point(
+            ggplot2::aes(color = predicted),
+            shape = 21,
+            size = 5,
+            stroke = 0.5,
+            show.legend = FALSE
+        ) +
+    ggplot2::scale_color_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    ))
+
+# save the plot
+ggplot2::ggsave(file.path(config$path$figures, "mds_plot.jpg"),
+    plot = mds_plot,
+    width = 8,
+    height = 6
+)

# time: 2024-09-19 13:43:46 UTC
# mode: r
+mds_plot <-
+    ggplot2::ggplot(mds_df, ggplot2::aes(x = X1, y = X2, color = class)) +
+    ggplot2::geom_point(
+        size = 1.5
+    ) +
+    ggplot2::geom_point(ggplot2::aes()) +
+    ggplot2::geom_point(
+        ggplot2::aes(color = predicted),
+        shape = 21,
+        size = 5,
+        stroke = 0.5,
+        show.legend = FALSE
+    ) +
+    ggplot2::scale_color_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    titheme()

# time: 2024-09-19 13:43:47 UTC
# mode: r
+# save the plot
+ggplot2::ggsave(file.path(config$path$figures, "mds_plot.jpg"),
+    plot = mds_plot,
+    width = 8,
+    height = 6
+)

# time: 2024-09-19 13:44:55 UTC
# mode: r
+oobplot + oob_dist_plot

# time: 2024-09-19 13:45:15 UTC
# mode: r
+renv::install('patchwork')

# time: 2024-09-19 13:45:45 UTC
# mode: r
+oobplot + oob_dist_plot

# time: 2024-09-19 13:46:00 UTC
# mode: r
+box::use(patchwork)

# time: 2024-09-19 13:46:02 UTC
# mode: r
+oobplot + oob_dist_plot

# time: 2024-09-19 13:46:19 UTC
# mode: r
+oobplot + oob_plot

# time: 2024-09-19 13:47:01 UTC
# mode: r
+oob_dist_plot + mds_plot

# time: 2024-09-19 13:56:36 UTC
# mode: r
+mds_plot <-
+    ggplot2::ggplot(mds_df, ggplot2::aes(x = X1, y = X2, color = class)) +
+    ggplot2::geom_point(
+        size = 1.5
+    ) +
+    ggplot2::geom_point(ggplot2::aes()) +
+    ggplot2::geom_point(
+        ggplot2::aes(color = predicted),
+        shape = 21,
+        size = 5,
+        stroke = 0.5,
+        show.legend = FALSE
+    ) +
+    ggplot2::scale_color_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    titheme() +
+    ggplot2::labs(
+        title = "MDS plot of random forest proximity matrix",
+        x = "MDS1", y = "MDS2"
+    ) +
+    base_breaks_x(range(mds_df$X1)) +
+    base_breaks_y(range(mds_df$X2))

# time: 2024-09-19 13:56:40 UTC
# mode: r
+box::use(patchwork)

# time: 2024-09-19 13:56:40 UTC
# mode: r
+oob_dist_plot + mds_plot

# time: 2024-09-19 13:58:05 UTC
# mode: r
+mds_plot <-
+    ggplot2::ggplot(mds_df, ggplot2::aes(x = X1, y = X2, color = class)) +
+    ggplot2::geom_point(
+        size = 1.5
+    ) +
+    ggplot2::geom_point(ggplot2::aes()) +
+    ggplot2::geom_point(
+        ggplot2::aes(color = predicted),
+        shape = 21,
+        size = 5,
+        stroke = 0.5,
+        show.legend = FALSE
+    ) +
+    ggplot2::scale_color_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    titheme() +
+    ggplot2::labs(
+        title = "MDS plot of random forest proximity matrix",
+        x = "MDS1", y = "MDS2"
+    ) +
+    base_breaks_x(range(mds_df$X1), expand = ggplot2::expansion(mult = .05)) +
+    base_breaks_y(range(mds_df$X2), expand = ggplot2::expansion(mult = .05))

# time: 2024-09-19 13:58:07 UTC
# mode: r
+oob_dist_plot + mds_plot

# time: 2024-09-19 13:58:54 UTC
# mode: r
+rf_combi_plot = oob_dist_plot + mds_plot

# time: 2024-09-19 13:59:13 UTC
# mode: r
+# save the plot
+ggplot2::ggsave(file.path(config$path$figures, "mds_combi_plot.jpg"),
+    plot = rf_combi_plot,
+    width = 13,
+    height = 6
+)

# time: 2024-09-19 14:00:07 UTC
# mode: r
+mds_plot <-
+    ggplot2::ggplot(mds_df, ggplot2::aes(x = X1, y = X2, color = class)) +
+    ggplot2::geom_point(
+        size = 1.5
+    ) +
+    ggplot2::geom_point(ggplot2::aes()) +
+    ggplot2::geom_point(
+        ggplot2::aes(color = predicted),
+        shape = 21,
+        size = 5,
+        stroke = 0.5,
+        show.legend = FALSE
+    ) +
+    ggplot2::scale_color_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    titheme() +
+    ggplot2::labs(
+        title = "MDS plot of random forest proximity matrix",
+        x = "MDS1", y = "MDS2"
+    ) +
+    ggplot2::theme(aspect.ratio =  1) +
+    base_breaks_x(range(mds_df$X1), expand = ggplot2::expansion(mult = .05)) +
+    base_breaks_y(range(mds_df$X2), expand = ggplot2::expansion(mult = .05))

# time: 2024-09-19 14:00:09 UTC
# mode: r
+rf_combi_plot = oob_dist_plot + mds_plot

# time: 2024-09-19 14:00:10 UTC
# mode: r
+# save the plot
+ggplot2::ggsave(file.path(config$path$figures, "mds_combi_plot.jpg"),
+    plot = rf_combi_plot,
+    width = 13,
+    height = 6
+)

# time: 2024-09-19 14:00:47 UTC
# mode: r
+set.seed(123)
+split <- split_data(all.id, all.label, percent.train)
+data <- prepare_data(
+    all.maf, split$train.id, split$test.id, split$train.label, split$test.label,
+    num.eigenvectors, num.threads
+)
+
+# Use all available data as here we are not interested in the model's performance
+data = data$train_df |> dplyr::bind_rows(data$test_df)
+
+set.seed(123)
+rf = randomForest::randomForest(
+    data[, 3:(2 + num.eigenvectors)],
+    y = as.factor(data$pop),
+    ntree = 300,
+    replace = FALSE,
+    proximity = TRUE,
+    oob.prox = TRUE
+)
+
+# cmd the proximity matrix from the model and plot
+prox <- 1 - rf$proximity
+mds <- stats::cmdscale(prox, k = 2)
+
+# plot the MDS
+mds_df <- data.frame(mds, class = rf$y, predicted = rf$predicted)
+
+point.size = 2
+circle.size = 8
+circle.border = 1
+
+mds_plot <-
+    ggplot2::ggplot(mds_df, ggplot2::aes(x = X1, y = X2, color = class)) +
+    ggplot2::geom_point(
+        size = 1.5
+    ) +
+    ggplot2::geom_point(ggplot2::aes()) +
+    ggplot2::geom_point(
+        ggplot2::aes(color = predicted),
+        shape = 21,
+        size = 5,
+        stroke = 0.5,
+        show.legend = FALSE
+    ) +
+    ggplot2::scale_color_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    titheme() +
+    ggplot2::labs(
+        title = "MDS plot of random forest proximity matrix",
+        x = "MDS1", y = "MDS2"
+    ) +
+    ggplot2::theme(aspect.ratio =  1) +
+    base_breaks_x(range(mds_df$X1), expand = ggplot2::expansion(mult = .05)) +
+    base_breaks_y(range(mds_df$X2), expand = ggplot2::expansion(mult = .05))
+
+
+
+
+rf_combi_plot = oob_dist_plot + mds_plot
+
+
+# save the plot
+ggplot2::ggsave(file.path(config$path$figures, "mds_combi_plot.jpg"),
+    plot = rf_combi_plot,
+    width = 13,
+    height = 6
+)

# time: 2024-09-19 14:02:51 UTC
# mode: r
+oob_dist_plot <- ggplot2::ggplot() +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(y = error, fill = class),
+        position = "identity", alpha = 0.65,
+        density = ggdist::density_bounded(bandwidth = .5, trim=FALSE)
+    ) +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(y = error, fill = "randomised"),
+        position = "identity", alpha = 0.65,
+        density = ggdist::density_bounded(bandwidth = .5,  trim=FALSE),
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(y = error, color = class),
+        position = ggplot2::position_dodge(
+            width = .3, preserve = "single"
+        )
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(y = error, color = "randomised"),
+        position = ggplot2::position_dodge(
+            width = .3, preserve = "single"
+        )
+    ) +
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "black") +
+    ggplot2::labs(
+        title = "Distribution of percent correct by class",
+        y = "Percent correct", x = "Density"
+    ) +
+    ggplot2::scale_fill_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007", "randomised" = "#716e6e"
+    ), labels =  c("immigrant",  "resident", "random\nperformance")) +
+    ggplot2::scale_color_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007", "randomised" = "grey"
+    )) +
+    base_breaks_y(40:100, expand = ggplot2::expansion(mult = .05)) +
+    base_breaks_x(0:1, expand = ggplot2::expansion(add = c(-0.1, 0))) +
+    titheme() +
+    ggplot2::theme(
+        aspect.ratio = 2.3,
+        legend.position = c(0.95, 0.95),
+        legend.justification = c("right", "top"),
+        legend.title = ggplot2::element_text(hjust = 1)
+    ) +
+    ggplot2::guides(
+        fill = ggplot2::guide_legend(
+            title = "Class",
+            label.position = "left", label.hjust = 1
+        ), color = "none"
+    )

# time: 2024-09-19 14:02:55 UTC
# mode: r
+rf_combi_plot = oob_dist_plot + mds_plot

# time: 2024-09-19 14:02:56 UTC
# mode: r
+# save the plot
+ggplot2::ggsave(file.path(config$path$figures, "mds_combi_plot.jpg"),
+    plot = rf_combi_plot,
+    width = 13,
+    height = 6
+)

# time: 2024-09-19 14:03:40 UTC
# mode: r
+range(mds_df$X2)

# time: 2024-09-19 14:04:08 UTC
# mode: r
+mds_plot <-
+    ggplot2::ggplot(mds_df, ggplot2::aes(x = X1, y = X2, color = class)) +
+    ggplot2::geom_point(
+        size = 1.5
+    ) +
+    ggplot2::geom_point(ggplot2::aes()) +
+    ggplot2::geom_point(
+        ggplot2::aes(color = predicted),
+        shape = 21,
+        size = 5,
+        stroke = 0.5,
+        show.legend = FALSE
+    ) +
+    ggplot2::scale_color_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    titheme() +
+    ggplot2::labs(
+        title = "MDS plot of random forest proximity matrix",
+        x = "MDS1", y = "MDS2"
+    ) +
+    ggplot2::theme(aspect.ratio =  1) +
+    base_breaks_x(range(mds_df$X1), expand = ggplot2::expansion(mult = .05)) +
+    base_breaks_y(range(mds_df$X2))

# time: 2024-09-19 14:04:08 UTC
# mode: r
+rf_combi_plot = oob_dist_plot + mds_plot

# time: 2024-09-19 14:04:09 UTC
# mode: r
+# save the plot
+ggplot2::ggsave(file.path(config$path$figures, "mds_combi_plot.jpg"),
+    plot = rf_combi_plot,
+    width = 13,
+    height = 6
+)

# time: 2024-09-19 14:04:43 UTC
# mode: r
+mds_plot <-
+    ggplot2::ggplot(mds_df, ggplot2::aes(x = X1, y = X2, color = class)) +
+    ggplot2::geom_point(
+        size = 1.5
+    ) +
+    ggplot2::geom_point(ggplot2::aes()) +
+    ggplot2::geom_point(
+        ggplot2::aes(color = predicted),
+        shape = 21,
+        size = 5,
+        stroke = 0.5,
+        show.legend = FALSE
+    ) +
+    ggplot2::scale_color_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    titheme() +
+    ggplot2::labs(
+        title = "MDS plot of random forest proximity matrix",
+        x = "MDS1", y = "MDS2"
+    ) +
+    ggplot2::theme(aspect.ratio =  1) +
+    base_breaks_x(-0.2:0.6, expand = ggplot2::expansion(mult = .05)) +
+    base_breaks_y(-0.2:0.6, expand = ggplot2::expansion(mult = .05))

# time: 2024-09-19 14:04:44 UTC
# mode: r
+rf_combi_plot = oob_dist_plot + mds_plot

# time: 2024-09-19 14:04:45 UTC
# mode: r
+# save the plot
+ggplot2::ggsave(file.path(config$path$figures, "mds_combi_plot.jpg"),
+    plot = rf_combi_plot,
+    width = 13,
+    height = 6
+)

# time: 2024-09-19 14:04:56 UTC
# mode: r
+-0.2:0.6

# time: 2024-09-19 14:05:11 UTC
# mode: r
+range(-0.2,0.6)

# time: 2024-09-19 14:05:24 UTC
# mode: r
+mds_plot <-
+    ggplot2::ggplot(mds_df, ggplot2::aes(x = X1, y = X2, color = class)) +
+    ggplot2::geom_point(
+        size = 1.5
+    ) +
+    ggplot2::geom_point(ggplot2::aes()) +
+    ggplot2::geom_point(
+        ggplot2::aes(color = predicted),
+        shape = 21,
+        size = 5,
+        stroke = 0.5,
+        show.legend = FALSE
+    ) +
+    ggplot2::scale_color_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    titheme() +
+    ggplot2::labs(
+        title = "MDS plot of random forest proximity matrix",
+        x = "MDS1", y = "MDS2"
+    ) +
+    ggplot2::theme(aspect.ratio = 1) +
+    base_breaks_x(range(-0.2, 0.6), expand = ggplot2::expansion(mult = .05)) +
+    base_breaks_y(range(-0.2, 0.6), expand = ggplot2::expansion(mult = .05))

# time: 2024-09-19 14:05:24 UTC
# mode: r
+rf_combi_plot = oob_dist_plot + mds_plot

# time: 2024-09-19 14:05:25 UTC
# mode: r
+# save the plot
+ggplot2::ggsave(file.path(config$path$figures, "mds_combi_plot.jpg"),
+    plot = rf_combi_plot,
+    width = 13,
+    height = 6
+)

# time: 2024-09-19 14:05:44 UTC
# mode: r
+set.seed(123)
+split <- split_data(all.id, all.label, percent.train)
+data <- prepare_data(
+    all.maf, split$train.id, split$test.id, split$train.label, split$test.label,
+    num.eigenvectors, num.threads
+)
+
+# Use all available data as here we are not interested in the model's performance
+data = data$train_df |> dplyr::bind_rows(data$test_df)
+
+set.seed(123)
+rf = randomForest::randomForest(
+    data[, 3:(2 + num.eigenvectors)],
+    y = as.factor(data$pop),
+    ntree = 300,
+    replace = FALSE,
+    proximity = TRUE,
+    oob.prox = TRUE
+)
+
+# cmd the proximity matrix from the model and plot
+prox <- 1 - rf$proximity
+mds <- stats::cmdscale(prox, k = 2)
+
+# plot the MDS
+mds_df <- data.frame(mds, class = rf$y, predicted = rf$predicted)
+
+point.size = 2
+circle.size = 8
+circle.border = 1
+
+mds_plot <-
+    ggplot2::ggplot(mds_df, ggplot2::aes(x = X1, y = X2, color = class)) +
+    ggplot2::geom_point(
+        size = 1.5
+    ) +
+    ggplot2::geom_point(ggplot2::aes()) +
+    ggplot2::geom_point(
+        ggplot2::aes(color = predicted),
+        shape = 21,
+        size = 5,
+        stroke = 0.5,
+        show.legend = FALSE
+    ) +
+    ggplot2::scale_color_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    titheme() +
+    ggplot2::labs(
+        title = "MDS plot of random forest proximity matrix",
+        x = "MDS1", y = "MDS2"
+    ) +
+    ggplot2::theme(aspect.ratio = 1) +
+    base_breaks_x(range(-0.2, 0.6), expand = ggplot2::expansion(mult = .05)) +
+    base_breaks_y(range(-0.2, 0.6), expand = ggplot2::expansion(mult = .05))
+
+
+
+
+rf_combi_plot = oob_dist_plot + mds_plot
+
+
+# save the plot
+ggplot2::ggsave(file.path(config$path$figures, "mds_combi_plot.jpg"),
+    plot = rf_combi_plot,
+    width = 13,
+    height = 6
+)

# time: 2024-09-19 14:06:42 UTC
# mode: r
+set.seed(37)
+split <- split_data(all.id, all.label, percent.train)
+data <- prepare_data(
+    all.maf, split$train.id, split$test.id, split$train.label, split$test.label,
+    num.eigenvectors, num.threads
+)
+
+# Use all available data as here we are not interested in the model's performance
+data = data$train_df |> dplyr::bind_rows(data$test_df)
+
+set.seed(37)
+rf = randomForest::randomForest(
+    data[, 3:(2 + num.eigenvectors)],
+    y = as.factor(data$pop),
+    ntree = 300,
+    replace = FALSE,
+    proximity = TRUE,
+    oob.prox = TRUE
+)
+
+# cmd the proximity matrix from the model and plot
+prox <- 1 - rf$proximity
+mds <- stats::cmdscale(prox, k = 2)
+
+# plot the MDS
+mds_df <- data.frame(mds, class = rf$y, predicted = rf$predicted)
+
+point.size = 2
+circle.size = 8
+circle.border = 1
+
+mds_plot <-
+    ggplot2::ggplot(mds_df, ggplot2::aes(x = X1, y = X2, color = class)) +
+    ggplot2::geom_point(
+        size = 1.5
+    ) +
+    ggplot2::geom_point(ggplot2::aes()) +
+    ggplot2::geom_point(
+        ggplot2::aes(color = predicted),
+        shape = 21,
+        size = 5,
+        stroke = 0.5,
+        show.legend = FALSE
+    ) +
+    ggplot2::scale_color_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    titheme() +
+    ggplot2::labs(
+        title = "MDS plot of random forest proximity matrix",
+        x = "MDS1", y = "MDS2"
+    ) +
+    ggplot2::theme(aspect.ratio = 1) +
+    base_breaks_x(range(-0.2, 0.6), expand = ggplot2::expansion(mult = .05)) +
+    base_breaks_y(range(-0.2, 0.6), expand = ggplot2::expansion(mult = .05))
+
+
+
+
+rf_combi_plot = oob_dist_plot + mds_plot
+
+
+# save the plot
+ggplot2::ggsave(file.path(config$path$figures, "mds_combi_plot.jpg"),
+    plot = rf_combi_plot,
+    width = 13,
+    height = 6
+)

# time: 2024-09-19 14:07:10 UTC
# mode: r
+mds_plot <-
+    ggplot2::ggplot(mds_df, ggplot2::aes(x = X1, y = X2, color = class)) +
+    ggplot2::geom_point(
+        size = 1.5
+    ) +
+    ggplot2::geom_point(ggplot2::aes()) +
+    ggplot2::geom_point(
+        ggplot2::aes(color = predicted),
+        shape = 21,
+        size = 5,
+        stroke = 0.5,
+        show.legend = FALSE
+    ) +
+    ggplot2::scale_color_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    titheme() +
+    ggplot2::labs(
+        title = "MDS plot of random forest proximity matrix",
+        x = "MDS1", y = "MDS2"
+    ) +
+    ggplot2::theme(aspect.ratio = 1) +
+    base_breaks_x(range(-0.2, 0.6), expand = ggplot2::expansion(mult = .05)) +
+    base_breaks_y(range(-0.2, 0.4), expand = ggplot2::expansion(mult = .05))

# time: 2024-09-19 14:07:10 UTC
# mode: r
+rf_combi_plot = oob_dist_plot + mds_plot

# time: 2024-09-19 14:07:11 UTC
# mode: r
+# save the plot
+ggplot2::ggsave(file.path(config$path$figures, "mds_combi_plot.jpg"),
+    plot = rf_combi_plot,
+    width = 13,
+    height = 6
+)

# time: 2024-09-19 14:07:45 UTC
# mode: r
+set.seed(123)
+split <- split_data(all.id, all.label, percent.train)
+data <- prepare_data(
+    all.maf, split$train.id, split$test.id, split$train.label, split$test.label,
+    num.eigenvectors, num.threads
+)
+
+# Use all available data as here we are not interested in the model's performance
+data = data$train_df |> dplyr::bind_rows(data$test_df)
+
+set.seed(123)
+rf = randomForest::randomForest(
+    data[, 3:(2 + num.eigenvectors)],
+    y = as.factor(data$pop),
+    ntree = 300,
+    replace = FALSE,
+    proximity = TRUE,
+    oob.prox = TRUE
+)
+
+# cmd the proximity matrix from the model and plot
+prox <- 1 - rf$proximity
+mds <- stats::cmdscale(prox, k = 2)
+
+# plot the MDS
+mds_df <- data.frame(mds, class = rf$y, predicted = rf$predicted)
+
+point.size = 2
+circle.size = 8
+circle.border = 1
+
+mds_plot <-
+    ggplot2::ggplot(mds_df, ggplot2::aes(x = X1, y = X2, color = class)) +
+    ggplot2::geom_point(
+        size = 1.5
+    ) +
+    ggplot2::geom_point(ggplot2::aes()) +
+    ggplot2::geom_point(
+        ggplot2::aes(color = predicted),
+        shape = 21,
+        size = 5,
+        stroke = 0.5,
+        show.legend = FALSE
+    ) +
+    ggplot2::scale_color_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    titheme() +
+    ggplot2::labs(
+        title = "MDS plot of random forest proximity matrix",
+        x = "MDS1", y = "MDS2"
+    ) +
+    ggplot2::theme(aspect.ratio = 1) +
+    base_breaks_x(range(-0.2, 0.6), expand = ggplot2::expansion(mult = .05)) +
+    base_breaks_y(range(-0.2, 0.6), expand = ggplot2::expansion(mult = .05))
+
+
+
+
+rf_combi_plot = oob_dist_plot + mds_plot
+
+
+# save the plot
+ggplot2::ggsave(file.path(config$path$figures, "mds_combi_plot.jpg"),
+    plot = rf_combi_plot,
+    width = 13,
+    height = 6
+)

# time: 2024-09-19 14:08:41 UTC
# mode: r
+mds_plot <-
+    ggplot2::ggplot(mds_df, ggplot2::aes(x = X1, y = X2, color = class)) +
+    ggplot2::geom_point(
+        size = 1.5
+    ) +
+    ggplot2::geom_point(ggplot2::aes()) +
+    ggplot2::geom_point(
+        ggplot2::aes(color = predicted),
+        shape = 21,
+        size = 5,
+        stroke = 0.5,
+        show.legend = FALSE
+    ) +
+    ggplot2::scale_color_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    titheme() +
+    ggplot2::labs(
+        title = "MDS plot of random forest proximity matrix",
+        x = "MDS1", y = "MDS2"
+    ) +
+    ggplot2::theme(aspect.ratio = 1) +
+    base_breaks_x(range(-0.2, 0.6), expand = ggplot2::expansion(mult = .05)) +
+    base_breaks_y(range(-0.2, 0.6), expand = ggplot2::expansion(mult = .05)) +
+    ggplot2::theme(
+        aspect.ratio = 2.3,
+        legend.position = c(0.95, 0.95),
+        legend.justification = c("right", "top"),
+        legend.title = ggplot2::element_text(hjust = 1)
+    )

# time: 2024-09-19 14:08:41 UTC
# mode: r
+rf_combi_plot = oob_dist_plot + mds_plot

# time: 2024-09-19 14:08:42 UTC
# mode: r
+# save the plot
+ggplot2::ggsave(file.path(config$path$figures, "mds_combi_plot.jpg"),
+    plot = rf_combi_plot,
+    width = 13,
+    height = 6
+)

# time: 2024-09-19 14:09:00 UTC
# mode: r
+mds_plot <-
+    ggplot2::ggplot(mds_df, ggplot2::aes(x = X1, y = X2, color = class)) +
+    ggplot2::geom_point(
+        size = 1.5
+    ) +
+    ggplot2::geom_point(ggplot2::aes()) +
+    ggplot2::geom_point(
+        ggplot2::aes(color = predicted),
+        shape = 21,
+        size = 5,
+        stroke = 0.5,
+        show.legend = FALSE
+    ) +
+    ggplot2::scale_color_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    titheme() +
+    ggplot2::labs(
+        title = "MDS plot of random forest proximity matrix",
+        x = "MDS1", y = "MDS2"
+    ) +
+    base_breaks_x(range(-0.2, 0.6), expand = ggplot2::expansion(mult = .05)) +
+    base_breaks_y(range(-0.2, 0.6), expand = ggplot2::expansion(mult = .05)) +
+    ggplot2::theme(
+        aspect.ratio = 1.5,
+        legend.position = c(0.95, 0.95),
+        legend.justification = c("right", "top"),
+        legend.title = ggplot2::element_text(hjust = 1)
+    )

# time: 2024-09-19 14:09:01 UTC
# mode: r
+rf_combi_plot = oob_dist_plot + mds_plot

# time: 2024-09-19 14:09:01 UTC
# mode: r
+# save the plot
+ggplot2::ggsave(file.path(config$path$figures, "mds_combi_plot.jpg"),
+    plot = rf_combi_plot,
+    width = 13,
+    height = 6
+)

# time: 2024-09-19 14:09:30 UTC
# mode: r
+rf_combi_plot = oob_dist_plot + ggplot2::theme(plot.margin = ggplot2::margin(r = 20)) + mds_plot

# time: 2024-09-19 14:09:31 UTC
# mode: r
+# save the plot
+ggplot2::ggsave(file.path(config$path$figures, "mds_combi_plot.jpg"),
+    plot = rf_combi_plot,
+    width = 13,
+    height = 6
+)

# time: 2024-09-19 14:11:08 UTC
# mode: r
+mds_plot <-
+    ggplot2::ggplot(mds_df, ggplot2::aes(x = X1, y = X2, color = class)) +
+    ggplot2::geom_point(
+        size = 1.5
+    ) +
+    # add points (real label) and circles (predicted label)
+    ggplot2::geom_point(ggplot2::aes()) +
+    ggplot2::geom_point(
+        ggplot2::aes(color = predicted),
+        shape = 21,
+        size = 5,
+        stroke = 0.5,
+        show.legend = TRUE
+    ) +
+    ggplot2::scale_color_manual(
+        values = c(
+            "immigrant" = "#5d8566", "resident" = "#c29007"
+        ),
+        labels = c(
+            "immigrant" = "Immigrant (Real)", "resident" = "Resident (Real)",
+            "immigrant" = "Immigrant (Predicted)", "resident" = "Resident (Predicted)"
+        )
+    ) +
+    titheme() +
+    ggplot2::labs(
+        title = "MDS plot of random forest proximity matrix",
+        x = "MDS1", y = "MDS2"
+    ) +
+    base_breaks_x(range(-0.2, 0.6), expand = ggplot2::expansion(mult = .05)) +
+    base_breaks_y(range(-0.2, 0.6), expand = ggplot2::expansion(mult = .05)) +
+    ggplot2::theme(
+        aspect.ratio = 1.5,
+        legend.position = c(0.95, 0.95),
+        legend.justification = c("right", "top"),
+        legend.title = ggplot2::element_text(hjust = 1)
+    )

# time: 2024-09-19 14:11:10 UTC
# mode: r
+rf_combi_plot = oob_dist_plot + ggplot2::theme(plot.margin = ggplot2::margin(r = 20)) + mds_plot

# time: 2024-09-19 14:11:10 UTC
# mode: r
+# save the plot
+ggplot2::ggsave(file.path(config$path$figures, "mds_combi_plot.jpg"),
+    plot = rf_combi_plot,
+    width = 13,
+    height = 6
+)

# time: 2024-09-19 14:14:04 UTC
# mode: r
+mds_plot <-
+    ggplot2::ggplot(mds_df, ggplot2::aes(x = X1, y = X2, color = class)) +
+    ggplot2::geom_point(
+        ggplot2::aes(fill = class)
+        size = 1.5
+    ) +
+    # add points (real label) and circles (predicted label)
+    ggplot2::geom_point(
+        ggplot2::aes(color = predicted),
+        shape = 21,
+        size = 5,
+        stroke = 0.5,
+        show.legend = FALSE
+    ) +
+    ggplot2::scale_color_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    ggplot2::scale_fill_manual(values = c( 
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    titheme() +
+    ggplot2::labs(
+        title = "MDS plot of random forest proximity matrix",
+        x = "MDS1", y = "MDS2"
+    ) +
+    base_breaks_x(range(-0.2, 0.6), expand = ggplot2::expansion(mult = .05)) +
+    base_breaks_y(range(-0.2, 0.6), expand = ggplot2::expansion(mult = .05)) +
+    ggplot2::theme(
+        aspect.ratio = 1.5,
+        legend.position = c(0.95, 0.95),
+        legend.justification = c("right", "top"),
+        legend.title = ggplot2::element_text(hjust = 1)
+    )

# time: 2024-09-19 14:14:10 UTC
# mode: r
+mds_plot <-
+    ggplot2::ggplot(mds_df, ggplot2::aes(x = X1, y = X2, color = class)) +
+    ggplot2::geom_point(
+        ggplot2::aes(fill = class),
+        size = 1.5
+    ) +
+    # add points (real label) and circles (predicted label)
+    ggplot2::geom_point(
+        ggplot2::aes(color = predicted),
+        shape = 21,
+        size = 5,
+        stroke = 0.5,
+        show.legend = FALSE
+    ) +
+    ggplot2::scale_color_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    ggplot2::scale_fill_manual(values = c( 
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    titheme() +
+    ggplot2::labs(
+        title = "MDS plot of random forest proximity matrix",
+        x = "MDS1", y = "MDS2"
+    ) +
+    base_breaks_x(range(-0.2, 0.6), expand = ggplot2::expansion(mult = .05)) +
+    base_breaks_y(range(-0.2, 0.6), expand = ggplot2::expansion(mult = .05)) +
+    ggplot2::theme(
+        aspect.ratio = 1.5,
+        legend.position = c(0.95, 0.95),
+        legend.justification = c("right", "top"),
+        legend.title = ggplot2::element_text(hjust = 1)
+    )

# time: 2024-09-19 14:14:11 UTC
# mode: r
+mds_plot

# time: 2024-09-19 14:14:18 UTC
# mode: r
+rf_combi_plot = oob_dist_plot + ggplot2::theme(plot.margin = ggplot2::margin(r = 20)) + mds_plot

# time: 2024-09-19 14:14:19 UTC
# mode: r
+# save the plot
+ggplot2::ggsave(file.path(config$path$figures, "mds_combi_plot.jpg"),
+    plot = rf_combi_plot,
+    width = 13,
+    height = 6
+)

# time: 2024-09-19 14:14:52 UTC
# mode: r
+mds_plot <-
+    ggplot2::ggplot(mds_df, ggplot2::aes(x = X1, y = X2)) +
+    ggplot2::geom_point(
+        ggplot2::aes(fill = class),
+        shape = 21,
+        size = 1.5
+    ) +
+    # add points (real label) and circles (predicted label)
+    ggplot2::geom_point(
+        ggplot2::aes(color = predicted),
+        shape = 21,
+        size = 5,
+        stroke = 0.5,
+        show.legend = FALSE
+    ) +
+    ggplot2::scale_color_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    ggplot2::scale_fill_manual(values = c( 
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    titheme() +
+    ggplot2::labs(
+        title = "MDS plot of random forest proximity matrix",
+        x = "MDS1", y = "MDS2"
+    ) +
+    base_breaks_x(range(-0.2, 0.6), expand = ggplot2::expansion(mult = .05)) +
+    base_breaks_y(range(-0.2, 0.6), expand = ggplot2::expansion(mult = .05)) +
+    ggplot2::theme(
+        aspect.ratio = 1.5,
+        legend.position = c(0.95, 0.95),
+        legend.justification = c("right", "top"),
+        legend.title = ggplot2::element_text(hjust = 1)
+    )

# time: 2024-09-19 14:14:53 UTC
# mode: r
+rf_combi_plot = oob_dist_plot + ggplot2::theme(plot.margin = ggplot2::margin(r = 20)) + mds_plot

# time: 2024-09-19 14:14:54 UTC
# mode: r
+# save the plot
+ggplot2::ggsave(file.path(config$path$figures, "mds_combi_plot.jpg"),
+    plot = rf_combi_plot,
+    width = 13,
+    height = 6
+)

# time: 2024-09-19 14:15:28 UTC
# mode: r
+mds_plot <-
+    ggplot2::ggplot(mds_df, ggplot2::aes(x = X1, y = X2)) +
+    ggplot2::geom_point(
+        ggplot2::aes(fill = class),
+        color = NA,
+        shape = 21,
+        size = 1.5
+    ) +
+    # add points (real label) and circles (predicted label)
+    ggplot2::geom_point(
+        ggplot2::aes(color = predicted),
+        shape = 21,
+        size = 5,
+        stroke = 0.5,
+        show.legend = FALSE
+    ) +
+    ggplot2::scale_color_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    ggplot2::scale_fill_manual(values = c( 
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    titheme() +
+    ggplot2::labs(
+        title = "MDS plot of random forest proximity matrix",
+        x = "MDS1", y = "MDS2"
+    ) +
+    base_breaks_x(range(-0.2, 0.6), expand = ggplot2::expansion(mult = .05)) +
+    base_breaks_y(range(-0.2, 0.6), expand = ggplot2::expansion(mult = .05)) +
+    ggplot2::theme(
+        aspect.ratio = 1.5,
+        legend.position = c(0.95, 0.95),
+        legend.justification = c("right", "top"),
+        legend.title = ggplot2::element_text(hjust = 1)
+    )

# time: 2024-09-19 14:15:29 UTC
# mode: r
+rf_combi_plot = oob_dist_plot + ggplot2::theme(plot.margin = ggplot2::margin(r = 20)) + mds_plot

# time: 2024-09-19 14:15:30 UTC
# mode: r
+# save the plot
+ggplot2::ggsave(file.path(config$path$figures, "mds_combi_plot.jpg"),
+    plot = rf_combi_plot,
+    width = 13,
+    height = 6
+)

# time: 2024-09-19 14:16:03 UTC
# mode: r
+mds_plot <-
+    ggplot2::ggplot(mds_df, ggplot2::aes(x = X1, y = X2, fill = class)) +
+    ggplot2::geom_point(
+        ggplot2::aes(fill = class),
+        color = "none",
+        shape = 21,
+        size = 1.5
+    ) +
+    # add points (real label) and circles (predicted label)
+    ggplot2::geom_point(
+        ggplot2::aes(color = predicted),
+        shape = 21,
+        size = 5,
+        stroke = 0.5,
+        show.legend = FALSE
+    ) +
+    ggplot2::scale_color_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    ggplot2::scale_fill_manual(values = c( 
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    titheme() +
+    ggplot2::labs(
+        title = "MDS plot of random forest proximity matrix",
+        x = "MDS1", y = "MDS2"
+    ) +
+    base_breaks_x(range(-0.2, 0.6), expand = ggplot2::expansion(mult = .05)) +
+    base_breaks_y(range(-0.2, 0.6), expand = ggplot2::expansion(mult = .05)) +
+    ggplot2::theme(
+        aspect.ratio = 1.5,
+        legend.position = c(0.95, 0.95),
+        legend.justification = c("right", "top"),
+        legend.title = ggplot2::element_text(hjust = 1)
+    )

# time: 2024-09-19 14:16:04 UTC
# mode: r
+rf_combi_plot = oob_dist_plot + ggplot2::theme(plot.margin = ggplot2::margin(r = 20)) + mds_plot

# time: 2024-09-19 14:16:04 UTC
# mode: r
+# save the plot
+ggplot2::ggsave(file.path(config$path$figures, "mds_combi_plot.jpg"),
+    plot = rf_combi_plot,
+    width = 13,
+    height = 6
+)

# time: 2024-09-19 14:17:18 UTC
# mode: r
+mds_plot <-
+    ggplot2::ggplot(mds_df, ggplot2::aes(x = X1, y = X2 color = predicted)) +
+    ggplot2::geom_point(
+        ggplot2::aes(fill = class),
+        shape = 21,
+        size = 1.5
+    ) +
+    # add points (real label) and circles (predicted label)
+    ggplot2::geom_point(
+        ggplot2::aes(color = predicted),
+        shape = 21,
+        size = 5,
+        stroke = 0.5,
+        show.legend = FALSE
+    ) +
+    ggplot2::scale_color_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    ggplot2::scale_fill_manual(values = c( 
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    titheme() +
+    ggplot2::labs(
+        title = "MDS plot of random forest proximity matrix",
+        x = "MDS1", y = "MDS2"
+    ) +
+    base_breaks_x(range(-0.2, 0.6), expand = ggplot2::expansion(mult = .05)) +
+    base_breaks_y(range(-0.2, 0.6), expand = ggplot2::expansion(mult = .05)) +
+    ggplot2::theme(
+        aspect.ratio = 1.5,
+        legend.position = c(0.95, 0.95),
+        legend.justification = c("right", "top"),
+        legend.title = ggplot2::element_text(hjust = 1)
+    )

# time: 2024-09-19 14:17:19 UTC
# mode: r
+rf_combi_plot = oob_dist_plot + ggplot2::theme(plot.margin = ggplot2::margin(r = 20)) + mds_plot

# time: 2024-09-19 14:17:29 UTC
# mode: r
+mds_plot <-
+    ggplot2::ggplot(mds_df, ggplot2::aes(x = X1, y = X2, color = predicted)) +
+    ggplot2::geom_point(
+        ggplot2::aes(fill = class),
+        shape = 21,
+        size = 1.5
+    ) +
+    # add points (real label) and circles (predicted label)
+    ggplot2::geom_point(
+        ggplot2::aes(color = predicted),
+        shape = 21,
+        size = 5,
+        stroke = 0.5,
+        show.legend = FALSE
+    ) +
+    ggplot2::scale_color_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    ggplot2::scale_fill_manual(values = c( 
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    titheme() +
+    ggplot2::labs(
+        title = "MDS plot of random forest proximity matrix",
+        x = "MDS1", y = "MDS2"
+    ) +
+    base_breaks_x(range(-0.2, 0.6), expand = ggplot2::expansion(mult = .05)) +
+    base_breaks_y(range(-0.2, 0.6), expand = ggplot2::expansion(mult = .05)) +
+    ggplot2::theme(
+        aspect.ratio = 1.5,
+        legend.position = c(0.95, 0.95),
+        legend.justification = c("right", "top"),
+        legend.title = ggplot2::element_text(hjust = 1)
+    )

# time: 2024-09-19 14:17:29 UTC
# mode: r
+rf_combi_plot = oob_dist_plot + ggplot2::theme(plot.margin = ggplot2::margin(r = 20)) + mds_plot

# time: 2024-09-19 14:17:30 UTC
# mode: r
+# save the plot
+ggplot2::ggsave(file.path(config$path$figures, "mds_combi_plot.jpg"),
+    plot = rf_combi_plot,
+    width = 13,
+    height = 6
+)

# time: 2024-09-19 14:17:44 UTC
# mode: r
+mds_plot <-
+    ggplot2::ggplot(mds_df, ggplot2::aes(x = X1, y = X2, color = predicted)) +
+    ggplot2::geom_point(
+        ggplot2::aes(fill = class),
+        shape = 21,
+        size = 1.5,
+        stroke = NA
+    ) +
+    # add points (real label) and circles (predicted label)
+    ggplot2::geom_point(
+        ggplot2::aes(color = predicted),
+        shape = 21,
+        size = 5,
+        stroke = 0.5,
+        show.legend = FALSE
+    ) +
+    ggplot2::scale_color_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    ggplot2::scale_fill_manual(values = c( 
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    titheme() +
+    ggplot2::labs(
+        title = "MDS plot of random forest proximity matrix",
+        x = "MDS1", y = "MDS2"
+    ) +
+    base_breaks_x(range(-0.2, 0.6), expand = ggplot2::expansion(mult = .05)) +
+    base_breaks_y(range(-0.2, 0.6), expand = ggplot2::expansion(mult = .05)) +
+    ggplot2::theme(
+        aspect.ratio = 1.5,
+        legend.position = c(0.95, 0.95),
+        legend.justification = c("right", "top"),
+        legend.title = ggplot2::element_text(hjust = 1)
+    )

# time: 2024-09-19 14:17:45 UTC
# mode: r
+rf_combi_plot = oob_dist_plot + ggplot2::theme(plot.margin = ggplot2::margin(r = 20)) + mds_plot

# time: 2024-09-19 14:17:45 UTC
# mode: r
+# save the plot
+ggplot2::ggsave(file.path(config$path$figures, "mds_combi_plot.jpg"),
+    plot = rf_combi_plot,
+    width = 13,
+    height = 6
+)

# time: 2024-09-19 14:18:05 UTC
# mode: r
+mds_plot <-
+    ggplot2::ggplot(mds_df, ggplot2::aes(x = X1, y = X2, color = predicted)) +
+    ggplot2::geom_point(
+        ggplot2::aes(fill = class),
+        shape = 21,
+        size = 1.5
+    ) +
+    # add points (real label) and circles (predicted label)
+    ggplot2::geom_point(
+        ggplot2::aes(color = predicted),
+        shape = 21,
+        size = 5,
+        stroke = 0.5,
+        show.legend = FALSE
+    ) +
+    ggplot2::scale_color_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    ggplot2::scale_fill_manual(values = c( 
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    titheme() +
+    ggplot2::labs(
+        title = "MDS plot of random forest proximity matrix",
+        x = "MDS1", y = "MDS2"
+    ) +
+    base_breaks_x(range(-0.2, 0.6), expand = ggplot2::expansion(mult = .05)) +
+    base_breaks_y(range(-0.2, 0.6), expand = ggplot2::expansion(mult = .05)) +
+    ggplot2::theme(
+        aspect.ratio = 1.5,
+        legend.position = c(0.95, 0.95),
+        legend.justification = c("right", "top"),
+        legend.title = ggplot2::element_text(hjust = 1)
+    )

# time: 2024-09-19 14:18:05 UTC
# mode: r
+rf_combi_plot = oob_dist_plot + ggplot2::theme(plot.margin = ggplot2::margin(r = 20)) + mds_plot

# time: 2024-09-19 14:18:05 UTC
# mode: r
+# save the plot
+ggplot2::ggsave(file.path(config$path$figures, "mds_combi_plot.jpg"),
+    plot = rf_combi_plot,
+    width = 13,
+    height = 6
+)

# time: 2024-09-19 14:18:48 UTC
# mode: r
+)) +

# time: 2024-09-19 14:18:52 UTC
# mode: r
+mds_plot <-
+    ggplot2::ggplot(mds_df, ggplot2::aes(x = X1, y = X2, color = predicted)) +
+    ggplot2::geom_point(
+        ggplot2::aes(fill = class),
+        shape = 21,
+        size = 1.5
+    ) +
+    ggplot2::scale_fill_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    # add points (real label) and circles (predicted label)
+    ggplot2::geom_point(
+            ggplot2::aes(color = predicted),
+            shape = 21,
+            size = 5,
+            stroke = 0.5,
+            show.legend = FALSE
+        ) +
+    ggplot2::scale_color_manual(values = c(
+            "immigrant" = "#5d8566", "resident" = "#c29007"
+        )) +
+    titheme() +
+    ggplot2::labs(
+        title = "MDS plot of random forest proximity matrix",
+        x = "MDS1", y = "MDS2"
+    ) +
+    base_breaks_x(range(-0.2, 0.6), expand = ggplot2::expansion(mult = .05)) +
+    base_breaks_y(range(-0.2, 0.6), expand = ggplot2::expansion(mult = .05)) +
+    ggplot2::theme(
+        aspect.ratio = 1.5,
+        legend.position = c(0.95, 0.95),
+        legend.justification = c("right", "top"),
+        legend.title = ggplot2::element_text(hjust = 1)
+    )

# time: 2024-09-19 14:18:53 UTC
# mode: r
+rf_combi_plot = oob_dist_plot + ggplot2::theme(plot.margin = ggplot2::margin(r = 20)) + mds_plot

# time: 2024-09-19 14:18:54 UTC
# mode: r
+# save the plot
+ggplot2::ggsave(file.path(config$path$figures, "mds_combi_plot.jpg"),
+    plot = rf_combi_plot,
+    width = 13,
+    height = 6
+)

# time: 2024-09-19 14:19:49 UTC
# mode: r
+mds_plot <-
+    ggplot2::ggplot(mds_df, ggplot2::aes(x = X1, y = X2, color = predicted)) +
+    ggplot2::geom_point(
+        ggplot2::aes(fill = class, stroke = class),
+        shape = 21,
+        size = 1.5
+    ) +
+    ggplot2::scale_fill_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    # add points (real label) and circles (predicted label)
+    ggplot2::geom_point(
+            ggplot2::aes(color = predicted),
+            shape = 21,
+            size = 5,
+            stroke = 0.5,
+            show.legend = FALSE
+        ) +
+    ggplot2::scale_color_manual(values = c(
+            "immigrant" = "#5d8566", "resident" = "#c29007"
+        )) +
+    titheme() +
+    ggplot2::labs(
+        title = "MDS plot of random forest proximity matrix",
+        x = "MDS1", y = "MDS2"
+    ) +
+    base_breaks_x(range(-0.2, 0.6), expand = ggplot2::expansion(mult = .05)) +
+    base_breaks_y(range(-0.2, 0.6), expand = ggplot2::expansion(mult = .05)) +
+    ggplot2::theme(
+        aspect.ratio = 1.5,
+        legend.position = c(0.95, 0.95),
+        legend.justification = c("right", "top"),
+        legend.title = ggplot2::element_text(hjust = 1)
+    )

# time: 2024-09-19 14:19:50 UTC
# mode: r
+rf_combi_plot = oob_dist_plot + ggplot2::theme(plot.margin = ggplot2::margin(r = 20)) + mds_plot

# time: 2024-09-19 14:19:50 UTC
# mode: r
+# save the plot
+ggplot2::ggsave(file.path(config$path$figures, "mds_combi_plot.jpg"),
+    plot = rf_combi_plot,
+    width = 13,
+    height = 6
+)

# time: 2024-09-19 14:19:57 UTC
# mode: r
+mds_plot <-
+    ggplot2::ggplot(mds_df, ggplot2::aes(x = X1, y = X2, color = predicted)) +
+    ggplot2::geom_point(
+        ggplot2::aes(fill = class, stroke = NA),
+        shape = 21,
+        size = 1.5
+    ) +
+    ggplot2::scale_fill_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    # add points (real label) and circles (predicted label)
+    ggplot2::geom_point(
+            ggplot2::aes(color = predicted),
+            shape = 21,
+            size = 5,
+            stroke = 0.5,
+            show.legend = FALSE
+        ) +
+    ggplot2::scale_color_manual(values = c(
+            "immigrant" = "#5d8566", "resident" = "#c29007"
+        )) +
+    titheme() +
+    ggplot2::labs(
+        title = "MDS plot of random forest proximity matrix",
+        x = "MDS1", y = "MDS2"
+    ) +
+    base_breaks_x(range(-0.2, 0.6), expand = ggplot2::expansion(mult = .05)) +
+    base_breaks_y(range(-0.2, 0.6), expand = ggplot2::expansion(mult = .05)) +
+    ggplot2::theme(
+        aspect.ratio = 1.5,
+        legend.position = c(0.95, 0.95),
+        legend.justification = c("right", "top"),
+        legend.title = ggplot2::element_text(hjust = 1)
+    )

# time: 2024-09-19 14:19:58 UTC
# mode: r
+rf_combi_plot = oob_dist_plot + ggplot2::theme(plot.margin = ggplot2::margin(r = 20)) + mds_plot

# time: 2024-09-19 14:19:58 UTC
# mode: r
+# save the plot
+ggplot2::ggsave(file.path(config$path$figures, "mds_combi_plot.jpg"),
+    plot = rf_combi_plot,
+    width = 13,
+    height = 6
+)

# time: 2024-09-19 14:20:59 UTC
# mode: r
+mds_plot <-
+    ggplot2::ggplot(mds_df, ggplot2::aes(x = X1, y = X2, color = predicted)) +
+    ggplot2::geom_point(
+        ggplot2::aes(fill = class),
+        shape = 21,
+        size = 1.5
+    ) +
+    ggplot2::scale_fill_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    # add points (real label) and circles (predicted label)
+    ggplot2::geom_point(
+            ggplot2::aes(color = predicted),
+            shape = 21,
+            size = 5,
+            stroke = 0.5,
+            show.legend = FALSE
+        ) +
+    ggplot2::scale_color_manual(values = c(
+            "immigrant" = "#5d8566", "resident" = "#c29007"
+        )) +
+    titheme() +
+    ggplot2::labs(
+        title = "MDS plot of random forest proximity matrix",
+        x = "MDS1", y = "MDS2"
+    ) +
+    base_breaks_x(range(-0.2, 0.6), expand = ggplot2::expansion(mult = .05)) +
+    base_breaks_y(range(-0.2, 0.6), expand = ggplot2::expansion(mult = .05)) +
+    ggplot2::theme(
+        aspect.ratio = 1.5,
+        legend.position = c(0.95, 0.95),
+        legend.justification = c("right", "top"),
+        legend.title = ggplot2::element_text(hjust = 1)
+    )

# time: 2024-09-19 14:21:00 UTC
# mode: r
+rf_combi_plot = oob_dist_plot + ggplot2::theme(plot.margin = ggplot2::margin(r = 20)) + mds_plot

# time: 2024-09-19 14:21:01 UTC
# mode: r
+# save the plot
+ggplot2::ggsave(file.path(config$path$figures, "mds_combi_plot.jpg"),
+    plot = rf_combi_plot,
+    width = 13,
+    height = 6
+)

# time: 2024-09-19 14:21:42 UTC
# mode: r
+mds_plot <-
+    ggplot2::ggplot(mds_df, ggplot2::aes(x = X1, y = X2, color = predicted)) +
+    ggplot2::geom_point(
+        ggplot2::aes(fill = class, color = NULL, stroke = 0),
+        shape = 21,
+        size = 1.5
+    ) +
+    ggplot2::scale_fill_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    # add points (real label) and circles (predicted label)
+    ggplot2::geom_point(
+            ggplot2::aes(color = predicted),
+            shape = 21,
+            size = 5,
+            stroke = 0.5,
+            show.legend = FALSE
+        ) +
+    ggplot2::scale_color_manual(values = c(
+            "immigrant" = "#5d8566", "resident" = "#c29007"
+        )) +
+    titheme() +
+    ggplot2::labs(
+        title = "MDS plot of random forest proximity matrix",
+        x = "MDS1", y = "MDS2"
+    ) +
+    base_breaks_x(range(-0.2, 0.6), expand = ggplot2::expansion(mult = .05)) +
+    base_breaks_y(range(-0.2, 0.6), expand = ggplot2::expansion(mult = .05)) +
+    ggplot2::theme(
+        aspect.ratio = 1.5,
+        legend.position = c(0.95, 0.95),
+        legend.justification = c("right", "top"),
+        legend.title = ggplot2::element_text(hjust = 1)
+    )

# time: 2024-09-19 14:21:43 UTC
# mode: r
+rf_combi_plot = oob_dist_plot + ggplot2::theme(plot.margin = ggplot2::margin(r = 20)) + mds_plot

# time: 2024-09-19 14:21:43 UTC
# mode: r
+# save the plot
+ggplot2::ggsave(file.path(config$path$figures, "mds_combi_plot.jpg"),
+    plot = rf_combi_plot,
+    width = 13,
+    height = 6
+)

# time: 2024-09-19 14:22:05 UTC
# mode: r
+mds_plot <-
+    ggplot2::ggplot(mds_df, ggplot2::aes(x = X1, y = X2, color = predicted)) +
+    ggplot2::geom_point(
+        ggplot2::aes(fill = class, color = NULL, stroke = 0),
+        shape = 21,
+        size = 1.5
+    ) +
+    ggplot2::scale_fill_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    # add points (real label) and circles (predicted label)
+    ggplot2::geom_point(
+            ggplot2::aes(color = predicted),
+            shape = 21,
+            size = 4,
+            stroke = 0.5,
+            show.legend = FALSE
+        ) +
+    ggplot2::scale_color_manual(values = c(
+            "immigrant" = "#5d8566", "resident" = "#c29007"
+        )) +
+    titheme() +
+    ggplot2::labs(
+        title = "MDS plot of random forest proximity matrix",
+        x = "MDS1", y = "MDS2"
+    ) +
+    base_breaks_x(range(-0.2, 0.6), expand = ggplot2::expansion(mult = .05)) +
+    base_breaks_y(range(-0.2, 0.6), expand = ggplot2::expansion(mult = .05)) +
+    ggplot2::theme(
+        aspect.ratio = 1.5,
+        legend.position = c(0.95, 0.95),
+        legend.justification = c("right", "top"),
+        legend.title = ggplot2::element_text(hjust = 1)
+    )

# time: 2024-09-19 14:22:06 UTC
# mode: r
+rf_combi_plot = oob_dist_plot + ggplot2::theme(plot.margin = ggplot2::margin(r = 20)) + mds_plot

# time: 2024-09-19 14:22:06 UTC
# mode: r
+# save the plot
+ggplot2::ggsave(file.path(config$path$figures, "mds_combi_plot.jpg"),
+    plot = rf_combi_plot,
+    width = 13,
+    height = 6
+)

# time: 2024-09-19 14:22:27 UTC
# mode: r
+mds_plot <-
+    ggplot2::ggplot(mds_df, ggplot2::aes(x = X1, y = X2, color = predicted)) +
+    ggplot2::geom_point(
+        ggplot2::aes(fill = class, color = NULL, stroke = 0),
+        shape = 21,
+        size = 1
+    ) +
+    ggplot2::scale_fill_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    # add points (real label) and circles (predicted label)
+    ggplot2::geom_point(
+            ggplot2::aes(color = predicted),
+            shape = 21,
+            size = 3,
+            stroke = 0.5,
+            show.legend = FALSE
+        ) +
+    ggplot2::scale_color_manual(values = c(
+            "immigrant" = "#5d8566", "resident" = "#c29007"
+        )) +
+    titheme() +
+    ggplot2::labs(
+        title = "MDS plot of random forest proximity matrix",
+        x = "MDS1", y = "MDS2"
+    ) +
+    base_breaks_x(range(-0.2, 0.6), expand = ggplot2::expansion(mult = .05)) +
+    base_breaks_y(range(-0.2, 0.6), expand = ggplot2::expansion(mult = .05)) +
+    ggplot2::theme(
+        aspect.ratio = 1.5,
+        legend.position = c(0.95, 0.95),
+        legend.justification = c("right", "top"),
+        legend.title = ggplot2::element_text(hjust = 1)
+    )

# time: 2024-09-19 14:22:27 UTC
# mode: r
+rf_combi_plot = oob_dist_plot + ggplot2::theme(plot.margin = ggplot2::margin(r = 20)) + mds_plot

# time: 2024-09-19 14:22:28 UTC
# mode: r
+# save the plot
+ggplot2::ggsave(file.path(config$path$figures, "mds_combi_plot.jpg"),
+    plot = rf_combi_plot,
+    width = 13,
+    height = 6
+)

# time: 2024-09-19 14:23:00 UTC
# mode: r
+mds_plot <-
+    ggplot2::ggplot(mds_df, ggplot2::aes(x = X1, y = X2, color = predicted)) +
+    ggplot2::geom_point(
+        ggplot2::aes(fill = class, color = NULL, stroke = 0),
+        shape = 21,
+        size = 1.2,
+        alpha= 0.9
+    ) +
+    ggplot2::scale_fill_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    # add points (real label) and circles (predicted label)
+    ggplot2::geom_point(
+            ggplot2::aes(color = predicted),
+            shape = 21,
+            size = 3.5,
+            stroke = 0.5,
+            alpha = 0.9,
+            show.legend = FALSE
+        ) +
+    ggplot2::scale_color_manual(values = c(
+            "immigrant" = "#5d8566", "resident" = "#c29007"
+        )) +
+    titheme() +
+    ggplot2::labs(
+        title = "MDS plot of random forest proximity matrix",
+        x = "MDS1", y = "MDS2"
+    ) +
+    base_breaks_x(range(-0.2, 0.6), expand = ggplot2::expansion(mult = .05)) +
+    base_breaks_y(range(-0.2, 0.6), expand = ggplot2::expansion(mult = .05)) +
+    ggplot2::theme(
+        aspect.ratio = 1.5,
+        legend.position = c(0.95, 0.95),
+        legend.justification = c("right", "top"),
+        legend.title = ggplot2::element_text(hjust = 1)
+    )

# time: 2024-09-19 14:23:00 UTC
# mode: r
+rf_combi_plot = oob_dist_plot + ggplot2::theme(plot.margin = ggplot2::margin(r = 20)) + mds_plot

# time: 2024-09-19 14:23:01 UTC
# mode: r
+# save the plot
+ggplot2::ggsave(file.path(config$path$figures, "mds_combi_plot.jpg"),
+    plot = rf_combi_plot,
+    width = 13,
+    height = 6
+)

# time: 2024-09-19 14:23:50 UTC
# mode: r
+mds_plot <-
+    ggplot2::ggplot(mds_df, ggplot2::aes(x = X1, y = X2)) +
+    ggplot2::geom_point(
+        ggplot2::aes(fill = class, color = NA, stroke = NA),
+        shape = 21,
+        size = 1.2,
+        alpha= 0.9
+    ) +
+    ggplot2::scale_fill_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    # add points (real label) and circles (predicted label)
+    ggplot2::geom_point(
+            ggplot2::aes(color = predicted),
+            shape = 21,
+            size = 3.5,
+            stroke = 0.5,
+            alpha = 0.9,
+            show.legend = FALSE
+        ) +
+    ggplot2::scale_color_manual(values = c(
+            "immigrant" = "#5d8566", "resident" = "#c29007"
+        )) +
+    titheme() +
+    ggplot2::labs(
+        title = "MDS plot of random forest proximity matrix",
+        x = "MDS1", y = "MDS2"
+    ) +
+    base_breaks_x(range(-0.2, 0.6), expand = ggplot2::expansion(mult = .05)) +
+    base_breaks_y(range(-0.2, 0.6), expand = ggplot2::expansion(mult = .05)) +
+    ggplot2::theme(
+        aspect.ratio = 1.5,
+        legend.position = c(0.95, 0.95),
+        legend.justification = c("right", "top"),
+        legend.title = ggplot2::element_text(hjust = 1)
+    )

# time: 2024-09-19 14:23:50 UTC
# mode: r
+rf_combi_plot = oob_dist_plot + ggplot2::theme(plot.margin = ggplot2::margin(r = 20)) + mds_plot

# time: 2024-09-19 14:23:51 UTC
# mode: r
+# save the plot
+ggplot2::ggsave(file.path(config$path$figures, "mds_combi_plot.jpg"),
+    plot = rf_combi_plot,
+    width = 13,
+    height = 6
+)

# time: 2024-09-19 14:24:03 UTC
# mode: r
+mds_plot <-
+    ggplot2::ggplot(mds_df, ggplot2::aes(x = X1, y = X2, color = predicted)) +
+    ggplot2::geom_point(
+        ggplot2::aes(fill = class, color = NULL, stroke = NULL),
+        shape = 21,
+        size = 1.2,
+        alpha= 0.9
+    ) +
+    ggplot2::scale_fill_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    # add points (real label) and circles (predicted label)
+    ggplot2::geom_point(
+            ggplot2::aes(color = predicted),
+            shape = 21,
+            size = 3.5,
+            stroke = 0.5,
+            alpha = 0.9,
+            show.legend = FALSE
+        ) +
+    ggplot2::scale_color_manual(values = c(
+            "immigrant" = "#5d8566", "resident" = "#c29007"
+        )) +
+    titheme() +
+    ggplot2::labs(
+        title = "MDS plot of random forest proximity matrix",
+        x = "MDS1", y = "MDS2"
+    ) +
+    base_breaks_x(range(-0.2, 0.6), expand = ggplot2::expansion(mult = .05)) +
+    base_breaks_y(range(-0.2, 0.6), expand = ggplot2::expansion(mult = .05)) +
+    ggplot2::theme(
+        aspect.ratio = 1.5,
+        legend.position = c(0.95, 0.95),
+        legend.justification = c("right", "top"),
+        legend.title = ggplot2::element_text(hjust = 1)
+    )

# time: 2024-09-19 14:24:04 UTC
# mode: r
+rf_combi_plot = oob_dist_plot + ggplot2::theme(plot.margin = ggplot2::margin(r = 20)) + mds_plot

# time: 2024-09-19 14:24:04 UTC
# mode: r
+# save the plot
+ggplot2::ggsave(file.path(config$path$figures, "mds_combi_plot.jpg"),
+    plot = rf_combi_plot,
+    width = 13,
+    height = 6
+)

# time: 2024-09-19 14:24:21 UTC
# mode: r
+mds_plot <-
+    ggplot2::ggplot(mds_df, ggplot2::aes(x = X1, y = X2)) +
+    ggplot2::geom_point(
+        ggplot2::aes(fill = class, color = NULL),
+        shape = 21,
+        size = 1.2,
+        alpha= 0.9
+    ) +
+    ggplot2::scale_fill_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    # add points (real label) and circles (predicted label)
+    ggplot2::geom_point(
+            ggplot2::aes(color = predicted),
+            shape = 21,
+            size = 3.5,
+            stroke = 0.5,
+            alpha = 0.9,
+            show.legend = FALSE
+        ) +
+    ggplot2::scale_color_manual(values = c(
+            "immigrant" = "#5d8566", "resident" = "#c29007"
+        )) +
+    titheme() +
+    ggplot2::labs(
+        title = "MDS plot of random forest proximity matrix",
+        x = "MDS1", y = "MDS2"
+    ) +
+    base_breaks_x(range(-0.2, 0.6), expand = ggplot2::expansion(mult = .05)) +
+    base_breaks_y(range(-0.2, 0.6), expand = ggplot2::expansion(mult = .05)) +
+    ggplot2::theme(
+        aspect.ratio = 1.5,
+        legend.position = c(0.95, 0.95),
+        legend.justification = c("right", "top"),
+        legend.title = ggplot2::element_text(hjust = 1)
+    )

# time: 2024-09-19 14:24:21 UTC
# mode: r
+rf_combi_plot = oob_dist_plot + ggplot2::theme(plot.margin = ggplot2::margin(r = 20)) + mds_plot

# time: 2024-09-19 14:24:22 UTC
# mode: r
+# save the plot
+ggplot2::ggsave(file.path(config$path$figures, "mds_combi_plot.jpg"),
+    plot = rf_combi_plot,
+    width = 13,
+    height = 6
+)

# time: 2024-09-19 14:24:34 UTC
# mode: r
+mds_plot <-
+    ggplot2::ggplot(mds_df, ggplot2::aes(x = X1, y = X2)) +
+    ggplot2::geom_point(
+        ggplot2::aes(fill = class, color = NULL),
+        shape = 21,
+        size = 1.2,
+        alpha= 0.9,
+        stroke = NA
+    ) +
+    ggplot2::scale_fill_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    # add points (real label) and circles (predicted label)
+    ggplot2::geom_point(
+            ggplot2::aes(color = predicted),
+            shape = 21,
+            size = 3.5,
+            stroke = 0.5,
+            alpha = 0.9,
+            show.legend = FALSE
+        ) +
+    ggplot2::scale_color_manual(values = c(
+            "immigrant" = "#5d8566", "resident" = "#c29007"
+        )) +
+    titheme() +
+    ggplot2::labs(
+        title = "MDS plot of random forest proximity matrix",
+        x = "MDS1", y = "MDS2"
+    ) +
+    base_breaks_x(range(-0.2, 0.6), expand = ggplot2::expansion(mult = .05)) +
+    base_breaks_y(range(-0.2, 0.6), expand = ggplot2::expansion(mult = .05)) +
+    ggplot2::theme(
+        aspect.ratio = 1.5,
+        legend.position = c(0.95, 0.95),
+        legend.justification = c("right", "top"),
+        legend.title = ggplot2::element_text(hjust = 1)
+    )

# time: 2024-09-19 14:24:35 UTC
# mode: r
+rf_combi_plot = oob_dist_plot + ggplot2::theme(plot.margin = ggplot2::margin(r = 20)) + mds_plot

# time: 2024-09-19 14:24:36 UTC
# mode: r
+# save the plot
+ggplot2::ggsave(file.path(config$path$figures, "mds_combi_plot.jpg"),
+    plot = rf_combi_plot,
+    width = 13,
+    height = 6
+)

# time: 2024-09-19 14:25:48 UTC
# mode: r
+mds_plot <-
+    ggplot2::ggplot(mds_df, ggplot2::aes(x = X1, y = X2, color = predicted)) +
+    ggplot2::geom_point(
+        ggplot2::aes(fill = class, stroke= NA),
+        shape = 21,
+        size = 1.2,
+        alpha= 0.9
+    ) +
+    ggplot2::scale_fill_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    # add points (real label) and circles (predicted label)
+    ggplot2::geom_point(
+            ggplot2::aes(color = predicted),
+            shape = 21,
+            size = 3.5,
+            stroke = 0.5,
+            alpha = 0.9,
+            show.legend = FALSE
+        ) +
+    ggplot2::scale_color_manual(values = c(
+            "immigrant" = "#5d8566", "resident" = "#c29007"
+        )) +
+    titheme() +
+    ggplot2::labs(
+        title = "MDS plot of random forest proximity matrix",
+        x = "MDS1", y = "MDS2"
+    ) +
+    base_breaks_x(range(-0.2, 0.6), expand = ggplot2::expansion(mult = .05)) +
+    base_breaks_y(range(-0.2, 0.6), expand = ggplot2::expansion(mult = .05)) +
+    ggplot2::theme(
+        aspect.ratio = 1.5,
+        legend.position = c(0.95, 0.95),
+        legend.justification = c("right", "top"),
+        legend.title = ggplot2::element_text(hjust = 1)
+    )

# time: 2024-09-19 14:25:48 UTC
# mode: r
+rf_combi_plot = oob_dist_plot + ggplot2::theme(plot.margin = ggplot2::margin(r = 20)) + mds_plot

# time: 2024-09-19 14:25:49 UTC
# mode: r
+# save the plot
+ggplot2::ggsave(file.path(config$path$figures, "mds_combi_plot.jpg"),
+    plot = rf_combi_plot,
+    width = 13,
+    height = 6
+)

# time: 2024-09-19 14:26:30 UTC
# mode: r
+mds_plot <-
+    ggplot2::ggplot(mds_df, ggplot2::aes(x = X1, y = X2, color = predicted)) +
+    ggplot2::geom_point(
+        ggplot2::aes(fill = class, stroke = NA),
+        shape = 21,
+        size = 1.2,
+        alpha = 0.9
+    ) +
+    ggplot2::scale_fill_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    # add points (real label) and circles (predicted label)
+    ggplot2::geom_point(
+        ggplot2::aes(color = predicted),
+        shape = 21,
+        size = 3.5,
+        stroke = 0.5,
+        alpha = 0.9,
+        show.legend = FALSE
+    ) +
+    ggplot2::scale_color_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    titheme() +
+    ggplot2::labs(
+        title = "MDS plot of random forest proximity matrix",
+        x = "MDS1", y = "MDS2"
+    ) +
+    ggplot2::guides(color = guide_legend(
+        order = 1,
+        override.aes = list(
+            color = c("blue", "red"),
+            fill = c("white", "white"),
+            linetype = c("blank", "solid"),
+            shape = c(19, NA)
+        )
+    )) +
+    base_breaks_x(range(-0.2, 0.6), expand = ggplot2::expansion(mult = .05)) +
+    base_breaks_y(range(-0.2, 0.6), expand = ggplot2::expansion(mult = .05)) +
+    ggplot2::theme(
+        aspect.ratio = 1.5,
+        legend.position = c(0.95, 0.95),
+        legend.justification = c("right", "top"),
+        legend.title = ggplot2::element_text(hjust = 1)
+    )

# time: 2024-09-19 14:26:38 UTC
# mode: r
+mds_plot <-
+    ggplot2::ggplot(mds_df, ggplot2::aes(x = X1, y = X2, color = predicted)) +
+    ggplot2::geom_point(
+        ggplot2::aes(fill = class, stroke = NA),
+        shape = 21,
+        size = 1.2,
+        alpha = 0.9
+    ) +
+    ggplot2::scale_fill_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    # add points (real label) and circles (predicted label)
+    ggplot2::geom_point(
+        ggplot2::aes(color = predicted),
+        shape = 21,
+        size = 3.5,
+        stroke = 0.5,
+        alpha = 0.9,
+        show.legend = FALSE
+    ) +
+    ggplot2::scale_color_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    titheme() +
+    ggplot2::labs(
+        title = "MDS plot of random forest proximity matrix",
+        x = "MDS1", y = "MDS2"
+    ) +
+    ggplot2::guides(color = ggplot2::guide_legend(
+        order = 1,
+        override.aes = list(
+            color = c("blue", "red"),
+            fill = c("white", "white"),
+            linetype = c("blank", "solid"),
+            shape = c(19, NA)
+        )
+    )) +
+    base_breaks_x(range(-0.2, 0.6), expand = ggplot2::expansion(mult = .05)) +
+    base_breaks_y(range(-0.2, 0.6), expand = ggplot2::expansion(mult = .05)) +
+    ggplot2::theme(
+        aspect.ratio = 1.5,
+        legend.position = c(0.95, 0.95),
+        legend.justification = c("right", "top"),
+        legend.title = ggplot2::element_text(hjust = 1)
+    )

# time: 2024-09-19 14:26:39 UTC
# mode: r
+rf_combi_plot = oob_dist_plot + ggplot2::theme(plot.margin = ggplot2::margin(r = 20)) + mds_plot

# time: 2024-09-19 14:26:39 UTC
# mode: r
+# save the plot
+ggplot2::ggsave(file.path(config$path$figures, "mds_combi_plot.jpg"),
+    plot = rf_combi_plot,
+    width = 13,
+    height = 6
+)

# time: 2024-09-19 14:27:23 UTC
# mode: r
+mds_plot <-
+    ggplot2::ggplot(mds_df, ggplot2::aes(x = X1, y = X2, color = predicted)) +
+    ggplot2::geom_point(
+        ggplot2::aes(fill = class, stroke = NA),
+        shape = 21,
+        size = 1.2,
+        alpha = 0.9
+    ) +
+    ggplot2::scale_fill_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    # add points (real label) and circles (predicted label)
+    ggplot2::geom_point(
+        ggplot2::aes(color = predicted),
+        shape = 21,
+        size = 3.5,
+        stroke = 0.5,
+        alpha = 0.9,
+        show.legend = FALSE
+    ) +
+    ggplot2::scale_color_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    titheme() +
+    ggplot2::labs(
+        title = "MDS plot of random forest proximity matrix",
+        x = "MDS1", y = "MDS2"
+    ) +
+    ggplot2::guides(color = ggplot2::guide_legend(
+        order = 1,
+        override.aes = list(
+            color = c("#5d8566", "#c29007"),
+            fill = c("#5d8566", "#c29007"), shape = 21, size = 3.5, stroke = 0.5
+        )
+    )) +
+    base_breaks_x(range(-0.2, 0.6), expand = ggplot2::expansion(mult = .05)) +
+    base_breaks_y(range(-0.2, 0.6), expand = ggplot2::expansion(mult = .05)) +
+    ggplot2::theme(
+        aspect.ratio = 1.5,
+        legend.position = c(0.95, 0.95),
+        legend.justification = c("right", "top"),
+        legend.title = ggplot2::element_text(hjust = 1)
+    )

# time: 2024-09-19 14:27:23 UTC
# mode: r
+rf_combi_plot = oob_dist_plot + ggplot2::theme(plot.margin = ggplot2::margin(r = 20)) + mds_plot

# time: 2024-09-19 14:27:24 UTC
# mode: r
+# save the plot
+ggplot2::ggsave(file.path(config$path$figures, "mds_combi_plot.jpg"),
+    plot = rf_combi_plot,
+    width = 13,
+    height = 6
+)

# time: 2024-09-19 14:27:44 UTC
# mode: r
+mds_plot <-
+    ggplot2::ggplot(mds_df, ggplot2::aes(x = X1, y = X2, color = predicted)) +
+    ggplot2::geom_point(
+        ggplot2::aes(fill = class, stroke = NA),
+        shape = 21,
+        size = 1.2,
+        alpha = 0.9
+    ) +
+    ggplot2::scale_fill_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    # add points (real label) and circles (predicted label)
+    ggplot2::geom_point(
+        ggplot2::aes(color = predicted),
+        shape = 21,
+        size = 3.5,
+        stroke = 0.5,
+        alpha = 0.9,
+        show.legend = FALSE
+    ) +
+    ggplot2::scale_color_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    titheme() +
+    ggplot2::labs(
+        title = "MDS plot of random forest proximity matrix",
+        x = "MDS1", y = "MDS2"
+    ) +
+    ggplot2::guides(color = ggplot2::guide_legend(
+        order = 1,
+        override.aes = list(
+            color = c("#5d8566", "#c29007"),
+            fill = c(NA,NA), shape = 21, size = 3.5, stroke = 0.5
+        )
+    )) +
+    base_breaks_x(range(-0.2, 0.6), expand = ggplot2::expansion(mult = .05)) +
+    base_breaks_y(range(-0.2, 0.6), expand = ggplot2::expansion(mult = .05)) +
+    ggplot2::theme(
+        aspect.ratio = 1.5,
+        legend.position = c(0.95, 0.95),
+        legend.justification = c("right", "top"),
+        legend.title = ggplot2::element_text(hjust = 1)
+    )

# time: 2024-09-19 14:27:45 UTC
# mode: r
+rf_combi_plot = oob_dist_plot + ggplot2::theme(plot.margin = ggplot2::margin(r = 20)) + mds_plot

# time: 2024-09-19 14:27:46 UTC
# mode: r
+# save the plot
+ggplot2::ggsave(file.path(config$path$figures, "mds_combi_plot.jpg"),
+    plot = rf_combi_plot,
+    width = 13,
+    height = 6
+)

# time: 2024-09-19 14:30:42 UTC
# mode: r
+mds_plot <-
+    ggplot2::ggplot(mds_df, ggplot2::aes(x = X1, y = X2, color = predicted)) +
+    ggplot2::geom_point(
+        ggplot2::aes(fill = class, stroke = NA), # nolint
+        shape = 21,
+        size = 1.2,
+        alpha = 0.9
+    ) +
+    ggplot2::scale_fill_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    # add points (real label) and circles (predicted label)
+    ggplot2::geom_point(
+        ggplot2::aes(color = predicted),
+        shape = 21,
+        size = 3.5,
+        stroke = 0.5,
+        alpha = 0.9,
+        show.legend = FALSE
+    ) +
+    ggplot2::scale_color_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    titheme() +
+    ggplot2::labs(
+        title = "MDS plot of random forest proximity matrix",
+        x = "MDS1", y = "MDS2"
+    ) +
+    ggplot2::guides(
+        color = ggplot2::guide_legend(
+            order = 1,
+            override.aes = list(
+            color = c("#5d8566", "#c29007"),
+            fill = c(NA,NA), 
+            shape = 21, 
+            size = 3.5, 
+            stroke = 0.5
+        )
+    ), fill = ggplot2::guide_legend(
+        order = 2,
+        override.aes = list(
+            color = c("#5d8566", "#c29007"),
+            fill = c("#5d8566", "#c29007"),
+            shape = 21,
+            size = 1.2,
+            alpha = 0.9
+        )
+    )) +
+    base_breaks_x(range(-0.2, 0.6), expand = ggplot2::expansion(mult = .05)) +
+    base_breaks_y(range(-0.2, 0.6), expand = ggplot2::expansion(mult = .05)) +
+    ggplot2::theme(
+        aspect.ratio = 1.5,
+        legend.position = c(0.95, 0.95),
+        legend.justification = c("right", "top"),
+        legend.title = ggplot2::element_text(hjust = 1)
+    )

# time: 2024-09-19 14:30:42 UTC
# mode: r
+rf_combi_plot = oob_dist_plot + ggplot2::theme(plot.margin = ggplot2::margin(r = 20)) + mds_plot

# time: 2024-09-19 14:30:43 UTC
# mode: r
+# save the plot
+ggplot2::ggsave(file.path(config$path$figures, "mds_combi_plot.jpg"),
+    plot = rf_combi_plot,
+    width = 13,
+    height = 6
+)

# time: 2024-09-19 14:32:22 UTC
# mode: r
+mds_plot <-
+    ggplot2::ggplot(mds_df, ggplot2::aes(x = X1, y = X2, color = predicted)) +
+    ggplot2::geom_point(
+        ggplot2::aes(fill = class, stroke = NA), # nolint
+        shape = 21,
+        size = 1.2,
+        alpha = 0.9
+    ) +
+    ggplot2::scale_fill_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    # add points (real label) and circles (predicted label)
+    ggplot2::geom_point(
+        ggplot2::aes(color = predicted),
+        shape = 21,
+        size = 3.5,
+        stroke = 0.5,
+        alpha = 0.9,
+        show.legend = FALSE
+    ) +
+    ggplot2::scale_color_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    titheme() +
+    ggplot2::labs(
+        title = "MDS plot of random forest proximity matrix",
+        x = "MDS1", y = "MDS2"
+    ) +
+    ggplot2::guides(
+        color = ggplot2::guide_legend(
+            title = "Predicted",
+            label.position = "left", 
+            label.hjust = 1,
+            order = 1,
+            override.aes = list(
+            color = c("#5d8566", "#c29007"),
+            fill = c(NA,NA), 
+            shape = 21, 
+            size = 3.5, 
+            stroke = 0.5
+        )
+    ), fill = ggplot2::guide_legend(
+            title = "Actual",
+            label.position = "left", 
+            label.hjust = 1,
+            order = 2,
+            override.aes = list(
+            color = c("#5d8566", "#c29007"),
+            fill = c("#5d8566", "#c29007"),
+            shape = 21,
+            size = 1.2,
+            alpha = 0.9
+        )
+    )) +
+    base_breaks_x(range(-0.2, 0.6), expand = ggplot2::expansion(mult = .05)) +
+    base_breaks_y(range(-0.2, 0.6), expand = ggplot2::expansion(mult = .05)) +
+    ggplot2::theme(
+        aspect.ratio = 1.5,
+        legend.position = c(0.95, 0.95),
+        legend.justification = c("right", "top"),
+        legend.title = ggplot2::element_text(hjust = 1)
+    )

# time: 2024-09-19 14:32:22 UTC
# mode: r
+rf_combi_plot = oob_dist_plot + ggplot2::theme(plot.margin = ggplot2::margin(r = 20)) + mds_plot

# time: 2024-09-19 14:32:23 UTC
# mode: r
+# save the plot
+ggplot2::ggsave(file.path(config$path$figures, "mds_combi_plot.jpg"),
+    plot = rf_combi_plot,
+    width = 13,
+    height = 6
+)

# time: 2024-09-19 14:33:06 UTC
# mode: r
+rf_combi_plot = mds_plot + ggplot2::theme(plot.margin = ggplot2::margin(r = 20)) + oob_dist_plot

# time: 2024-09-19 14:33:07 UTC
# mode: r
+# save the plot
+ggplot2::ggsave(file.path(config$path$figures, "mds_combi_plot.jpg"),
+    plot = rf_combi_plot,
+    width = 13,
+    height = 6
+)

# time: 2024-09-19 14:35:16 UTC
# mode: r
+box::use(R / plot[titheme, base_breaks_x, base_breaks_y])

# time: 2024-09-19 14:35:25 UTC
# mode: r
+base_breaks_y

# time: 2024-09-19 14:35:36 UTC
# mode: r
+unsupervised_mds_plot

# time: 2024-09-19 14:36:18 UTC
# mode: r
+# Import configuration file # nolint
+config <- config::get()
+box::use(R / plot[titheme, base_breaks_x, base_breaks_y])
+box::use(patchwork)
+
+progressr::handlers(progressr::handler_pbcol(
+    adjust = 1.0,
+    complete = function(s) cli::bg_red(cli::col_black(s)),
+    incomplete = function(s) cli::bg_cyan(cli::col_black(s))
+))
+
+# parameters
+percent.train <- 0.7
+num.threads <- 44
+num.eigenvectors <- 15
+set.seed(555)
+
+# Input files
+immigrant.info <- file.path(config$path$data, "600K_immigrants.fam")
+immigrant.vcf <- file.path(config$path$data, "600K_immigrants.vcf")
+resident.vcf <- file.path(config$path$data, "600K_residents.vcf")
+
+immigrant.gds <- file.path(config$path$data, "immigrant_recode.gds")
+resident.gds <- file.path(config$path$data, "resident_recode.gds")
+all.gds <- file.path(config$path$data, "all_recode.gds")
+
+
+# Load all the data
+all.maf <- SNPRelate::snpgdsOpen(all.gds, allow.duplicate = TRUE)
+
+# Load labels
+immigrant.id <- gdsfmt::read.gdsn(gdsfmt::index.gdsn(
+    SNPRelate::snpgdsOpen(immigrant.gds),
+    "sample.id"
+))
+resident.id <- gdsfmt::read.gdsn(gdsfmt::index.gdsn(
+    SNPRelate::snpgdsOpen(resident.gds),
+    "sample.id"
+))
+
+all.id <- gdsfmt::read.gdsn(gdsfmt::index.gdsn(all.maf, "sample.id"))
+all.label <- ifelse(all.id %in% immigrant.id, "immigrant", "resident")
+
+
+# Function to split data into training and testing sets
+split_data <- function(all.id, all.label, percent.train) {
+    # Split data by class
+    labels <- unique(all.label)
+    class_0 <- all.id[all.label == labels[1]]
+    class_1 <- all.id[all.label == labels[2]]
+
+    # Determine the size of the smaller class
+    min_class_size <- min(length(class_0), length(class_1))
+
+    # Undersample the majority class
+    if (length(class_0) > min_class_size) {
+        class_0 <- sample(class_0, min_class_size)
+    } else {
+        class_1 <- sample(class_1, min_class_size)
+    }
+
+    # Combine the balanced classes
+    balanced_ids <- c(class_0, class_1)
+    balanced_labels <- c(
+        rep(labels[1], length(class_0)),
+        rep(labels[2], length(class_1))
+    )
+
+    # Calculate the number of samples for training
+    num_train <- round(length(balanced_ids) * percent.train)
+
+    # Ensure equal representation of both classes in train and test sets
+    num_train_per_class <- num_train %/% 2
+
+    # Randomly select samples for training from each class
+    train_indices <- c(
+        sample(1:min_class_size, num_train_per_class),
+        sample((min_class_size + 1):(2 * min_class_size), num_train_per_class)
+    )
+
+    train.id <- balanced_ids[train_indices]
+    test.id <- balanced_ids[-train_indices]
+    train.label <- balanced_labels[train_indices]
+    test.label <- balanced_labels[-train_indices]
+
+    list(
+        train.id = train.id, test.id = test.id,
+        train.label = train.label, test.label = test.label
+    )
+}
+# Function to perform PCA and prepare data frames
+prepare_data <- function(
+    all.maf, train.id, test.id,
+    train.label, test.label, num.eigenvectors, num.threads) {
+    pca <- SNPRelate::snpgdsPCA(
+        all.maf,
+        sample.id = train.id, num.thread = num.threads, verbose = FALSE
+    )
+    snp_loadings <- SNPRelate::snpgdsPCASNPLoading(
+        pca, all.maf,
+        num.thread = num.threads, verbose = FALSE
+    )
+    sample_loadings <- SNPRelate::snpgdsPCASampLoading(
+        snp_loadings, all.maf,
+        sample.id = test.id, num.thread = num.threads, verbose = FALSE
+    )
+    train_eigenvects <- data.frame(
+        sample.id = pca$sample.id, pca$eigenvect[, 1:num.eigenvectors]
+    )
+    test_eigenvects <- data.frame(
+        sample.id = sample_loadings$sample.id, sample_loadings$eigenvect[, 1:num.eigenvectors]
+    )
+    train_df <- data.frame(sample.id = train.id, pop = train.label, train_eigenvects[, -1])
+    test_df <- data.frame(sample.id = test.id, pop = test.label, test_eigenvects[, -1])
+    list(train_df = train_df, test_df = test_df)
+}
+
+# Function to train a random forest with optional randomized labels
+train_random_forest <- function(
+    train_df, test_df, num.eigenvectors, randomize_labels = FALSE) {
+    if (randomize_labels) {
+        train_df$pop <- sample(train_df$pop)
+    }
+
+    return(randomForest::randomForest(
+        train_df[, 3:(2 + num.eigenvectors)],
+        y = as.factor(train_df$pop),
+        data = train_df,
+        xtest = test_df[, 3:(2 + num.eigenvectors)],
+        ytest = as.factor(test_df$pop),
+        ntree = 500,
+        replace = FALSE,
+        proximity = TRUE
+    ))
+}
+
+# Function to run a single iteration
+run_iteration <- function(
+    all.id, all.label, all.maf, percent.train, num.eigenvectors, num.threads, randomize_labels) {
+    # Split data
+    split <- split_data(all.id, all.label, percent.train)
+
+    # Prepare data
+    data <- prepare_data(
+        all.maf, split$train.id, split$test.id, split$train.label, split$test.label,
+        num.eigenvectors, num.threads
+    )
+
+    # Train random forest
+    rf <- train_random_forest(data$train_df, data$test_df, num.eigenvectors, randomize_labels)
+
+    # Extract OOB error rates
+    oob_data <- rfPermute::plotTrace(rf, plot = FALSE)$data
+
+    # Return both OOB data, the random forest model, and the train/test labels
+    return(list(
+        oob_data = oob_data, rf_model = rf,
+        train_labels = split$train.label, test_labels = split$test.label
+    ))
+}
+
+# Main function to run multiple iterations
+run_analysis <- function(
+    all.id, all.label, all.maf, percent.train,
+    num.eigenvectors, num.threads,
+    n_iterations = 1) {
+    set.seed(123) # For reproducibility
+
+    # Initialize progress bar
+    progressr::with_progress({
+        p <- progressr::progressor(along = 1:(2 * n_iterations))
+
+        # Run iterations with original labels
+        original_results <- replicate(n_iterations,
+            {
+                p()
+                run_iteration(
+                    all.id, all.label, all.maf, percent.train,
+                    num.eigenvectors, num.threads, FALSE
+                )
+            },
+            simplify = FALSE
+        )
+
+        # Run iterations with randomized labels
+        random_results <- replicate(n_iterations,
+            {
+                p()
+                run_iteration(
+                    all.id, all.label, all.maf, percent.train,
+                    num.eigenvectors, num.threads, TRUE
+                )
+            },
+            simplify = FALSE
+        )
+    })
+
+    # Separate OOB data, RF models, and train/test labels
+    original_oob <- lapply(original_results, function(x) x$oob_data)
+    original_rf_models <- lapply(original_results, function(x) x$rf_model)
+    original_train_labels <- lapply(original_results, function(x) x$train_labels)
+    original_test_labels <- lapply(original_results, function(x) x$test_labels)
+
+    random_oob <- lapply(random_results, function(x) x$oob_data)
+    random_rf_models <- lapply(random_results, function(x) x$rf_model)
+    random_train_labels <- lapply(random_results, function(x) x$train_labels)
+    random_test_labels <- lapply(random_results, function(x) x$test_labels)
+
+    # Combine OOB results
+    oob_df <- dplyr::as_tibble(do.call(rbind, original_oob))
+    random_oob_df <- dplyr::as_tibble(do.call(rbind, random_oob))
+
+    list(
+        oob_df = oob_df,
+        random_oob_df = random_oob_df,
+        original_rf_models = original_rf_models,
+        random_rf_models = random_rf_models,
+        original_train_labels = original_train_labels,
+        original_test_labels = original_test_labels,
+        random_train_labels = random_train_labels,
+        random_test_labels = random_test_labels
+    )
+}
+
+calculate_mean_error <- function(data) {
+    data |>
+        dplyr::group_by(trees, class) |>
+        dplyr::summarise(mean_error = mean(error), .groups = "drop") |> # nolint: object_usage_linter.
+        dplyr::filter(class != "OOB")
+}
+
+
+# ----------------------------------- main ----------------------------------- #
+
+# TODO:
+# - RF error rate plot
+# - Summary statistics for random and original models
+# - MDS plot
+# - Confusion matrix
+# - Calculate some sort of distance between points and cluster centroids
+
+# Check if results file exists
+results_file <- file.path(config$path$data, "rf_results.rds")

# time: 2024-09-19 14:38:38 UTC
# mode: r
+# Run the analysis
+    results <- run_analysis(all.id, all.label, all.maf, percent.train,
+        num.eigenvectors, num.threads,
+        n_iterations = 20
+    )
+
+    # Save the results
+    saveRDS(results, results_file)

# time: 2024-09-19 14:46:45 UTC
# mode: r
+# Import configuration file # nolint
+config <- config::get()
+box::use(R / plot[titheme, base_breaks_x, base_breaks_y])
+box::use(patchwork)
+
+progressr::handlers(progressr::handler_pbcol(
+    adjust = 1.0,
+    complete = function(s) cli::bg_red(cli::col_black(s)),
+    incomplete = function(s) cli::bg_cyan(cli::col_black(s))
+))
+
+# parameters
+percent.train <- 0.7
+num.threads <- 44
+num.eigenvectors <- 15
+set.seed(555)
+
+# Input files
+immigrant.info <- file.path(config$path$data, "600K_immigrants.fam")
+immigrant.vcf <- file.path(config$path$data, "600K_immigrants.vcf")
+resident.vcf <- file.path(config$path$data, "600K_residents.vcf")
+
+immigrant.gds <- file.path(config$path$data, "immigrant_recode.gds")
+resident.gds <- file.path(config$path$data, "resident_recode.gds")
+all.gds <- file.path(config$path$data, "all_recode.gds")
+
+
+# Load all the data
+all.maf <- SNPRelate::snpgdsOpen(all.gds, allow.duplicate = TRUE)
+
+# Load labels
+immigrant.id <- gdsfmt::read.gdsn(gdsfmt::index.gdsn(
+    SNPRelate::snpgdsOpen(immigrant.gds),
+    "sample.id"
+))
+resident.id <- gdsfmt::read.gdsn(gdsfmt::index.gdsn(
+    SNPRelate::snpgdsOpen(resident.gds),
+    "sample.id"
+))
+
+all.id <- gdsfmt::read.gdsn(gdsfmt::index.gdsn(all.maf, "sample.id"))
+all.label <- ifelse(all.id %in% immigrant.id, "immigrant", "resident")
+
+
+# Function to split data into training and testing sets
+split_data <- function(all.id, all.label, percent.train) {
+    # Split data by class
+    labels <- unique(all.label)
+    class_0 <- all.id[all.label == labels[1]]
+    class_1 <- all.id[all.label == labels[2]]
+
+    # Determine the size of the smaller class
+    min_class_size <- min(length(class_0), length(class_1))
+
+    # Undersample the majority class
+    if (length(class_0) > min_class_size) {
+        class_0 <- sample(class_0, min_class_size)
+    } else {
+        class_1 <- sample(class_1, min_class_size)
+    }
+
+    # Combine the balanced classes
+    balanced_ids <- c(class_0, class_1)
+    balanced_labels <- c(
+        rep(labels[1], length(class_0)),
+        rep(labels[2], length(class_1))
+    )
+
+    # Calculate the number of samples for training
+    num_train <- round(length(balanced_ids) * percent.train)
+
+    # Ensure equal representation of both classes in train and test sets
+    num_train_per_class <- num_train %/% 2
+
+    # Randomly select samples for training from each class
+    train_indices <- c(
+        sample(1:min_class_size, num_train_per_class),
+        sample((min_class_size + 1):(2 * min_class_size), num_train_per_class)
+    )
+
+    train.id <- balanced_ids[train_indices]
+    test.id <- balanced_ids[-train_indices]
+    train.label <- balanced_labels[train_indices]
+    test.label <- balanced_labels[-train_indices]
+
+    list(
+        train.id = train.id, test.id = test.id,
+        train.label = train.label, test.label = test.label
+    )
+}
+# Function to perform PCA and prepare data frames
+prepare_data <- function(
+    all.maf, train.id, test.id,
+    train.label, test.label, num.eigenvectors, num.threads) {
+    pca <- SNPRelate::snpgdsPCA(
+        all.maf,
+        sample.id = train.id, num.thread = num.threads, verbose = FALSE
+    )
+    snp_loadings <- SNPRelate::snpgdsPCASNPLoading(
+        pca, all.maf,
+        num.thread = num.threads, verbose = FALSE
+    )
+    sample_loadings <- SNPRelate::snpgdsPCASampLoading(
+        snp_loadings, all.maf,
+        sample.id = test.id, num.thread = num.threads, verbose = FALSE
+    )
+    train_eigenvects <- data.frame(
+        sample.id = pca$sample.id, pca$eigenvect[, 1:num.eigenvectors]
+    )
+    test_eigenvects <- data.frame(
+        sample.id = sample_loadings$sample.id, sample_loadings$eigenvect[, 1:num.eigenvectors]
+    )
+    train_df <- data.frame(sample.id = train.id, pop = train.label, train_eigenvects[, -1])
+    test_df <- data.frame(sample.id = test.id, pop = test.label, test_eigenvects[, -1])
+    list(train_df = train_df, test_df = test_df)
+}
+
+# Function to train a random forest with optional randomized labels
+train_random_forest <- function(
+    train_df, test_df, num.eigenvectors, randomize_labels = FALSE) {
+    if (randomize_labels) {
+        train_df$pop <- sample(train_df$pop)
+    }
+
+    return(randomForest::randomForest(
+        train_df[, 3:(2 + num.eigenvectors)],
+        y = as.factor(train_df$pop),
+        data = train_df,
+        xtest = test_df[, 3:(2 + num.eigenvectors)],
+        ytest = as.factor(test_df$pop),
+        ntree = 500,
+        replace = FALSE,
+        proximity = TRUE
+    ))
+}
+
+# Function to run a single iteration
+run_iteration <- function(
+    all.id, all.label, all.maf, percent.train, num.eigenvectors, num.threads, randomize_labels) {
+    # Split data
+    split <- split_data(all.id, all.label, percent.train)
+
+    # Prepare data
+    data <- prepare_data(
+        all.maf, split$train.id, split$test.id, split$train.label, split$test.label,
+        num.eigenvectors, num.threads
+    )
+
+    # Train random forest
+    rf <- train_random_forest(data$train_df, data$test_df, num.eigenvectors, randomize_labels)
+
+    # Extract OOB error rates
+    oob_data <- rfPermute::plotTrace(rf, plot = FALSE)$data
+
+    # Return both OOB data, the random forest model, and the train/test labels
+    return(list(
+        oob_data = oob_data, rf_model = rf,
+        train_labels = split$train.label, test_labels = split$test.label
+    ))
+}
+
+# Main function to run multiple iterations
+run_analysis <- function(
+    all.id, all.label, all.maf, percent.train,
+    num.eigenvectors, num.threads,
+    n_iterations = 1) {
+    set.seed(123) # For reproducibility
+
+    # Initialize progress bar
+    progressr::with_progress({
+        p <- progressr::progressor(along = 1:(2 * n_iterations))
+
+        # Run iterations with original labels
+        original_results <- replicate(n_iterations,
+            {
+                p()
+                run_iteration(
+                    all.id, all.label, all.maf, percent.train,
+                    num.eigenvectors, num.threads, FALSE
+                )
+            },
+            simplify = FALSE
+        )
+
+        # Run iterations with randomized labels
+        random_results <- replicate(n_iterations,
+            {
+                p()
+                run_iteration(
+                    all.id, all.label, all.maf, percent.train,
+                    num.eigenvectors, num.threads, TRUE
+                )
+            },
+            simplify = FALSE
+        )
+    })
+
+    # Separate OOB data, RF models, and train/test labels
+    original_oob <- lapply(original_results, function(x) x$oob_data)
+    original_rf_models <- lapply(original_results, function(x) x$rf_model)
+    original_train_labels <- lapply(original_results, function(x) x$train_labels)
+    original_test_labels <- lapply(original_results, function(x) x$test_labels)
+
+    random_oob <- lapply(random_results, function(x) x$oob_data)
+    random_rf_models <- lapply(random_results, function(x) x$rf_model)
+    random_train_labels <- lapply(random_results, function(x) x$train_labels)
+    random_test_labels <- lapply(random_results, function(x) x$test_labels)
+
+    # Combine OOB results
+    oob_df <- dplyr::as_tibble(do.call(rbind, original_oob))
+    random_oob_df <- dplyr::as_tibble(do.call(rbind, random_oob))
+
+    list(
+        oob_df = oob_df,
+        random_oob_df = random_oob_df,
+        original_rf_models = original_rf_models,
+        random_rf_models = random_rf_models,
+        original_train_labels = original_train_labels,
+        original_test_labels = original_test_labels,
+        random_train_labels = random_train_labels,
+        random_test_labels = random_test_labels
+    )
+}
+
+calculate_mean_error <- function(data) {
+    data |>
+        dplyr::group_by(trees, class) |>
+        dplyr::summarise(mean_error = mean(error), .groups = "drop") |> # nolint: object_usage_linter.
+        dplyr::filter(class != "OOB")
+}
+
+
+# ----------------------------------- main ----------------------------------- #
+
+# TODO:
+# - RF error rate plot
+# - Summary statistics for random and original models
+# - MDS plot
+# - Confusion matrix
+# - Calculate some sort of distance between points and cluster centroids
+
+# Check if results file exists
+results_file <- file.path(config$path$data, "rf_results.rds")
+
+if (file.exists(results_file)) {
+    # Load the results
+    results <- readRDS(results_file)
+} else {
+    # Run the analysis
+    results <- run_analysis(all.id, all.label, all.maf, percent.train,
+        num.eigenvectors, num.threads,
+        n_iterations = 20
+    )
+
+    # Save the results
+    saveRDS(results, results_file)
+}
+
+
+# Calculate mean error for all iterations
+mean_oob_df <- calculate_mean_error(results$oob_df)
+mean_random_oob_df <- calculate_mean_error(results$random_oob_df)
+
+# Create the plot data
+plot_data <- list(
+    oob_df = results$oob_df |>
+        dplyr::filter(class != "OOB"),
+    random_oob_df = results$random_oob_df |>
+        dplyr::filter(class != "OOB"),
+    mean_oob_df = mean_oob_df,
+    mean_random_oob_df = mean_random_oob_df
+)
+
+# Create the plot
+oobplot <- ggplot2::ggplot() +
+    ggplot2::geom_line(data = plot_data$oob_df, ggplot2::aes(
+        x = trees, y = error, color = class
+    ), alpha = 0.1) +
+    ggplot2::geom_line(data = plot_data$random_oob_df, ggplot2::aes(
+        x = trees, y = error, color = class
+    ), alpha = 0.1, linetype = "dashed") +
+    ggplot2::geom_line(data = plot_data$mean_oob_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class
+    ), linewidth = 1.5) +
+    ggplot2::geom_line(data = plot_data$mean_random_oob_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class
+    ), linewidth = 1.5, linetype = "dashed") +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(
+        title = "OOB error rate (Solid: Original, Dashed: Randomized)",
+        x = "Number of trees", y = "Percent correct"
+    ) +
+    ggplot2::scale_color_manual(values = c(
+        "OOB" = "#4e4e4e",
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    ggplot2::coord_cartesian(ylim = c(0, 100)) +
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "red") +
+    ggplot2::theme(aspect.ratio = 1, text = ggplot2::element_text(size = 12)) +
+    ggplot2::scale_y_continuous(labels = scales::percent_format(scale = 1))
+
+# Save the plot
+ggplot2::ggsave(file.path(config$path$figures, "oob_plot.jpg"),
+    plot =
+        oobplot,
+    width = 8,
+    height = 6
+)
+
+# get data from tree 100 to tree 500 and plot the distribution of percent correct
+
+
+oob_df <- dplyr::bind_rows(
+    list(
+        oob_df = plot_data$oob_df,
+        random_oob_df = plot_data$random_oob_df
+    ),
+    .id = "source"
+) |>
+    dplyr::filter(trees >= 100 & trees <= 500) |>
+
+# plot the distribution of percent correct by class
+
+oob_dist_plot <- ggplot2::ggplot() +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(y = error, fill = class),
+        position = "identity", alpha = 0.65,
+        density = ggdist::density_bounded(bandwidth = .5, trim=FALSE)
+    ) +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(y = error, fill = "randomised"),
+        position = "identity", alpha = 0.65,
+        density = ggdist::density_bounded(bandwidth = .5,  trim=FALSE),
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(y = error, color = class),
+        position = ggplot2::position_dodge(
+            width = .3, preserve = "single"
+        )
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(y = error, color = "randomised"),
+        position = ggplot2::position_dodge(
+            width = .3, preserve = "single"
+        )
+    ) +
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "black") +
+    ggplot2::labs(
+        title = "Distribution of percent correct by class",
+        y = "Percent correct", x = "Density"
+    ) +
+    ggplot2::scale_fill_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007", "randomised" = "#716e6e"
+    ), labels =  c("immigrant",  "resident", "random\nperformance")) +
+    ggplot2::scale_color_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007", "randomised" = "grey"
+    )) +
+    base_breaks_y(40:100, expand = ggplot2::expansion(mult = .05)) +
+    base_breaks_x(0:1, expand = ggplot2::expansion(add = c(-0.1, 0))) +
+    titheme() +
+    ggplot2::theme(
+        aspect.ratio = 2.3,
+        legend.position = c(0.95, 0.95),
+        legend.justification = c("right", "top"),
+        legend.title = ggplot2::element_text(hjust = 1)
+    ) +
+    ggplot2::guides(
+        fill = ggplot2::guide_legend(
+            title = "Class",
+            label.position = "left", label.hjust = 1
+        ), color = "none"
+    )
+
+# Save the plot
+ggplot2::ggsave(file.path(config$path$figures, "oob_dist_plot.jpg"),
+    plot = oob_dist_plot,
+    width = 8,
+    height = 6
+)
+
+# run a single random forest model:
+
+set.seed(123)
+split <- split_data(all.id, all.label, percent.train)
+data <- prepare_data(
+    all.maf, split$train.id, split$test.id, split$train.label, split$test.label,
+    num.eigenvectors, num.threads
+)
+
+# Use all available data as here we are not interested in the model's performance
+data = data$train_df |> dplyr::bind_rows(data$test_df)
+
+set.seed(123)
+rf = randomForest::randomForest(
+    data[, 3:(2 + num.eigenvectors)],
+    y = as.factor(data$pop),
+    ntree = 300,
+    replace = FALSE,
+    proximity = TRUE,
+    oob.prox = TRUE
+)
+
+# cmd the proximity matrix from the model and plot
+prox <- 1 - rf$proximity
+mds <- stats::cmdscale(prox, k = 2)
+
+# plot the MDS
+mds_df <- data.frame(mds, class = rf$y, predicted = rf$predicted)
+
+point.size = 2
+circle.size = 8
+circle.border = 1
+
+mds_plot <-
+    ggplot2::ggplot(mds_df, ggplot2::aes(x = X1, y = X2, color = predicted)) +
+    ggplot2::geom_point(
+        ggplot2::aes(fill = class, stroke = NA), # nolint
+        shape = 21,
+        size = 1.2,
+        alpha = 0.9
+    ) +
+    ggplot2::scale_fill_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    # add points (real label) and circles (predicted label)
+    ggplot2::geom_point(
+        ggplot2::aes(color = predicted),
+        shape = 21,
+        size = 3.5,
+        stroke = 0.5,
+        alpha = 0.9,
+        show.legend = FALSE
+    ) +
+    ggplot2::scale_color_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    titheme() +
+    ggplot2::labs(
+        title = "MDS plot of random forest proximity matrix",
+        x = "MDS1", y = "MDS2"
+    ) +
+    ggplot2::guides(
+        color = ggplot2::guide_legend(
+            title = "Predicted",
+            label.position = "left", 
+            label.hjust = 1,
+            order = 1,
+            override.aes = list(
+            color = c("#5d8566", "#c29007"),
+            fill = c(NA,NA), 
+            shape = 21, 
+            size = 3.5, 
+            stroke = 0.5
+        )
+    ), fill = ggplot2::guide_legend(
+            title = "Actual",
+            label.position = "left", 
+            label.hjust = 1,
+            order = 2,
+            override.aes = list(
+            color = c("#5d8566", "#c29007"),
+            fill = c("#5d8566", "#c29007"),
+            shape = 21,
+            size = 1.2,
+            alpha = 0.9
+        )
+    )) +
+    base_breaks_x(range(-0.2, 0.6), expand = ggplot2::expansion(mult = .05)) +
+    base_breaks_y(range(-0.2, 0.6), expand = ggplot2::expansion(mult = .05)) +
+    ggplot2::theme(
+        aspect.ratio = 1.5,
+        legend.position = c(0.95, 0.95),
+        legend.justification = c("right", "top"),
+        legend.title = ggplot2::element_text(hjust = 1)
+    ) 
+
+
+
+rf_combi_plot = oob_dist_plot + ggplot2::theme(plot.margin = ggplot2::margin(r = 20)) + mds_plot
+
+
+# save the plot
+ggplot2::ggsave(file.path(config$path$figures, "mds_combi_plot.jpg"),
+    plot = rf_combi_plot,
+    width = 13,
+    height = 6
+)

# time: 2024-09-19 14:47:28 UTC
# mode: r
+# Import configuration file # nolint
+config <- config::get()
+box::use(R / plot[titheme, base_breaks_x, base_breaks_y])
+box::use(patchwork)
+
+progressr::handlers(progressr::handler_pbcol(
+    adjust = 1.0,
+    complete = function(s) cli::bg_red(cli::col_black(s)),
+    incomplete = function(s) cli::bg_cyan(cli::col_black(s))
+))
+
+# parameters
+percent.train <- 0.7
+num.threads <- 44
+num.eigenvectors <- 15
+set.seed(555)
+
+# Input files
+immigrant.info <- file.path(config$path$data, "600K_immigrants.fam")
+immigrant.vcf <- file.path(config$path$data, "600K_immigrants.vcf")
+resident.vcf <- file.path(config$path$data, "600K_residents.vcf")
+
+immigrant.gds <- file.path(config$path$data, "immigrant_recode.gds")
+resident.gds <- file.path(config$path$data, "resident_recode.gds")
+all.gds <- file.path(config$path$data, "all_recode.gds")
+
+
+# Load all the data
+all.maf <- SNPRelate::snpgdsOpen(all.gds, allow.duplicate = TRUE)
+
+# Load labels
+immigrant.id <- gdsfmt::read.gdsn(gdsfmt::index.gdsn(
+    SNPRelate::snpgdsOpen(immigrant.gds),
+    "sample.id"
+))
+resident.id <- gdsfmt::read.gdsn(gdsfmt::index.gdsn(
+    SNPRelate::snpgdsOpen(resident.gds),
+    "sample.id"
+))
+
+all.id <- gdsfmt::read.gdsn(gdsfmt::index.gdsn(all.maf, "sample.id"))
+all.label <- ifelse(all.id %in% immigrant.id, "immigrant", "resident")
+
+
+# Function to split data into training and testing sets
+split_data <- function(all.id, all.label, percent.train) {
+    # Split data by class
+    labels <- unique(all.label)
+    class_0 <- all.id[all.label == labels[1]]
+    class_1 <- all.id[all.label == labels[2]]
+
+    # Determine the size of the smaller class
+    min_class_size <- min(length(class_0), length(class_1))
+
+    # Undersample the majority class
+    if (length(class_0) > min_class_size) {
+        class_0 <- sample(class_0, min_class_size)
+    } else {
+        class_1 <- sample(class_1, min_class_size)
+    }
+
+    # Combine the balanced classes
+    balanced_ids <- c(class_0, class_1)
+    balanced_labels <- c(
+        rep(labels[1], length(class_0)),
+        rep(labels[2], length(class_1))
+    )
+
+    # Calculate the number of samples for training
+    num_train <- round(length(balanced_ids) * percent.train)
+
+    # Ensure equal representation of both classes in train and test sets
+    num_train_per_class <- num_train %/% 2
+
+    # Randomly select samples for training from each class
+    train_indices <- c(
+        sample(1:min_class_size, num_train_per_class),
+        sample((min_class_size + 1):(2 * min_class_size), num_train_per_class)
+    )
+
+    train.id <- balanced_ids[train_indices]
+    test.id <- balanced_ids[-train_indices]
+    train.label <- balanced_labels[train_indices]
+    test.label <- balanced_labels[-train_indices]
+
+    list(
+        train.id = train.id, test.id = test.id,
+        train.label = train.label, test.label = test.label
+    )
+}
+# Function to perform PCA and prepare data frames
+prepare_data <- function(
+    all.maf, train.id, test.id,
+    train.label, test.label, num.eigenvectors, num.threads) {
+    pca <- SNPRelate::snpgdsPCA(
+        all.maf,
+        sample.id = train.id, num.thread = num.threads, verbose = FALSE
+    )
+    snp_loadings <- SNPRelate::snpgdsPCASNPLoading(
+        pca, all.maf,
+        num.thread = num.threads, verbose = FALSE
+    )
+    sample_loadings <- SNPRelate::snpgdsPCASampLoading(
+        snp_loadings, all.maf,
+        sample.id = test.id, num.thread = num.threads, verbose = FALSE
+    )
+    train_eigenvects <- data.frame(
+        sample.id = pca$sample.id, pca$eigenvect[, 1:num.eigenvectors]
+    )
+    test_eigenvects <- data.frame(
+        sample.id = sample_loadings$sample.id, sample_loadings$eigenvect[, 1:num.eigenvectors]
+    )
+    train_df <- data.frame(sample.id = train.id, pop = train.label, train_eigenvects[, -1])
+    test_df <- data.frame(sample.id = test.id, pop = test.label, test_eigenvects[, -1])
+    list(train_df = train_df, test_df = test_df)
+}
+
+# Function to train a random forest with optional randomized labels
+train_random_forest <- function(
+    train_df, test_df, num.eigenvectors, randomize_labels = FALSE) {
+    if (randomize_labels) {
+        train_df$pop <- sample(train_df$pop)
+    }
+
+    return(randomForest::randomForest(
+        train_df[, 3:(2 + num.eigenvectors)],
+        y = as.factor(train_df$pop),
+        data = train_df,
+        xtest = test_df[, 3:(2 + num.eigenvectors)],
+        ytest = as.factor(test_df$pop),
+        ntree = 500,
+        replace = FALSE,
+        proximity = TRUE
+    ))
+}
+
+# Function to run a single iteration
+run_iteration <- function(
+    all.id, all.label, all.maf, percent.train, num.eigenvectors, num.threads, randomize_labels) {
+    # Split data
+    split <- split_data(all.id, all.label, percent.train)
+
+    # Prepare data
+    data <- prepare_data(
+        all.maf, split$train.id, split$test.id, split$train.label, split$test.label,
+        num.eigenvectors, num.threads
+    )
+
+    # Train random forest
+    rf <- train_random_forest(data$train_df, data$test_df, num.eigenvectors, randomize_labels)
+
+    # Extract OOB error rates
+    oob_data <- rfPermute::plotTrace(rf, plot = FALSE)$data
+
+    # Return both OOB data, the random forest model, and the train/test labels
+    return(list(
+        oob_data = oob_data, rf_model = rf,
+        train_labels = split$train.label, test_labels = split$test.label
+    ))
+}
+
+# Main function to run multiple iterations
+run_analysis <- function(
+    all.id, all.label, all.maf, percent.train,
+    num.eigenvectors, num.threads,
+    n_iterations = 1) {
+    set.seed(123) # For reproducibility
+
+    # Initialize progress bar
+    progressr::with_progress({
+        p <- progressr::progressor(along = 1:(2 * n_iterations))
+
+        # Run iterations with original labels
+        original_results <- replicate(n_iterations,
+            {
+                p()
+                run_iteration(
+                    all.id, all.label, all.maf, percent.train,
+                    num.eigenvectors, num.threads, FALSE
+                )
+            },
+            simplify = FALSE
+        )
+
+        # Run iterations with randomized labels
+        random_results <- replicate(n_iterations,
+            {
+                p()
+                run_iteration(
+                    all.id, all.label, all.maf, percent.train,
+                    num.eigenvectors, num.threads, TRUE
+                )
+            },
+            simplify = FALSE
+        )
+    })
+
+    # Separate OOB data, RF models, and train/test labels
+    original_oob <- lapply(original_results, function(x) x$oob_data)
+    original_rf_models <- lapply(original_results, function(x) x$rf_model)
+    original_train_labels <- lapply(original_results, function(x) x$train_labels)
+    original_test_labels <- lapply(original_results, function(x) x$test_labels)
+
+    random_oob <- lapply(random_results, function(x) x$oob_data)
+    random_rf_models <- lapply(random_results, function(x) x$rf_model)
+    random_train_labels <- lapply(random_results, function(x) x$train_labels)
+    random_test_labels <- lapply(random_results, function(x) x$test_labels)
+
+    # Combine OOB results
+    oob_df <- dplyr::as_tibble(do.call(rbind, original_oob))
+    random_oob_df <- dplyr::as_tibble(do.call(rbind, random_oob))
+
+    list(
+        oob_df = oob_df,
+        random_oob_df = random_oob_df,
+        original_rf_models = original_rf_models,
+        random_rf_models = random_rf_models,
+        original_train_labels = original_train_labels,
+        original_test_labels = original_test_labels,
+        random_train_labels = random_train_labels,
+        random_test_labels = random_test_labels
+    )
+}
+
+calculate_mean_error <- function(data) {
+    data |>
+        dplyr::group_by(trees, class) |>
+        dplyr::summarise(mean_error = mean(error), .groups = "drop") |> # nolint: object_usage_linter.
+        dplyr::filter(class != "OOB")
+}

# time: 2024-09-19 14:47:33 UTC
# mode: r
+# ----------------------------------- main ----------------------------------- #
+
+# TODO:
+# - RF error rate plot
+# - Summary statistics for random and original models
+# - MDS plot
+# - Confusion matrix
+# - Calculate some sort of distance between points and cluster centroids
+
+# Check if results file exists
+results_file <- file.path(config$path$data, "rf_results.rds")

# time: 2024-09-19 14:47:34 UTC
# mode: r
+if (file.exists(results_file)) {
+    # Load the results
+    results <- readRDS(results_file)
+} else {
+    # Run the analysis
+    results <- run_analysis(all.id, all.label, all.maf, percent.train,
+        num.eigenvectors, num.threads,
+        n_iterations = 20
+    )
+
+    # Save the results
+    saveRDS(results, results_file)
+}

# time: 2024-09-19 14:47:36 UTC
# mode: r
+# Calculate mean error for all iterations
+mean_oob_df <- calculate_mean_error(results$oob_df)

# time: 2024-09-19 14:47:37 UTC
# mode: r
+mean_random_oob_df <- calculate_mean_error(results$random_oob_df)

# time: 2024-09-19 14:47:37 UTC
# mode: r
+# Create the plot data
+plot_data <- list(
+    oob_df = results$oob_df |>
+        dplyr::filter(class != "OOB"),
+    random_oob_df = results$random_oob_df |>
+        dplyr::filter(class != "OOB"),
+    mean_oob_df = mean_oob_df,
+    mean_random_oob_df = mean_random_oob_df
+)

# time: 2024-09-19 14:47:39 UTC
# mode: r
+# Create the plot
+oobplot <- ggplot2::ggplot() +
+    ggplot2::geom_line(data = plot_data$oob_df, ggplot2::aes(
+        x = trees, y = error, color = class
+    ), alpha = 0.1) +
+    ggplot2::geom_line(data = plot_data$random_oob_df, ggplot2::aes(
+        x = trees, y = error, color = class
+    ), alpha = 0.1, linetype = "dashed") +
+    ggplot2::geom_line(data = plot_data$mean_oob_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class
+    ), linewidth = 1.5) +
+    ggplot2::geom_line(data = plot_data$mean_random_oob_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class
+    ), linewidth = 1.5, linetype = "dashed") +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(
+        title = "OOB error rate (Solid: Original, Dashed: Randomized)",
+        x = "Number of trees", y = "Percent correct"
+    ) +
+    ggplot2::scale_color_manual(values = c(
+        "OOB" = "#4e4e4e",
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    ggplot2::coord_cartesian(ylim = c(0, 100)) +
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "red") +
+    ggplot2::theme(aspect.ratio = 1, text = ggplot2::element_text(size = 12)) +
+    ggplot2::scale_y_continuous(labels = scales::percent_format(scale = 1))

# time: 2024-09-19 14:47:39 UTC
# mode: r
+# Save the plot
+ggplot2::ggsave(file.path(config$path$figures, "oob_plot.jpg"),
+    plot =
+        oobplot,
+    width = 8,
+    height = 6
+)

# time: 2024-09-19 14:47:43 UTC
# mode: r
+# get data from tree 100 to tree 500 and plot the distribution of percent correct
+
+
+oob_df <- dplyr::bind_rows(
+    list(
+        oob_df = plot_data$oob_df,
+        random_oob_df = plot_data$random_oob_df
+    ),
+    .id = "source"
+) |>
+    dplyr::filter(trees >= 100 & trees <= 500) |>
+
+# plot the distribution of percent correct by class
+
+oob_dist_plot <- ggplot2::ggplot() +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(y = error, fill = class),
+        position = "identity", alpha = 0.65,
+        density = ggdist::density_bounded(bandwidth = .5, trim=FALSE)
+    ) +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(y = error, fill = "randomised"),
+        position = "identity", alpha = 0.65,
+        density = ggdist::density_bounded(bandwidth = .5,  trim=FALSE),
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(y = error, color = class),
+        position = ggplot2::position_dodge(
+            width = .3, preserve = "single"
+        )
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(y = error, color = "randomised"),
+        position = ggplot2::position_dodge(
+            width = .3, preserve = "single"
+        )
+    ) +
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "black") +
+    ggplot2::labs(
+        title = "Distribution of percent correct by class",
+        y = "Percent correct", x = "Density"
+    ) +
+    ggplot2::scale_fill_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007", "randomised" = "#716e6e"
+    ), labels =  c("immigrant",  "resident", "random\nperformance")) +
+    ggplot2::scale_color_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007", "randomised" = "grey"
+    )) +
+    base_breaks_y(40:100, expand = ggplot2::expansion(mult = .05)) +
+    base_breaks_x(0:1, expand = ggplot2::expansion(add = c(-0.1, 0))) +
+    titheme() +
+    ggplot2::theme(
+        aspect.ratio = 2.3,
+        legend.position = c(0.95, 0.95),
+        legend.justification = c("right", "top"),
+        legend.title = ggplot2::element_text(hjust = 1)
+    ) +
+    ggplot2::guides(
+        fill = ggplot2::guide_legend(
+            title = "Class",
+            label.position = "left", label.hjust = 1
+        ), color = "none"
+    )

# time: 2024-09-19 14:48:47 UTC
# mode: r
+# get data from tree 100 to tree 500 and plot the distribution of percent correct
+
+
+oob_df <- dplyr::bind_rows(
+    list(
+        oob_df = plot_data$oob_df,
+        random_oob_df = plot_data$random_oob_df
+    ),
+    .id = "source"
+) |>
+    dplyr::filter(trees >= 100 & trees <= 500) |>
+
+# plot the distribution of percent correct by class
+
+oob_dist_plot <- ggplot2::ggplot() +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(y = error, fill = class),
+        position = "identity", alpha = 0.65,
+        density = ggdist::density_bounded(bandwidth = .5, trim=FALSE)
+    ) +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(y = error, fill = "randomised"),
+        position = "identity", alpha = 0.65,
+        density = ggdist::density_bounded(bandwidth = .5,  trim=FALSE),
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(y = error, color = class),
+        position = ggplot2::position_dodge(
+            width = .3, preserve = "single"
+        )
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(y = error, color = "randomised"),
+        position = ggplot2::position_dodge(
+            width = .3, preserve = "single"
+        )
+    ) +
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "black") +
+    ggplot2::labs(
+        title = "Distribution of percent correct by class",
+        y = "Percent correct", x = "Density"
+    ) +
+    ggplot2::scale_fill_manual(
+        values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007", "randomised" = "#716e6e"
+    ), labels =  c("immigrant",  "resident", "random\nperformance")) +
+    ggplot2::scale_color_manual(
+        values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007", "randomised" = "grey"
+    )) +
+    base_breaks_y(40:100, expand = ggplot2::expansion(mult = .05)) +
+    base_breaks_x(0:1, expand = ggplot2::expansion(add = c(-0.1, 0))) +
+    titheme() +
+    ggplot2::theme(
+        aspect.ratio = 2.3,
+        legend.position = c(0.95, 0.95),
+        legend.justification = c("right", "top"),
+        legend.title = ggplot2::element_text(hjust = 1)
+    ) +
+    ggplot2::guides(
+        fill = ggplot2::guide_legend(
+            title = "Class",
+            label.position = "left", 
+            label.hjust = 1
+        ), 
+        color = "none"
+    )

# time: 2024-09-19 14:49:02 UTC
# mode: r
+oob_dist_plot <- ggplot2::ggplot() +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(y = error, fill = class),
+        position = "identity", alpha = 0.65,
+        density = ggdist::density_bounded(bandwidth = .5, trim=FALSE)
+    ) +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(y = error, fill = "randomised"),
+        position = "identity", alpha = 0.65,
+        density = ggdist::density_bounded(bandwidth = .5,  trim=FALSE),
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(y = error, color = class),
+        position = ggplot2::position_dodge(
+            width = .3, preserve = "single"
+        )
+    )

# time: 2024-09-19 14:49:08 UTC
# mode: r
+# get data from tree 100 to tree 500 and plot the distribution of percent correct
+
+
+oob_df <- dplyr::bind_rows(
+    list(
+        oob_df = plot_data$oob_df,
+        random_oob_df = plot_data$random_oob_df
+    ),
+    .id = "source"
+) |>
+    dplyr::filter(trees >= 100 & trees <= 500)

# time: 2024-09-19 14:49:09 UTC
# mode: r
+# plot the distribution of percent correct by class
+
+oob_dist_plot <- ggplot2::ggplot() +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(y = error, fill = class),
+        position = "identity", alpha = 0.65,
+        density = ggdist::density_bounded(bandwidth = .5, trim=FALSE)
+    ) +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(y = error, fill = "randomised"),
+        position = "identity", alpha = 0.65,
+        density = ggdist::density_bounded(bandwidth = .5,  trim=FALSE),
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(y = error, color = class),
+        position = ggplot2::position_dodge(
+            width = .3, preserve = "single"
+        )
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(y = error, color = "randomised"),
+        position = ggplot2::position_dodge(
+            width = .3, preserve = "single"
+        )
+    ) +
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "black") +
+    ggplot2::labs(
+        title = "Distribution of percent correct by class",
+        y = "Percent correct", x = "Density"
+    ) +
+    ggplot2::scale_fill_manual(
+        values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007", "randomised" = "#716e6e"
+    ), labels =  c("immigrant",  "resident", "random\nperformance")) +
+    ggplot2::scale_color_manual(
+        values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007", "randomised" = "grey"
+    )) +
+    base_breaks_y(40:100, expand = ggplot2::expansion(mult = .05)) +
+    base_breaks_x(0:1, expand = ggplot2::expansion(add = c(-0.1, 0))) +
+    titheme() +
+    ggplot2::theme(
+        aspect.ratio = 2.3,
+        legend.position = c(0.95, 0.95),
+        legend.justification = c("right", "top"),
+        legend.title = ggplot2::element_text(hjust = 1)
+    ) +
+    ggplot2::guides(
+        fill = ggplot2::guide_legend(
+            title = "Class",
+            label.position = "left", 
+            label.hjust = 1
+        ), 
+        color = "none"
+    )

# time: 2024-09-19 14:49:43 UTC
# mode: r
+# plot the distribution of percent correct by class
+
+oob_dist_plot <- ggplot2::ggplot() +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(y = error, fill = class),
+        position = "identity", alpha = 0.65,
+        density = ggdist::density_bounded(bandwidth = .5, trim=FALSE)
+    ) +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(y = error, fill = "randomised"),
+        position = "identity", alpha = 0.65,
+        density = ggdist::density_bounded(bandwidth = .5,  trim=FALSE),
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(y = error, color = class),
+        position = ggplot2::position_dodge(
+            width = .3, preserve = "single"
+        )
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(y = error, color = "randomised"),
+        position = ggplot2::position_dodge(
+            width = .3, preserve = "single"
+        )
+    ) +
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "black") +
+    ggplot2::labs(
+        title = "Distribution of percent correct by class",
+        y = "Percent correct", x = "Density"
+    ) +
+    ggplot2::scale_fill_manual(
+        values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007", "randomised" = "#716e6e"
+    ), labels =  c("immigrant",  "resident", "random\nperformance")) +
+    ggplot2::scale_color_manual(
+        values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007", "randomised" = "grey"
+    )) +
+    base_breaks_y(40:100, expand = ggplot2::expansion(mult = .05)) +
+    base_breaks_x(0:1, expand = ggplot2::expansion(add = c(-0.1, 0))) +
+    titheme() +
+    ggplot2::theme(
+        aspect.ratio = 2.3,
+        legend.position.inside = c(0.95, 0.95),
+        legend.justification = c("right", "top"),
+        legend.title = ggplot2::element_text(hjust = 1)
+    ) +
+    ggplot2::guides(
+        fill = ggplot2::guide_legend(
+            title = "Class",
+            label.position = "left", 
+            label.hjust = 1
+        ), 
+        color = "none"
+    )

# time: 2024-09-19 14:49:44 UTC
# mode: r
+# Save the plot
+ggplot2::ggsave(file.path(config$path$figures, "oob_dist_plot.jpg"),
+    plot = oob_dist_plot,
+    width = 8,
+    height = 6
+)

# time: 2024-09-19 14:49:52 UTC
# mode: r
+set.seed(123)
+split <- split_data(all.id, all.label, percent.train)
+data <- prepare_data(
+    all.maf, split$train.id, split$test.id, split$train.label, split$test.label,
+    num.eigenvectors, num.threads
+)
+
+# Use all available data as here we are not interested in the model's performance
+data = data$train_df |> dplyr::bind_rows(data$test_df)
+
+set.seed(123)
+rf = randomForest::randomForest(
+    data[, 3:(2 + num.eigenvectors)],
+    y = as.factor(data$pop),
+    ntree = 300,
+    replace = FALSE,
+    proximity = TRUE,
+    oob.prox = TRUE
+)
+
+# cmd the proximity matrix from the model and plot
+prox <- 1 - rf$proximity
+mds <- stats::cmdscale(prox, k = 2)
+
+# plot the MDS
+mds_df <- data.frame(mds, class = rf$y, predicted = rf$predicted)
+
+point.size = 2
+circle.size = 8
+circle.border = 1

# time: 2024-09-19 14:50:18 UTC
# mode: r
+mds_plot <-
+    ggplot2::ggplot(mds_df, ggplot2::aes(x = X1, y = X2, color = predicted)) +
+    ggplot2::geom_point(
+        ggplot2::aes(fill = class, stroke = NA), # nolint
+        shape = 21,
+        size = 1.2,
+        alpha = 0.9
+    ) +
+    ggplot2::scale_fill_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    # add points (real label) and circles (predicted label)
+    ggplot2::geom_point(
+        ggplot2::aes(color = predicted),
+        shape = 21,
+        size = 3.5,
+        stroke = 0.5,
+        alpha = 0.9,
+        show.legend = FALSE
+    ) +
+    ggplot2::scale_color_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    titheme() +
+    ggplot2::labs(
+        title = "MDS plot of random forest proximity matrix",
+        x = "MDS1", y = "MDS2"
+    ) +
+    ggplot2::guides(
+        color = ggplot2::guide_legend(
+            title = "Predicted",
+            label.position = "left",
+            label.hjust = 1,
+            order = 1,
+            override.aes = list(
+                color = c("#5d8566", "#c29007"),
+                fill = c(NA, NA),
+                shape = 21,
+                size = 3.5,
+                stroke = 0.5
+            )
+        ), 
+        fill = ggplot2::guide_legend(
+            title = "Actual",
+            label.position = "left",
+            label.hjust = 1,
+            order = 2,
+            override.aes = list(
+                color = c("#5d8566", "#c29007"),
+                fill = c("#5d8566", "#c29007"),
+                shape = 21,
+                size = 1.2,
+                alpha = 0.9
+            )
+        )
+    ) +
+    base_breaks_x(range(-0.2, 0.6), expand = ggplot2::expansion(mult = .05)) +
+    base_breaks_y(range(-0.2, 0.6), expand = ggplot2::expansion(mult = .05)) +
+    ggplot2::theme(
+        aspect.ratio = 1.5,
+        legend.position.inside = c(0.95, 0.95),
+        legend.justification = c("right", "top"),
+        legend.title = ggplot2::element_text(hjust = 1)
+    )

# time: 2024-09-19 14:50:19 UTC
# mode: r
+rf_combi_plot <- oob_dist_plot + ggplot2::theme(plot.margin = ggplot2::margin(r = 20)) + mds_plot

# time: 2024-09-19 14:50:20 UTC
# mode: r
+# save the plot
+ggplot2::ggsave(file.path(config$path$figures, "mds_combi_plot.jpg"),
+    plot = rf_combi_plot,
+    width = 13,
+    height = 6
+)

# time: 2024-09-19 14:52:16 UTC
# mode: r
+# Create the plot data
+plot_data <- list(
+    oob_df = results$oob_df |>
+        dplyr::filter(class != "OOB"),
+    random_oob_df = results$random_oob_df |>
+        dplyr::filter(class != "OOB"),
+    mean_oob_df = mean_oob_df,
+    mean_random_oob_df = mean_random_oob_df
+)

# time: 2024-09-19 14:52:17 UTC
# mode: r
+# Create the plot
+oobplot <- ggplot2::ggplot() +
+    ggplot2::geom_line(data = plot_data$oob_df, ggplot2::aes(
+        x = trees, y = error, color = class
+    ), alpha = 0.1) +
+    ggplot2::geom_line(data = plot_data$random_oob_df, ggplot2::aes(
+        x = trees, y = error, color = class
+    ), alpha = 0.1, linetype = "dashed") +
+    ggplot2::geom_line(data = plot_data$mean_oob_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class
+    ), linewidth = 1.5) +
+    ggplot2::geom_line(data = plot_data$mean_random_oob_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class
+    ), linewidth = 1.5, linetype = "dashed") +
+    ggplot2::theme_minimal() +
+    ggplot2::labs(
+        title = "OOB error rate (Solid: Original, Dashed: Randomized)",
+        x = "Number of trees", y = "Percent correct"
+    ) +
+    ggplot2::scale_color_manual(values = c(
+        "OOB" = "#4e4e4e",
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    ggplot2::coord_cartesian(ylim = c(0, 100)) +
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "red") +
+    ggplot2::theme(aspect.ratio = 1, text = ggplot2::element_text(size = 12)) +
+    ggplot2::scale_y_continuous(labels = scales::percent_format(scale = 1))

# time: 2024-09-19 14:52:18 UTC
# mode: r
+# Save the plot
+ggplot2::ggsave(file.path(config$path$figures, "oob_plot.jpg"),
+    plot =
+        oobplot,
+    width = 8,
+    height = 6
+)

# time: 2024-09-19 14:52:19 UTC
# mode: r
+# get data from tree 100 to tree 500 and plot the distribution of percent correct
+
+
+oob_df <- dplyr::bind_rows(
+    list(
+        oob_df = plot_data$oob_df,
+        random_oob_df = plot_data$random_oob_df
+    ),
+    .id = "source"
+) |>
+    dplyr::filter(trees >= 100 & trees <= 500)

# time: 2024-09-19 14:52:19 UTC
# mode: r
+# plot the distribution of percent correct by class
+
+oob_dist_plot <- ggplot2::ggplot() +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(y = error, fill = class),
+        position = "identity", alpha = 0.65,
+        density = ggdist::density_bounded(bandwidth = .5, trim = FALSE)
+    ) +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(y = error, fill = "randomised"),
+        position = "identity", alpha = 0.65,
+        density = ggdist::density_bounded(bandwidth = .5, trim = FALSE),
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(y = error, color = class),
+        position = ggplot2::position_dodge(
+            width = .3, preserve = "single"
+        )
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(y = error, color = "randomised"),
+        position = ggplot2::position_dodge(
+            width = .3, preserve = "single"
+        )
+    ) +
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "black") +
+    ggplot2::labs(
+        title = "Distribution of percent correct by class",
+        y = "Percent correct", x = "Density"
+    ) +
+    ggplot2::scale_fill_manual(
+        values = c(
+            "immigrant" = "#5d8566", "resident" = "#c29007", "randomised" = "#716e6e"
+        ), labels = c("immigrant", "resident", "random\nperformance")
+    ) +
+    ggplot2::scale_color_manual(
+        values = c(
+            "immigrant" = "#5d8566", "resident" = "#c29007", "randomised" = "grey"
+        )
+    ) +
+    base_breaks_y(40:100, expand = ggplot2::expansion(mult = .05)) +
+    base_breaks_x(0:1, expand = ggplot2::expansion(add = c(-0.1, 0))) +
+    titheme() +
+    ggplot2::theme(
+        aspect.ratio = 2.3,
+        legend.position = "inside",
+        legend.position.inside = c(0.95, 0.95),
+        legend.justification = c("right", "top"),
+        legend.title = ggplot2::element_text(hjust = 1)
+    ) +
+    ggplot2::guides(
+        fill = ggplot2::guide_legend(
+            title = "Class",
+            label.position = "left",
+            label.hjust = 1
+        ),
+        color = "none"
+    )

# time: 2024-09-19 14:52:21 UTC
# mode: r
+# Save the plot
+ggplot2::ggsave(file.path(config$path$figures, "oob_dist_plot.jpg"),
+    plot = oob_dist_plot,
+    width = 8,
+    height = 6
+)

# time: 2024-09-19 14:53:01 UTC
# mode: r
+# plot the distribution of percent correct by class
+
+oob_dist_plot <- ggplot2::ggplot() +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(y = error, fill = class),
+        position = "identity", alpha = 0.65,
+        density = ggdist::density_bounded(bandwidth = .5, trim = FALSE)
+    ) +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(y = error, fill = "randomised"),
+        position = "identity", alpha = 0.65,
+        density = ggdist::density_bounded(bandwidth = .5, trim = FALSE),
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(y = error, color = class),
+        position = ggplot2::position_dodge(
+            width = .3, preserve = "single"
+        )
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(y = error, color = "randomised"),
+        position = ggplot2::position_dodge(
+            width = .3, preserve = "single"
+        )
+    ) +
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "black") +
+    ggplot2::labs(
+        title = "Distribution of percent correct by class",
+        y = "Percent correct", x = "Density"
+    ) +
+    ggplot2::scale_fill_manual(
+        values = c(
+            "immigrant" = "#5d8566", "resident" = "#c29007", "randomised" = "#716e6e"
+        ), labels = c("immigrant", "resident", "random\nperformance")
+    ) +
+    ggplot2::scale_color_manual(
+        values = c(
+            "immigrant" = "#5d8566", "resident" = "#c29007", "randomised" = "grey"
+        )
+    ) +
+    base_breaks_y(40:100, expand = ggplot2::expansion(mult = .05)) +
+    base_breaks_x(0:1, expand = ggplot2::expansion(add = c(-0.1, 0))) +
+    titheme() +
+    ggplot2::theme(
+        aspect.ratio = 2.3,
+        legend.position = "inside",
+        legend.position.inside = c(0.95, 0.95),
+        legend.justification = c("right", "top"),
+        legend.title = ggplot2::element_text(hjust = 1)
+    ) +
+    ggplot2::guides(
+        fill = ggplot2::guide_legend(
+            title = "Class",
+            label.position = "left",
+            label.hjust = 1
+        ),
+        color = "none"
+    )
+
+
+mds_plot <-
+    ggplot2::ggplot(mds_df, ggplot2::aes(x = X1, y = X2, color = predicted)) +
+    ggplot2::geom_point(
+        ggplot2::aes(fill = class, stroke = NA), # nolint
+        shape = 21,
+        size = 1.2,
+        alpha = 0.9
+    ) +
+    ggplot2::scale_fill_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    # add points (real label) and circles (predicted label)
+    ggplot2::geom_point(
+        ggplot2::aes(color = predicted),
+        shape = 21,
+        size = 3.5,
+        stroke = 0.5,
+        alpha = 0.9,
+        show.legend = FALSE
+    ) +
+    ggplot2::scale_color_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    titheme() +
+    ggplot2::labs(
+        title = "MDS plot of random forest proximity matrix",
+        x = "MDS1", y = "MDS2"
+    ) +
+    ggplot2::guides(
+        color = ggplot2::guide_legend(
+            title = "Predicted",
+            label.position = "left",
+            label.hjust = 1,
+            order = 1,
+            override.aes = list(
+                color = c("#5d8566", "#c29007"),
+                fill = c(NA, NA),
+                shape = 21,
+                size = 3.5,
+                stroke = 0.5
+            )
+        ), 
+        fill = ggplot2::guide_legend(
+            title = "Actual",
+            label.position = "left",
+            label.hjust = 1,
+            order = 2,
+            override.aes = list(
+                color = c("#5d8566", "#c29007"),
+                fill = c("#5d8566", "#c29007"),
+                shape = 21,
+                size = 1.2,
+                alpha = 0.9
+            )
+        )
+    ) +
+    base_breaks_x(range(-0.2, 0.6), expand = ggplot2::expansion(mult = .05)) +
+    base_breaks_y(range(-0.2, 0.6), expand = ggplot2::expansion(mult = .05)) +
+    ggplot2::theme(
+        aspect.ratio = 1.5,
+        legend.position = "inside",
+        legend.position.inside = c(0.95, 0.95),
+        legend.justification = c("right", "top"),
+        legend.title = ggplot2::element_text(hjust = 1)
+    )
+
+
+
+rf_combi_plot <- oob_dist_plot + ggplot2::theme(plot.margin = ggplot2::margin(r = 20)) + mds_plot
+
+
+# save the plot
+ggplot2::ggsave(file.path(config$path$figures, "mds_combi_plot.jpg"),
+    plot = rf_combi_plot,
+    width = 13,
+    height = 6
+)

# time: 2024-09-19 14:55:29 UTC
# mode: r
+# save the plot
+ggplot2::ggsave(
+    file.path(config$path$figures, "mds_combi_plot.jpg"),
+    plot = rf_combi_plot,
+    width = 9,
+    height = 6,
+    bg = "white"
+)

# time: 2024-09-19 14:56:25 UTC
# mode: r
+# plot the distribution of percent correct by class
+
+oob_dist_plot <- ggplot2::ggplot() +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(y = error, fill = class),
+        position = "identity", alpha = 0.65,
+        density = ggdist::density_bounded(bandwidth = 1, trim = FALSE)
+    ) +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(y = error, fill = "randomised"),
+        position = "identity", alpha = 0.65,
+        density = ggdist::density_bounded(bandwidth = 1, trim = FALSE),
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(y = error, color = class),
+        position = ggplot2::position_dodge(
+            width = .3, preserve = "single"
+        )
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(y = error, color = "randomised"),
+        position = ggplot2::position_dodge(
+            width = .3, preserve = "single"
+        )
+    ) +
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "black") +
+    ggplot2::labs(
+        title = "Distribution of percent correct by class",
+        y = "Percent correct", x = "Density"
+    ) +
+    ggplot2::scale_fill_manual(
+        values = c(
+            "immigrant" = "#5d8566", "resident" = "#c29007", "randomised" = "#716e6e"
+        ), labels = c("immigrant", "resident", "random\nperformance")
+    ) +
+    ggplot2::scale_color_manual(
+        values = c(
+            "immigrant" = "#5d8566", "resident" = "#c29007", "randomised" = "grey"
+        )
+    ) +
+    base_breaks_y(40:100, expand = ggplot2::expansion(mult = .05)) +
+    base_breaks_x(0:1, expand = ggplot2::expansion(add = c(-0.1, 0))) +
+    titheme() +
+    ggplot2::theme(
+        aspect.ratio = 2.3,
+        legend.position = "inside",
+        legend.position.inside = c(0.95, 0.95),
+        legend.justification = c("right", "top"),
+        legend.title = ggplot2::element_text(hjust = 1)
+    ) +
+    ggplot2::guides(
+        fill = ggplot2::guide_legend(
+            title = "Class",
+            label.position = "left",
+            label.hjust = 1
+        ),
+        color = "none"
+    )

# time: 2024-09-19 14:56:26 UTC
# mode: r
+mds_plot <-
+    ggplot2::ggplot(mds_df, ggplot2::aes(x = X1, y = X2, color = predicted)) +
+    ggplot2::geom_point(
+        ggplot2::aes(fill = class, stroke = NA), # nolint
+        shape = 21,
+        size = 1.2,
+        alpha = 0.9
+    ) +
+    ggplot2::scale_fill_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    # add points (real label) and circles (predicted label)
+    ggplot2::geom_point(
+        ggplot2::aes(color = predicted),
+        shape = 21,
+        size = 3.5,
+        stroke = 0.5,
+        alpha = 0.9,
+        show.legend = FALSE
+    ) +
+    ggplot2::scale_color_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    titheme() +
+    ggplot2::labs(
+        title = "MDS plot of random forest proximity matrix",
+        x = "MDS1", y = "MDS2"
+    ) +
+    ggplot2::guides(
+        color = ggplot2::guide_legend(
+            title = "Predicted",
+            label.position = "left",
+            label.hjust = 1,
+            order = 1,
+            override.aes = list(
+                color = c("#5d8566", "#c29007"),
+                fill = c(NA, NA),
+                shape = 21,
+                size = 3.5,
+                stroke = 0.5
+            )
+        ), 
+        fill = ggplot2::guide_legend(
+            title = "Actual",
+            label.position = "left",
+            label.hjust = 1,
+            order = 2,
+            override.aes = list(
+                color = c("#5d8566", "#c29007"),
+                fill = c("#5d8566", "#c29007"),
+                shape = 21,
+                size = 1.2,
+                alpha = 0.9
+            )
+        )
+    ) +
+    base_breaks_x(range(-0.2, 0.6), expand = ggplot2::expansion(mult = .05)) +
+    base_breaks_y(range(-0.2, 0.6), expand = ggplot2::expansion(mult = .05)) +
+    ggplot2::theme(
+        aspect.ratio = 1.5,
+        legend.position = "inside",
+        legend.position.inside = c(0.95, 0.95),
+        legend.justification = c("right", "top"),
+        legend.title = ggplot2::element_text(hjust = 1)
+    )

# time: 2024-09-19 14:56:26 UTC
# mode: r
+rf_combi_plot <- oob_dist_plot + ggplot2::theme(plot.margin = ggplot2::margin(r = 20)) + mds_plot

# time: 2024-09-19 14:56:27 UTC
# mode: r
+# save the plot
+ggplot2::ggsave(
+    file.path(config$path$figures, "mds_combi_plot.jpg"),
+    plot = rf_combi_plot,
+    width = 9,
+    height = 6,
+    bg = "white"
+)

# time: 2024-09-19 14:57:10 UTC
# mode: r
+# save the plot
+ggplot2::ggsave(
+    file.path(config$path$figures, "mds_combi_plot.jpg"),
+    plot = rf_combi_plot,
+    width = 9,
+    height = 6,
+    units = "cm",
+    bg = "white"
+)

# time: 2024-09-19 14:57:20 UTC
# mode: r
+# save the plot
+ggplot2::ggsave(
+    file.path(config$path$figures, "mds_combi_plot.jpg"),
+    plot = rf_combi_plot,
+    width = 15,
+    height = 11,
+    units = "cm",
+    bg = "white"
+)

# time: 2024-09-19 14:58:34 UTC
# mode: r
+# plot the distribution of percent correct by class
+
+oob_dist_plot <- ggplot2::ggplot() +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(y = error, fill = class),
+        position = "identity", alpha = 0.65,
+        density = ggdist::density_bounded(bandwidth = 1, trim = FALSE)
+    ) +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(y = error, fill = "randomised"),
+        position = "identity", alpha = 0.65,
+        density = ggdist::density_bounded(bandwidth = 1, trim = FALSE),
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(y = error, color = class),
+        position = ggplot2::position_dodge(
+            width = .3, preserve = "single"
+        )
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(y = error, color = "randomised"),
+        position = ggplot2::position_dodge(
+            width = .3, preserve = "single"
+        )
+    ) +
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "black") +
+    ggplot2::labs(
+        title = "Distribution of percent correct by class",
+        y = "Percent correct", x = "Density"
+    ) +
+    ggplot2::scale_fill_manual(
+        values = c(
+            "immigrant" = "#5d8566", "resident" = "#c29007", "randomised" = "#716e6e"
+        ), labels = c("immigrant", "resident", "random\nperformance")
+    ) +
+    ggplot2::scale_color_manual(
+        values = c(
+            "immigrant" = "#5d8566", "resident" = "#c29007", "randomised" = "grey"
+        )
+    ) +
+    base_breaks_y(40:100, expand = ggplot2::expansion(mult = .05)) +
+    base_breaks_x(0:1, expand = ggplot2::expansion(add = c(-0.1, 0))) +
+    titheme() +
+    ggplot2::theme(
+        aspect.ratio = 2.3,
+        legend.position = "inside",
+        legend.position.inside = c(0.98, 0.95),
+        legend.justification = c("right", "top"),
+        legend.title = ggplot2::element_text(hjust = 1)
+    ) +
+    ggplot2::guides(
+        fill = ggplot2::guide_legend(
+            title = "Class",
+            label.position = "left",
+            label.hjust = 1
+        ),
+        color = "none"
+    )

# time: 2024-09-19 14:58:34 UTC
# mode: r
+mds_plot <-
+    ggplot2::ggplot(mds_df, ggplot2::aes(x = X1, y = X2, color = predicted)) +
+    ggplot2::geom_point(
+        ggplot2::aes(fill = class, stroke = NA), # nolint
+        shape = 21,
+        size = 1.2,
+        alpha = 0.9
+    ) +
+    ggplot2::scale_fill_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    # add points (real label) and circles (predicted label)
+    ggplot2::geom_point(
+        ggplot2::aes(color = predicted),
+        shape = 21,
+        size = 3.5,
+        stroke = 0.5,
+        alpha = 0.9,
+        show.legend = FALSE
+    ) +
+    ggplot2::scale_color_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    titheme() +
+    ggplot2::labs(
+        title = "MDS plot of random forest proximity matrix",
+        x = "MDS1", y = "MDS2"
+    ) +
+    ggplot2::guides(
+        color = ggplot2::guide_legend(
+            title = "Predicted",
+            label.position = "left",
+            label.hjust = 1,
+            order = 1,
+            override.aes = list(
+                color = c("#5d8566", "#c29007"),
+                fill = c(NA, NA),
+                shape = 21,
+                size = 3.5,
+                stroke = 0.5
+            )
+        ), 
+        fill = ggplot2::guide_legend(
+            title = "Actual",
+            label.position = "left",
+            label.hjust = 1,
+            order = 2,
+            override.aes = list(
+                color = c("#5d8566", "#c29007"),
+                fill = c("#5d8566", "#c29007"),
+                shape = 21,
+                size = 1.2,
+                alpha = 0.9
+            )
+        )
+    ) +
+    base_breaks_x(range(-0.2, 0.6), expand = ggplot2::expansion(mult = .05)) +
+    base_breaks_y(range(-0.2, 0.6), expand = ggplot2::expansion(mult = .05)) +
+    ggplot2::theme(
+        aspect.ratio = 1.5,
+        legend.position = "inside",
+        legend.position.inside = c(0.95, 0.95),
+        legend.justification = c("right", "top"),
+        legend.title = ggplot2::element_text(hjust = 1)
+    )

# time: 2024-09-19 14:58:35 UTC
# mode: r
+rf_combi_plot <- oob_dist_plot + ggplot2::theme(plot.margin = ggplot2::margin(r = 20)) + mds_plot

# time: 2024-09-19 14:58:35 UTC
# mode: r
+# save the plot
+ggplot2::ggsave(
+    file.path(config$path$figures, "mds_combi_plot.jpg"),
+    plot = rf_combi_plot,
+    width = 15,
+    height = 11,
+    units = "cm",
+    bg = "white"
+)

# time: 2024-09-19 14:59:32 UTC
# mode: r
+# plot the distribution of percent correct by class
+
+oob_dist_plot <- ggplot2::ggplot() +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(y = error, fill = class),
+        position = "identity", alpha = 0.65,
+        density = ggdist::density_bounded(bandwidth = 1, trim = FALSE)
+    ) +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(y = error, fill = "randomised"),
+        position = "identity", alpha = 0.65,
+        density = ggdist::density_bounded(bandwidth = 1, trim = FALSE),
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(y = error, color = class),
+        position = ggplot2::position_dodge(
+            width = .4, preserve = "single"
+        )
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(y = error, color = "randomised"),
+        position = ggplot2::position_dodge(
+            width = .4, preserve = "single"
+        )
+    ) +
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "black") +
+    ggplot2::labs(
+        title = "Distribution of percent correct by class",
+        y = "Percent correct", x = "Density"
+    ) +
+    ggplot2::scale_fill_manual(
+        values = c(
+            "immigrant" = "#5d8566", "resident" = "#c29007", "randomised" = "#716e6e"
+        ), labels = c("immigrant", "resident", "random\nperformance")
+    ) +
+    ggplot2::scale_color_manual(
+        values = c(
+            "immigrant" = "#5d8566", "resident" = "#c29007", "randomised" = "grey"
+        )
+    ) +
+    base_breaks_y(40:100, expand = ggplot2::expansion(mult = .05)) +
+    base_breaks_x(0:1, expand = ggplot2::expansion(add = c(-0.1, 0))) +
+    titheme() +
+    ggplot2::theme(
+        aspect.ratio = 2.3,
+        legend.position = "inside",
+        legend.position.inside = c(0.98, 0.95),
+        legend.justification = c("right", "top"),
+        legend.title = ggplot2::element_text(hjust = 1)
+    ) +
+    ggplot2::guides(
+        fill = ggplot2::guide_legend(
+            title = "Class",
+            label.position = "left",
+            label.hjust = 1
+        ),
+        color = "none"
+    )

# time: 2024-09-19 14:59:33 UTC
# mode: r
+mds_plot <-
+    ggplot2::ggplot(mds_df, ggplot2::aes(x = X1, y = X2, color = predicted)) +
+    ggplot2::geom_point(
+        ggplot2::aes(fill = class, stroke = NA), # nolint
+        shape = 21,
+        size = 1.2,
+        alpha = 0.9
+    ) +
+    ggplot2::scale_fill_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    # add points (real label) and circles (predicted label)
+    ggplot2::geom_point(
+        ggplot2::aes(color = predicted),
+        shape = 21,
+        size = 3.5,
+        stroke = 0.5,
+        alpha = 0.9,
+        show.legend = FALSE
+    ) +
+    ggplot2::scale_color_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    titheme() +
+    ggplot2::labs(
+        title = "MDS plot of random forest proximity matrix",
+        x = "MDS1", y = "MDS2"
+    ) +
+    ggplot2::guides(
+        color = ggplot2::guide_legend(
+            title = "Predicted",
+            label.position = "left",
+            label.hjust = 1,
+            order = 1,
+            override.aes = list(
+                color = c("#5d8566", "#c29007"),
+                fill = c(NA, NA),
+                shape = 21,
+                size = 3.5,
+                stroke = 0.5
+            )
+        ), 
+        fill = ggplot2::guide_legend(
+            title = "Actual",
+            label.position = "left",
+            label.hjust = 1,
+            order = 2,
+            override.aes = list(
+                color = c("#5d8566", "#c29007"),
+                fill = c("#5d8566", "#c29007"),
+                shape = 21,
+                size = 1.2,
+                alpha = 0.9
+            )
+        )
+    ) +
+    base_breaks_x(range(-0.2, 0.6), expand = ggplot2::expansion(mult = .05)) +
+    base_breaks_y(range(-0.2, 0.6), expand = ggplot2::expansion(mult = .05)) +
+    ggplot2::theme(
+        aspect.ratio = 1.5,
+        legend.position = "inside",
+        legend.position.inside = c(0.95, 0.95),
+        legend.justification = c("right", "top"),
+        legend.title = ggplot2::element_text(hjust = 1)
+    )

# time: 2024-09-19 14:59:33 UTC
# mode: r
+rf_combi_plot <- oob_dist_plot + ggplot2::theme(plot.margin = ggplot2::margin(r = 20)) + mds_plot

# time: 2024-09-19 14:59:34 UTC
# mode: r
+# save the plot
+ggplot2::ggsave(
+    file.path(config$path$figures, "mds_combi_plot.jpg"),
+    plot = rf_combi_plot,
+    width = 15,
+    height = 11,
+    units = "cm",
+    bg = "white"
+)

# time: 2024-09-19 15:00:09 UTC
# mode: r
+# plot the distribution of percent correct by class
+
+oob_dist_plot <- ggplot2::ggplot() +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(y = error, fill = class),
+        position = "identity", alpha = 0.65,
+        density = ggdist::density_bounded(bandwidth = 1, trim = FALSE)
+    ) +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(y = error, fill = "randomised"),
+        position = "identity", alpha = 0.65,
+        density = ggdist::density_bounded(bandwidth = 1, trim = FALSE),
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(y = error, color = class),
+        position = ggplot2::position_dodge(
+            width = .5, preserve = "single"
+        )
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(y = error, color = "randomised"),
+        position = ggplot2::position_dodge(
+            width = .5, preserve = "single"
+        )
+    ) +
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "black") +
+    ggplot2::labs(
+        title = "Distribution of percent correct by class",
+        y = "Percent correct", x = "Density"
+    ) +
+    ggplot2::scale_fill_manual(
+        values = c(
+            "immigrant" = "#5d8566", "resident" = "#c29007", "randomised" = "#716e6e"
+        ), labels = c("immigrant", "resident", "random\nperformance")
+    ) +
+    ggplot2::scale_color_manual(
+        values = c(
+            "immigrant" = "#5d8566", "resident" = "#c29007", "randomised" = "grey"
+        )
+    ) +
+    base_breaks_y(40:100, expand = ggplot2::expansion(mult = .05)) +
+    base_breaks_x(0:1, expand = ggplot2::expansion(add = c(-0.1, 0))) +
+    titheme() +
+    ggplot2::theme(
+        aspect.ratio = 2.3,
+        legend.position = "inside",
+        legend.position.inside = c(0.98, 0.95),
+        legend.justification = c("right", "top"),
+        legend.title = ggplot2::element_text(hjust = 1)
+    ) +
+    ggplot2::guides(
+        fill = ggplot2::guide_legend(
+            title = "Class",
+            label.position = "left",
+            label.hjust = 1
+        ),
+        color = "none"
+    )

# time: 2024-09-19 15:00:09 UTC
# mode: r
+mds_plot <-
+    ggplot2::ggplot(mds_df, ggplot2::aes(x = X1, y = X2, color = predicted)) +
+    ggplot2::geom_point(
+        ggplot2::aes(fill = class, stroke = NA), # nolint
+        shape = 21,
+        size = 1.2,
+        alpha = 0.9
+    ) +
+    ggplot2::scale_fill_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    # add points (real label) and circles (predicted label)
+    ggplot2::geom_point(
+        ggplot2::aes(color = predicted),
+        shape = 21,
+        size = 3.5,
+        stroke = 0.5,
+        alpha = 0.9,
+        show.legend = FALSE
+    ) +
+    ggplot2::scale_color_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    titheme() +
+    ggplot2::labs(
+        title = "MDS plot of random forest proximity matrix",
+        x = "MDS1", y = "MDS2"
+    ) +
+    ggplot2::guides(
+        color = ggplot2::guide_legend(
+            title = "Predicted",
+            label.position = "left",
+            label.hjust = 1,
+            order = 1,
+            override.aes = list(
+                color = c("#5d8566", "#c29007"),
+                fill = c(NA, NA),
+                shape = 21,
+                size = 3.5,
+                stroke = 0.5
+            )
+        ), 
+        fill = ggplot2::guide_legend(
+            title = "Actual",
+            label.position = "left",
+            label.hjust = 1,
+            order = 2,
+            override.aes = list(
+                color = c("#5d8566", "#c29007"),
+                fill = c("#5d8566", "#c29007"),
+                shape = 21,
+                size = 1.2,
+                alpha = 0.9
+            )
+        )
+    ) +
+    base_breaks_x(range(-0.2, 0.6), expand = ggplot2::expansion(mult = .05)) +
+    base_breaks_y(range(-0.2, 0.6), expand = ggplot2::expansion(mult = .05)) +
+    ggplot2::theme(
+        aspect.ratio = 1.5,
+        legend.position = "inside",
+        legend.position.inside = c(0.95, 0.95),
+        legend.justification = c("right", "top"),
+        legend.title = ggplot2::element_text(hjust = 1)
+    )

# time: 2024-09-19 15:00:10 UTC
# mode: r
+rf_combi_plot <- oob_dist_plot + ggplot2::theme(plot.margin = ggplot2::margin(r = 20)) + mds_plot

# time: 2024-09-19 15:00:10 UTC
# mode: r
+# save the plot
+ggplot2::ggsave(
+    file.path(config$path$figures, "mds_combi_plot.jpg"),
+    plot = rf_combi_plot,
+    width = 15,
+    height = 11,
+    units = "cm",
+    bg = "white"
+)

# time: 2024-09-19 15:00:38 UTC
# mode: r
+rf_combi_plot <- oob_dist_plot + 
+    ggplot2::theme(plot.margin = ggplot2::margin(r = 20)) + 
+    mds_plot + 
+    patchwork::plot_annotation(tag_levels = 'A') & 
+    ggplot2::theme(plot.title = ggplot2::element_blank())

# time: 2024-09-19 15:00:40 UTC
# mode: r
+# save the plot
+ggplot2::ggsave(
+    file.path(config$path$figures, "mds_combi_plot.jpg"),
+    plot = rf_combi_plot,
+    width = 15,
+    height = 11,
+    units = "cm",
+    bg = "white"
+)

# time: 2024-09-19 15:02:41 UTC
# mode: r
+rf_combi_plot <- oob_dist_plot +
+    ggplot2::theme(plot.margin = ggplot2::margin(r = 20)) +
+    mds_plot +
+    patchwork::plot_annotation(
+        tag_levels = "A",
+        theme = ggplot2::theme(plot.title = ggplot2::element_text(face = "bold"))
+    ) &
+    ggplot2::theme(plot.title = ggplot2::element_blank())

# time: 2024-09-19 15:02:42 UTC
# mode: r
+# save the plot
+ggplot2::ggsave(
+    file.path(config$path$figures, "mds_combi_plot.jpg"),
+    plot = rf_combi_plot,
+    width = 15,
+    height = 11,
+    units = "cm",
+    bg = "white"
+)

# time: 2024-09-19 15:03:15 UTC
# mode: r
+rf_combi_plot <- oob_dist_plot +
+    ggplot2::theme(plot.margin = ggplot2::margin(r = 20)) +
+    mds_plot +
+    patchwork::plot_annotation(
+        tag_levels = "A",
+        theme = ggplot2::theme(plot.tag = ggplot2::element_text(face = "bold"))
+    ) &
+    ggplot2::theme(plot.title = ggplot2::element_blank())

# time: 2024-09-19 15:03:15 UTC
# mode: r
+# save the plot
+ggplot2::ggsave(
+    file.path(config$path$figures, "mds_combi_plot.jpg"),
+    plot = rf_combi_plot,
+    width = 15,
+    height = 11,
+    units = "cm",
+    bg = "white"
+)

# time: 2024-09-19 15:04:02 UTC
# mode: r
+rf_combi_plot <- oob_dist_plot +
+    ggplot2::theme(plot.margin = ggplot2::margin(r = 20)) +
+    mds_plot +
+    patchwork::plot_annotation(
+        tag_levels = "A",
+        theme = ggplot2::theme(plot.tag = ggplot2::element_text(face = "italic"))
+    ) &
+    ggplot2::theme(plot.title = ggplot2::element_blank())

# time: 2024-09-19 15:04:02 UTC
# mode: r
+# save the plot
+ggplot2::ggsave(
+    file.path(config$path$figures, "mds_combi_plot.jpg"),
+    plot = rf_combi_plot,
+    width = 15,
+    height = 11,
+    units = "cm",
+    bg = "white"
+)

# time: 2024-09-19 15:04:37 UTC
# mode: r
+rf_combi_plot <- oob_dist_plot +
+    ggplot2::theme(plot.margin = ggplot2::margin(r = 20)) +
+    mds_plot +
+    patchwork::plot_annotation(
+        tag_levels = "A"
+    ) &
+    ggplot2::theme(
+        plot.title = ggplot2::element_blank(),
+        plot.tag = ggplot2::element_text(face = "italic")
+    )

# time: 2024-09-19 15:04:38 UTC
# mode: r
+# save the plot
+ggplot2::ggsave(
+    file.path(config$path$figures, "mds_combi_plot.jpg"),
+    plot = rf_combi_plot,
+    width = 15,
+    height = 11,
+    units = "cm",
+    bg = "white"
+)

# time: 2024-09-19 15:04:45 UTC
# mode: r
+rf_combi_plot <- oob_dist_plot +
+    ggplot2::theme(plot.margin = ggplot2::margin(r = 20)) +
+    mds_plot +
+    patchwork::plot_annotation(
+        tag_levels = "A"
+    ) &
+    ggplot2::theme(
+        plot.title = ggplot2::element_blank(),
+        plot.tag = ggplot2::element_text(face = "bold")
+    )

# time: 2024-09-19 15:04:46 UTC
# mode: r
+# save the plot
+ggplot2::ggsave(
+    file.path(config$path$figures, "mds_combi_plot.jpg"),
+    plot = rf_combi_plot,
+    width = 15,
+    height = 11,
+    units = "cm",
+    bg = "white"
+)

# time: 2024-09-19 15:05:06 UTC
# mode: r
+rf_combi_plot <- oob_dist_plot +
+    ggplot2::theme(plot.margin = ggplot2::margin(r = 20)) +
+    mds_plot +
+    patchwork::plot_annotation(
+        tag_levels = "A"
+    ) &
+    ggplot2::theme(
+        plot.title = ggplot2::element_blank(),
+        plot.tag = ggplot2::element_text(family = "Roboto Condensed", face = "bold")
+    )

# time: 2024-09-19 15:05:07 UTC
# mode: r
+# save the plot
+ggplot2::ggsave(
+    file.path(config$path$figures, "mds_combi_plot.jpg"),
+    plot = rf_combi_plot,
+    width = 15,
+    height = 11,
+    units = "cm",
+    bg = "white"
+)

# time: 2024-09-19 15:05:14 UTC
# mode: r
+rf_combi_plot <- oob_dist_plot +
+    ggplot2::theme(plot.margin = ggplot2::margin(r = 20)) +
+    mds_plot +
+    patchwork::plot_annotation(
+        tag_levels = "A"
+    ) &
+    ggplot2::theme(
+        plot.title = ggplot2::element_blank(),
+        plot.tag = ggplot2::element_text(family = "Helvetica", face = "bold")
+    )

# time: 2024-09-19 15:05:15 UTC
# mode: r
+# save the plot
+ggplot2::ggsave(
+    file.path(config$path$figures, "mds_combi_plot.jpg"),
+    plot = rf_combi_plot,
+    width = 15,
+    height = 11,
+    units = "cm",
+    bg = "white"
+)

# time: 2024-09-19 15:05:36 UTC
# mode: r
+rf_combi_plot <- oob_dist_plot +
+    ggplot2::theme(plot.margin = ggplot2::margin(r = 20)) +
+    mds_plot +
+    patchwork::plot_annotation(
+        tag_levels = "A"
+    ) &
+    ggplot2::theme(
+        plot.title = ggplot2::element_blank(),
+        plot.tag = ggplot2::element_text(face = "plain")
+    )

# time: 2024-09-19 15:05:36 UTC
# mode: r
+# save the plot
+ggplot2::ggsave(
+    file.path(config$path$figures, "mds_combi_plot.jpg"),
+    plot = rf_combi_plot,
+    width = 15,
+    height = 11,
+    units = "cm",
+    bg = "white"
+)

# time: 2024-09-19 15:06:55 UTC
# mode: r
+# plot the distribution of percent correct by class
+
+oob_dist_plot <- ggplot2::ggplot() +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(y = error, fill = class),
+        position = "identity", alpha = 0.65,
+        density = ggdist::density_bounded(bandwidth = 1, trim = FALSE)
+    ) +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(y = error, fill = "randomised"),
+        position = "identity", alpha = 0.65,
+        density = ggdist::density_bounded(bandwidth = 1, trim = FALSE),
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(y = error, color = class),
+        position = ggplot2::position_dodge(
+            width = .5, preserve = "single"
+        )
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(y = error, color = "randomised"),
+        position = ggplot2::position_dodge(
+            width = .5, preserve = "single"
+        )
+    ) +
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "black") +
+    ggplot2::labs(
+        title = "Distribution of percent correct by class",
+        y = "Percent correct", x = "Density"
+    ) +
+    ggplot2::scale_fill_manual(
+        values = c(
+            "immigrant" = "#5d8566", "resident" = "#c29007", "randomised" = "#716e6e"
+        ), labels = c("immigrant", "resident", "random\nperformance")
+    ) +
+    ggplot2::scale_color_manual(
+        values = c(
+            "immigrant" = "#5d8566", "resident" = "#c29007", "randomised" = "grey"
+        )
+    ) +
+    base_breaks_y(40:100, expand = ggplot2::expansion(mult = .05)) +
+    base_breaks_x(0:1, expand = ggplot2::expansion(add = c(-0.1, 0))) +
+    titheme() +
+    ggplot2::theme(
+        aspect.ratio = 2.3,
+        legend.position = "inside",
+        legend.position.inside = c(0.98, 0.95),
+        legend.justification = c("left", "top"),
+        legend.title = ggplot2::element_text(hjust = 0)
+    ) +
+    ggplot2::guides(
+        fill = ggplot2::guide_legend(
+            title = "Class",
+            label.position = "right",
+            label.hjust = 0
+        ),
+        color = "none"
+    )

# time: 2024-09-19 15:06:56 UTC
# mode: r
+mds_plot <-
+    ggplot2::ggplot(mds_df, ggplot2::aes(x = X1, y = X2, color = predicted)) +
+    ggplot2::geom_point(
+        ggplot2::aes(fill = class, stroke = NA), # nolint
+        shape = 21,
+        size = 1.2,
+        alpha = 0.9
+    ) +
+    ggplot2::scale_fill_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    # add points (real label) and circles (predicted label)
+    ggplot2::geom_point(
+        ggplot2::aes(color = predicted),
+        shape = 21,
+        size = 3.5,
+        stroke = 0.5,
+        alpha = 0.9,
+        show.legend = FALSE
+    ) +
+    ggplot2::scale_color_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    titheme() +
+    ggplot2::labs(
+        title = "MDS plot of random forest proximity matrix",
+        x = "MDS1", y = "MDS2"
+    ) +
+    ggplot2::guides(
+        color = ggplot2::guide_legend(
+            title = "Predicted",
+            label.position = "left",
+            label.hjust = 1,
+            order = 1,
+            override.aes = list(
+                color = c("#5d8566", "#c29007"),
+                fill = c(NA, NA),
+                shape = 21,
+                size = 3.5,
+                stroke = 0.5
+            )
+        ),
+        fill = ggplot2::guide_legend(
+            title = "Actual",
+            label.position = "left",
+            label.hjust = 1,
+            order = 2,
+            override.aes = list(
+                color = c("#5d8566", "#c29007"),
+                fill = c("#5d8566", "#c29007"),
+                shape = 21,
+                size = 1.2,
+                alpha = 0.9
+            )
+        )
+    ) +
+    base_breaks_x(range(-0.2, 0.6), expand = ggplot2::expansion(mult = .05)) +
+    base_breaks_y(range(-0.2, 0.6), expand = ggplot2::expansion(mult = .05)) +
+    ggplot2::theme(
+        aspect.ratio = 1.5,
+        legend.position = "inside",
+        legend.position.inside = c(0.95, 0.95),
+        legend.justification = c("right", "top"),
+        legend.title = ggplot2::element_text(hjust = 1)
+    )

# time: 2024-09-19 15:06:56 UTC
# mode: r
+rf_combi_plot <- oob_dist_plot +
+    ggplot2::theme(plot.margin = ggplot2::margin(r = 20)) +
+    mds_plot +
+    patchwork::plot_annotation(
+        tag_levels = "A"
+    ) &
+    ggplot2::theme(
+        plot.title = ggplot2::element_blank(),
+        plot.tag = ggplot2::element_text(face = "plain")
+    )

# time: 2024-09-19 15:06:57 UTC
# mode: r
+# save the plot
+ggplot2::ggsave(
+    file.path(config$path$figures, "mds_combi_plot.jpg"),
+    plot = rf_combi_plot,
+    width = 15,
+    height = 11,
+    units = "cm",
+    bg = "white"
+)

# time: 2024-09-19 15:07:26 UTC
# mode: r
+# plot the distribution of percent correct by class
+
+oob_dist_plot <- ggplot2::ggplot() +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(y = error, fill = class),
+        position = "identity", alpha = 0.65,
+        density = ggdist::density_bounded(bandwidth = 1, trim = FALSE)
+    ) +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(y = error, fill = "randomised"),
+        position = "identity", alpha = 0.65,
+        density = ggdist::density_bounded(bandwidth = 1, trim = FALSE),
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(y = error, color = class),
+        position = ggplot2::position_dodge(
+            width = .5, preserve = "single"
+        )
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(y = error, color = "randomised"),
+        position = ggplot2::position_dodge(
+            width = .5, preserve = "single"
+        )
+    ) +
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "black") +
+    ggplot2::labs(
+        title = "Distribution of percent correct by class",
+        y = "Percent correct", x = "Density"
+    ) +
+    ggplot2::scale_fill_manual(
+        values = c(
+            "immigrant" = "#5d8566", "resident" = "#c29007", "randomised" = "#716e6e"
+        ), labels = c("immigrant", "resident", "random\nperformance")
+    ) +
+    ggplot2::scale_color_manual(
+        values = c(
+            "immigrant" = "#5d8566", "resident" = "#c29007", "randomised" = "grey"
+        )
+    ) +
+    base_breaks_y(40:100, expand = ggplot2::expansion(mult = .05)) +
+    base_breaks_x(0:1, expand = ggplot2::expansion(add = c(-0.1, 0))) +
+    titheme() +
+    ggplot2::theme(
+        aspect.ratio = 2.3,
+        legend.position = "inside",
+        legend.position.inside = c(0, 0.95),
+        legend.justification = c("left", "top"),
+        legend.title = ggplot2::element_text(hjust = 0)
+    ) +
+    ggplot2::guides(
+        fill = ggplot2::guide_legend(
+            title = "Class",
+            label.position = "right",
+            label.hjust = 0
+        ),
+        color = "none"
+    )

# time: 2024-09-19 15:07:26 UTC
# mode: r
+mds_plot <-
+    ggplot2::ggplot(mds_df, ggplot2::aes(x = X1, y = X2, color = predicted)) +
+    ggplot2::geom_point(
+        ggplot2::aes(fill = class, stroke = NA), # nolint
+        shape = 21,
+        size = 1.2,
+        alpha = 0.9
+    ) +
+    ggplot2::scale_fill_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    # add points (real label) and circles (predicted label)
+    ggplot2::geom_point(
+        ggplot2::aes(color = predicted),
+        shape = 21,
+        size = 3.5,
+        stroke = 0.5,
+        alpha = 0.9,
+        show.legend = FALSE
+    ) +
+    ggplot2::scale_color_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    titheme() +
+    ggplot2::labs(
+        title = "MDS plot of random forest proximity matrix",
+        x = "MDS1", y = "MDS2"
+    ) +
+    ggplot2::guides(
+        color = ggplot2::guide_legend(
+            title = "Predicted",
+            label.position = "left",
+            label.hjust = 1,
+            order = 1,
+            override.aes = list(
+                color = c("#5d8566", "#c29007"),
+                fill = c(NA, NA),
+                shape = 21,
+                size = 3.5,
+                stroke = 0.5
+            )
+        ),
+        fill = ggplot2::guide_legend(
+            title = "Actual",
+            label.position = "left",
+            label.hjust = 1,
+            order = 2,
+            override.aes = list(
+                color = c("#5d8566", "#c29007"),
+                fill = c("#5d8566", "#c29007"),
+                shape = 21,
+                size = 1.2,
+                alpha = 0.9
+            )
+        )
+    ) +
+    base_breaks_x(range(-0.2, 0.6), expand = ggplot2::expansion(mult = .05)) +
+    base_breaks_y(range(-0.2, 0.6), expand = ggplot2::expansion(mult = .05)) +
+    ggplot2::theme(
+        aspect.ratio = 1.5,
+        legend.position = "inside",
+        legend.position.inside = c(0.95, 0.95),
+        legend.justification = c("right", "top"),
+        legend.title = ggplot2::element_text(hjust = 1)
+    )

# time: 2024-09-19 15:07:27 UTC
# mode: r
+rf_combi_plot <- oob_dist_plot +
+    ggplot2::theme(plot.margin = ggplot2::margin(r = 20)) +
+    mds_plot +
+    patchwork::plot_annotation(
+        tag_levels = "A"
+    ) &
+    ggplot2::theme(
+        plot.title = ggplot2::element_blank(),
+        plot.tag = ggplot2::element_text(face = "plain")
+    )

# time: 2024-09-19 15:07:27 UTC
# mode: r
+# save the plot
+ggplot2::ggsave(
+    file.path(config$path$figures, "mds_combi_plot.jpg"),
+    plot = rf_combi_plot,
+    width = 15,
+    height = 11,
+    units = "cm",
+    bg = "white"
+)

# time: 2024-09-19 15:07:42 UTC
# mode: r
+# plot the distribution of percent correct by class
+
+oob_dist_plot <- ggplot2::ggplot() +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(y = error, fill = class),
+        position = "identity", alpha = 0.65,
+        density = ggdist::density_bounded(bandwidth = 1, trim = FALSE)
+    ) +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(y = error, fill = "randomised"),
+        position = "identity", alpha = 0.65,
+        density = ggdist::density_bounded(bandwidth = 1, trim = FALSE),
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(y = error, color = class),
+        position = ggplot2::position_dodge(
+            width = .5, preserve = "single"
+        )
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(y = error, color = "randomised"),
+        position = ggplot2::position_dodge(
+            width = .5, preserve = "single"
+        )
+    ) +
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "black") +
+    ggplot2::labs(
+        title = "Distribution of percent correct by class",
+        y = "Percent correct", x = "Density"
+    ) +
+    ggplot2::scale_fill_manual(
+        values = c(
+            "immigrant" = "#5d8566", "resident" = "#c29007", "randomised" = "#716e6e"
+        ), labels = c("immigrant", "resident", "random\nperformance")
+    ) +
+    ggplot2::scale_color_manual(
+        values = c(
+            "immigrant" = "#5d8566", "resident" = "#c29007", "randomised" = "grey"
+        )
+    ) +
+    base_breaks_y(40:100, expand = ggplot2::expansion(mult = .05)) +
+    base_breaks_x(0:1, expand = ggplot2::expansion(add = c(-0.1, 0))) +
+    titheme() +
+    ggplot2::theme(
+        aspect.ratio = 2.3,
+        legend.position = "inside",
+        legend.position.inside = c(0.2, 0.95),
+        legend.justification = c("left", "top"),
+        legend.title = ggplot2::element_text(hjust = 0)
+    ) +
+    ggplot2::guides(
+        fill = ggplot2::guide_legend(
+            title = "Class",
+            label.position = "right",
+            label.hjust = 0
+        ),
+        color = "none"
+    )

# time: 2024-09-19 15:07:42 UTC
# mode: r
+mds_plot <-
+    ggplot2::ggplot(mds_df, ggplot2::aes(x = X1, y = X2, color = predicted)) +
+    ggplot2::geom_point(
+        ggplot2::aes(fill = class, stroke = NA), # nolint
+        shape = 21,
+        size = 1.2,
+        alpha = 0.9
+    ) +
+    ggplot2::scale_fill_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    # add points (real label) and circles (predicted label)
+    ggplot2::geom_point(
+        ggplot2::aes(color = predicted),
+        shape = 21,
+        size = 3.5,
+        stroke = 0.5,
+        alpha = 0.9,
+        show.legend = FALSE
+    ) +
+    ggplot2::scale_color_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    titheme() +
+    ggplot2::labs(
+        title = "MDS plot of random forest proximity matrix",
+        x = "MDS1", y = "MDS2"
+    ) +
+    ggplot2::guides(
+        color = ggplot2::guide_legend(
+            title = "Predicted",
+            label.position = "left",
+            label.hjust = 1,
+            order = 1,
+            override.aes = list(
+                color = c("#5d8566", "#c29007"),
+                fill = c(NA, NA),
+                shape = 21,
+                size = 3.5,
+                stroke = 0.5
+            )
+        ),
+        fill = ggplot2::guide_legend(
+            title = "Actual",
+            label.position = "left",
+            label.hjust = 1,
+            order = 2,
+            override.aes = list(
+                color = c("#5d8566", "#c29007"),
+                fill = c("#5d8566", "#c29007"),
+                shape = 21,
+                size = 1.2,
+                alpha = 0.9
+            )
+        )
+    ) +
+    base_breaks_x(range(-0.2, 0.6), expand = ggplot2::expansion(mult = .05)) +
+    base_breaks_y(range(-0.2, 0.6), expand = ggplot2::expansion(mult = .05)) +
+    ggplot2::theme(
+        aspect.ratio = 1.5,
+        legend.position = "inside",
+        legend.position.inside = c(0.95, 0.95),
+        legend.justification = c("right", "top"),
+        legend.title = ggplot2::element_text(hjust = 1)
+    )

# time: 2024-09-19 15:07:42 UTC
# mode: r
+rf_combi_plot <- oob_dist_plot +
+    ggplot2::theme(plot.margin = ggplot2::margin(r = 20)) +
+    mds_plot +
+    patchwork::plot_annotation(
+        tag_levels = "A"
+    ) &
+    ggplot2::theme(
+        plot.title = ggplot2::element_blank(),
+        plot.tag = ggplot2::element_text(face = "plain")
+    )

# time: 2024-09-19 15:07:43 UTC
# mode: r
+# save the plot
+ggplot2::ggsave(
+    file.path(config$path$figures, "mds_combi_plot.jpg"),
+    plot = rf_combi_plot,
+    width = 15,
+    height = 11,
+    units = "cm",
+    bg = "white"
+)

# time: 2024-09-19 15:08:03 UTC
# mode: r
+# plot the distribution of percent correct by class
+
+oob_dist_plot <- ggplot2::ggplot() +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(y = error, fill = class),
+        position = "identity", alpha = 0.65,
+        density = ggdist::density_bounded(bandwidth = 1, trim = FALSE)
+    ) +
+    ggdist::stat_slab(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(y = error, fill = "randomised"),
+        position = "identity", alpha = 0.65,
+        density = ggdist::density_bounded(bandwidth = 1, trim = FALSE),
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "oob_df"),
+        ggplot2::aes(y = error, color = class),
+        position = ggplot2::position_dodge(
+            width = .5, preserve = "single"
+        )
+    ) +
+    ggdist::stat_pointinterval(
+        data = oob_df |> dplyr::filter(source == "random_oob_df"),
+        ggplot2::aes(y = error, color = "randomised"),
+        position = ggplot2::position_dodge(
+            width = .5, preserve = "single"
+        )
+    ) +
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "black") +
+    ggplot2::labs(
+        title = "Distribution of percent correct by class",
+        y = "Percent correct", x = "Density"
+    ) +
+    ggplot2::scale_fill_manual(
+        values = c(
+            "immigrant" = "#5d8566", "resident" = "#c29007", "randomised" = "#716e6e"
+        ), labels = c("immigrant", "resident", "random\nperformance")
+    ) +
+    ggplot2::scale_color_manual(
+        values = c(
+            "immigrant" = "#5d8566", "resident" = "#c29007", "randomised" = "grey"
+        )
+    ) +
+    base_breaks_y(40:100, expand = ggplot2::expansion(mult = .05)) +
+    base_breaks_x(0:1, expand = ggplot2::expansion(add = c(-0.1, 0))) +
+    titheme() +
+    ggplot2::theme(
+        aspect.ratio = 2.3,
+        legend.position = "inside",
+        legend.position.inside = c(0.98, 0.95),
+        legend.justification = c("right", "top"),
+        legend.title = ggplot2::element_text(hjust = 1)
+    ) +
+    ggplot2::guides(
+        fill = ggplot2::guide_legend(
+            title = "Class",
+            label.position = "left",
+            label.hjust = 1
+        ),
+        color = "none"
+    )

# time: 2024-09-19 15:08:04 UTC
# mode: r
+mds_plot <-
+    ggplot2::ggplot(mds_df, ggplot2::aes(x = X1, y = X2, color = predicted)) +
+    ggplot2::geom_point(
+        ggplot2::aes(fill = class, stroke = NA), # nolint
+        shape = 21,
+        size = 1.2,
+        alpha = 0.9
+    ) +
+    ggplot2::scale_fill_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    # add points (real label) and circles (predicted label)
+    ggplot2::geom_point(
+        ggplot2::aes(color = predicted),
+        shape = 21,
+        size = 3.5,
+        stroke = 0.5,
+        alpha = 0.9,
+        show.legend = FALSE
+    ) +
+    ggplot2::scale_color_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    titheme() +
+    ggplot2::labs(
+        title = "MDS plot of random forest proximity matrix",
+        x = "MDS1", y = "MDS2"
+    ) +
+    ggplot2::guides(
+        color = ggplot2::guide_legend(
+            title = "Predicted",
+            label.position = "left",
+            label.hjust = 1,
+            order = 1,
+            override.aes = list(
+                color = c("#5d8566", "#c29007"),
+                fill = c(NA, NA),
+                shape = 21,
+                size = 3.5,
+                stroke = 0.5
+            )
+        ),
+        fill = ggplot2::guide_legend(
+            title = "Actual",
+            label.position = "left",
+            label.hjust = 1,
+            order = 2,
+            override.aes = list(
+                color = c("#5d8566", "#c29007"),
+                fill = c("#5d8566", "#c29007"),
+                shape = 21,
+                size = 1.2,
+                alpha = 0.9
+            )
+        )
+    ) +
+    base_breaks_x(range(-0.2, 0.6), expand = ggplot2::expansion(mult = .05)) +
+    base_breaks_y(range(-0.2, 0.6), expand = ggplot2::expansion(mult = .05)) +
+    ggplot2::theme(
+        aspect.ratio = 1.5,
+        legend.position = "inside",
+        legend.position.inside = c(0.95, 0.95),
+        legend.justification = c("right", "top"),
+        legend.title = ggplot2::element_text(hjust = 1)
+    )

# time: 2024-09-19 15:08:04 UTC
# mode: r
+rf_combi_plot <- oob_dist_plot +
+    ggplot2::theme(plot.margin = ggplot2::margin(r = 20)) +
+    mds_plot +
+    patchwork::plot_annotation(
+        tag_levels = "A"
+    ) &
+    ggplot2::theme(
+        plot.title = ggplot2::element_blank(),
+        plot.tag = ggplot2::element_text(face = "plain")
+    )

# time: 2024-09-19 15:08:05 UTC
# mode: r
+# save the plot
+ggplot2::ggsave(
+    file.path(config$path$figures, "mds_combi_plot.jpg"),
+    plot = rf_combi_plot,
+    width = 15,
+    height = 11,
+    units = "cm",
+    bg = "white"
+)

# time: 2024-09-19 15:12:31 UTC
# mode: r
+mds_plot <-
+    ggplot2::ggplot(mds_df, ggplot2::aes(x = X1, y = X2, color = predicted)) +
+    ggplot2::geom_point(
+        ggplot2::aes(fill = class, stroke = NA), # nolint
+        shape = 21,
+        size = 1,
+        alpha = 0.7
+    ) +
+    ggplot2::scale_fill_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    # add points (real label) and circles (predicted label)
+    ggplot2::geom_point(
+        ggplot2::aes(color = predicted),
+        shape = 21,
+        size = 3,
+        stroke = 0.5,
+        alpha = 0.7,
+        show.legend = FALSE
+    ) +
+    ggplot2::scale_color_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007"
+    )) +
+    titheme() +
+    ggplot2::labs(
+        title = "MDS plot of random forest proximity matrix",
+        x = "MDS1", y = "MDS2"
+    ) +
+    ggplot2::guides(
+        color = ggplot2::guide_legend(
+            title = "Predicted",
+            label.position = "left",
+            label.hjust = 1,
+            order = 1,
+            override.aes = list(
+                color = c("#5d8566", "#c29007"),
+                fill = c(NA, NA),
+                shape = 21,
+                size = 3.5,
+                stroke = 0.5
+            )
+        ),
+        fill = ggplot2::guide_legend(
+            title = "Actual",
+            label.position = "left",
+            label.hjust = 1,
+            order = 2,
+            override.aes = list(
+                color = c("#5d8566", "#c29007"),
+                fill = c("#5d8566", "#c29007"),
+                shape = 21,
+                size = 1.2,
+                alpha = 0.9
+            )
+        )
+    ) +
+    base_breaks_x(range(-0.2, 0.6), expand = ggplot2::expansion(mult = .05)) +
+    base_breaks_y(range(-0.2, 0.6), expand = ggplot2::expansion(mult = .05)) +
+    ggplot2::theme(
+        aspect.ratio = 1.5,
+        legend.position = "inside",
+        legend.position.inside = c(0.95, 0.95),
+        legend.justification = c("right", "top"),
+        legend.title = ggplot2::element_text(hjust = 1)
+    )

# time: 2024-09-19 15:12:31 UTC
# mode: r
+rf_combi_plot <- oob_dist_plot +
+    ggplot2::theme(plot.margin = ggplot2::margin(r = 20)) +
+    mds_plot +
+    patchwork::plot_annotation(
+        tag_levels = "A"
+    ) &
+    ggplot2::theme(
+        plot.title = ggplot2::element_blank(),
+        plot.tag = ggplot2::element_text(face = "plain")
+    )

# time: 2024-09-19 15:12:32 UTC
# mode: r
+# save the plot
+ggplot2::ggsave(
+    file.path(config$path$figures, "mds_combi_plot.jpg"),
+    plot = rf_combi_plot,
+    width = 15,
+    height = 11,
+    units = "cm",
+    bg = "white"
+)

# time: 2024-09-19 15:16:11 UTC
# mode: r
+# Create the plot
+oobplot <- ggplot2::ggplot() +
+    ggplot2::geom_line(data = plot_data$oob_df, ggplot2::aes(
+        x = trees, y = error, color = class
+    ), alpha = 0.1) +
+    ggplot2::geom_line(data = plot_data$random_oob_df, ggplot2::aes(
+        x = trees, y = error, color = class
+    ), alpha = 0.1, linetype = "dashed") +
+    ggplot2::geom_line(data = plot_data$mean_oob_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class
+    ), linewidth = 1.5) +
+    ggplot2::geom_line(data = plot_data$mean_random_oob_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class
+    ), linewidth = 1.5, linetype = "dashed") +
+    ggplot2::labs(
+        title = "OOB error rate (Solid: Original, Dashed: Randomized)",
+        x = "Number of trees", y = "Percent correct"
+    ) +
+    ggplot2::scale_color_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007", "randomised" = "grey"
+    )) +
+    base_breaks_y(40:100, expand = ggplot2::expansion(mult = .05)) +
+    base_breaks_x(0:500, expand = ggplot2::expansion(add = c(-0.1, 0))) +
+    titheme() +
+    ggplot2::theme(
+        aspect.ratio = 2.3,
+        legend.position = "inside",
+        legend.position.inside = c(0.98, 0.95),
+        legend.justification = c("right", "top"),
+        legend.title = ggplot2::element_text(hjust = 1)
+    ) +
+    ggplot2::guides(
+        color = ggplot2::guide_legend(
+            title = "Class",
+            label.position = "left",
+            label.hjust = 1
+        )
+    )

# time: 2024-09-19 15:16:13 UTC
# mode: r
+oobplot

# time: 2024-09-19 15:16:54 UTC
# mode: r
+# Create the plot
+oobplot <- ggplot2::ggplot() +
+    ggplot2::geom_line(data = plot_data$oob_df, ggplot2::aes(
+        x = trees, y = error, color = class
+    ), alpha = 0.1) +
+    ggplot2::geom_line(data = plot_data$random_oob_df, ggplot2::aes(
+        x = trees, y = error, color = class
+    ), alpha = 0.1, linetype = "dashed") +
+    ggplot2::geom_line(data = plot_data$mean_oob_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class
+    ), linewidth = 1.5) +
+    ggplot2::geom_line(data = plot_data$mean_random_oob_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class
+    ), linewidth = 1.5, linetype = "dashed") +
+    ggplot2::labs(
+        title = "OOB error rate (Solid: Original, Dashed: Randomized)",
+        x = "Number of trees", y = "Percent correct"
+    ) +
+    ggplot2::scale_color_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007", "randomised" = "grey"
+    )) +
+    base_breaks_y(40:100, expand = ggplot2::expansion(mult = .05)) +
+    base_breaks_x(0:500, expand = ggplot2::expansion(mult = .05)) +
+    titheme() +
+    ggplot2::theme(
+        aspect.ratio = 2.3,
+        legend.position = "inside",
+        legend.position.inside = c(0.98, 0.95),
+        legend.justification = c("right", "top"),
+        legend.title = ggplot2::element_text(hjust = 1)
+    ) +
+    ggplot2::guides(
+        color = ggplot2::guide_legend(
+            title = "Class",
+            label.position = "left",
+            label.hjust = 1
+        )
+    )

# time: 2024-09-19 15:16:55 UTC
# mode: r
+# Save the plot
+ggplot2::ggsave(file.path(config$path$figures, "oob_plot.jpg"),
+    plot =
+        oobplot,
+    width = 8,
+    height = 6
+)

# time: 2024-09-19 15:17:26 UTC
# mode: r
+# Create the plot
+oobplot <- ggplot2::ggplot() +
+    ggplot2::geom_line(data = plot_data$oob_df, ggplot2::aes(
+        x = trees, y = error, color = class
+    ), alpha = 0.1) +
+    ggplot2::geom_line(data = plot_data$random_oob_df, ggplot2::aes(
+        x = trees, y = error, color = class
+    ), alpha = 0.1, linetype = "dashed") +
+    ggplot2::geom_line(data = plot_data$mean_oob_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class
+    ), linewidth = 1.5) +
+    ggplot2::geom_line(data = plot_data$mean_random_oob_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class
+    ), linewidth = 1.5, linetype = "dashed") +
+    # add line at 50% correct
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "black") +
+    ggplot2::labs(
+        title = "OOB error rate (Solid: Original, Dashed: Randomized)",
+        x = "Number of trees", y = "Percent correct"
+    ) +
+    ggplot2::scale_color_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007", "randomised" = "grey"
+    )) +
+    base_breaks_y(40:100, expand = ggplot2::expansion(mult = .05)) +
+    base_breaks_x(0:500, expand = ggplot2::expansion(mult = .05)) +
+    titheme() +
+    ggplot2::theme(
+        aspect.ratio = 2.3,
+        legend.position = "inside",
+        legend.position.inside = c(0.98, 0.95),
+        legend.justification = c("right", "top"),
+        legend.title = ggplot2::element_text(hjust = 1)
+    ) +
+    ggplot2::guides(
+        color = ggplot2::guide_legend(
+            title = "Class",
+            label.position = "left",
+            label.hjust = 1
+        )
+    )

# time: 2024-09-19 15:17:27 UTC
# mode: r
+# Save the plot
+ggplot2::ggsave(file.path(config$path$figures, "oob_plot.jpg"),
+    plot =
+        oobplot,
+    width = 8,
+    height = 6
+)

# time: 2024-09-19 15:17:44 UTC
# mode: r
+# Create the plot
+oobplot <- ggplot2::ggplot() +
+    ggplot2::geom_line(data = plot_data$oob_df, ggplot2::aes(
+        x = trees, y = error, color = class
+    ), alpha = 0.1) +
+    ggplot2::geom_line(data = plot_data$random_oob_df, ggplot2::aes(
+        x = trees, y = error, color = class
+    ), alpha = 0.1, linetype = "dashed") +
+    ggplot2::geom_line(data = plot_data$mean_oob_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class
+    ), linewidth = 1.5) +
+    ggplot2::geom_line(data = plot_data$mean_random_oob_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class
+    ), linewidth = 1.5, linetype = "dashed") +
+    # add line at 50% correct
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "black") +
+    ggplot2::labs(
+        title = "OOB error rate (Solid: Original, Dashed: Randomized)",
+        x = "Number of trees", y = "Percent correct"
+    ) +
+    ggplot2::scale_color_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007", "randomised" = "grey"
+    )) +
+    base_breaks_y(40:100, expand = ggplot2::expansion(mult = .05)) +
+    base_breaks_x(0:500, expand = ggplot2::expansion(mult = .05)) +
+    titheme() +
+    ggplot2::theme(
+        aspect.ratio = 2,
+        legend.position = "inside",
+        legend.position.inside = c(0.98, 0.95),
+        legend.justification = c("right", "top"),
+        legend.title = ggplot2::element_text(hjust = 1)
+    ) +
+    ggplot2::guides(
+        color = ggplot2::guide_legend(
+            title = "Class",
+            label.position = "left",
+            label.hjust = 1
+        )
+    )

# time: 2024-09-19 15:17:44 UTC
# mode: r
+# Save the plot
+ggplot2::ggsave(file.path(config$path$figures, "oob_plot.jpg"),
+    plot =
+        oobplot,
+    width = 8,
+    height = 6
+)

# time: 2024-09-19 15:17:49 UTC
# mode: r
+# Create the plot
+oobplot <- ggplot2::ggplot() +
+    ggplot2::geom_line(data = plot_data$oob_df, ggplot2::aes(
+        x = trees, y = error, color = class
+    ), alpha = 0.1) +
+    ggplot2::geom_line(data = plot_data$random_oob_df, ggplot2::aes(
+        x = trees, y = error, color = class
+    ), alpha = 0.1, linetype = "dashed") +
+    ggplot2::geom_line(data = plot_data$mean_oob_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class
+    ), linewidth = 1.5) +
+    ggplot2::geom_line(data = plot_data$mean_random_oob_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class
+    ), linewidth = 1.5, linetype = "dashed") +
+    # add line at 50% correct
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "black") +
+    ggplot2::labs(
+        title = "OOB error rate (Solid: Original, Dashed: Randomized)",
+        x = "Number of trees", y = "Percent correct"
+    ) +
+    ggplot2::scale_color_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007", "randomised" = "grey"
+    )) +
+    base_breaks_y(40:100, expand = ggplot2::expansion(mult = .05)) +
+    base_breaks_x(0:500, expand = ggplot2::expansion(mult = .05)) +
+    titheme() +
+    ggplot2::theme(
+        aspect.ratio = 1,8,
+        legend.position = "inside",
+        legend.position.inside = c(0.98, 0.95),
+        legend.justification = c("right", "top"),
+        legend.title = ggplot2::element_text(hjust = 1)
+    ) +
+    ggplot2::guides(
+        color = ggplot2::guide_legend(
+            title = "Class",
+            label.position = "left",
+            label.hjust = 1
+        )
+    )

# time: 2024-09-19 15:17:49 UTC
# mode: r
+# Save the plot
+ggplot2::ggsave(file.path(config$path$figures, "oob_plot.jpg"),
+    plot =
+        oobplot,
+    width = 8,
+    height = 6
+)

# time: 2024-09-19 15:17:56 UTC
# mode: r
+# Create the plot
+oobplot <- ggplot2::ggplot() +
+    ggplot2::geom_line(data = plot_data$oob_df, ggplot2::aes(
+        x = trees, y = error, color = class
+    ), alpha = 0.1) +
+    ggplot2::geom_line(data = plot_data$random_oob_df, ggplot2::aes(
+        x = trees, y = error, color = class
+    ), alpha = 0.1, linetype = "dashed") +
+    ggplot2::geom_line(data = plot_data$mean_oob_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class
+    ), linewidth = 1.5) +
+    ggplot2::geom_line(data = plot_data$mean_random_oob_df, ggplot2::aes(
+        x = trees, y = mean_error, color = class
+    ), linewidth = 1.5, linetype = "dashed") +
+    # add line at 50% correct
+    ggplot2::geom_hline(yintercept = 50, linetype = "dotted", color = "black") +
+    ggplot2::labs(
+        title = "OOB error rate (Solid: Original, Dashed: Randomized)",
+        x = "Number of trees", y = "Percent correct"
+    ) +
+    ggplot2::scale_color_manual(values = c(
+        "immigrant" = "#5d8566", "resident" = "#c29007", "randomised" = "grey"
+    )) +
+    base_breaks_y(40:100, expand = ggplot2::expansion(mult = .05)) +
+    base_breaks_x(0:500, expand = ggplot2::expansion(mult = .05)) +
+    titheme() +
+    ggplot2::theme(
+        aspect.ratio = 1.8,
+        legend.position = "inside",
+        legend.position.inside = c(0.98, 0.95),
+        legend.justification = c("right", "top"),
+        legend.title = ggplot2::element_text(hjust = 1)
+    ) +
+    ggplot2::guides(
+        color = ggplot2::guide_legend(
+            title = "Class",
+            label.position = "left",
+            label.hjust = 1
+        )
+    )

# time: 2024-09-19 15:17:57 UTC
# mode: r
+# Save the plot
+ggplot2::ggsave(file.path(config$path$figures, "oob_plot.jpg"),
+    plot =
+        oobplot,
+    width = 8,
+    height = 6
+)

# time: 2024-09-19 15:19:08 UTC
# mode: r
+# Create the plot
+oobplot <- ggplot2::ggplot() +
+    ggplot2::geom_line(
+        data = plot_data$oob_df,
+        ggplot2::aes(x = trees, y = error, color = class),
+        alpha = 0.1
+    ) +
+    ggplot2::geom_line(
+        data = plot_data$random_oob_df,
+        ggplot2::aes(x = trees, y = error, color = class),
+        alpha = 0.1,
+        linetype = "dashed"
+    ) +
+    ggplot2::geom_line(
+        data = plot_data$mean_oob_df,
+        ggplot2::aes(x = trees, y = mean_error, color = class),
+        linewidth = 1.5
+    ) +
+    ggplot2::geom_line(
+        data = plot_data$mean_random_oob_df,
+        ggplot2::aes(x = trees, y = mean_error, color = class),
+        linewidth = 1.5,
+        linetype = "dashed"
+    ) +
+    ggplot2::geom_hline(
+        yintercept = 50,
+        linetype = "dotted",
+        color = "black"
+    ) +
+    ggplot2::labs(
+        title = "OOB error rate (Solid: Original, Dashed: Randomized)",
+        x = "Number of trees",
+        y = "Percent correct"
+    ) +
+    ggplot2::scale_color_manual(
+        values = c(
+            "immigrant" = "#5d8566",
+            "resident" = "#c29007",
+            "randomised" = "grey"
+        )
+    ) +
+    base_breaks_y(
+        40:100,
+        expand = ggplot2::expansion(mult = .05)
+    ) +
+    base_breaks_x(
+        0:500,
+        expand = ggplot2::expansion(mult = .05)
+    ) +
+    titheme() +
+    ggplot2::theme(
+        aspect.ratio = 1.8,
+        legend.position = "inside",
+        legend.position.inside = c(0.98, 0.95),
+        legend.justification = c("right", "top"),
+        legend.title = ggplot2::element_text(hjust = 1)
+    ) +
+    ggplot2::guides(
+        color = ggplot2::guide_legend(
+            title = "Class",
+            label.position = "left",
+            label.hjust = 1
+        )
+    )

# time: 2024-09-19 15:19:09 UTC
# mode: r
+# Save the plot
+ggplot2::ggsave(file.path(config$path$figures, "oob_plot.jpg"),
+    plot =
+        oobplot,
+    width = 8,
+    height = 6
+)

# time: 2024-09-19 15:20:32 UTC
# mode: r
+plot_data

# time: 2024-09-19 15:21:35 UTC
# mode: r
+# at each tree, average the values for each class (only for the randomised model)
+plot_data$random_oob_df <- plot_data$random_oob_df |>
+    dplyr::group_by(trees) |>
+    dplyr::summarise(mean_error = mean(mean_error), .groups = "drop")

# time: 2024-09-19 15:22:19 UTC
# mode: r
+# Create the plot data
+plot_data <- list(
+    oob_df = results$oob_df |>
+        dplyr::filter(class != "OOB"),
+    random_oob_df = results$random_oob_df |>
+        dplyr::filter(class != "OOB"),
+    mean_oob_df = mean_oob_df,
+    mean_random_oob_df = mean_random_oob_df
+)

# time: 2024-09-19 15:22:20 UTC
# mode: r
+# at each tree, average the values for each class (only for the randomised model)
+plot_data$random_oob_df <- plot_data$random_oob_df |>
+    dplyr::group_by(trees) |>
+    dplyr::summarise(error = mean(error), .groups = "drop")

# time: 2024-09-19 15:22:20 UTC
# mode: r
+plot_data$mean_random_oob_df <- plot_data$mean_random_oob_df |>
+    dplyr::group_by(trees) |>
+    dplyr::summarise(mean_error = mean(mean_error), .groups = "drop")

# time: 2024-09-19 15:23:01 UTC
# mode: r
+# Create the plot
+oobplot <- ggplot2::ggplot() +
+    ggplot2::geom_line(
+        data = plot_data$random_oob_df,
+        ggplot2::aes(x = trees, y = error),
+        alpha = 0.1,
+        linetype = "dashed"
+    ) +
+    ggplot2::geom_line(
+        data = plot_data$mean_random_oob_df,
+        ggplot2::aes(x = trees, y = mean_error),
+        linewidth = 1.5,
+        linetype = "dashed"
+    ) +
+    ggplot2::geom_line(
+        data = plot_data$oob_df,
+        ggplot2::aes(x = trees, y = error, color = class),
+        alpha = 0.1
+    ) +
+    ggplot2::geom_line(
+        data = plot_data$mean_oob_df,
+        ggplot2::aes(x = trees, y = mean_error, color = class),
+        linewidth = 1.5
+    ) +
+    ggplot2::geom_hline(
+        yintercept = 50,
+        linetype = "dotted",
+        color = "black"
+    ) +
+    ggplot2::labs(
+        title = "OOB error rate (Solid: Original, Dashed: Randomized)",
+        x = "Number of trees",
+        y = "Percent correct"
+    ) +
+    ggplot2::scale_color_manual(
+        values = c(
+            "immigrant" = "#5d8566",
+            "resident" = "#c29007",
+            "randomised" = "grey"
+        )
+    ) +
+    base_breaks_y(40:100, expand = ggplot2::expansion(mult = .05)) +
+    base_breaks_x(0:500, expand = ggplot2::expansion(mult = .05)) +
+    titheme() +
+    ggplot2::theme(
+        aspect.ratio = 1.8,
+        legend.position = "inside",
+        legend.position.inside = c(0.98, 0.95),
+        legend.justification = c("right", "top"),
+        legend.title = ggplot2::element_text(hjust = 1)
+    ) +
+    ggplot2::guides(
+        color = ggplot2::guide_legend(
+            title = "Class",
+            label.position = "left",
+            label.hjust = 1
+        )
+    )

# time: 2024-09-19 15:23:02 UTC
# mode: r
+# Save the plot
+ggplot2::ggsave(file.path(config$path$figures, "oob_plot.jpg"),
+    plot =
+        oobplot,
+    width = 8,
+    height = 6
+)

# time: 2024-09-19 15:23:28 UTC
# mode: r
+plot_data$random_oob_df

# time: 2024-09-19 15:24:23 UTC
# mode: r
+# Create the plot
+oobplot <- ggplot2::ggplot() +
+    ggplot2::geom_line(
+        data = plot_data$random_oob_df,
+        ggplot2::aes(x = trees, y = error),
+        alpha = 0.1,
+        linetype = "dashed", 
+        color = "randomised"
+    ) +
+    ggplot2::geom_line(
+        data = plot_data$mean_random_oob_df,
+        ggplot2::aes(x = trees, y = mean_error),
+        linewidth = 1.5,
+        linetype = "dashed"
+    ) +
+    ggplot2::geom_line(
+        data = plot_data$oob_df,
+        ggplot2::aes(x = trees, y = error, color = class),
+        alpha = 0.1
+    ) +
+    ggplot2::geom_line(
+        data = plot_data$mean_oob_df,
+        ggplot2::aes(x = trees, y = mean_error, color = class),
+        linewidth = 1.5
+    ) +
+    ggplot2::geom_hline(
+        yintercept = 50,
+        linetype = "dotted",
+        color = "black"
+    ) +
+    ggplot2::labs(
+        title = "OOB error rate (Solid: Original, Dashed: Randomized)",
+        x = "Number of trees",
+        y = "Percent correct"
+    ) +
+    ggplot2::scale_color_manual(
+        values = c(
+            "immigrant" = "#5d8566",
+            "resident" = "#c29007",
+            "randomised" = "grey"
+        )
+    ) +
+    base_breaks_y(40:100, expand = ggplot2::expansion(mult = .05)) +
+    base_breaks_x(0:500, expand = ggplot2::expansion(mult = .05)) +
+    titheme() +
+    ggplot2::theme(
+        aspect.ratio = 1.8,
+        legend.position = "inside",
+        legend.position.inside = c(0.98, 0.95),
+        legend.justification = c("right", "top"),
+        legend.title = ggplot2::element_text(hjust = 1)
+    ) +
+    ggplot2::guides(
+        color = ggplot2::guide_legend(
+            title = "Class",
+            label.position = "left",
+            label.hjust = 1
+        )
+    )

# time: 2024-09-19 15:24:23 UTC
# mode: r
+# Save the plot
+ggplot2::ggsave(file.path(config$path$figures, "oob_plot.jpg"),
+    plot =
+        oobplot,
+    width = 8,
+    height = 6
+)

# time: 2024-09-19 15:24:54 UTC
# mode: r
+# Create the plot
+oobplot <- ggplot2::ggplot() +
+    ggplot2::geom_line(
+        data = plot_data$random_oob_df,
+        ggplot2::aes(x = trees, y = error, color = "randomised"),
+        alpha = 0.1,
+        linetype = "dashed"
+    ) +
+    ggplot2::geom_line(
+        data = plot_data$mean_random_oob_df,
+        ggplot2::aes(x = trees, y = mean_error),
+        linewidth = 1.5,
+        linetype = "dashed"
+    ) +
+    ggplot2::geom_line(
+        data = plot_data$oob_df,
+        ggplot2::aes(x = trees, y = error, color = class),
+        alpha = 0.1
+    ) +
+    ggplot2::geom_line(
+        data = plot_data$mean_oob_df,
+        ggplot2::aes(x = trees, y = mean_error, color = class),
+        linewidth = 1.5
+    ) +
+    ggplot2::geom_hline(
+        yintercept = 50,
+        linetype = "dotted",
+        color = "black"
+    ) +
+    ggplot2::labs(
+        title = "OOB error rate (Solid: Original, Dashed: Randomized)",
+        x = "Number of trees",
+        y = "Percent correct"
+    ) +
+    ggplot2::scale_color_manual(
+        values = c(
+            "immigrant" = "#5d8566",
+            "resident" = "#c29007",
+            "randomised" = "grey"
+        )
+    ) +
+    base_breaks_y(40:100, expand = ggplot2::expansion(mult = .05)) +
+    base_breaks_x(0:500, expand = ggplot2::expansion(mult = .05)) +
+    titheme() +
+    ggplot2::theme(
+        aspect.ratio = 1.8,
+        legend.position = "inside",
+        legend.position.inside = c(0.98, 0.95),
+        legend.justification = c("right", "top"),
+        legend.title = ggplot2::element_text(hjust = 1)
+    ) +
+    ggplot2::guides(
+        color = ggplot2::guide_legend(
+            title = "Class",
+            label.position = "left",
+            label.hjust = 1
+        )
+    )

# time: 2024-09-19 15:24:55 UTC
# mode: r
+# Save the plot
+ggplot2::ggsave(file.path(config$path$figures, "oob_plot.jpg"),
+    plot =
+        oobplot,
+    width = 8,
+    height = 6
+)

# time: 2024-09-19 15:25:05 UTC
# mode: r
+# Create the plot
+oobplot <- ggplot2::ggplot() +
+    ggplot2::geom_line(
+        data = plot_data$random_oob_df,
+        ggplot2::aes(x = trees, y = error, color = "randomised"),
+        alpha = 0.1,
+        linetype = "dashed"
+    ) +
+    ggplot2::geom_line(
+        data = plot_data$mean_random_oob_df,
+        ggplot2::aes(x = trees, y = mean_error),
+        linewidth = 1.5,
+        linetype = "dashed"
+    ) +
+    ggplot2::geom_line(
+        data = plot_data$oob_df,
+        ggplot2::aes(x = trees, y = error, color = class),
+        alpha = 0.1
+    ) +
+    ggplot2::geom_line(
+        data = plot_data$mean_oob_df,
+        ggplot2::aes(x = trees, y = mean_error, color = class),
+        linewidth = 1.5
+    ) +
+    ggplot2::geom_hline(
+        yintercept = 50,
+        linetype = "dotted",
+        color = "black"
+    ) +
+    ggplot2::labs(
+        title = "OOB error rate (Solid: Original, Dashed: Randomized)",
+        x = "Number of trees",
+        y = "Percent correct"
+    ) +
+    ggplot2::scale_color_manual(
+        values = c(
+            "immigrant" = "#5d8566",
+            "resident" = "#c29007",
+            "randomised" = "#9c3131"
+        )
+    ) +
+    base_breaks_y(40:100, expand = ggplot2::expansion(mult = .05)) +
+    base_breaks_x(0:500, expand = ggplot2::expansion(mult = .05)) +
+    titheme() +
+    ggplot2::theme(
+        aspect.ratio = 1.8,
+        legend.position = "inside",
+        legend.position.inside = c(0.98, 0.95),
+        legend.justification = c("right", "top"),
+        legend.title = ggplot2::element_text(hjust = 1)
+    ) +
+    ggplot2::guides(
+        color = ggplot2::guide_legend(
+            title = "Class",
+            label.position = "left",
+            label.hjust = 1
+        )
+    )

# time: 2024-09-19 15:25:05 UTC
# mode: r
+# Save the plot
+ggplot2::ggsave(file.path(config$path$figures, "oob_plot.jpg"),
+    plot =
+        oobplot,
+    width = 8,
+    height = 6
+)

# time: 2024-09-19 15:25:58 UTC
# mode: r
+# Create the plot
+oobplot <- ggplot2::ggplot() +
+    ggplot2::geom_line(
+        data = plot_data$random_oob_df,
+        ggplot2::aes(x = trees, y = error, color = "randomised"),
+        alpha = 0.7,
+        linetype = "dashed"
+    ) +
+    ggplot2::geom_line(
+        data = plot_data$mean_random_oob_df,
+        ggplot2::aes(x = trees, y = mean_error),
+        linewidth = 1.5,
+        linetype = "dashed"
+    ) +
+    ggplot2::geom_line(
+        data = plot_data$oob_df,
+        ggplot2::aes(x = trees, y = error, color = class),
+        alpha = 0.1
+    ) +
+    ggplot2::geom_line(
+        data = plot_data$mean_oob_df,
+        ggplot2::aes(x = trees, y = mean_error, color = class),
+        linewidth = 1.5
+    ) +
+    ggplot2::geom_hline(
+        yintercept = 50,
+        linetype = "dotted",
+        color = "black"
+    ) +
+    ggplot2::labs(
+        title = "OOB error rate (Solid: Original, Dashed: Randomized)",
+        x = "Number of trees",
+        y = "Percent correct"
+    ) +
+    ggplot2::scale_color_manual(
+        values = c(
+            "immigrant" = "#5d8566",
+            "resident" = "#c29007",
+            "randomised" = "#9c3131"
+        )
+    ) +
+    base_breaks_y(40:100, expand = ggplot2::expansion(mult = .05)) +
+    base_breaks_x(0:500, expand = ggplot2::expansion(mult = .05)) +
+    titheme() +
+    ggplot2::theme(
+        aspect.ratio = 1.8,
+        legend.position = "inside",
+        legend.position.inside = c(0.98, 0.95),
+        legend.justification = c("right", "top"),
+        legend.title = ggplot2::element_text(hjust = 1)
+    ) +
+    ggplot2::guides(
+        color = ggplot2::guide_legend(
+            title = "Class",
+            label.position = "left",
+            label.hjust = 1
+        )
+    )

# time: 2024-09-19 15:25:58 UTC
# mode: r
+# Save the plot
+ggplot2::ggsave(file.path(config$path$figures, "oob_plot.jpg"),
+    plot =
+        oobplot,
+    width = 8,
+    height = 6
+)

# time: 2024-09-19 15:26:16 UTC
# mode: r
+# Create the plot data
+plot_data <- list(
+    oob_df = results$oob_df |>
+        dplyr::filter(class != "OOB"),
+    random_oob_df = results$random_oob_df |>
+        dplyr::filter(class != "OOB"),
+    mean_oob_df = mean_oob_df,
+    mean_random_oob_df = mean_random_oob_df
+)

# time: 2024-09-19 15:26:23 UTC
# mode: r
+plot_data$random_oob_df |>
+    dplyr::group_by(trees)

# time: 2024-09-19 15:26:48 UTC
# mode: r
+# at each tree, average the values for each class (only for the randomised model)
+plot_data$random_oob_df <- plot_data$random_oob_df |>
+    dplyr::group_by(trees, class) |>
+    dplyr::summarise(error = mean(error), .groups = "drop")

# time: 2024-09-19 15:26:49 UTC
# mode: r
+plot_data$mean_random_oob_df <- plot_data$mean_random_oob_df |>
+    dplyr::group_by(trees) |>
+    dplyr::summarise(mean_error = mean(mean_error), .groups = "drop")

# time: 2024-09-19 15:26:50 UTC
# mode: r
+# Create the plot
+oobplot <- ggplot2::ggplot() +
+    ggplot2::geom_line(
+        data = plot_data$random_oob_df,
+        ggplot2::aes(x = trees, y = error, color = "randomised"),
+        alpha = 0.7,
+        linetype = "dashed"
+    ) +
+    ggplot2::geom_line(
+        data = plot_data$mean_random_oob_df,
+        ggplot2::aes(x = trees, y = mean_error),
+        linewidth = 1.5,
+        linetype = "dashed"
+    ) +
+    ggplot2::geom_line(
+        data = plot_data$oob_df,
+        ggplot2::aes(x = trees, y = error, color = class),
+        alpha = 0.1
+    ) +
+    ggplot2::geom_line(
+        data = plot_data$mean_oob_df,
+        ggplot2::aes(x = trees, y = mean_error, color = class),
+        linewidth = 1.5
+    ) +
+    ggplot2::geom_hline(
+        yintercept = 50,
+        linetype = "dotted",
+        color = "black"
+    ) +
+    ggplot2::labs(
+        title = "OOB error rate (Solid: Original, Dashed: Randomized)",
+        x = "Number of trees",
+        y = "Percent correct"
+    ) +
+    ggplot2::scale_color_manual(
+        values = c(
+            "immigrant" = "#5d8566",
+            "resident" = "#c29007",
+            "randomised" = "#9c3131"
+        )
+    ) +
+    base_breaks_y(40:100, expand = ggplot2::expansion(mult = .05)) +
+    base_breaks_x(0:500, expand = ggplot2::expansion(mult = .05)) +
+    titheme() +
+    ggplot2::theme(
+        aspect.ratio = 1.8,
+        legend.position = "inside",
+        legend.position.inside = c(0.98, 0.95),
+        legend.justification = c("right", "top"),
+        legend.title = ggplot2::element_text(hjust = 1)
+    ) +
+    ggplot2::guides(
+        color = ggplot2::guide_legend(
+            title = "Class",
+            label.position = "left",
+            label.hjust = 1
+        )
+    )

# time: 2024-09-19 15:26:50 UTC
# mode: r
+# Save the plot
+ggplot2::ggsave(file.path(config$path$figures, "oob_plot.jpg"),
+    plot =
+        oobplot,
+    width = 8,
+    height = 6
+)

# time: 2024-09-19 15:27:39 UTC
# mode: r
+# Create the plot data
+plot_data <- list(
+    oob_df = results$oob_df |>
+        dplyr::filter(class != "OOB"),
+    random_oob_df = results$random_oob_df |>
+        dplyr::filter(class != "OOB"),
+    mean_oob_df = mean_oob_df,
+    mean_random_oob_df = mean_random_oob_df
+)

# time: 2024-09-19 15:27:40 UTC
# mode: r
+# Create the plot
+oobplot <- ggplot2::ggplot() +
+    ggplot2::geom_line(
+        data = plot_data$random_oob_df,
+        ggplot2::aes(x = trees, y = error, color = "randomised"),
+        alpha = 0.7,
+        linetype = "dashed"
+    ) +
+    ggplot2::geom_line(
+        data = plot_data$mean_random_oob_df,
+        ggplot2::aes(x = trees, y = mean_error),
+        linewidth = 1.5,
+        linetype = "dashed"
+    ) +
+    ggplot2::geom_line(
+        data = plot_data$oob_df,
+        ggplot2::aes(x = trees, y = error, color = class),
+        alpha = 0.1
+    ) +
+    ggplot2::geom_line(
+        data = plot_data$mean_oob_df,
+        ggplot2::aes(x = trees, y = mean_error, color = class),
+        linewidth = 1.5
+    ) +
+    ggplot2::geom_hline(
+        yintercept = 50,
+        linetype = "dotted",
+        color = "black"
+    ) +
+    ggplot2::labs(
+        title = "OOB error rate (Solid: Original, Dashed: Randomized)",
+        x = "Number of trees",
+        y = "Percent correct"
+    ) +
+    ggplot2::scale_color_manual(
+        values = c(
+            "immigrant" = "#5d8566",
+            "resident" = "#c29007",
+            "randomised" = "#9c3131"
+        )
+    ) +
+    base_breaks_y(40:100, expand = ggplot2::expansion(mult = .05)) +
+    base_breaks_x(0:500, expand = ggplot2::expansion(mult = .05)) +
+    titheme() +
+    ggplot2::theme(
+        aspect.ratio = 1.8,
+        legend.position = "inside",
+        legend.position.inside = c(0.98, 0.95),
+        legend.justification = c("right", "top"),
+        legend.title = ggplot2::element_text(hjust = 1)
+    ) +
+    ggplot2::guides(
+        color = ggplot2::guide_legend(
+            title = "Class",
+            label.position = "left",
+            label.hjust = 1
+        )
+    )

# time: 2024-09-19 15:27:40 UTC
# mode: r
+# Save the plot
+ggplot2::ggsave(file.path(config$path$figures, "oob_plot.jpg"),
+    plot =
+        oobplot,
+    width = 8,
+    height = 6
+)

# time: 2024-09-19 15:28:18 UTC
# mode: r
+# Create the plot data
+plot_data <- list(
+    oob_df = results$oob_df |>
+        dplyr::filter(class != "OOB"),
+    random_oob_df = results$random_oob_df |>
+        dplyr::filter(class != "OOB"),
+    mean_oob_df = mean_oob_df,
+    mean_random_oob_df = mean_random_oob_df
+)

# time: 2024-09-19 15:28:19 UTC
# mode: r
+# Create the plot
+oobplot <- ggplot2::ggplot() +
+    ggplot2::geom_line(
+        data = plot_data$random_oob_df,
+        ggplot2::aes(x = trees, y = error, color = "randomised"),
+        alpha = 0.1,
+        linetype = "dashed"
+    ) +
+    ggplot2::geom_line(
+        data = plot_data$mean_random_oob_df,
+        ggplot2::aes(x = trees, y = mean_error),
+        linewidth = 1.5,
+        linetype = "dashed"
+    ) +
+    ggplot2::geom_line(
+        data = plot_data$oob_df,
+        ggplot2::aes(x = trees, y = error, color = class),
+        alpha = 0.1
+    ) +
+    ggplot2::geom_line(
+        data = plot_data$mean_oob_df,
+        ggplot2::aes(x = trees, y = mean_error, color = class),
+        linewidth = 1.5
+    ) +
+    ggplot2::geom_hline(
+        yintercept = 50,
+        linetype = "dotted",
+        color = "black"
+    ) +
+    ggplot2::labs(
+        title = "OOB error rate (Solid: Original, Dashed: Randomized)",
+        x = "Number of trees",
+        y = "Percent correct"
+    ) +
+    ggplot2::scale_color_manual(
+        values = c(
+            "immigrant" = "#5d8566",
+            "resident" = "#c29007",
+            "randomised" = "#9c3131"
+        )
+    ) +
+    base_breaks_y(40:100, expand = ggplot2::expansion(mult = .05)) +
+    base_breaks_x(0:500, expand = ggplot2::expansion(mult = .05)) +
+    titheme() +
+    ggplot2::theme(
+        aspect.ratio = 1.8,
+        legend.position = "inside",
+        legend.position.inside = c(0.98, 0.95),
+        legend.justification = c("right", "top"),
+        legend.title = ggplot2::element_text(hjust = 1)
+    ) +
+    ggplot2::guides(
+        color = ggplot2::guide_legend(
+            title = "Class",
+            label.position = "left",
+            label.hjust = 1
+        )
+    )

# time: 2024-09-19 15:28:26 UTC
# mode: r
+# Create the plot
+oobplot <- ggplot2::ggplot() +
+    ggplot2::geom_line(
+        data = plot_data$random_oob_df,
+        ggplot2::aes(x = trees, y = error, color = "randomised"),
+        alpha = 0.1,
+        linetype = "dashed"
+    ) +
+    ggplot2::geom_line(
+        data = plot_data$mean_random_oob_df,
+        ggplot2::aes(x = trees, y = mean_error),
+        linewidth = 1.5,
+        linetype = "dashed"
+    ) +
+    ggplot2::geom_line(
+        data = plot_data$oob_df,
+        ggplot2::aes(x = trees, y = error, color = class),
+        alpha = 0.1
+    ) +
+    ggplot2::geom_line(
+        data = plot_data$mean_oob_df,
+        ggplot2::aes(x = trees, y = mean_error, color = class),
+        linewidth = 1.5
+    ) +
+    ggplot2::geom_hline(
+        yintercept = 50,
+        linetype = "dotted",
+        color = "black"
+    ) +
+    ggplot2::labs(
+        title = "OOB error rate (Solid: Original, Dashed: Randomized)",
+        x = "Number of trees",
+        y = "Percent correct"
+    ) +
+    ggplot2::scale_color_manual(
+        values = c(
+            "immigrant" = "#5d8566",
+            "resident" = "#c29007",
+            "randomised" = "#919191"
+        )
+    ) +
+    base_breaks_y(40:100, expand = ggplot2::expansion(mult = .05)) +
+    base_breaks_x(0:500, expand = ggplot2::expansion(mult = .05)) +
+    titheme() +
+    ggplot2::theme(
+        aspect.ratio = 1.8,
+        legend.position = "inside",
+        legend.position.inside = c(0.98, 0.95),
+        legend.justification = c("right", "top"),
+        legend.title = ggplot2::element_text(hjust = 1)
+    ) +
+    ggplot2::guides(
+        color = ggplot2::guide_legend(
+            title = "Class",
+            label.position = "left",
+            label.hjust = 1
+        )
+    )

# time: 2024-09-19 15:28:26 UTC
# mode: r
+# Save the plot
+ggplot2::ggsave(file.path(config$path$figures, "oob_plot.jpg"),
+    plot =
+        oobplot,
+    width = 8,
+    height = 6
+)

# time: 2024-09-19 15:28:35 UTC
# mode: r
+plot_data

# time: 2024-09-19 15:28:59 UTC
# mode: r
+# Create the plot data
+plot_data <- list(
+    oob_df = results$oob_df |>
+        dplyr::filter(class != "OOB"),
+    random_oob_df = results$random_oob_df |>
+        dplyr::filter(class != "OOB"),
+    mean_oob_df = mean_oob_df,
+    mean_random_oob_df = mean_random_oob_df |> dplyr::group_by(trees) |>
+        dplyr::summarise(mean_error = mean(mean_error), .groups = "drop")
+)

# time: 2024-09-19 15:29:00 UTC
# mode: r
+# Create the plot
+oobplot <- ggplot2::ggplot() +
+    ggplot2::geom_line(
+        data = plot_data$random_oob_df,
+        ggplot2::aes(x = trees, y = error, color = "randomised"),
+        alpha = 0.1,
+        linetype = "dashed"
+    ) +
+    ggplot2::geom_line(
+        data = plot_data$mean_random_oob_df,
+        ggplot2::aes(x = trees, y = mean_error),
+        linewidth = 1.5,
+        linetype = "dashed"
+    ) +
+    ggplot2::geom_line(
+        data = plot_data$oob_df,
+        ggplot2::aes(x = trees, y = error, color = class),
+        alpha = 0.1
+    ) +
+    ggplot2::geom_line(
+        data = plot_data$mean_oob_df,
+        ggplot2::aes(x = trees, y = mean_error, color = class),
+        linewidth = 1.5
+    ) +
+    ggplot2::geom_hline(
+        yintercept = 50,
+        linetype = "dotted",
+        color = "black"
+    ) +
+    ggplot2::labs(
+        title = "OOB error rate (Solid: Original, Dashed: Randomized)",
+        x = "Number of trees",
+        y = "Percent correct"
+    ) +
+    ggplot2::scale_color_manual(
+        values = c(
+            "immigrant" = "#5d8566",
+            "resident" = "#c29007",
+            "randomised" = "#919191"
+        )
+    ) +
+    base_breaks_y(40:100, expand = ggplot2::expansion(mult = .05)) +
+    base_breaks_x(0:500, expand = ggplot2::expansion(mult = .05)) +
+    titheme() +
+    ggplot2::theme(
+        aspect.ratio = 1.8,
+        legend.position = "inside",
+        legend.position.inside = c(0.98, 0.95),
+        legend.justification = c("right", "top"),
+        legend.title = ggplot2::element_text(hjust = 1)
+    ) +
+    ggplot2::guides(
+        color = ggplot2::guide_legend(
+            title = "Class",
+            label.position = "left",
+            label.hjust = 1
+        )
+    )

# time: 2024-09-19 15:29:01 UTC
# mode: r
+# Save the plot
+ggplot2::ggsave(file.path(config$path$figures, "oob_plot.jpg"),
+    plot =
+        oobplot,
+    width = 8,
+    height = 6
+)

# time: 2024-09-19 15:29:26 UTC
# mode: r
+# Create the plot
+oobplot <- ggplot2::ggplot() +
+    ggplot2::geom_line(
+        data = plot_data$random_oob_df,
+        ggplot2::aes(x = trees, y = error, color = "randomised"),
+        alpha = 0.1,
+        linetype = "dashed"
+    ) +
+    ggplot2::geom_line(
+        data = plot_data$mean_random_oob_df,
+        ggplot2::aes(x = trees, y = mean_error),
+        linewidth = 1.5,
+        linetype = "dashed"
+    ) +
+    ggplot2::geom_line(
+        data = plot_data$oob_df,
+        ggplot2::aes(x = trees, y = error, color = class),
+        alpha = 0.1
+    ) +
+    ggplot2::geom_line(
+        data = plot_data$mean_oob_df,
+        ggplot2::aes(x = trees, y = mean_error, color = class),
+        linewidth = 1.5
+    ) +
+    ggplot2::geom_hline(
+        yintercept = 50,
+        linetype = "dotted",
+        color = "black"
+    ) +
+    ggplot2::labs(
+        title = "OOB error rate (Solid: Original, Dashed: Randomized)",
+        x = "Number of trees",
+        y = "Percent correct"
+    ) +
+    ggplot2::scale_color_manual(
+        values = c(
+            "immigrant" = "#5d8566",
+            "resident" = "#c29007",
+            "randomised" = "#919191"
+        )
+    ) +
+    base_breaks_y(40:100, expand = ggplot2::expansion(mult = .05)) +
+    base_breaks_x(0:500, expand = ggplot2::expansion(mult = .05)) +
+    titheme() +
+    ggplot2::theme(
+        aspect.ratio = 1.8,
+        legend.position = "inside",
+        legend.position.inside = c(0.98, 0.95),
+        legend.justification = c("right", "top"),
+        legend.title = ggplot2::element_text(hjust = 1)
+    ) +
+    ggplot2::guides(
+        fill = ggplot2::guide_legend(
+            title = "Class",
+            label.position = "left",
+            label.hjust = 1
+        )
+    )

# time: 2024-09-19 15:29:26 UTC
# mode: r
+# Save the plot
+ggplot2::ggsave(file.path(config$path$figures, "oob_plot.jpg"),
+    plot =
+        oobplot,
+    width = 8,
+    height = 6
+)

# time: 2024-09-19 15:29:55 UTC
# mode: r
+# Create the plot
+oobplot <- ggplot2::ggplot() +
+    ggplot2::geom_line(
+        data = plot_data$random_oob_df,
+        ggplot2::aes(x = trees, y = error, color = "randomised"),
+        alpha = 0.1,
+        linetype = "dashed"
+    ) +
+    ggplot2::geom_line(
+        data = plot_data$mean_random_oob_df,
+        ggplot2::aes(x = trees, y = mean_error, color = "randomised"),
+        linewidth = 1.5,
+        linetype = "dashed"
+    ) +
+    ggplot2::geom_line(
+        data = plot_data$oob_df,
+        ggplot2::aes(x = trees, y = error, color = class),
+        alpha = 0.1
+    ) +
+    ggplot2::geom_line(
+        data = plot_data$mean_oob_df,
+        ggplot2::aes(x = trees, y = mean_error, color = class),
+        linewidth = 1.5
+    ) +
+    ggplot2::geom_hline(
+        yintercept = 50,
+        linetype = "dotted",
+        color = "black"
+    ) +
+    ggplot2::labs(
+        title = "OOB error rate (Solid: Original, Dashed: Randomized)",
+        x = "Number of trees",
+        y = "Percent correct"
+    ) +
+    ggplot2::scale_color_manual(
+        values = c(
+            "immigrant" = "#5d8566",
+            "resident" = "#c29007",
+            "randomised" = "#919191"
+        )
+    ) +
+    base_breaks_y(40:100, expand = ggplot2::expansion(mult = .05)) +
+    base_breaks_x(0:500, expand = ggplot2::expansion(mult = .05)) +
+    titheme() +
+    ggplot2::theme(
+        aspect.ratio = 1.8,
+        legend.position = "inside",
+        legend.position.inside = c(0.98, 0.95),
+        legend.justification = c("right", "top"),
+        legend.title = ggplot2::element_text(hjust = 1)
+    ) +
+    ggplot2::guides(
+        color = ggplot2::guide_legend(
+            title = "Class",
+            label.position = "left",
+            label.hjust = 1
+        )
+    )

# time: 2024-09-19 15:29:56 UTC
# mode: r
+# Save the plot
+ggplot2::ggsave(file.path(config$path$figures, "oob_plot.jpg"),
+    plot =
+        oobplot,
+    width = 8,
+    height = 6
+)

# time: 2024-09-19 15:29:56 UTC
# mode: r
+# get data from tree 100 to tree 500 and plot the distribution of percent correct
+
+
+oob_df <- dplyr::bind_rows(
+    list(
+        oob_df = plot_data$oob_df,
+        random_oob_df = plot_data$random_oob_df
+    ),
+    .id = "source"
+) |>
+    dplyr::filter(trees >= 100 & trees <= 500)

# time: 2024-09-19 15:30:13 UTC
# mode: r
+# Create the plot
+oobplot <- ggplot2::ggplot() +
+    ggplot2::geom_line(
+        data = plot_data$random_oob_df,
+        ggplot2::aes(x = trees, y = error, color = "randomised"),
+        alpha = 0.1
+    ) +
+    ggplot2::geom_line(
+        data = plot_data$mean_random_oob_df,
+        ggplot2::aes(x = trees, y = mean_error, color = "randomised"),
+        linewidth = 1.5
+    ) +
+    ggplot2::geom_line(
+        data = plot_data$oob_df,
+        ggplot2::aes(x = trees, y = error, color = class),
+        alpha = 0.1
+    ) +
+    ggplot2::geom_line(
+        data = plot_data$mean_oob_df,
+        ggplot2::aes(x = trees, y = mean_error, color = class),
+        linewidth = 1.5
+    ) +
+    ggplot2::geom_hline(
+        yintercept = 50,
+        linetype = "dotted",
+        color = "black"
+    ) +
+    ggplot2::labs(
+        title = "OOB error rate (Solid: Original, Dashed: Randomized)",
+        x = "Number of trees",
+        y = "Percent correct"
+    ) +
+    ggplot2::scale_color_manual(
+        values = c(
+            "immigrant" = "#5d8566",
+            "resident" = "#c29007",
+            "randomised" = "#919191"
+        )
+    ) +
+    base_breaks_y(40:100, expand = ggplot2::expansion(mult = .05)) +
+    base_breaks_x(0:500, expand = ggplot2::expansion(mult = .05)) +
+    titheme() +
+    ggplot2::theme(
+        aspect.ratio = 1.8,
+        legend.position = "inside",
+        legend.position.inside = c(0.98, 0.95),
+        legend.justification = c("right", "top"),
+        legend.title = ggplot2::element_text(hjust = 1)
+    ) +
+    ggplot2::guides(
+        color = ggplot2::guide_legend(
+            title = "Class",
+            label.position = "left",
+            label.hjust = 1
+        )
+    )

# time: 2024-09-19 15:30:13 UTC
# mode: r
+# Save the plot
+ggplot2::ggsave(file.path(config$path$figures, "oob_plot.jpg"),
+    plot =
+        oobplot,
+    width = 8,
+    height = 6
+)

# time: 2024-09-19 15:31:41 UTC
# mode: r
+# from the proximity matrix, calculate the distance between each point and the centroid of the resident class
+
+# calculate the centroid of the resident class
+resident_centroid <- mds_df |>
+    dplyr::filter(class == "resident") |>
+    dplyr::summarise(across(c(X1, X2), mean)) |>
+    dplyr::pull()

# time: 2024-09-19 15:31:47 UTC
# mode: r
+resident_centroid

# time: 2024-09-19 15:32:25 UTC
# mode: r
+# from the proximity matrix, calculate the distance between each point and the centroid of the resident class
+
+# calculate the centroid of the resident class using the proximity matrix (not the MDS plot)
+centroid <- colMeans(prox[rf$y == "resident", ])

# time: 2024-09-19 15:32:27 UTC
# mode: r
+centroid

# time: 2024-09-19 15:32:41 UTC
# mode: r
+# calculate the distance between each point and the centroid
+distances <- apply(prox, 1, function(x) sum((x - centroid)^2))

# time: 2024-09-19 15:33:16 UTC
# mode: r
+# plot the distribution of distances
+dist_plot <- ggplot2::ggplot() +
+    ggplot2::geom_density(
+        ggplot2::aes(x = distances, fill = rf$y),
+        alpha = 0.5
+    ) +
+    ggplot2::labs(
+        title = "Distribution of distances to resident centroid",
+        x = "Distance", y = "Density"
+    ) +
+    ggplot2::scale_fill_manual(values = 
+        c(" resident" = "#c29007",
+            "immigrant" = "#5d8566")
+    )

# time: 2024-09-19 15:33:18 UTC
# mode: r
+dist_plot
